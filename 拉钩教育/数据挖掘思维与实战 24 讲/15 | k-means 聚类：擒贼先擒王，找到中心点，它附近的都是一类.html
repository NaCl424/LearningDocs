<!DOCTYPE html><html lang="en"><head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>15 | k-means 聚类：擒贼先擒王，找到中心点，它附近的都是一类</title>
<style type="text/css">
:root {
    --control-text-color: #777;
    --select-text-bg-color: rgba(223, 197, 223);  /*#7e66992e;*/
    
    /* side bar */
    --side-bar-bg-color: rgb(255, 255, 255);
    --active-file-text-color: #8163bd;
    --active-file-bg-color: #E9E4F0;
    --item-hover-bg-color: #E9E4F0;
    --active-file-border-color: #8163bd;

    --title-color: #6c549c;
    --font-sans-serif: 'Ubuntu', 'Source Sans Pro', sans-serif !important;
    --font-monospace: 'Fira Code', 'Roboto Mono', monospace !important;
    --purple-1: #8163bd;
    --purple-2: #79589F;
    --purple-3: #fd5eb8;
    --purple-light-1: rgba(99, 99, 172, .05);
    --purple-light-2: rgba(99, 99, 172, .1);
    --purple-light-3: rgba(99, 99, 172, .2);
    --purple-light-4: rgba(129, 99, 189, .3);
    --purple-light-5: #E9E4F0;
    --purple-light-6: rgba(129, 99, 189, .8);
}

/* html {
    font-size: 16px;
} */

body {
    font-family: var(--font-sans-serif);
    color: #34495e;
    -webkit-font-smoothing: antialiased;
    line-height: 1.6rem;
    letter-spacing: 0;
    margin: 0;
    overflow-x: hidden;
}

/* 页边距 和 页面大小 */
#write {
    padding-left: 6ch;
    padding-right: 6ch;
    margin: 0 auto;
}

#write p {
    line-height: 1.6rem;
    word-spacing: .05rem;
}

#write ol li {
    padding-left: 0.5rem;
}

#write > ul:first-child,
#write > ol:first-child {
    margin-top: 30px;
}

body > *:first-child {
    margin-top: 0 !important;
}

body > *:last-child {
    margin-bottom: 0 !important;
}

a {
    color: var(--purple-1);
    padding: 0 2px;
    text-decoration: none;
}
.md-content {
    color: var(--purple-light-6);
}
#write a {
    border-bottom: 1px solid var(--purple-1);
    color: var(--purple-1);
    text-decoration: none;
}

h1,
h2,
h3,
h4,
h5,
h6 {
    position: relative;
    margin-top: 1rem;
    margin-bottom: 0.5rem;
    /* font-weight: bold; */
    font-weight: 500 !important;
    line-height: 1.4;
    cursor: text;
    color: var(--title-color);
    font-family: var(--font-sans-serif);
}

h1:hover a.anchor,
h2:hover a.anchor,
h3:hover a.anchor,
h4:hover a.anchor,
h5:hover a.anchor,
h6:hover a.anchor {
    text-decoration: none;
}

h1 tt,
h1 code {
    font-size: inherit !important;
}
h2 tt,
h2 code {
    font-size: inherit !important;
}
h3 tt,
h3 code {
    font-size: inherit !important;
}
h4 tt,
h4 code {
    font-size: inherit !important;
}
h5 tt,
h5 code {
    font-size: inherit !important;
}
h6 tt,
h6 code {
    font-size: inherit !important;
}


h1 {
    padding-bottom: .4rem;
    font-size: 2.2rem;
    line-height: 1.3;
}
h1 {
    text-align: center;
    padding-bottom: 0.3em;
    font-size: 2.2em;
    line-height: 1.2;
    margin: 2.4em auto 1.2em;
}
h1:after {
    content: '';
    display: block;
    margin: 0.2em auto 0;
    width: 100px;
    height: 2px;
    border-bottom: 2px solid var(--title-color);
}

h2 {
    margin: 1.6em auto 0.5em;
    padding-left: 10px;
    line-height: 1.4;
    font-size: 1.8em;
    border-left: 9px solid var(--title-color);
    border-bottom: 1px solid var(--title-color);
}
h3 {
    font-size: 1.5rem;
    margin: 1.2em auto 0.5em;
}
h4 {
    font-size: 1.3rem;
}
h5 {
    font-size: 1.2rem;
}
h6 {
    font-size: 1.1rem;
}

p,
blockquote,
ul,
ol,
dl,
table {
    margin: 0.8em 0;
}

li > ol,
li > ul {
    margin: 0 0;
}

hr {
    height: 2px;
    padding: 0;
    margin: 16px 0;
    background-color: #e7e7e7;
    border: 0 none;
    overflow: hidden;
    box-sizing: content-box;
}

body > h2:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0;
}

body > h3:first-child,
body > h4:first-child,
body > h5:first-child,
body > h6:first-child {
    margin-top: 0;
    padding-top: 0;
}

a:first-child h1,
a:first-child h2,
a:first-child h3,
a:first-child h4,
a:first-child h5,
a:first-child h6 {
    margin-top: 0;
    padding-top: 0;
}

h1 p,
h2 p,
h3 p,
h4 p,
h5 p,
h6 p {
    margin-top: 0;
}

li p.first {
    display: inline-block;
}

ul,
ol {
    padding-left: 30px;
}

ul:first-child,
ol:first-child {
    margin-top: 0;
}

ul:last-child,
ol:last-child {
    margin-bottom: 0;
}

/* 引用 */
blockquote {
    /* margin-left: 1rem; */
    border-left: 4px solid var(--purple-light-4);
    padding: 10px 15px;
    color: #777;
    background-color: var(--purple-light-1);
}

/* 表格 */
table {
    padding: 0;
    word-break: initial;
}

table tr {
    border-top: 1px solid #dfe2e5;
    margin: 0;
    padding: 0;
}

/* 表格 背景色 */
table tr:nth-child(2n),
thead {
    background-color: var(--purple-light-1);
}
#write table thead th {
    background-color: var(--purple-light-2);
}

table tr th {
    font-weight: bold;
    border: 1px solid #dfe2e5;
    border-bottom: 0;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr td {
    border: 1px solid #dfe2e5;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr th:first-child,
table tr td:first-child {
    margin-top: 0;
}

table tr th:last-child,
table tr td:last-child {
    margin-bottom: 0;
}

/* 粗体 */
#write strong {
    padding: 0 2px;
    color: var(--purple-1);
}

/* 斜体 */
#write em {
    padding: 0 5px 0 2px;
    /* font-style: normal; */
    color: #42b983;
}

/* inline code */
#write code, tt {
    padding: 2px 4px;
    border-radius: 2px;
    font-family: var(--font-monospace);
    font-size: 0.92rem;
    color: var(--purple-3); 
    background-color: rgba(99, 99, 172, .05);
}

tt {
    margin: 0 2px;
}

#write .md-footnote {
    background-color: #f8f8f8;
    color: var(--purple-3);
}

/* heighlight. */
#write mark {
    background-color: #fbd3ea;
    border-radius: 2px;
    padding: 2px 4px;
    margin: 0 2px;
}

#write del {
    padding: 1px 2px;
}

.md-task-list-item > input {
    margin-left: -1.3em;
}

@media print {
    html {
        font-size: 0.9rem;
    }

    table,
    pre {
        page-break-inside: avoid;
    }

    pre {
        word-wrap: break-word;
    }
}

#write pre.md-meta-block {
    padding: 1rem;
    font-size: 85%;
    line-height: 1.45;
    background-color: #f7f7f7;
    border: 0;
    border-radius: 3px;
    color: #777777;
    margin-top: 0 !important;
}

.mathjax-block > .code-tooltip {
    bottom: .375rem;
}

/* 图片 */
.md-image > .md-meta {
    border-radius: 3px;
    font-family: var(--font-monospace);
    padding: 2px 0 0 4px;
    font-size: 0.9em;
    color: inherit;
}
p .md-image:only-child{
    width: auto;
    text-align: left;
    margin-left: 2rem;
}
.md-tag {
    color: inherit;
}
/* 当 “![shadow-随便写]()”写时，会有阴影 */
.md-image img[alt|='shadow'] {
    /* box-shadow: 0 4px 24px -6px #ddd; */
    box-shadow:var(--purple-light-2) 0px 10px 15px;
}

#write a.md-toc-inner {
    line-height: 1.6;
    white-space: pre-line;
    border-bottom: none;
    font-size: 0.9rem;
}

#typora-quick-open {
    border: 1px solid #ddd;
    background-color: #f8f8f8;
}

#typora-quick-open-item {
    background-color: #FAFAFA;
    border-color: #FEFEFE #e5e5e5 #e5e5e5 #eee;
    border-style: solid;
    border-width: 1px;
}

#md-notification:before {
    top: 10px;
}

header,
.context-menu,
.megamenu-content,
footer {
    font-family: var(--font-sans-serif);
}

.file-node-content:hover .file-node-icon,
.file-node-content:hover .file-node-open-state {
    visibility: visible;
}

.md-lang {
    color: #b4654d;
}

.html-for-mac .context-menu {
    --item-hover-bg-color: #E6F0FE;
}

/* 代码框 */
/* CodeMirror 3024 Day theme */

/* 代码段 背景 */
pre {
    --select-text-bg-color: rgba(223, 197, 223) !important;
    margin: .5em 0;
    padding: 1em 1.4em;
    border-radius: 8px;
    background: #f6f8fa;
    overflow-x: auto;
    box-sizing: border-box;
    font-size: 14px;
}

/* 边框 */
.md-fences {
    border: 1px solid #e7eaed;
    border-radius: 3px;
}

.cm-s-inner {
  padding: .25rem;
  border-radius: .25rem;
}

.cm-s-inner.CodeMirror, .cm-s-inner .CodeMirror-gutters {
  background-color: #f8f8f8 !important;
  color: #3a3432 !important;
  border: none;
}

.cm-s-inner .CodeMirror-gutters {
  color: #6d8a88;
}

.cm-s-inner .CodeMirror-cursor {
  border-left: solid thin #5c5855 !important;
}

.cm-s-inner .CodeMirror-linenumber {
  color: #807d7c;
}

.cm-s-inner .CodeMirror-line::selection, .cm-s-inner .CodeMirror-line::-moz-selection,
.cm-s-inner .CodeMirror-line > span::selection,
.cm-s-inner .CodeMirror-line > span::-moz-selection,
.cm-s-inner .CodeMirror-line > span > span::selection,
.cm-s-inner .CodeMirror-line > span > span::-moz-selection {
  background: var(--purple-light-2);
}

.cm-s-inner span.cm-comment {
  color: #cdab53;
}

.cm-s-inner span.cm-string, .cm-s-inner span.cm-string-2 {
  color: #f2b01d;
}

.cm-s-inner span.cm-number {
  color: #a34e8f;
}

.cm-s-inner span.cm-variable {
  color: #01a252;
}

.cm-s-inner span.cm-variable-2 {
  color: #01a0e4;
}

.cm-s-inner span.cm-def {
  /* color: #e8bbd0; */
  color: #e2287f;
}

.cm-s-inner span.cm-operator {
  color: #ff79c6;
}

.cm-s-inner span.cm-keyword {
  color: #db2d20;
}

.cm-s-inner span.cm-atom {
  color: #a34e8f;
}

.cm-s-inner span.cm-meta {
  color: inherit;
}

.cm-s-inner span.cm-tag {
  color: #db2d20;
}

.cm-s-inner span.cm-attribute {
  color: #01a252;
}

.cm-s-inner span.cm-qualifier {
  color: #388aa3;
}

.cm-s-inner span.cm-property {
  color: #01a252;
}

.cm-s-inner span.cm-builtin {
  color: #388aa3;
}

.cm-s-inner span.cm-variable-3, .cm-s-inner span.cm-type {
  color: #ffb86c;
}

.cm-s-inner span.cm-bracket {
  color: #3a3432;
}

.cm-s-inner span.cm-link {
  color: #a34e8f;
}

.cm-s-inner span.cm-error {
  background: #db2d20;
  color: #5c5855;
}

/* .md-fences.md-focus .cm-s-inner .CodeMirror-activeline-background {
  background: var(--purple-light-2);
} */

.cm-s-inner .CodeMirror-matchingbracket {
  text-decoration: underline;
  color: #a34e8f !important;
}

#fences-auto-suggest .active {
  background: #ddd;
}

#write .code-tooltip {
  bottom: initial;
  top: calc(100% - 1px);
  background: #f7f7f7;
  border: 1px solid #ddd;
  border-top: 0;
}

.auto-suggest-container {
  border-color: #b4b4b4;
}

.auto-suggest-container .autoComplt-hint.active {
  background: #b4b4b4;
  color: inherit;
}

/* task list */
#write .md-task-list-item > input {
  -webkit-appearance: initial;
  display: block;
  position: absolute;
  border: 1px solid #b4b4b4;
  border-radius: .25rem;
  margin-top: .1rem;
  margin-left: -1.8rem;
  height: 1.2rem;
  width: 1.2rem;
  transition: background 0.3s;
}

#write .md-task-list-item > input:focus {
  outline: none;
  box-shadow: none;
}

#write .md-task-list-item > input:hover {
  background: #ddd;
}

#write .md-task-list-item > input[checked]::before {
  content: '';
  position: absolute;
  top: 20%;
  left: 50%;
  height: 60%;
  width: 2px;
  transform: rotate(40deg);
  background: #333;
}

#write .md-task-list-item > input[checked]::after {
  content: '';
  position: absolute;
  top: 46%;
  left: 25%;
  height: 30%;
  width: 2px;
  transform: rotate(-40deg);
  background: #333;
}

#write .md-task-list-item > p {
  transition: color 0.3s, opacity 0.3s;
}

#write .md-task-list-item.task-list-done > p {
  color: #b4b4b4;
  text-decoration: line-through;
}

#write .md-task-list-item.task-list-done > p > .md-emoji {
  opacity: .5;
}

#write .md-task-list-item.task-list-done > p > .md-link > a {
  opacity: .6;
}

/* sidebar and outline */
.pin-outline .outline-active {
  color: var(--active-file-text-color); 
}

.file-list-item {
    border-bottom: 1px solid;
    border-color: var(--purple-light-5);
}

.file-list-item-summary {
    font-weight: 400;
}

.file-list-item.active {
    color: var(--active-file-text-color);
    background-color: var(--purple-light-5);
}

.file-tree-node.active>.file-node-background {
    background-color: var(--purple-light-5);
    font-weight: 700;
} 

.file-tree-node.active>.file-node-content {
    color: var(--active-file-text-color);
    font-weight: 700;
}

.file-node-content {
    color: #5e676d;
}

.sidebar-tabs {
    border-bottom: none;
}
.sidebar-tab.active {
    font-weight: 400;
}

.sidebar-content-content {
    font-size: 0.9rem;
}

img {
    max-width: 100%;
}

body {
    background-color: rgb(237, 237, 237);
}
#content {
    width: 836px;
    padding: 50px;
    background: #fff;
    margin: 0 auto;
}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/purple.css*/</style><style type="text/css">.hljs{display:block;overflow-x:auto;padding:.5em;color:#383a42;background:#fafafa}.hljs-comment,.hljs-quote{color:#a0a1a7;font-style:italic}.hljs-doctag,.hljs-formula,.hljs-keyword{color:#a626a4}.hljs-deletion,.hljs-name,.hljs-section,.hljs-selector-tag,.hljs-subst{color:#e45649}.hljs-literal{color:#0184bb}.hljs-addition,.hljs-attribute,.hljs-meta-string,.hljs-regexp,.hljs-string{color:#50a14f}.hljs-built_in,.hljs-class .hljs-title{color:#c18401}.hljs-attr,.hljs-number,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-pseudo,.hljs-template-variable,.hljs-type,.hljs-variable{color:#986801}.hljs-bullet,.hljs-link,.hljs-meta,.hljs-selector-id,.hljs-symbol,.hljs-title{color:#4078f2}.hljs-emphasis{font-style:italic}.hljs-strong{font-weight:700}.hljs-link{text-decoration:underline}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/atom-one-light.min.css*/</style></head>
<body>
  <div id="content"><h1>15 | k-means 聚类：擒贼先擒王，找到中心点，它附近的都是一类</h1><p data-nodeid="43999" class="">关于分类算法，我的讲解已经告一段落，从这一小节开始，我们进入聚类算法的学习。不知道你是否对前面讲解的“什么是聚类问题”还有印象，我在这里再简单介绍一下。</p>

<p data-nodeid="43853">聚类算法属于无监督学习，与分类算法这种有监督学习不同的是，聚类算法事先并不需要知道数据的类别标签，而只是根据数据特征去学习，找到相似数据的特征，然后把已知的数据集划分成几个不同的类别。</p>
<p data-nodeid="43854">比如说我们有一堆树叶，对于分类问题来说，我们已经知道了过去的每一片树叶的类别。比如这个是枫树叶，那个是橡树叶，经过学习之后拿来一片新的叶子，你看了一眼，然后说这是枫树叶。而对于聚类问题，这里一堆树叶的具体类别你是不知道的，所以你只能学习，这个叶子是圆的，那个是五角星形的；这个边缘光滑，那个边缘有锯齿……这样你根据自己的判定，把一箱子树叶分成了几个小堆，但是这一堆到底是什么树叶你还是不知道的。</p>
<h3 data-nodeid="43855">一个例子</h3>
<p data-nodeid="43856">今天我要介绍的聚类算法称为 K-means 算法。首先我还是讲一个小例子来介绍一下这个方法的思路。</p>
<p data-nodeid="43857">假设我们在罪恶都市里，有三个区域，每个区域有一个帮派进行管理。每个帮派都有一个大佬，每个大佬都管理着一群小弟，小弟们也有不同的等级。大佬给高级小弟安排任务，高级小弟再给低级小弟安排任务，而低级小弟们负责具体实施。有些小弟可能就在自己的区域活动，管理本区域内的店铺、保障本区域的治安；有些小弟可能会负责跟其他两个帮派联络、洽谈地盘、交易等业务。</p>
<p data-nodeid="43858">这个时候来了个国民警卫队要整治这个区域，所以他们希望能够把帮派的关系理清楚，但是有那么多人该从哪里入手呢？最好的方案当然是先把大佬抓到，然后看一下他都联系谁就一目了然了。但是国民警卫队也不知道谁是大佬，那要怎么办？</p>
<p data-nodeid="43859">假设国民警卫队已经知道这里面有三个帮派，那么国民警卫队派人在每个区设一个点，先随便抓一个人，最开始可能抓到的只是一个边缘小弟，甚至有一些可能抓到的两个是同一个帮派。但是没关系，先假设他是大佬，看跟他联系密切的都是哪些人，然后再从这些人里找一个跟其他人联系更密切的人。就这样反复寻找，最后终于找到每个帮派的大佬，而大佬联系的那些人自然就是这个帮派的小弟了。</p>
<p data-nodeid="43860"><img src="https://s0.lgstatic.com/i/image/M00/4F/87/CgqCHl9gf5yAU4WwAACqgSyrVqc484.png" alt="Drawing 0.png" data-nodeid="43916"></p>
<h3 data-nodeid="43861">算法原理</h3>
<p data-nodeid="43862">上面的小故事可以看到一些 K-means 的思想。接着我们来具体介绍一下算法的原理。假设我们的数据总共有 m 条，我们计划分为 3 个类别。如果我们的数据有两个特征维度，那我们的数据就分布在一个二维平面上，如果有十个维度，就分布在一个十维的空间中。</p>
<p data-nodeid="43863">第一轮，先随机在这个空间中选取三个点，我们称之为<strong data-nodeid="43928">中心点</strong>，当然选取的三个点不一定是实际的数据点。接着计算所有的点到这三个点的距离，这里的距离计算仍然使用的是<strong data-nodeid="43929">欧氏距离</strong>，每个点都选择距离最近的那个作为自己的中心点。这个时候我们就已经把数据划分成了三个组。使用每个组的数据计算出这些数据的一个均值，使用这个均值作为下一轮迭代的中心点。</p>
<p data-nodeid="43864">后面若干轮重复上面的过程进行迭代，当达到一些条件，比如说规定的轮次或者中心点的变动很小等，就可以停止运行了。</p>
<p data-nodeid="43865">K-means 的算法原理就已经解释完了，也是非常简洁、易于理解，但是这里面有一些问题需要解决。</p>
<h4 data-nodeid="43866">如何确定 k 值</h4>
<p data-nodeid="43867">在算法实现的过程中，我们面临的问题就是如何确定 K 值。因为在日常的情况下，我们也不知道这些数据到底会有多少个类别，或者分为多少个类别会比较好，所以在选择 K 值的时候比较困难，只能根据经验先拍一个数值。</p>
<p data-nodeid="43868">有一个比较常用的方法，叫作<strong data-nodeid="43939">手肘法</strong>。就是去循环尝试 K 值，计算在不同的 K 值情况下，所有数据的损失，即用每一个数据点到中心点的距离之和计算平均距离。可以想到，当 K=1 的时候，这个距离和肯定是最大的；当 K=m 的时候，每个点也是自己的中心点，这个时候全局的距离和是 0，平均距离也是 0，当然我们不可能设置成 K=m。</p>
<p data-nodeid="43869">而在逐渐加大 K 的过程中，会有一个点，使这个平均距离发生急剧的变化，如果把这个距离与 K 的关系画出来，就可以看到一个拐点，也就是我们说的手肘。</p>
<p data-nodeid="43870">如下图，我在这里虚拟了一份数据，可以看到在 K=4 的时候就是我们的肘点，在这个肘点前平均距离下降迅速，在 4 之后平均距离下降变得缓慢。但是这个方法只能适用 K 值不那么大的情况，如果 K 值较大，如几千几万，那迭代的次数就太多了，当然你也可以选择一个比较大的学习率来加以改进。不过总体而言，需要消耗一定的时间。</p>
<p data-nodeid="43871"><img src="https://s0.lgstatic.com/i/image/M00/4F/7C/Ciqc1F9gf7iAKmKsAAB2Vo-8AXw694.png" alt="Drawing 1.png" data-nodeid="43944"></p>
<p data-nodeid="43872">要确定 K 值确实是一项比较费时费力的事情，但是也是必须要做的事情。下面我们来看看这个算法的优缺点。</p>
<h3 data-nodeid="43873">算法优缺点</h3>
<h4 data-nodeid="43874">优点</h4>
<ul data-nodeid="43875">
<li data-nodeid="43876">
<p data-nodeid="43877"><strong data-nodeid="43952">简洁明了，计算复杂度低。</strong> K-means 的原理非常容易理解，整个计算过程与数学推理也不是很困难。</p>
</li>
<li data-nodeid="43878">
<p data-nodeid="43879"><strong data-nodeid="43957">收敛速度较快。</strong> 通常经过几个轮次的迭代之后就可以获得还不错的效果。</p>
</li>
</ul>
<h4 data-nodeid="43880">缺点</h4>
<ul data-nodeid="43881">
<li data-nodeid="43882">
<p data-nodeid="43883"><strong data-nodeid="43963">结果不稳定。</strong> 由于初始值随机设定，以及数据的分布情况，每次学习的结果往往会有一些差异。</p>
</li>
<li data-nodeid="43884">
<p data-nodeid="43885"><strong data-nodeid="43968">无法解决样本不均衡的问题。</strong> 对于类别数据量差距较大的情况无法进行判断。</p>
</li>
<li data-nodeid="43886">
<p data-nodeid="43887"><strong data-nodeid="43973">容易收敛到局部最优解。</strong> 在局部最优解的时候，迭代无法引起中心点的变化，迭代将结束。</p>
</li>
<li data-nodeid="43888">
<p data-nodeid="43889"><strong data-nodeid="43978">受噪声影响较大。</strong> 如果存在一些噪声数据，会影响均值的计算，进而引起聚类的效果偏差。</p>
</li>
</ul>
<h3 data-nodeid="43890">尝试动手</h3>
<p data-nodeid="43891">和前面一样，在对 K-means 算法有了一定了解之后，我们来动手尝试通过代码来实际感受 K-means 算法的效果。这次我们使用的仍然是鸢尾花数据集，当然，由于是聚类，我们不需要使用标签数据，只需要使用特征数据就可以了。</p>
<pre class="lang-python" data-nodeid="43892"><code data-language="python"><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> datasets
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">from</span> sklearn.cluster <span class="hljs-keyword">import</span> KMeans
<span class="hljs-string">""" 画出聚类后的图像
labels: 聚类后的label, 从0开始的数字
cents: 质心坐标
n_cluster: 聚类后簇的数量
color: 每一簇的颜色
"""</span>&nbsp;
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">draw_result</span>(<span class="hljs-params">train_x, labels, cents, title</span>):</span>
    n_clusters = np.unique(labels).shape[<span class="hljs-number">0</span>]
    color = [<span class="hljs-string">"red"</span>, <span class="hljs-string">"orange"</span>, <span class="hljs-string">"yellow"</span>]
    plt.figure()
    plt.title(title)
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(n_clusters):
        current_data = train_x[labels == i]
        plt.scatter(current_data[:, <span class="hljs-number">0</span>], current_data[:,<span class="hljs-number">1</span>], c=color[i])
        <span class="hljs-comment">#使用蓝色的星形表示中心点位置</span>
        plt.scatter(cents[i, <span class="hljs-number">0</span>], cents[i, <span class="hljs-number">1</span>], c=<span class="hljs-string">"blue"</span>, marker=<span class="hljs-string">"*"</span>, s=<span class="hljs-number">100</span>)
    <span class="hljs-keyword">return</span> plt
<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    iris = datasets.load_iris()
    iris_x = iris.data
    <span class="hljs-comment">#设定聚类数目为3</span>
    clf = KMeans(n_clusters=<span class="hljs-number">3</span>, max_iter=<span class="hljs-number">10</span>,n_init=<span class="hljs-number">10</span>, init=<span class="hljs-string">"k-means++"</span>, algorithm=<span class="hljs-string">"full"</span>, tol=<span class="hljs-number">1e-4</span>,n_jobs= <span class="hljs-number">-1</span>,random_state=<span class="hljs-number">1</span>)
    clf.fit(iris_x)
    print(<span class="hljs-string">"SSE = {0}"</span>.format(clf.inertia_))
    draw_result(iris_x, clf.labels_, clf.cluster_centers_, <span class="hljs-string">"kmeans"</span>).show()
<span class="hljs-comment">#输出结果</span>
SSE = <span class="hljs-number">78.851441426146</span>
注：SSE是误差平方和，这个值越接近<span class="hljs-number">0</span>说明效果越好
</code></pre>
<p data-nodeid="43893">通过运行上面的代码，会输出下面的这幅图像，当然，我们的鸢尾花数据集的属性有四个维度，这里输出的图像我们只使用了两个维度，但是仍然可以看出通过 K-means 计算出的中心点与数据分布基本上是一致的，而且效果也还不错。</p>
<p data-nodeid="43894"><img src="https://s0.lgstatic.com/i/image/M00/4F/7C/Ciqc1F9gf8yAJ8IgAAA_Qm-JjDU571.png" alt="Drawing 2.png" data-nodeid="43984"></p>
<h3 data-nodeid="43895">扩展内容</h3>
<p data-nodeid="43896">做完了实践，我们再来看一下 K-means 都有什么样的衍生方法。由于 K-means 也是一种非常不错的方法，所以有很多人为了改正它存在的一些问题进行了相应的研究。</p>
<h4 data-nodeid="43897">K-means++</h4>
<p data-nodeid="43898">第一种是 K-means++，这种方法主要在初始选取中心点的时候进行了优化。原本第一轮是随机进行选取的，但是由于算法可能会陷入局部最优解，随机地选取可能引起结果的不稳定。K-means++ 则是从已有的数据中随机地进行多次选取 K 个中心点，每次都计算这一次选中的中心点的距离，然后取一组最大的作为初始化中心点。</p>
<h4 data-nodeid="43899">mini&nbsp;batch&nbsp;K-means</h4>
<p data-nodeid="44591" class="">第二种 mini&nbsp;batch 方法，主要是基于在数据量和数据维度都特别大的情况下，针对运算变得异常缓慢的问题进行的改进。我们前面提到，K-means 的收敛速度相对较快，所以前面几步的变动比较大，到了后面的步骤其实只有非常小的变动。mini&nbsp;batch 的方案就是在迭代时，不再使用所有的点，而是每个集合中选取一部分点进行计算，从而降低计算的复杂度。</p>


<h3 data-nodeid="43901">总结</h3>
<p data-nodeid="43902">写到这里，本课时的主要内容已经告一段落。这节课我们进入了新的算法类型——聚类算法的学习。在开头我又简单介绍了一下什么是聚类算法，聚类与分类有什么样的区别，接着就讲到了本节课的主角——K-means 算法，它是一种非常简洁的基于划分的聚类算法。与前面一样，在介绍完算法的思想之后我加入了一段代码来实现快速上手，并且加入了一个画图的方法来展示聚类的效果。</p>
<p data-nodeid="43903">在看完了这一课时的内容之后，你是否能在自己的工作中使用 K-means 来解决问题了呢？下一课时，我们将介绍另外一种聚类算法“DBScan”，到时见。</p>
<blockquote data-nodeid="43904">
<p data-nodeid="43905" class="">点击下方链接查看源代码（不定时更新）以及相关工具：<br>
<a href="https://github.com/icegomic/GomicDatamining/tree/master/LagouCodes" data-nodeid="43998">https://github.com/icegomic/GomicDatamining/tree/master/LagouCodes</a></p>
</blockquote></div>

</body></html>
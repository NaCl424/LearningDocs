<!DOCTYPE html><html lang="en"><head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>18 | 线性回归与逻辑回归:找到一个函数去拟合数据</title>
<style type="text/css">
:root {
    --control-text-color: #777;
    --select-text-bg-color: rgba(223, 197, 223);  /*#7e66992e;*/
    
    /* side bar */
    --side-bar-bg-color: rgb(255, 255, 255);
    --active-file-text-color: #8163bd;
    --active-file-bg-color: #E9E4F0;
    --item-hover-bg-color: #E9E4F0;
    --active-file-border-color: #8163bd;

    --title-color: #6c549c;
    --font-sans-serif: 'Ubuntu', 'Source Sans Pro', sans-serif !important;
    --font-monospace: 'Fira Code', 'Roboto Mono', monospace !important;
    --purple-1: #8163bd;
    --purple-2: #79589F;
    --purple-3: #fd5eb8;
    --purple-light-1: rgba(99, 99, 172, .05);
    --purple-light-2: rgba(99, 99, 172, .1);
    --purple-light-3: rgba(99, 99, 172, .2);
    --purple-light-4: rgba(129, 99, 189, .3);
    --purple-light-5: #E9E4F0;
    --purple-light-6: rgba(129, 99, 189, .8);
}

/* html {
    font-size: 16px;
} */

body {
    font-family: var(--font-sans-serif);
    color: #34495e;
    -webkit-font-smoothing: antialiased;
    line-height: 1.6rem;
    letter-spacing: 0;
    margin: 0;
    overflow-x: hidden;
}

/* 页边距 和 页面大小 */
#write {
    padding-left: 6ch;
    padding-right: 6ch;
    margin: 0 auto;
}

#write p {
    line-height: 1.6rem;
    word-spacing: .05rem;
}

#write ol li {
    padding-left: 0.5rem;
}

#write > ul:first-child,
#write > ol:first-child {
    margin-top: 30px;
}

body > *:first-child {
    margin-top: 0 !important;
}

body > *:last-child {
    margin-bottom: 0 !important;
}

a {
    color: var(--purple-1);
    padding: 0 2px;
    text-decoration: none;
}
.md-content {
    color: var(--purple-light-6);
}
#write a {
    border-bottom: 1px solid var(--purple-1);
    color: var(--purple-1);
    text-decoration: none;
}

h1,
h2,
h3,
h4,
h5,
h6 {
    position: relative;
    margin-top: 1rem;
    margin-bottom: 0.5rem;
    /* font-weight: bold; */
    font-weight: 500 !important;
    line-height: 1.4;
    cursor: text;
    color: var(--title-color);
    font-family: var(--font-sans-serif);
}

h1:hover a.anchor,
h2:hover a.anchor,
h3:hover a.anchor,
h4:hover a.anchor,
h5:hover a.anchor,
h6:hover a.anchor {
    text-decoration: none;
}

h1 tt,
h1 code {
    font-size: inherit !important;
}
h2 tt,
h2 code {
    font-size: inherit !important;
}
h3 tt,
h3 code {
    font-size: inherit !important;
}
h4 tt,
h4 code {
    font-size: inherit !important;
}
h5 tt,
h5 code {
    font-size: inherit !important;
}
h6 tt,
h6 code {
    font-size: inherit !important;
}


h1 {
    padding-bottom: .4rem;
    font-size: 2.2rem;
    line-height: 1.3;
}
h1 {
    text-align: center;
    padding-bottom: 0.3em;
    font-size: 2.2em;
    line-height: 1.2;
    margin: 2.4em auto 1.2em;
}
h1:after {
    content: '';
    display: block;
    margin: 0.2em auto 0;
    width: 100px;
    height: 2px;
    border-bottom: 2px solid var(--title-color);
}

h2 {
    margin: 1.6em auto 0.5em;
    padding-left: 10px;
    line-height: 1.4;
    font-size: 1.8em;
    border-left: 9px solid var(--title-color);
    border-bottom: 1px solid var(--title-color);
}
h3 {
    font-size: 1.5rem;
    margin: 1.2em auto 0.5em;
}
h4 {
    font-size: 1.3rem;
}
h5 {
    font-size: 1.2rem;
}
h6 {
    font-size: 1.1rem;
}

p,
blockquote,
ul,
ol,
dl,
table {
    margin: 0.8em 0;
}

li > ol,
li > ul {
    margin: 0 0;
}

hr {
    height: 2px;
    padding: 0;
    margin: 16px 0;
    background-color: #e7e7e7;
    border: 0 none;
    overflow: hidden;
    box-sizing: content-box;
}

body > h2:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0;
}

body > h3:first-child,
body > h4:first-child,
body > h5:first-child,
body > h6:first-child {
    margin-top: 0;
    padding-top: 0;
}

a:first-child h1,
a:first-child h2,
a:first-child h3,
a:first-child h4,
a:first-child h5,
a:first-child h6 {
    margin-top: 0;
    padding-top: 0;
}

h1 p,
h2 p,
h3 p,
h4 p,
h5 p,
h6 p {
    margin-top: 0;
}

li p.first {
    display: inline-block;
}

ul,
ol {
    padding-left: 30px;
}

ul:first-child,
ol:first-child {
    margin-top: 0;
}

ul:last-child,
ol:last-child {
    margin-bottom: 0;
}

/* 引用 */
blockquote {
    /* margin-left: 1rem; */
    border-left: 4px solid var(--purple-light-4);
    padding: 10px 15px;
    color: #777;
    background-color: var(--purple-light-1);
}

/* 表格 */
table {
    padding: 0;
    word-break: initial;
}

table tr {
    border-top: 1px solid #dfe2e5;
    margin: 0;
    padding: 0;
}

/* 表格 背景色 */
table tr:nth-child(2n),
thead {
    background-color: var(--purple-light-1);
}
#write table thead th {
    background-color: var(--purple-light-2);
}

table tr th {
    font-weight: bold;
    border: 1px solid #dfe2e5;
    border-bottom: 0;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr td {
    border: 1px solid #dfe2e5;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr th:first-child,
table tr td:first-child {
    margin-top: 0;
}

table tr th:last-child,
table tr td:last-child {
    margin-bottom: 0;
}

/* 粗体 */
#write strong {
    padding: 0 2px;
    color: var(--purple-1);
}

/* 斜体 */
#write em {
    padding: 0 5px 0 2px;
    /* font-style: normal; */
    color: #42b983;
}

/* inline code */
#write code, tt {
    padding: 2px 4px;
    border-radius: 2px;
    font-family: var(--font-monospace);
    font-size: 0.92rem;
    color: var(--purple-3); 
    background-color: rgba(99, 99, 172, .05);
}

tt {
    margin: 0 2px;
}

#write .md-footnote {
    background-color: #f8f8f8;
    color: var(--purple-3);
}

/* heighlight. */
#write mark {
    background-color: #fbd3ea;
    border-radius: 2px;
    padding: 2px 4px;
    margin: 0 2px;
}

#write del {
    padding: 1px 2px;
}

.md-task-list-item > input {
    margin-left: -1.3em;
}

@media print {
    html {
        font-size: 0.9rem;
    }

    table,
    pre {
        page-break-inside: avoid;
    }

    pre {
        word-wrap: break-word;
    }
}

#write pre.md-meta-block {
    padding: 1rem;
    font-size: 85%;
    line-height: 1.45;
    background-color: #f7f7f7;
    border: 0;
    border-radius: 3px;
    color: #777777;
    margin-top: 0 !important;
}

.mathjax-block > .code-tooltip {
    bottom: .375rem;
}

/* 图片 */
.md-image > .md-meta {
    border-radius: 3px;
    font-family: var(--font-monospace);
    padding: 2px 0 0 4px;
    font-size: 0.9em;
    color: inherit;
}
p .md-image:only-child{
    width: auto;
    text-align: left;
    margin-left: 2rem;
}
.md-tag {
    color: inherit;
}
/* 当 “![shadow-随便写]()”写时，会有阴影 */
.md-image img[alt|='shadow'] {
    /* box-shadow: 0 4px 24px -6px #ddd; */
    box-shadow:var(--purple-light-2) 0px 10px 15px;
}

#write a.md-toc-inner {
    line-height: 1.6;
    white-space: pre-line;
    border-bottom: none;
    font-size: 0.9rem;
}

#typora-quick-open {
    border: 1px solid #ddd;
    background-color: #f8f8f8;
}

#typora-quick-open-item {
    background-color: #FAFAFA;
    border-color: #FEFEFE #e5e5e5 #e5e5e5 #eee;
    border-style: solid;
    border-width: 1px;
}

#md-notification:before {
    top: 10px;
}

header,
.context-menu,
.megamenu-content,
footer {
    font-family: var(--font-sans-serif);
}

.file-node-content:hover .file-node-icon,
.file-node-content:hover .file-node-open-state {
    visibility: visible;
}

.md-lang {
    color: #b4654d;
}

.html-for-mac .context-menu {
    --item-hover-bg-color: #E6F0FE;
}

/* 代码框 */
/* CodeMirror 3024 Day theme */

/* 代码段 背景 */
pre {
    --select-text-bg-color: rgba(223, 197, 223) !important;
    margin: .5em 0;
    padding: 1em 1.4em;
    border-radius: 8px;
    background: #f6f8fa;
    overflow-x: auto;
    box-sizing: border-box;
    font-size: 14px;
}

/* 边框 */
.md-fences {
    border: 1px solid #e7eaed;
    border-radius: 3px;
}

.cm-s-inner {
  padding: .25rem;
  border-radius: .25rem;
}

.cm-s-inner.CodeMirror, .cm-s-inner .CodeMirror-gutters {
  background-color: #f8f8f8 !important;
  color: #3a3432 !important;
  border: none;
}

.cm-s-inner .CodeMirror-gutters {
  color: #6d8a88;
}

.cm-s-inner .CodeMirror-cursor {
  border-left: solid thin #5c5855 !important;
}

.cm-s-inner .CodeMirror-linenumber {
  color: #807d7c;
}

.cm-s-inner .CodeMirror-line::selection, .cm-s-inner .CodeMirror-line::-moz-selection,
.cm-s-inner .CodeMirror-line > span::selection,
.cm-s-inner .CodeMirror-line > span::-moz-selection,
.cm-s-inner .CodeMirror-line > span > span::selection,
.cm-s-inner .CodeMirror-line > span > span::-moz-selection {
  background: var(--purple-light-2);
}

.cm-s-inner span.cm-comment {
  color: #cdab53;
}

.cm-s-inner span.cm-string, .cm-s-inner span.cm-string-2 {
  color: #f2b01d;
}

.cm-s-inner span.cm-number {
  color: #a34e8f;
}

.cm-s-inner span.cm-variable {
  color: #01a252;
}

.cm-s-inner span.cm-variable-2 {
  color: #01a0e4;
}

.cm-s-inner span.cm-def {
  /* color: #e8bbd0; */
  color: #e2287f;
}

.cm-s-inner span.cm-operator {
  color: #ff79c6;
}

.cm-s-inner span.cm-keyword {
  color: #db2d20;
}

.cm-s-inner span.cm-atom {
  color: #a34e8f;
}

.cm-s-inner span.cm-meta {
  color: inherit;
}

.cm-s-inner span.cm-tag {
  color: #db2d20;
}

.cm-s-inner span.cm-attribute {
  color: #01a252;
}

.cm-s-inner span.cm-qualifier {
  color: #388aa3;
}

.cm-s-inner span.cm-property {
  color: #01a252;
}

.cm-s-inner span.cm-builtin {
  color: #388aa3;
}

.cm-s-inner span.cm-variable-3, .cm-s-inner span.cm-type {
  color: #ffb86c;
}

.cm-s-inner span.cm-bracket {
  color: #3a3432;
}

.cm-s-inner span.cm-link {
  color: #a34e8f;
}

.cm-s-inner span.cm-error {
  background: #db2d20;
  color: #5c5855;
}

/* .md-fences.md-focus .cm-s-inner .CodeMirror-activeline-background {
  background: var(--purple-light-2);
} */

.cm-s-inner .CodeMirror-matchingbracket {
  text-decoration: underline;
  color: #a34e8f !important;
}

#fences-auto-suggest .active {
  background: #ddd;
}

#write .code-tooltip {
  bottom: initial;
  top: calc(100% - 1px);
  background: #f7f7f7;
  border: 1px solid #ddd;
  border-top: 0;
}

.auto-suggest-container {
  border-color: #b4b4b4;
}

.auto-suggest-container .autoComplt-hint.active {
  background: #b4b4b4;
  color: inherit;
}

/* task list */
#write .md-task-list-item > input {
  -webkit-appearance: initial;
  display: block;
  position: absolute;
  border: 1px solid #b4b4b4;
  border-radius: .25rem;
  margin-top: .1rem;
  margin-left: -1.8rem;
  height: 1.2rem;
  width: 1.2rem;
  transition: background 0.3s;
}

#write .md-task-list-item > input:focus {
  outline: none;
  box-shadow: none;
}

#write .md-task-list-item > input:hover {
  background: #ddd;
}

#write .md-task-list-item > input[checked]::before {
  content: '';
  position: absolute;
  top: 20%;
  left: 50%;
  height: 60%;
  width: 2px;
  transform: rotate(40deg);
  background: #333;
}

#write .md-task-list-item > input[checked]::after {
  content: '';
  position: absolute;
  top: 46%;
  left: 25%;
  height: 30%;
  width: 2px;
  transform: rotate(-40deg);
  background: #333;
}

#write .md-task-list-item > p {
  transition: color 0.3s, opacity 0.3s;
}

#write .md-task-list-item.task-list-done > p {
  color: #b4b4b4;
  text-decoration: line-through;
}

#write .md-task-list-item.task-list-done > p > .md-emoji {
  opacity: .5;
}

#write .md-task-list-item.task-list-done > p > .md-link > a {
  opacity: .6;
}

/* sidebar and outline */
.pin-outline .outline-active {
  color: var(--active-file-text-color); 
}

.file-list-item {
    border-bottom: 1px solid;
    border-color: var(--purple-light-5);
}

.file-list-item-summary {
    font-weight: 400;
}

.file-list-item.active {
    color: var(--active-file-text-color);
    background-color: var(--purple-light-5);
}

.file-tree-node.active>.file-node-background {
    background-color: var(--purple-light-5);
    font-weight: 700;
} 

.file-tree-node.active>.file-node-content {
    color: var(--active-file-text-color);
    font-weight: 700;
}

.file-node-content {
    color: #5e676d;
}

.sidebar-tabs {
    border-bottom: none;
}
.sidebar-tab.active {
    font-weight: 400;
}

.sidebar-content-content {
    font-size: 0.9rem;
}

img {
    max-width: 100%;
}

body {
    background-color: rgb(237, 237, 237);
}
#content {
    width: 836px;
    padding: 50px;
    background: #fff;
    margin: 0 auto;
}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/purple.css*/</style><style type="text/css">.hljs{display:block;overflow-x:auto;padding:.5em;color:#383a42;background:#fafafa}.hljs-comment,.hljs-quote{color:#a0a1a7;font-style:italic}.hljs-doctag,.hljs-formula,.hljs-keyword{color:#a626a4}.hljs-deletion,.hljs-name,.hljs-section,.hljs-selector-tag,.hljs-subst{color:#e45649}.hljs-literal{color:#0184bb}.hljs-addition,.hljs-attribute,.hljs-meta-string,.hljs-regexp,.hljs-string{color:#50a14f}.hljs-built_in,.hljs-class .hljs-title{color:#c18401}.hljs-attr,.hljs-number,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-pseudo,.hljs-template-variable,.hljs-type,.hljs-variable{color:#986801}.hljs-bullet,.hljs-link,.hljs-meta,.hljs-selector-id,.hljs-symbol,.hljs-title{color:#4078f2}.hljs-emphasis{font-style:italic}.hljs-strong{font-weight:700}.hljs-link{text-decoration:underline}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/atom-one-light.min.css*/</style></head>
<body>
  <div id="content"><h1>18 | 线性回归与逻辑回归:找到一个函数去拟合数据</h1><p data-nodeid="126703" class="">经过了这么久的学习，我们终于结束了分类和聚类算法的相关内容，这一课时我将为你讲解关于回归算法的内容。</p>


<p data-nodeid="126153">从标题可以看出来，我们这次课程会涉及线性回归和逻辑回归，这两个回归有什么样的含义呢？虽然都叫作回归，它们的处理方式有什么不同呢？带着这些问题，我们就开始本课时的学习吧。</p>
<h3 data-nodeid="126154">一个例子</h3>
<p data-nodeid="126155">我们还是先从一个例子出发。想象你已经是一家公司的 CEO，你的公司旗下有着优质的明星产品——一种新型的保健品“星耀脑黄金”。为了让你的产品卖得更好，你要到处去投放广告，让大家都知道这个产品，激发大家购买的欲望。我们都知道投放广告是要花钱的，投放得越多，钱花得越多；知道的人越多，产品卖得越多。</p>
<p data-nodeid="127425">根据历史累计的广告投放经费和销售额，我们可以画出一些点。</p>
<p data-nodeid="127426" class=""><img src="https://s0.lgstatic.com/i/image/M00/59/67/CgqCHl9xemCANxZJAAAXgKELoKQ502.png" alt="Drawing 0.png" data-nodeid="127430"></p>


<p data-nodeid="126158">从这个图上可以看出，有些点位的收益相对较高，有些点位的收益相对较低，但是总体是一个正相关的关系。很自然地，你内心感觉需要画出一条线，就如下面图中的一样，来拟合投放广告经费和销售额的关系。</p>
<p data-nodeid="128151">虽然它对于每一个单点来说都不是那么精确，但是它却十分简洁，有了这条线，你只需要设定一个广告费的数额，就一定可以算出一个销售额。这样当你在开股东大会的时候，就可以跟大家说：“我花这么多广告费是有价值的，只要我们的投放广告费达到多少多少亿，销售额也就能达到多少多少亿。”</p>
<p data-nodeid="128152" class=""><img src="https://s0.lgstatic.com/i/image/M00/59/5D/Ciqc1F9xfCqAT3cKAAAeEA32Q9U005.png" alt="Drawing 1.png" data-nodeid="128156"></p>


<p data-nodeid="126161">经过了上面的步骤，我们其实就已经完成了线性回归的模型构建，即根据已有的数据去寻找一条直线，尽量接近这些数据，以用于对以后的数据进行预测，但是具体该怎么去找这条线呢？接下来我们看一下线性回归的原理。</p>
<h3 data-nodeid="126162">线性回归的算法原理</h3>
<p data-nodeid="126163">首先我们要明确一下，什么是线性，什么是非线性。</p>
<p data-nodeid="128521" class=""><strong data-nodeid="128526">线性：</strong> 结果与特征之间是一次函数关系，比如表现在上面的例子中就是一条直线。</p>

<p data-nodeid="128893" class=""><strong data-nodeid="128898">非线性：</strong> 结果与特征之间不是一次函数关系，比如二次函数、三次函数，表现在图中是一条曲线，就是非线性的。</p>

<p data-nodeid="126166">明白了这两个词，我们再来看回归模型是如何构建的。</p>
<p data-nodeid="129627">比如在我们的例子中只有一个变量就是广告费，一个结果值是销售额。我们假设它们符合线性关系，那么我们先预设一个方程：</p>
<p data-nodeid="129628" class=""><img src="https://s0.lgstatic.com/i/image/M00/59/5D/Ciqc1F9xfDOASY3jAAAERDbMy6Y411.png" alt="Drawing 2.png" data-nodeid="129632"></p>


<p data-nodeid="126169">所以我们只要根据数据求出 a 和 b 就完成了。</p>
<p data-nodeid="126170">但是这里有一个困难，那就是我们的数据不是完全分布在这条线上的，那就需要一个方法来评估每次生成的线的效果，然后去进行相应的调整，以达到最好的效果。提到优化，这里又需要引入两个概念，让我慢慢介绍。</p>
<p data-nodeid="130001" class=""><strong data-nodeid="130006">损失函数：</strong> 不要被这个高大上的名称吓到，用一句话来解释，就是计算每一个样本点的结果值和当前的函数值的差值。当然具体到这里面，所使用的是残差平方和（Sum of Squares for Error），这是一种最常用的损失函数。如果你对具体的公式感兴趣，可以在网上查到它的具体信息。</p>

<p data-nodeid="130377" class=""><strong data-nodeid="130382">最小二乘法：</strong> 知道了损失函数，只要有一条线，我们就可以通过损失函数来计算假设结果为这条线的情况下，损失值的大小。而这里的最小二乘法就是要找到一组 a、b 的值，使得损失值达到最小。这里的二乘就是平方的意思。</p>

<p data-nodeid="126173">到这里是不是对算法原理的理解就清晰很多了呢？那么我们再来看下它有哪些优缺点。</p>
<h3 data-nodeid="126174">线性回归的优缺点</h3>
<h4 data-nodeid="126175">优点</h4>
<ul data-nodeid="126176">
<li data-nodeid="126177">
<p data-nodeid="126178"><strong data-nodeid="126269">运算速度快</strong>。由于算法很简单，而且符合非常简洁的数学原理，不管是建模速度，还是预测速度都是非常快的。</p>
</li>
<li data-nodeid="126179">
<p data-nodeid="126180"><strong data-nodeid="126274">可解释性强</strong>。由于最终我们可以得到一个函数公式，根据计算出的公式系数就可以很明确地知道每个变量的影响大小。</p>
</li>
<li data-nodeid="126181">
<p data-nodeid="126182"><strong data-nodeid="126279">对线性关系拟合效果好</strong>。当然，相比之下，如果数据是非线性关系，那么就不合适了。</p>
</li>
</ul>
<h4 data-nodeid="126183">缺点</h4>
<ul data-nodeid="126184">
<li data-nodeid="126185">
<p data-nodeid="126186"><strong data-nodeid="126285">预测的精确度较低</strong>。由于获得的模型只是要求最小的损失，而不是对数据良好的拟合，所以精确度略低。</p>
</li>
<li data-nodeid="126187">
<p data-nodeid="126188"><strong data-nodeid="126290">不相关的特征会影响结果</strong>。对噪声数据也比较难处理，所以在数据处理阶段需要剔除不相关的特征以及噪声数据。</p>
</li>
<li data-nodeid="126189">
<p data-nodeid="126190"><strong data-nodeid="126295">容易出现过拟合</strong>。尤其在数据量较少的情况下，可能出现这种问题。</p>
</li>
</ul>
<h3 data-nodeid="126191">逻辑回归（Logistic Regression）</h3>
<p data-nodeid="126192">到这里，你可能比较疑惑，为什么我标题里写的线性回归与逻辑回归，而上面一直在讲线性回归？别担心，我们马上就讲到逻辑回归的相关内容。</p>
<p data-nodeid="126193">如果你已经了解了上面的线性回归，其实你就已经掌握了回归的方法，对于不同的回归算法，只不过是把对应的函数进行替换，把线性方程替换成非线性方程，或者其他各种各样的方程，以便更好地拟合数据。</p>
<p data-nodeid="126194">而这里为什么要把逻辑回归拎出来呢？因为我们常说的回归算法是对比分类算法来说的，回归与分类有很多相似性，是有监督学习的两大分支。我们前面也介绍过，它们的区别是分类算法输出的是离散的分类结果，而回归算法输出的是连续数值结果，这两种结果可以通过一定的方法进行转换。</p>
<p data-nodeid="126195">而逻辑回归就是这样一个典型的例子。它虽然叫作回归，但实际上却是用来解决分类问题，只不过在中间过程中，它使用的是回归的方法。</p>
<p data-nodeid="131119">关于分类问题，假设一个二分类问题，只有一个变量 x 会引起结果标签的变化，那么把它俩表示在平面上就是下图这样的效果，前半部分的结果都是 0，后半部分的结果都是 1。</p>
<p data-nodeid="131120" class=""><img src="https://s0.lgstatic.com/i/image/M00/59/5D/Ciqc1F9xfEaAEvWUAAAR5sCKx8o342.png" alt="Drawing 3.png" data-nodeid="131124"></p>


<p data-nodeid="131863">在逻辑回归算法中，使用了 sigmoid 函数来拟合数据。可以看出 sigmoid 函数有点像是被掰弯的线性函数直线，这样函数的取值范围被限定在了 0 和 1 之间，很明显，使用这个函数去拟合上面的二分类结果要比线性直线好得多。</p>
<p data-nodeid="132243"><img src="https://s0.lgstatic.com/i/image/M00/59/69/CgqCHl9xfFCAeI5CAANwu6rWfKw704.png" alt="Drawing 4.png" data-nodeid="132247"></p>
<div data-nodeid="132244" class=""><p style="text-align:center">（图片来源于百度）</p></div>





<p data-nodeid="126201">当然，选择 sigmoid 曲线并不是偶然的，而是通过了精密的计算之后得出的方案。这里涉及了概率对数函数（Logit）的数学推导，这也是逻辑回归名字的来源。同时，在输出结果的时候，借助了极大似然估计的方法来对预测出的结果进行损失的估计。</p>
<p data-nodeid="126202">当然，逻辑回归里所涉及的内容还有很多，其中使用了大量的数学推导，这里就不再做过多的介绍，如果你对推导过程感兴趣，可以进行更深入的学习。下面我们进入到动手环节，尝试在代码中使用线性回归来解决问题。</p>
<h3 data-nodeid="126203">尝试动手</h3>
<p data-nodeid="126204">在代码环节，今天我们仍然尝试自己来生成数据。</p>
<p data-nodeid="126205">首先，仍然是引入我们需要用到的包。</p>
<pre class="lang-python" data-nodeid="126206"><code data-language="python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LinearRegression
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
</code></pre>
<p data-nodeid="126207">然后，我们在这里生成数据。我假设了我们的数据偏移量为 2.128，并且生成了 100 个点，作为我们的样本数据。</p>
<pre class="lang-python" data-nodeid="126208"><code data-language="python"><span class="hljs-comment">#生成数据的方法</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">generateData</span>():</span>
    X = []
    y = []
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>, <span class="hljs-number">100</span>):
        tem_x = []
        tem_x.append(i)
        X.append(tem_x)
        tem_y = []
        tem_y.append(i + <span class="hljs-number">2.128</span> + np.random.uniform(<span class="hljs-number">-15</span>,<span class="hljs-number">15</span>))
        y.append(tem_y)
    plt.scatter(X, y, alpha=<span class="hljs-number">0.6</span>) <span class="hljs-comment"># 绘制散点图，透明度为0.6（这样颜色浅一点，比较好看）</span>
    <span class="hljs-comment">#plt.show()</span>
    <span class="hljs-keyword">return</span> X,y
</code></pre>
<p data-nodeid="132980">生成完的数据可以在下面的图中看到。</p>
<p data-nodeid="132981" class=""><img src="https://s0.lgstatic.com/i/image/M00/59/69/CgqCHl9xfF6ACR9VAAAz0fDWSXE796.png" alt="Drawing 5.png" data-nodeid="132985"></p>


<p data-nodeid="126211">在我们的主方法中，首先使用生成样本的方法生成了我们的数据，然后这次使用了 sklearn 中自带的数据切割方法对数据进行了切分，80% 作为训练集、20% 作为测试集。然后调用了线性回归算法，并使用预测方法对测试数据进行预测。</p>
<pre class="lang-python" data-nodeid="126212"><code data-language="python"><span class="hljs-comment">#主方法</span>
<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    np.random.seed(<span class="hljs-number">0</span>)
    X,y = generateData()
    print(len(X))
    X_train,X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="hljs-number">0.2</span>, random_state=<span class="hljs-number">0</span>)
    regressor = LinearRegression()
    regressor.fit(X_train, y_train)
    y_result = regressor.predict(X_test)
    plt.plot(X_test, y_result, color=<span class="hljs-string">'red'</span>,alpha=<span class="hljs-number">0.6</span>, linewidth=<span class="hljs-number">3</span>,    label=<span class="hljs-string">'Predicted Line'</span>) <span class="hljs-comment"># plotting</span>
    plt.show()
</code></pre>
<p data-nodeid="133718">在最后，根据预测的结果绘制出了算法学习到的直线，如下图显示：</p>
<p data-nodeid="133719" class=""><img src="https://s0.lgstatic.com/i/image/M00/59/69/CgqCHl9xfGWALyj0AABBPX1tjbY714.png" alt="Drawing 6.png" data-nodeid="133723"></p>


<p data-nodeid="126215">通过上面的代码，我们成功实现了使用线性回归算法来学习数据的规律，并拟合出一条直线。当新数据来了之后，直接把样本数据套入这个直线的方程中，就可以计算出结果。</p>
<h3 data-nodeid="126216">总结</h3>
<p data-nodeid="126217">完成了动手环节，让我们再来回顾一下本课时的重点内容。在这节课中，我们介绍了回归方法，其中主要讲解了线性回归，同时简单介绍了逻辑回归。它俩虽然都有“回归”这个字眼，却存在着一些区别，当然，也有着一些相似。然后我们借助工具包实现了线性回归的代码调用，并绘制了相应的图像来展示回归的效果。</p>
<p data-nodeid="134460">回归方法是非常常用的数据分析和数据挖掘方法，它的原理简单、运行快速，在很多数值型的预测需求中都发挥着巨大的价值。当然，除了这一小节中讲的线性回归和逻辑回归，还有很多不同的回归方程可以使用，以解决不同的问题。</p>


<blockquote data-nodeid="126220">
<p data-nodeid="126221">点击下方链接查看源代码（不定时更新）以及相关工具：<br>
<a href="https://github.com/icegomic/GomicDatamining/tree/master/LagouCodes" data-nodeid="126334">https://github.com/icegomic/GomicDatamining/tree/master/LagouCodes</a></p>
</blockquote></div>

</body></html>
<!DOCTYPE html><html lang="en"><head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>09 | KNN 算法：近朱者赤，近墨者黑</title>
<style type="text/css">
:root {
    --control-text-color: #777;
    --select-text-bg-color: rgba(223, 197, 223);  /*#7e66992e;*/
    
    /* side bar */
    --side-bar-bg-color: rgb(255, 255, 255);
    --active-file-text-color: #8163bd;
    --active-file-bg-color: #E9E4F0;
    --item-hover-bg-color: #E9E4F0;
    --active-file-border-color: #8163bd;

    --title-color: #6c549c;
    --font-sans-serif: 'Ubuntu', 'Source Sans Pro', sans-serif !important;
    --font-monospace: 'Fira Code', 'Roboto Mono', monospace !important;
    --purple-1: #8163bd;
    --purple-2: #79589F;
    --purple-3: #fd5eb8;
    --purple-light-1: rgba(99, 99, 172, .05);
    --purple-light-2: rgba(99, 99, 172, .1);
    --purple-light-3: rgba(99, 99, 172, .2);
    --purple-light-4: rgba(129, 99, 189, .3);
    --purple-light-5: #E9E4F0;
    --purple-light-6: rgba(129, 99, 189, .8);
}

/* html {
    font-size: 16px;
} */

body {
    font-family: var(--font-sans-serif);
    color: #34495e;
    -webkit-font-smoothing: antialiased;
    line-height: 1.6rem;
    letter-spacing: 0;
    margin: 0;
    overflow-x: hidden;
}

/* 页边距 和 页面大小 */
#write {
    padding-left: 6ch;
    padding-right: 6ch;
    margin: 0 auto;
}

#write p {
    line-height: 1.6rem;
    word-spacing: .05rem;
}

#write ol li {
    padding-left: 0.5rem;
}

#write > ul:first-child,
#write > ol:first-child {
    margin-top: 30px;
}

body > *:first-child {
    margin-top: 0 !important;
}

body > *:last-child {
    margin-bottom: 0 !important;
}

a {
    color: var(--purple-1);
    padding: 0 2px;
    text-decoration: none;
}
.md-content {
    color: var(--purple-light-6);
}
#write a {
    border-bottom: 1px solid var(--purple-1);
    color: var(--purple-1);
    text-decoration: none;
}

h1,
h2,
h3,
h4,
h5,
h6 {
    position: relative;
    margin-top: 1rem;
    margin-bottom: 0.5rem;
    /* font-weight: bold; */
    font-weight: 500 !important;
    line-height: 1.4;
    cursor: text;
    color: var(--title-color);
    font-family: var(--font-sans-serif);
}

h1:hover a.anchor,
h2:hover a.anchor,
h3:hover a.anchor,
h4:hover a.anchor,
h5:hover a.anchor,
h6:hover a.anchor {
    text-decoration: none;
}

h1 tt,
h1 code {
    font-size: inherit !important;
}
h2 tt,
h2 code {
    font-size: inherit !important;
}
h3 tt,
h3 code {
    font-size: inherit !important;
}
h4 tt,
h4 code {
    font-size: inherit !important;
}
h5 tt,
h5 code {
    font-size: inherit !important;
}
h6 tt,
h6 code {
    font-size: inherit !important;
}


h1 {
    padding-bottom: .4rem;
    font-size: 2.2rem;
    line-height: 1.3;
}
h1 {
    text-align: center;
    padding-bottom: 0.3em;
    font-size: 2.2em;
    line-height: 1.2;
    margin: 2.4em auto 1.2em;
}
h1:after {
    content: '';
    display: block;
    margin: 0.2em auto 0;
    width: 100px;
    height: 2px;
    border-bottom: 2px solid var(--title-color);
}

h2 {
    margin: 1.6em auto 0.5em;
    padding-left: 10px;
    line-height: 1.4;
    font-size: 1.8em;
    border-left: 9px solid var(--title-color);
    border-bottom: 1px solid var(--title-color);
}
h3 {
    font-size: 1.5rem;
    margin: 1.2em auto 0.5em;
}
h4 {
    font-size: 1.3rem;
}
h5 {
    font-size: 1.2rem;
}
h6 {
    font-size: 1.1rem;
}

p,
blockquote,
ul,
ol,
dl,
table {
    margin: 0.8em 0;
}

li > ol,
li > ul {
    margin: 0 0;
}

hr {
    height: 2px;
    padding: 0;
    margin: 16px 0;
    background-color: #e7e7e7;
    border: 0 none;
    overflow: hidden;
    box-sizing: content-box;
}

body > h2:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0;
}

body > h3:first-child,
body > h4:first-child,
body > h5:first-child,
body > h6:first-child {
    margin-top: 0;
    padding-top: 0;
}

a:first-child h1,
a:first-child h2,
a:first-child h3,
a:first-child h4,
a:first-child h5,
a:first-child h6 {
    margin-top: 0;
    padding-top: 0;
}

h1 p,
h2 p,
h3 p,
h4 p,
h5 p,
h6 p {
    margin-top: 0;
}

li p.first {
    display: inline-block;
}

ul,
ol {
    padding-left: 30px;
}

ul:first-child,
ol:first-child {
    margin-top: 0;
}

ul:last-child,
ol:last-child {
    margin-bottom: 0;
}

/* 引用 */
blockquote {
    /* margin-left: 1rem; */
    border-left: 4px solid var(--purple-light-4);
    padding: 10px 15px;
    color: #777;
    background-color: var(--purple-light-1);
}

/* 表格 */
table {
    padding: 0;
    word-break: initial;
}

table tr {
    border-top: 1px solid #dfe2e5;
    margin: 0;
    padding: 0;
}

/* 表格 背景色 */
table tr:nth-child(2n),
thead {
    background-color: var(--purple-light-1);
}
#write table thead th {
    background-color: var(--purple-light-2);
}

table tr th {
    font-weight: bold;
    border: 1px solid #dfe2e5;
    border-bottom: 0;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr td {
    border: 1px solid #dfe2e5;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr th:first-child,
table tr td:first-child {
    margin-top: 0;
}

table tr th:last-child,
table tr td:last-child {
    margin-bottom: 0;
}

/* 粗体 */
#write strong {
    padding: 0 2px;
    color: var(--purple-1);
}

/* 斜体 */
#write em {
    padding: 0 5px 0 2px;
    /* font-style: normal; */
    color: #42b983;
}

/* inline code */
#write code, tt {
    padding: 2px 4px;
    border-radius: 2px;
    font-family: var(--font-monospace);
    font-size: 0.92rem;
    color: var(--purple-3); 
    background-color: rgba(99, 99, 172, .05);
}

tt {
    margin: 0 2px;
}

#write .md-footnote {
    background-color: #f8f8f8;
    color: var(--purple-3);
}

/* heighlight. */
#write mark {
    background-color: #fbd3ea;
    border-radius: 2px;
    padding: 2px 4px;
    margin: 0 2px;
}

#write del {
    padding: 1px 2px;
}

.md-task-list-item > input {
    margin-left: -1.3em;
}

@media print {
    html {
        font-size: 0.9rem;
    }

    table,
    pre {
        page-break-inside: avoid;
    }

    pre {
        word-wrap: break-word;
    }
}

#write pre.md-meta-block {
    padding: 1rem;
    font-size: 85%;
    line-height: 1.45;
    background-color: #f7f7f7;
    border: 0;
    border-radius: 3px;
    color: #777777;
    margin-top: 0 !important;
}

.mathjax-block > .code-tooltip {
    bottom: .375rem;
}

/* 图片 */
.md-image > .md-meta {
    border-radius: 3px;
    font-family: var(--font-monospace);
    padding: 2px 0 0 4px;
    font-size: 0.9em;
    color: inherit;
}
p .md-image:only-child{
    width: auto;
    text-align: left;
    margin-left: 2rem;
}
.md-tag {
    color: inherit;
}
/* 当 “![shadow-随便写]()”写时，会有阴影 */
.md-image img[alt|='shadow'] {
    /* box-shadow: 0 4px 24px -6px #ddd; */
    box-shadow:var(--purple-light-2) 0px 10px 15px;
}

#write a.md-toc-inner {
    line-height: 1.6;
    white-space: pre-line;
    border-bottom: none;
    font-size: 0.9rem;
}

#typora-quick-open {
    border: 1px solid #ddd;
    background-color: #f8f8f8;
}

#typora-quick-open-item {
    background-color: #FAFAFA;
    border-color: #FEFEFE #e5e5e5 #e5e5e5 #eee;
    border-style: solid;
    border-width: 1px;
}

#md-notification:before {
    top: 10px;
}

header,
.context-menu,
.megamenu-content,
footer {
    font-family: var(--font-sans-serif);
}

.file-node-content:hover .file-node-icon,
.file-node-content:hover .file-node-open-state {
    visibility: visible;
}

.md-lang {
    color: #b4654d;
}

.html-for-mac .context-menu {
    --item-hover-bg-color: #E6F0FE;
}

/* 代码框 */
/* CodeMirror 3024 Day theme */

/* 代码段 背景 */
pre {
    --select-text-bg-color: rgba(223, 197, 223) !important;
    margin: .5em 0;
    padding: 1em 1.4em;
    border-radius: 8px;
    background: #f6f8fa;
    overflow-x: auto;
    box-sizing: border-box;
    font-size: 14px;
}

/* 边框 */
.md-fences {
    border: 1px solid #e7eaed;
    border-radius: 3px;
}

.cm-s-inner {
  padding: .25rem;
  border-radius: .25rem;
}

.cm-s-inner.CodeMirror, .cm-s-inner .CodeMirror-gutters {
  background-color: #f8f8f8 !important;
  color: #3a3432 !important;
  border: none;
}

.cm-s-inner .CodeMirror-gutters {
  color: #6d8a88;
}

.cm-s-inner .CodeMirror-cursor {
  border-left: solid thin #5c5855 !important;
}

.cm-s-inner .CodeMirror-linenumber {
  color: #807d7c;
}

.cm-s-inner .CodeMirror-line::selection, .cm-s-inner .CodeMirror-line::-moz-selection,
.cm-s-inner .CodeMirror-line > span::selection,
.cm-s-inner .CodeMirror-line > span::-moz-selection,
.cm-s-inner .CodeMirror-line > span > span::selection,
.cm-s-inner .CodeMirror-line > span > span::-moz-selection {
  background: var(--purple-light-2);
}

.cm-s-inner span.cm-comment {
  color: #cdab53;
}

.cm-s-inner span.cm-string, .cm-s-inner span.cm-string-2 {
  color: #f2b01d;
}

.cm-s-inner span.cm-number {
  color: #a34e8f;
}

.cm-s-inner span.cm-variable {
  color: #01a252;
}

.cm-s-inner span.cm-variable-2 {
  color: #01a0e4;
}

.cm-s-inner span.cm-def {
  /* color: #e8bbd0; */
  color: #e2287f;
}

.cm-s-inner span.cm-operator {
  color: #ff79c6;
}

.cm-s-inner span.cm-keyword {
  color: #db2d20;
}

.cm-s-inner span.cm-atom {
  color: #a34e8f;
}

.cm-s-inner span.cm-meta {
  color: inherit;
}

.cm-s-inner span.cm-tag {
  color: #db2d20;
}

.cm-s-inner span.cm-attribute {
  color: #01a252;
}

.cm-s-inner span.cm-qualifier {
  color: #388aa3;
}

.cm-s-inner span.cm-property {
  color: #01a252;
}

.cm-s-inner span.cm-builtin {
  color: #388aa3;
}

.cm-s-inner span.cm-variable-3, .cm-s-inner span.cm-type {
  color: #ffb86c;
}

.cm-s-inner span.cm-bracket {
  color: #3a3432;
}

.cm-s-inner span.cm-link {
  color: #a34e8f;
}

.cm-s-inner span.cm-error {
  background: #db2d20;
  color: #5c5855;
}

/* .md-fences.md-focus .cm-s-inner .CodeMirror-activeline-background {
  background: var(--purple-light-2);
} */

.cm-s-inner .CodeMirror-matchingbracket {
  text-decoration: underline;
  color: #a34e8f !important;
}

#fences-auto-suggest .active {
  background: #ddd;
}

#write .code-tooltip {
  bottom: initial;
  top: calc(100% - 1px);
  background: #f7f7f7;
  border: 1px solid #ddd;
  border-top: 0;
}

.auto-suggest-container {
  border-color: #b4b4b4;
}

.auto-suggest-container .autoComplt-hint.active {
  background: #b4b4b4;
  color: inherit;
}

/* task list */
#write .md-task-list-item > input {
  -webkit-appearance: initial;
  display: block;
  position: absolute;
  border: 1px solid #b4b4b4;
  border-radius: .25rem;
  margin-top: .1rem;
  margin-left: -1.8rem;
  height: 1.2rem;
  width: 1.2rem;
  transition: background 0.3s;
}

#write .md-task-list-item > input:focus {
  outline: none;
  box-shadow: none;
}

#write .md-task-list-item > input:hover {
  background: #ddd;
}

#write .md-task-list-item > input[checked]::before {
  content: '';
  position: absolute;
  top: 20%;
  left: 50%;
  height: 60%;
  width: 2px;
  transform: rotate(40deg);
  background: #333;
}

#write .md-task-list-item > input[checked]::after {
  content: '';
  position: absolute;
  top: 46%;
  left: 25%;
  height: 30%;
  width: 2px;
  transform: rotate(-40deg);
  background: #333;
}

#write .md-task-list-item > p {
  transition: color 0.3s, opacity 0.3s;
}

#write .md-task-list-item.task-list-done > p {
  color: #b4b4b4;
  text-decoration: line-through;
}

#write .md-task-list-item.task-list-done > p > .md-emoji {
  opacity: .5;
}

#write .md-task-list-item.task-list-done > p > .md-link > a {
  opacity: .6;
}

/* sidebar and outline */
.pin-outline .outline-active {
  color: var(--active-file-text-color); 
}

.file-list-item {
    border-bottom: 1px solid;
    border-color: var(--purple-light-5);
}

.file-list-item-summary {
    font-weight: 400;
}

.file-list-item.active {
    color: var(--active-file-text-color);
    background-color: var(--purple-light-5);
}

.file-tree-node.active>.file-node-background {
    background-color: var(--purple-light-5);
    font-weight: 700;
} 

.file-tree-node.active>.file-node-content {
    color: var(--active-file-text-color);
    font-weight: 700;
}

.file-node-content {
    color: #5e676d;
}

.sidebar-tabs {
    border-bottom: none;
}
.sidebar-tab.active {
    font-weight: 400;
}

.sidebar-content-content {
    font-size: 0.9rem;
}

img {
    max-width: 100%;
}

body {
    background-color: rgb(237, 237, 237);
}
#content {
    width: 836px;
    padding: 50px;
    background: #fff;
    margin: 0 auto;
}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/purple.css*/</style><style type="text/css">.hljs{display:block;overflow-x:auto;padding:.5em;color:#383a42;background:#fafafa}.hljs-comment,.hljs-quote{color:#a0a1a7;font-style:italic}.hljs-doctag,.hljs-formula,.hljs-keyword{color:#a626a4}.hljs-deletion,.hljs-name,.hljs-section,.hljs-selector-tag,.hljs-subst{color:#e45649}.hljs-literal{color:#0184bb}.hljs-addition,.hljs-attribute,.hljs-meta-string,.hljs-regexp,.hljs-string{color:#50a14f}.hljs-built_in,.hljs-class .hljs-title{color:#c18401}.hljs-attr,.hljs-number,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-pseudo,.hljs-template-variable,.hljs-type,.hljs-variable{color:#986801}.hljs-bullet,.hljs-link,.hljs-meta,.hljs-selector-id,.hljs-symbol,.hljs-title{color:#4078f2}.hljs-emphasis{font-style:italic}.hljs-strong{font-weight:700}.hljs-link{text-decoration:underline}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/atom-one-light.min.css*/</style></head>
<body>
  <div id="content"><h1>09 | KNN 算法：近朱者赤，近墨者黑</h1><p data-nodeid="6191">你好，从这一课时开始，我们将进入“模块三：分类问题”的学习。在算法部分，我会介绍一个跟算法思想相关的小例子，然后介绍算法的优缺点和适用场景，对于部分算法我将给出算法模块的调用方法，此外一些扩展的内容我会放在最后讲解。在每一个类型的算法最后，我都尽量安排一节小小的实践课，一起来看看数据挖掘是如何做的。</p>


<p data-nodeid="5567">今天我要讲的这个算法是<strong data-nodeid="5610">最近邻算法</strong>（K-NearestNeighbor），简称 KNN 算法。</p>
<h3 data-nodeid="6435" class="">一个例子</h3>

<p data-nodeid="5569">有一句老话叫作“物以类聚、人以群分”。想象我们在一个特别的社区里，一条清澈的小河从社区中心流过，小河左侧环境优美，住着一群有钱人，家家户户都是别墅；而小河的另一侧，住着大片贫民，用茅草和纸板搭建的临时住所密密麻麻的。这时有一个新的住户从外面搬进了这个社区，他住在了小河的左侧，此时社区里就传开了消息：“我们这又搬来了一户有钱人家。”可是谁都不认识他，也看不到他的银行账户，为什么就认定他是有钱人呢？那是因为他跟有钱人住在一起了。故事到了这里，也就说明了最近邻算法的思路：“你跟谁住得近，你就跟谁是同一类”。</p>
<h3 data-nodeid="6679" class="">算法原理</h3>

<p data-nodeid="5571">有了思路，我们再来看看原理，KNN 算法是如何处理的。用一句话来解释 KNN 算法原理，那就是找到 K 个与新数据最近的样本，取样本中最多的一个类别作为新数据的类别。在前面的例子中，找到和新搬进来的一户人家住的<strong data-nodeid="5619">距离最近的 K 户人家</strong>，看看 K 户人家中是有钱人多还是穷人多，取多的那个类别作为新搬来这户的类别。所以，显然他住在富人区，那附近就会有更多的富人。</p>
<p data-nodeid="7157">这里面我们提到了一个<strong data-nodeid="7168">距离最近</strong>，关于距离该怎么计算呢？最常见的一个计算方法就是<strong data-nodeid="7169">欧式距离</strong>，即两点之间的连线，如果放在地图上就是两个房子的直线距离。当然除了欧式距离，还有很多距离计算的方式，比如曼哈顿距离、切比雪夫距离等。</p>
<p data-nodeid="7158" class=""><img src="https://s0.lgstatic.com/i/image/M00/47/33/Ciqc1F9HW3CAeptMAAIa-9HbVTg67.jpeg" alt="image.jpeg" data-nodeid="7172"></p>


<h3 data-nodeid="9969" class="">算法的优缺点</h3>

<p data-nodeid="5575">如此简单的算法都有哪些优缺点呢？下面我结合使用场景进行分析。</p>
<h4 data-nodeid="9713" class="">优点</h4>

<p data-nodeid="7415" class=""><strong data-nodeid="7420">简单易实现：</strong> 刚把 KNN 算法介绍完了，是不是很简单？从上面的内容可以看出来，KNN 算法最后实际上并没有抽象出任何模型，而是把全部的数据集直接当作模型本身，当一条新数据来了之后跟数据集里面的每一条数据进行对比。</p>

<p data-nodeid="5578">所以可以看到 KNN 算法的一些优点，首当其冲的就是这个算法简单，简单到都不需要进行什么训练了，只要把样本数据整理好了，就结束了，来一条新数据就可以进行预测了。</p>
<p data-nodeid="7665" class=""><strong data-nodeid="7670">对于边界不规则的数据效果较好：</strong> 可以想到，我们最终的预测是把未知数据作为中心点，然后画一个圈，使得圈里有 K 个数据，所以对于边界不规则的数据，要比线性的分类器效果更好。因为线性分类器可以理解成画一条线来分类，不规则的数据则很难找到一条线将其分成左右两边。</p>

<h4 data-nodeid="9457" class="">缺点</h4>


<p data-nodeid="7917" class=""><strong data-nodeid="7922">只适合小数据集：</strong> 正是因为这个算法太简单，每次预测新数据都需要使用全部的数据集，所以如果数据集太大，就会消耗非常长的时间，占用非常大的存储空间。</p>

<p data-nodeid="8171" class=""><strong data-nodeid="8176">数据不平衡效果不好：</strong> 如果数据集中的数据不平衡，有的类别数据特别多，有的类别数据特别少，那么这种方法就会失效了，因为特别多的数据最后在投票的时候会更有竞争优势。</p>

<p data-nodeid="8427" class=""><strong data-nodeid="8432">必须要做数据标准化：</strong> 由于使用距离来进行计算，如果数据量纲不同，数值较大的字段影响就会变大，所以需要对数据进行标准化，比如都转换到 0-1 的区间。</p>

<p data-nodeid="8685" class=""><strong data-nodeid="8690">不适合特征维度太多的数据：</strong> 由于我们只能处理小数据集，如果数据的维度太多，那么样本在每个维度上的分布就很少。比如我们只有三个样本，每个样本只有一个维度，这比每个样本有三个维度特征要明显很多。</p>

<h3 data-nodeid="8945" class="">关于 K 的选取</h3>

<p data-nodeid="5586">K 值的选取会影响到模型的效果。在极端情况下，如果 K 取 1，由于富人区人均面积都很大，家里可能是别墅加后花园，富人与富人房子的距离相对较远，那个恰好住在河边的人可能跟河对面的一户贫民家最近，那么这个新人就会被判定为贫民。</p>
<p data-nodeid="5587">如果 K 取值与数据集的大小一样，那么也可想而知，由于贫民的人数户数都远远多于富人，那么所有新进来的人，不管他住哪里都会被判定为贫民。这种情况下，最终结果就是整个样本中占多数的分类的结果，这个模型也就没有什么作用了。</p>
<p data-nodeid="5588">用我们前面学过的内容来看，当<strong data-nodeid="5675">K 越小的时候容易过拟合</strong>，因为结果的判断与某一个点强相关。而<strong data-nodeid="5676">K 越大的时候容易欠拟合</strong>，因为要考虑所有样本的情况，那就等于什么都不考虑。</p>
<p data-nodeid="5589">对于 K 的取值，一种显而易见的办法就是从 1 开始不断地尝试，查看准确率。随着 K 的增加，一般情况下准确率会先变大后变小，然后选取效果最好的那个 K 值就好了。当然，关于 K 最好使用奇数，因为偶数在投票的时候就困难了，如果两个类别的投票数量是一样的，那就没办法抉择了，只能随机选一个。</p>
<p data-nodeid="5590">所以选取一个合适的 K 值也是 KNN 算法在实现时候的一个难点，需要根据经验和效果去进行尝试。</p>
<h3 data-nodeid="10225" class="">尝试动手</h3>

<p data-nodeid="5592">接下来，我们尝试借助代码来使用 KNN 算法。今天的动手环节可能要多一点，因为还涉及一些周边的东西，所以我会把前后的代码都写上，包括数据集获取、数据的处理以及训练和预测等环节，在后面一些算法的动手环节就不需要再去重复了。</p>
<p data-nodeid="5593">首先是导入我们所需要的依赖库：</p>
<pre class="lang-dart" data-nodeid="13031"><code data-language="dart">from sklearn <span class="hljs-keyword">import</span> datasets&nbsp; #sklearn的数据集
from sklearn.neighbors <span class="hljs-keyword">import</span> KNeighborsClassifier #sklearn模块的KNN类
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np #矩阵运算库numpy
np.random.seed(<span class="hljs-number">0</span>)&nbsp;&nbsp;
#设置随机种子，不设置的话默认是按系统时间作为参数，设置后可以保证我们每次产生的随机数是一样的
</code></pre>











<p data-nodeid="5595">在这里我们使用一个叫作鸢尾花数据集的数据，这个数据集里面有 150 条数据，共有 3 个类别，即 Setosa 鸢尾花、Versicolour 鸢尾花和 Virginica 鸢尾花，每个类别有 50 条数据，每条数据有 4 个维度，分别记录了鸢尾花的花萼长度、花萼宽度、花瓣长度和花瓣宽度。</p>
<pre class="lang-yaml" data-nodeid="17111"><code data-language="yaml"><span class="hljs-string">iris=datasets.load_iris()</span> <span class="hljs-comment">#获取鸢尾花数据集</span>
<span class="hljs-string">iris_x=iris.data</span>&nbsp; &nbsp;<span class="hljs-comment">#数据部分</span>
<span class="hljs-string">iris_y=iris.target</span>&nbsp; <span class="hljs-comment">#类别部分</span>
<span class="hljs-comment">#从150条数据中选140条作为训练集，10条作为测试集。permutation 接收一个数作为参数(这里为数据集长度150),产生一个0-149乱序一维数组</span>
<span class="hljs-string">randomarr=</span> <span class="hljs-string">np.random.permutation(len(iris_x))</span>
<span class="hljs-string">iris_x_train</span> <span class="hljs-string">=</span> <span class="hljs-string">iris_x[randomarr[:-10]]</span> <span class="hljs-comment">#训练集数据</span>
<span class="hljs-string">iris_y_train</span> <span class="hljs-string">=</span> <span class="hljs-string">iris_y[randomarr[:-10]]</span> <span class="hljs-comment">#训练集标签</span>
<span class="hljs-string">iris_x_test</span>&nbsp;&nbsp;<span class="hljs-string">=</span> <span class="hljs-string">iris_x[randomarr[-10:]]</span> <span class="hljs-comment">#测试集数据</span>
<span class="hljs-string">iris_y_test</span>&nbsp;&nbsp;<span class="hljs-string">=</span> <span class="hljs-string">iris_y[randomarr[-10:]]</span> <span class="hljs-comment">#测试集标签</span>
<span class="hljs-comment">#定义一个knn分类器对象</span>
<span class="hljs-string">knn</span> <span class="hljs-string">=</span> <span class="hljs-string">KNeighborsClassifier()</span>
<span class="hljs-comment">#调用该对象的训练方法，主要接收两个参数：训练数据集及其类别标签</span>
<span class="hljs-string">knn.fit(iris_x_train,</span> <span class="hljs-string">iris_y_train)</span>&nbsp;&nbsp;
<span class="hljs-comment">#调用预测方法，主要接收一个参数：测试数据集</span>
<span class="hljs-string">iris_y_predict</span> <span class="hljs-string">=</span> <span class="hljs-string">knn.predict(iris_x_test)</span>
<span class="hljs-comment">#计算各测试样本预测的概率值 这里我们没有用概率值，但是在实际工作中可能会参考概率值来进行最后结果的筛选，而不是直接使用给出的预测标签</span>
<span class="hljs-string">probility=knn.predict_proba(iris_x_test)</span>&nbsp;&nbsp;
<span class="hljs-comment">#计算与最后一个测试样本距离最近的5个点，返回的是这些样本的序号组成的数组</span>
<span class="hljs-string">neighborpoint=knn.kneighbors([iris_x_test[-1]],5)</span>
<span class="hljs-comment">#调用该对象的打分方法，计算出准确率</span>
<span class="hljs-string">score=knn.score(iris_x_test,iris_y_test,sample_weight=None)</span>
<span class="hljs-comment">#输出测试的结果</span>
<span class="hljs-string">print('iris_y_predict</span> <span class="hljs-string">=</span> <span class="hljs-string">')&nbsp;&nbsp;
print(iris_y_predict)&nbsp;&nbsp;
#输出原始测试数据集的正确标签，以方便对比
print('</span><span class="hljs-string">iris_y_test</span> <span class="hljs-string">=</span> <span class="hljs-string">')
print(iris_y_test)&nbsp;&nbsp;&nbsp;
&nbsp;
#输出准确率计算结果
print('</span><span class="hljs-string">Accuracy:',score)</span>
</code></pre>
















<p data-nodeid="5597">下面是输出的结果：</p>
<pre class="lang-java" data-nodeid="18131"><code data-language="java">iris_y_predict = 
[<span class="hljs-number">1</span> <span class="hljs-number">2</span> <span class="hljs-number">1</span> <span class="hljs-number">0</span> <span class="hljs-number">0</span> <span class="hljs-number">0</span> <span class="hljs-number">2</span> <span class="hljs-number">1</span> <span class="hljs-number">2</span> <span class="hljs-number">0</span>]
iris_y_test = 
[<span class="hljs-number">1</span> <span class="hljs-number">1</span> <span class="hljs-number">1</span> <span class="hljs-number">0</span> <span class="hljs-number">0</span> <span class="hljs-number">0</span> <span class="hljs-number">2</span> <span class="hljs-number">1</span> <span class="hljs-number">2</span> <span class="hljs-number">0</span>]
Accuracy: <span class="hljs-number">0.9</span>
</code></pre>




<p data-nodeid="18386">可以看到，该模型的准确率为0.9，其中第二个数据预测错误了。</p>
<p data-nodeid="18387">经过上面的一个动手尝试，我们已经成功地实践了KNN算法，并使用它对鸢尾花数据进行了分类计算，不知道你是不是有点小激动？当然，关于里面的很多细节这里都没有涉及，希望大家接下来能够更加深入地去探索。</p>

<h3 data-nodeid="18644" class="">总结</h3>

<p data-nodeid="5943">这一小节，我们开始真正走进了一个算法之中，去研究算法的奥秘。当然，我期望以一种简单易学的方式向你介绍算法的原理，并去掉了那些让人头疼的计算公式。在这一节里，我介绍了KNN分类算法，从一个例子开始，然后引入了它的原理，并希望你能了解它的优缺点，对于后面的算法，我也会沿用这种方式去介绍。最后，我还写出了一段简单的代码，如果你已经在电脑上安装了 Python，那你可以复制并直接运行它，当然我希望你能够自己去敲一遍代码，这样也能够加深你的印象。</p></div>

</body></html>
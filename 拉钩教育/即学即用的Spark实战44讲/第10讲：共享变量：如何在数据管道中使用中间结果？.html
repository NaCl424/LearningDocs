<!DOCTYPE html><html lang="en"><head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>第10讲：共享变量：如何在数据管道中使用中间结果？</title>
<style type="text/css">
:root {
    --control-text-color: #777;
    --select-text-bg-color: rgba(223, 197, 223);  /*#7e66992e;*/
    
    /* side bar */
    --side-bar-bg-color: rgb(255, 255, 255);
    --active-file-text-color: #8163bd;
    --active-file-bg-color: #E9E4F0;
    --item-hover-bg-color: #E9E4F0;
    --active-file-border-color: #8163bd;

    --title-color: #6c549c;
    --font-sans-serif: 'Ubuntu', 'Source Sans Pro', sans-serif !important;
    --font-monospace: 'Fira Code', 'Roboto Mono', monospace !important;
    --purple-1: #8163bd;
    --purple-2: #79589F;
    --purple-3: #fd5eb8;
    --purple-light-1: rgba(99, 99, 172, .05);
    --purple-light-2: rgba(99, 99, 172, .1);
    --purple-light-3: rgba(99, 99, 172, .2);
    --purple-light-4: rgba(129, 99, 189, .3);
    --purple-light-5: #E9E4F0;
    --purple-light-6: rgba(129, 99, 189, .8);
}

/* html {
    font-size: 16px;
} */

body {
    font-family: var(--font-sans-serif);
    color: #34495e;
    -webkit-font-smoothing: antialiased;
    line-height: 1.6rem;
    letter-spacing: 0;
    margin: 0;
    overflow-x: hidden;
}

/* 页边距 和 页面大小 */
#write {
    padding-left: 6ch;
    padding-right: 6ch;
    margin: 0 auto;
}

#write p {
    line-height: 1.6rem;
    word-spacing: .05rem;
}

#write ol li {
    padding-left: 0.5rem;
}

#write > ul:first-child,
#write > ol:first-child {
    margin-top: 30px;
}

body > *:first-child {
    margin-top: 0 !important;
}

body > *:last-child {
    margin-bottom: 0 !important;
}

a {
    color: var(--purple-1);
    padding: 0 2px;
    text-decoration: none;
}
.md-content {
    color: var(--purple-light-6);
}
#write a {
    border-bottom: 1px solid var(--purple-1);
    color: var(--purple-1);
    text-decoration: none;
}

h1,
h2,
h3,
h4,
h5,
h6 {
    position: relative;
    margin-top: 1rem;
    margin-bottom: 0.5rem;
    /* font-weight: bold; */
    font-weight: 500 !important;
    line-height: 1.4;
    cursor: text;
    color: var(--title-color);
    font-family: var(--font-sans-serif);
}

h1:hover a.anchor,
h2:hover a.anchor,
h3:hover a.anchor,
h4:hover a.anchor,
h5:hover a.anchor,
h6:hover a.anchor {
    text-decoration: none;
}

h1 tt,
h1 code {
    font-size: inherit !important;
}
h2 tt,
h2 code {
    font-size: inherit !important;
}
h3 tt,
h3 code {
    font-size: inherit !important;
}
h4 tt,
h4 code {
    font-size: inherit !important;
}
h5 tt,
h5 code {
    font-size: inherit !important;
}
h6 tt,
h6 code {
    font-size: inherit !important;
}


h1 {
    padding-bottom: .4rem;
    font-size: 2.2rem;
    line-height: 1.3;
}
h1 {
    text-align: center;
    padding-bottom: 0.3em;
    font-size: 2.2em;
    line-height: 1.2;
    margin: 2.4em auto 1.2em;
}
h1:after {
    content: '';
    display: block;
    margin: 0.2em auto 0;
    width: 100px;
    height: 2px;
    border-bottom: 2px solid var(--title-color);
}

h2 {
    margin: 1.6em auto 0.5em;
    padding-left: 10px;
    line-height: 1.4;
    font-size: 1.8em;
    border-left: 9px solid var(--title-color);
    border-bottom: 1px solid var(--title-color);
}
h3 {
    font-size: 1.5rem;
    margin: 1.2em auto 0.5em;
}
h4 {
    font-size: 1.3rem;
}
h5 {
    font-size: 1.2rem;
}
h6 {
    font-size: 1.1rem;
}

p,
blockquote,
ul,
ol,
dl,
table {
    margin: 0.8em 0;
}

li > ol,
li > ul {
    margin: 0 0;
}

hr {
    height: 2px;
    padding: 0;
    margin: 16px 0;
    background-color: #e7e7e7;
    border: 0 none;
    overflow: hidden;
    box-sizing: content-box;
}

body > h2:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0;
}

body > h3:first-child,
body > h4:first-child,
body > h5:first-child,
body > h6:first-child {
    margin-top: 0;
    padding-top: 0;
}

a:first-child h1,
a:first-child h2,
a:first-child h3,
a:first-child h4,
a:first-child h5,
a:first-child h6 {
    margin-top: 0;
    padding-top: 0;
}

h1 p,
h2 p,
h3 p,
h4 p,
h5 p,
h6 p {
    margin-top: 0;
}

li p.first {
    display: inline-block;
}

ul,
ol {
    padding-left: 30px;
}

ul:first-child,
ol:first-child {
    margin-top: 0;
}

ul:last-child,
ol:last-child {
    margin-bottom: 0;
}

/* 引用 */
blockquote {
    /* margin-left: 1rem; */
    border-left: 4px solid var(--purple-light-4);
    padding: 10px 15px;
    color: #777;
    background-color: var(--purple-light-1);
}

/* 表格 */
table {
    padding: 0;
    word-break: initial;
}

table tr {
    border-top: 1px solid #dfe2e5;
    margin: 0;
    padding: 0;
}

/* 表格 背景色 */
table tr:nth-child(2n),
thead {
    background-color: var(--purple-light-1);
}
#write table thead th {
    background-color: var(--purple-light-2);
}

table tr th {
    font-weight: bold;
    border: 1px solid #dfe2e5;
    border-bottom: 0;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr td {
    border: 1px solid #dfe2e5;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr th:first-child,
table tr td:first-child {
    margin-top: 0;
}

table tr th:last-child,
table tr td:last-child {
    margin-bottom: 0;
}

/* 粗体 */
#write strong {
    padding: 0 2px;
    color: var(--purple-1);
}

/* 斜体 */
#write em {
    padding: 0 5px 0 2px;
    /* font-style: normal; */
    color: #42b983;
}

/* inline code */
#write code, tt {
    padding: 2px 4px;
    border-radius: 2px;
    font-family: var(--font-monospace);
    font-size: 0.92rem;
    color: var(--purple-3); 
    background-color: rgba(99, 99, 172, .05);
}

tt {
    margin: 0 2px;
}

#write .md-footnote {
    background-color: #f8f8f8;
    color: var(--purple-3);
}

/* heighlight. */
#write mark {
    background-color: #fbd3ea;
    border-radius: 2px;
    padding: 2px 4px;
    margin: 0 2px;
}

#write del {
    padding: 1px 2px;
}

.md-task-list-item > input {
    margin-left: -1.3em;
}

@media print {
    html {
        font-size: 0.9rem;
    }

    table,
    pre {
        page-break-inside: avoid;
    }

    pre {
        word-wrap: break-word;
    }
}

#write pre.md-meta-block {
    padding: 1rem;
    font-size: 85%;
    line-height: 1.45;
    background-color: #f7f7f7;
    border: 0;
    border-radius: 3px;
    color: #777777;
    margin-top: 0 !important;
}

.mathjax-block > .code-tooltip {
    bottom: .375rem;
}

/* 图片 */
.md-image > .md-meta {
    border-radius: 3px;
    font-family: var(--font-monospace);
    padding: 2px 0 0 4px;
    font-size: 0.9em;
    color: inherit;
}
p .md-image:only-child{
    width: auto;
    text-align: left;
    margin-left: 2rem;
}
.md-tag {
    color: inherit;
}
/* 当 “![shadow-随便写]()”写时，会有阴影 */
.md-image img[alt|='shadow'] {
    /* box-shadow: 0 4px 24px -6px #ddd; */
    box-shadow:var(--purple-light-2) 0px 10px 15px;
}

#write a.md-toc-inner {
    line-height: 1.6;
    white-space: pre-line;
    border-bottom: none;
    font-size: 0.9rem;
}

#typora-quick-open {
    border: 1px solid #ddd;
    background-color: #f8f8f8;
}

#typora-quick-open-item {
    background-color: #FAFAFA;
    border-color: #FEFEFE #e5e5e5 #e5e5e5 #eee;
    border-style: solid;
    border-width: 1px;
}

#md-notification:before {
    top: 10px;
}

header,
.context-menu,
.megamenu-content,
footer {
    font-family: var(--font-sans-serif);
}

.file-node-content:hover .file-node-icon,
.file-node-content:hover .file-node-open-state {
    visibility: visible;
}

.md-lang {
    color: #b4654d;
}

.html-for-mac .context-menu {
    --item-hover-bg-color: #E6F0FE;
}

/* 代码框 */
/* CodeMirror 3024 Day theme */

/* 代码段 背景 */
pre {
    --select-text-bg-color: rgba(223, 197, 223) !important;
    margin: .5em 0;
    padding: 1em 1.4em;
    border-radius: 8px;
    background: #f6f8fa;
    overflow-x: auto;
    box-sizing: border-box;
    font-size: 14px;
}

/* 边框 */
.md-fences {
    border: 1px solid #e7eaed;
    border-radius: 3px;
}

.cm-s-inner {
  padding: .25rem;
  border-radius: .25rem;
}

.cm-s-inner.CodeMirror, .cm-s-inner .CodeMirror-gutters {
  background-color: #f8f8f8 !important;
  color: #3a3432 !important;
  border: none;
}

.cm-s-inner .CodeMirror-gutters {
  color: #6d8a88;
}

.cm-s-inner .CodeMirror-cursor {
  border-left: solid thin #5c5855 !important;
}

.cm-s-inner .CodeMirror-linenumber {
  color: #807d7c;
}

.cm-s-inner .CodeMirror-line::selection, .cm-s-inner .CodeMirror-line::-moz-selection,
.cm-s-inner .CodeMirror-line > span::selection,
.cm-s-inner .CodeMirror-line > span::-moz-selection,
.cm-s-inner .CodeMirror-line > span > span::selection,
.cm-s-inner .CodeMirror-line > span > span::-moz-selection {
  background: var(--purple-light-2);
}

.cm-s-inner span.cm-comment {
  color: #cdab53;
}

.cm-s-inner span.cm-string, .cm-s-inner span.cm-string-2 {
  color: #f2b01d;
}

.cm-s-inner span.cm-number {
  color: #a34e8f;
}

.cm-s-inner span.cm-variable {
  color: #01a252;
}

.cm-s-inner span.cm-variable-2 {
  color: #01a0e4;
}

.cm-s-inner span.cm-def {
  /* color: #e8bbd0; */
  color: #e2287f;
}

.cm-s-inner span.cm-operator {
  color: #ff79c6;
}

.cm-s-inner span.cm-keyword {
  color: #db2d20;
}

.cm-s-inner span.cm-atom {
  color: #a34e8f;
}

.cm-s-inner span.cm-meta {
  color: inherit;
}

.cm-s-inner span.cm-tag {
  color: #db2d20;
}

.cm-s-inner span.cm-attribute {
  color: #01a252;
}

.cm-s-inner span.cm-qualifier {
  color: #388aa3;
}

.cm-s-inner span.cm-property {
  color: #01a252;
}

.cm-s-inner span.cm-builtin {
  color: #388aa3;
}

.cm-s-inner span.cm-variable-3, .cm-s-inner span.cm-type {
  color: #ffb86c;
}

.cm-s-inner span.cm-bracket {
  color: #3a3432;
}

.cm-s-inner span.cm-link {
  color: #a34e8f;
}

.cm-s-inner span.cm-error {
  background: #db2d20;
  color: #5c5855;
}

/* .md-fences.md-focus .cm-s-inner .CodeMirror-activeline-background {
  background: var(--purple-light-2);
} */

.cm-s-inner .CodeMirror-matchingbracket {
  text-decoration: underline;
  color: #a34e8f !important;
}

#fences-auto-suggest .active {
  background: #ddd;
}

#write .code-tooltip {
  bottom: initial;
  top: calc(100% - 1px);
  background: #f7f7f7;
  border: 1px solid #ddd;
  border-top: 0;
}

.auto-suggest-container {
  border-color: #b4b4b4;
}

.auto-suggest-container .autoComplt-hint.active {
  background: #b4b4b4;
  color: inherit;
}

/* task list */
#write .md-task-list-item > input {
  -webkit-appearance: initial;
  display: block;
  position: absolute;
  border: 1px solid #b4b4b4;
  border-radius: .25rem;
  margin-top: .1rem;
  margin-left: -1.8rem;
  height: 1.2rem;
  width: 1.2rem;
  transition: background 0.3s;
}

#write .md-task-list-item > input:focus {
  outline: none;
  box-shadow: none;
}

#write .md-task-list-item > input:hover {
  background: #ddd;
}

#write .md-task-list-item > input[checked]::before {
  content: '';
  position: absolute;
  top: 20%;
  left: 50%;
  height: 60%;
  width: 2px;
  transform: rotate(40deg);
  background: #333;
}

#write .md-task-list-item > input[checked]::after {
  content: '';
  position: absolute;
  top: 46%;
  left: 25%;
  height: 30%;
  width: 2px;
  transform: rotate(-40deg);
  background: #333;
}

#write .md-task-list-item > p {
  transition: color 0.3s, opacity 0.3s;
}

#write .md-task-list-item.task-list-done > p {
  color: #b4b4b4;
  text-decoration: line-through;
}

#write .md-task-list-item.task-list-done > p > .md-emoji {
  opacity: .5;
}

#write .md-task-list-item.task-list-done > p > .md-link > a {
  opacity: .6;
}

/* sidebar and outline */
.pin-outline .outline-active {
  color: var(--active-file-text-color); 
}

.file-list-item {
    border-bottom: 1px solid;
    border-color: var(--purple-light-5);
}

.file-list-item-summary {
    font-weight: 400;
}

.file-list-item.active {
    color: var(--active-file-text-color);
    background-color: var(--purple-light-5);
}

.file-tree-node.active>.file-node-background {
    background-color: var(--purple-light-5);
    font-weight: 700;
} 

.file-tree-node.active>.file-node-content {
    color: var(--active-file-text-color);
    font-weight: 700;
}

.file-node-content {
    color: #5e676d;
}

.sidebar-tabs {
    border-bottom: none;
}
.sidebar-tab.active {
    font-weight: 400;
}

.sidebar-content-content {
    font-size: 0.9rem;
}

img {
    max-width: 100%;
}

body {
    background-color: rgb(237, 237, 237);
}
#content {
    width: 836px;
    padding: 50px;
    background: #fff;
    margin: 0 auto;
}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/purple.css*/</style><style type="text/css">.hljs{display:block;overflow-x:auto;padding:.5em;color:#383a42;background:#fafafa}.hljs-comment,.hljs-quote{color:#a0a1a7;font-style:italic}.hljs-doctag,.hljs-formula,.hljs-keyword{color:#a626a4}.hljs-deletion,.hljs-name,.hljs-section,.hljs-selector-tag,.hljs-subst{color:#e45649}.hljs-literal{color:#0184bb}.hljs-addition,.hljs-attribute,.hljs-meta-string,.hljs-regexp,.hljs-string{color:#50a14f}.hljs-built_in,.hljs-class .hljs-title{color:#c18401}.hljs-attr,.hljs-number,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-pseudo,.hljs-template-variable,.hljs-type,.hljs-variable{color:#986801}.hljs-bullet,.hljs-link,.hljs-meta,.hljs-selector-id,.hljs-symbol,.hljs-title{color:#4078f2}.hljs-emphasis{font-style:italic}.hljs-strong{font-weight:700}.hljs-link{text-decoration:underline}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/atom-one-light.min.css*/</style></head>
<body>
  <div id="content"><h1>第10讲：共享变量：如何在数据管道中使用中间结果？</h1><p>今天我将为你讲解：如何用共享变量在数据管道中使用中间结果。共享变量是 Spark 中进阶特性之一，一共有两种：</p>
<ul>
<li>广播变量；</li>
<li>累加器。</li>
</ul>
<p>这两种变量可以认为是在用算子定义的数据管道外的两个全局变量，供所有计算任务使用。在 Spark 作业中，用户编写的高阶函数会在集群中的 Executor 里执行，这些 Executor 可能会用到相同的变量，这些变量被复制到每个 Executor 中，而 Executor 对变量的更新不会传回 Driver。</p>
<p>在计算任务中支持通用的可读写变量一般是低效的，即便如此，Spark 还是提供了两类共享变量：广播变量（broadcast variable）与累加器（accumulator）。当然，对于分布式变量，如果不加限制会出现一致性的问题，所以共享变量是两种非常特殊的变量。</p>
<ul>
<li>广播变量：只读；</li>
<li>累加器：只能增加。</li>
</ul>
<h3>广播变量</h3>
<p>广播变量类似于 MapReduce 中的 DistributeFile，通常来说是一份不大的数据集，一旦广播变量在 Driver 中被创建，整个数据集就会在集群中进行广播，能让所有正在运行的计算任务以只读方式访问。广播变量支持一些简单的数据类型，如整型、集合类型等，也支持很多复杂数据类型，如一些自定义的数据类型。</p>
<p>广播变量为了保证数据被广播到所有节点，使用了很多办法。这其实是一个很重要的问题，我们不能期望 100 个或者 1000 个 Executor 去连接 Driver，并拉取数据，这会让 Driver 不堪重负。Executor 采用的是通过 HTTP 连接去拉取数据，类似于 BitTorrent 点对点传输。这样的方式更具扩展性，避免了所有 Executor 都去向 Driver 请求数据而造成 Driver 故障。</p>
<p>Spark 广播机制运作方式是这样的：Driver 将已序列化的数据切分成小块，然后将其存储在自己的块管理器 BlockManager 中，当 Executor 开始运行时，每个 Executor 首先从自己的内部块管理器中试图获取广播变量，如果以前广播过，那么直接使用；如果没有，Executor 就会从 Driver 或者其他可用的 Executor 去拉取数据块。一旦拿到数据块，就会放到自己的块管理器中。供自己和其他需要拉取的 Executor 使用。这就很好地防止了 Driver 单点的性能瓶颈，如下图所示。</p>
<p><img src="https://s0.lgstatic.com/i/image/M00/09/F1/CgqCHl69BwmAP2B7AAGvkqEmVkk327.png" alt="图片1.png"></p>
<p>下面来看看如何在 Spark 作业中创建、使用广播变量。代码如下：</p>
<pre><code data-language="js" class="lang-js">scala&gt; val rdd_one = sc.parallelize(Seq(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>))
<span class="hljs-attr">rdd_one</span>: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[<span class="hljs-number">101</span>] at
parallelize at &lt;<span class="hljs-built_in">console</span>&gt;:<span class="hljs-number">25</span>
    scala&gt; val i = <span class="hljs-number">5</span>
    <span class="hljs-attr">i</span>: Int = <span class="hljs-number">5</span>
scala&gt; val bi = sc.broadcast(i)
<span class="hljs-attr">bi</span>: org.apache.spark.broadcast.Broadcast[Int] = Broadcast(<span class="hljs-number">147</span>)
scala&gt; bi.value
<span class="hljs-attr">res166</span>: Int = <span class="hljs-number">5</span>
scala&gt; rdd_one.take(<span class="hljs-number">5</span>)
<span class="hljs-attr">res164</span>: <span class="hljs-built_in">Array</span>[Int] = <span class="hljs-built_in">Array</span>(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>)
scala&gt; rdd_one.map(<span class="hljs-function"><span class="hljs-params">j</span> =&gt;</span> j + bi.value).take(<span class="hljs-number">5</span>)
<span class="hljs-attr">res165</span>: <span class="hljs-built_in">Array</span>[Int] = <span class="hljs-built_in">Array</span>(<span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>)
</code></pre>
<p>在用户定义的高阶函数中，可以直接使用广播变量的引用。下面看一个集合类型的广播变量：</p>
<pre><code>scala&gt; val rdd_one = sc.parallelize(Seq(1,2,3))
    rdd_one: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[109] at
parallelize at &lt;console&gt;:25
scala&gt; val m = scala.collection.mutable.HashMap(1 -&gt; 2, 2 -&gt; 3, 3 -&gt; 4)
    m: scala.collection.mutable.HashMap[Int,Int] = Map(2 -&gt; 3, 1 -&gt; 2, 3 -&gt; 4)
scala&gt; val bm = sc.broadcast(m)
bm:
org.apache.spark.broadcast.Broadcast[scala.collection.mutable.HashMap[Int,I
nt]] = Broadcast(178)
scala&gt; rdd_one.map(j =&gt; j * bm.value(j)).take(5)
res191: Array[Int] = Array(2, 6, 12)
</code></pre>
<p>该例中，元素乘以元素对应值得到最后结果。广播变量会持续占用内存，当我们不需要的时候，可以用 unpersist 算子将其移除，这时，如果计算任务又用到广播变量，那么就会重新拉取数据，如下：</p>
<pre><code data-language="java" class="lang-java">    ...
scala&gt; val rdd_one = sc.parallelize(Seq(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>))
rdd_one: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[<span class="hljs-number">101</span>] at
parallelize at &lt;console&gt;:<span class="hljs-number">25</span>
scala&gt; val k = <span class="hljs-number">5</span>
k: Int = <span class="hljs-number">5</span>
scala&gt; val bk = sc.broadcast(k)
bk: org.apache.spark.broadcast.Broadcast[Int] = Broadcast(<span class="hljs-number">163</span>)
scala&gt; rdd_one.map(j =&gt; j + bk.value).take(<span class="hljs-number">5</span>)
res184: Array[Int] = Array(<span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>)
scala&gt; bk.unpersist
scala&gt; rdd_one.map(j =&gt; j + bk.value).take(<span class="hljs-number">5</span>)
res186: Array[Int] = Array(<span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>)
</code></pre>
<p>你还可以使用 destroy 方法彻底销毁广播变量，调用该方法后，如果计算任务中又用到广播变量，则会抛出异常：</p>
<pre><code data-language="java" class="lang-java">scala&gt; val rdd_one = sc.parallelize(Seq(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>))
rdd_one: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[<span class="hljs-number">101</span>] at
parallelize at &lt;console&gt;:<span class="hljs-number">25</span>
scala&gt; val k = <span class="hljs-number">5</span>
k: Int = <span class="hljs-number">5</span>
scala&gt; val bk = sc.broadcast(k)
bk: org.apache.spark.broadcast.Broadcast[Int] = Broadcast(<span class="hljs-number">163</span>)
scala&gt; rdd_one.map(j =&gt; j + bk.value).take(<span class="hljs-number">5</span>)
res184: Array[Int] = Array(<span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>)
scala&gt; bk.destroy
scala&gt; rdd_one.map(j =&gt; j + bk.value).take(<span class="hljs-number">5</span>)
<span class="hljs-number">17</span>/<span class="hljs-number">05</span>/<span class="hljs-number">27</span> <span class="hljs-number">14</span>:<span class="hljs-number">07</span>:<span class="hljs-number">28</span> ERROR Utils: Exception encountered
org.apache.spark.SparkException: <span class="hljs-function">Attempted to use <span class="hljs-title">Broadcast</span><span class="hljs-params">(<span class="hljs-number">163</span>)</span> after it
was <span class="hljs-title">destroyed</span> <span class="hljs-params">(destroy at &lt;console&gt;:<span class="hljs-number">30</span>)</span>
at org.apache.spark.broadcast.Broadcast.<span class="hljs-title">assertValid</span><span class="hljs-params">(Broadcast.scala:<span class="hljs-number">144</span>)</span>
at
org.apache.spark.broadcast.TorrentBroadcast$$anonfun$writeObject$1.apply$mc
V$<span class="hljs-title">sp</span><span class="hljs-params">(TorrentBroadcast.scala:<span class="hljs-number">202</span>)</span>
at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$wri
</span></code></pre>
<p><strong>广播变量在一定数据量范围内可以有效地使作业避免 Shuffle，使计算尽可能本地运行，Spark 的 Map 端连接操作就是用广播变量实现的。</strong></p>
<p>为了让你更好地理解上面那句话的意思，我再举一个比较典型的场景，我们希望对海量的日志进行校验，日志可以简单认为是如下的格式：<br>
表 A：校验码，内容</p>
<p>也就是说，我们需要根据校验码的不同，对内容采取不同规则的校验，而检验码与校验规则的映射则存储在另外一个数据库：<br>
表 B：校验码，规则</p>
<p>这样，情况就比较清楚了，如果不考虑广播变量，我们有这么两种做法：</p>
<ol>
<li>直接使用 map 算子，在 map 算子中的自定义函数中去查询数据库，那么有多少行，就要查询多少次数据库，这样性能非常差。</li>
<li>先将表 B 查出来转化为 RDD，使用 join 算子进行连接操作后，再使用 map 算子进行处理，这样做性能会比前一种方式好很多，但是会引起大量的 Shuffle 操作，对资源消耗不小。</li>
</ol>
<p>当考虑广播变量后，我们有了这样一种做法（Python 风格伪代码）：</p>
<pre><code data-language="SQL" class="lang-SQL"><span class="hljs-comment">###表A</span>
tableA = spark.sparkcontext.textFrom('/path')
<span class="hljs-comment">###广播表B</span>
validateTable = spark.sparkcontext.broadcast(queryTable())
<span class="hljs-comment">###验证函数，在验证函数中会取得对应的校验规则进行校验</span>
def validate(validateNo,validateTable ):
......
<span class="hljs-comment">##统计校验结果</span>
validateResult = tableA.map(validate).reduceByKey((lambda x , y: x + y))
....
</code></pre>
<p>这样，相当于先将小表进行广播，广播到每个 Executor 的内存中，供 map 函数使用，这就避免了 Shuffle，虽然语义上还是 join（小表放内存），但无论是资源消耗还是执行时间，都要远优于前面两种方式。</p>
<h3>累加器</h3>
<p>与广播变量只读不同，累加器是一种只能进行增加操作的共享变量。如果你想知道记录中有多少错误数据，一种方法是针对这种错误数据编写额外逻辑，另一种方式是使用累加器。用法如下：</p>
<pre><code data-language="java" class="lang-java">    ...
scala&gt; val acc1 = sc.longAccumulator(<span class="hljs-string">"acc1"</span>)
acc1: org.apache.spark.util.LongAccumulator = LongAccumulator(id: <span class="hljs-number">10355</span>,
name: Some(acc1), value: <span class="hljs-number">0</span>)
scala&gt; val someRDD = tableRDD.map(x =&gt; {acc1.add(<span class="hljs-number">1</span>); x})
someRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[<span class="hljs-number">99</span>] at map at
&lt;console&gt;:<span class="hljs-number">29</span>
scala&gt; acc1.value
res156: Long = <span class="hljs-number">0</span> <span class="hljs-comment">/*there has been no action on the RDD so accumulator did
not get incremented*/</span>
scala&gt; someRDD.count
res157: Long = <span class="hljs-number">351</span>
scala&gt; acc1.value
res158: Long = <span class="hljs-number">351</span>
scala&gt; acc1
res145: org.apache.spark.util.LongAccumulator = LongAccumulator(id: <span class="hljs-number">10355</span>,
name: Some(acc1), value: <span class="hljs-number">351</span>)
</code></pre>
<p>上面这个例子用 SparkContext 初始化了一个长整型的累加器。LongAccumulator 方法会将累加器变量置为 0。行动算子 count 触发计算后，累加器在 map 函数中被调用，其值会一直增加，最后定格为 351。Spark 内置的累加器有如下几种。</p>
<ul>
<li>LongAccumulator：长整型累加器，用于求和、计数、求均值的 64 位整数。</li>
<li>DoubleAccumulator：双精度型累加器，用于求和、计数、求均值的双精度浮点数。</li>
<li>CollectionAccumulator[T]：集合型累加器，可以用来收集所需信息的集合。</li>
</ul>
<p>所有这些累加器都是继承自 AccumulatorV2，如果这些累加器还是不能满足用户的需求，Spark 允许自定义累加器。如果需要某两列进行汇总，无疑自定义累加器比直接编写逻辑要方便很多，例如：</p>
<p><img src="https://s0.lgstatic.com/i/image/M00/09/F1/CgqCHl69BxaAR5emAAAg3H3pKGc444.png" alt="图片2.png"></p>
<p>这个表只有两列，需要统计 A 列与 B 列的汇总值。下面来看看根据上面的逻辑如何实现一个自定义累加器。代码如下：</p>
<pre><code data-language="java" class="lang-java">	<span class="hljs-keyword">import</span> org.apache.spark.util.AccumulatorV2
	<span class="hljs-keyword">import</span> org.apache.spark.SparkConf
	<span class="hljs-keyword">import</span> org.apache.spark.SparkContext
	<span class="hljs-keyword">import</span> org.apache.spark.SparkConf
	 
	<span class="hljs-comment">// 构造一个保存累加结果的类</span>
	<span class="hljs-function"><span class="hljs-keyword">case</span> class <span class="hljs-title">SumAandB</span><span class="hljs-params">(A: Long, B: Long)</span>
	 
	class FieldAccumulator extends AccumulatorV2[SumAandB,SumAandB] </span>{
	
	<span class="hljs-keyword">private</span> <span class="hljs-keyword">var</span> A:Long = <span class="hljs-number">0L</span>
	<span class="hljs-keyword">private</span> <span class="hljs-keyword">var</span> B:Long = <span class="hljs-number">0L</span>
	    <span class="hljs-comment">// 如果A和B同时为0，则累加器值为0</span>
	    override def isZero: Boolean = A == <span class="hljs-number">0</span> &amp;&amp; B == <span class="hljs-number">0L</span>
	    <span class="hljs-comment">// 复制一个累加器</span>
	    <span class="hljs-function">override def <span class="hljs-title">copy</span><span class="hljs-params">()</span>: FieldAccumulator </span>= {
	        val newAcc = <span class="hljs-keyword">new</span> FieldAccumulator
	        newAcc.A = <span class="hljs-keyword">this</span>.A
	        newAcc.B = <span class="hljs-keyword">this</span>.B
	        newAcc
	    }
	    <span class="hljs-comment">// 重置累加器为0</span>
	    <span class="hljs-function">override def <span class="hljs-title">reset</span><span class="hljs-params">()</span>: Unit </span>= { A = <span class="hljs-number">0</span> ; B = <span class="hljs-number">0L</span> }
	    <span class="hljs-comment">// 用累加器记录汇总结果</span>
	    <span class="hljs-function">override def <span class="hljs-title">add</span><span class="hljs-params">(v: SumAandB)</span>: Unit </span>= {
	        A += v.A
	        B += v.B
	    }
	    <span class="hljs-comment">// 合并两个累加器</span>
	    <span class="hljs-function">override def <span class="hljs-title">merge</span><span class="hljs-params">(other: AccumulatorV2[SumAandB, SumAandB])</span>: Unit </span>= {
	        other match {
	        <span class="hljs-keyword">case</span> o: FieldAccumulator =&gt; {
	            A += o.A
	            B += o.B}
	        <span class="hljs-keyword">case</span> _ =&gt;
	        }
	    }
	    <span class="hljs-comment">// 当Spark调用时返回结果</span>
	    override def value: SumAandB = SumAandB(A,B)
	}
</code></pre>
<p>凡是有关键字 override 的方法，均是重载实现自己逻辑的方法。累加器调用方式如下：</p>
<pre><code data-language="java" class="lang-java"><span class="hljs-keyword">package</span> com.spark.examples.rdd
 
<span class="hljs-keyword">import</span> org.apache.spark.SparkConf
<span class="hljs-keyword">import</span> org.apache.spark.SparkContext
 
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Driver</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">App</span></span>{

  val conf = <span class="hljs-keyword">new</span> SparkConf
  val sc = <span class="hljs-keyword">new</span> SparkContext(conf)
  val filedAcc = <span class="hljs-keyword">new</span> FieldAccumulator
  sc.register(filedAcc, <span class="hljs-string">" filedAcc "</span>)
  <span class="hljs-comment">// 过滤掉表头</span>
  val tableRDD = sc.textFile(<span class="hljs-string">"table.csv"</span>).filter(_.split(<span class="hljs-string">","</span>)(<span class="hljs-number">0</span>) != <span class="hljs-string">"A"</span>)
  tableRDD.map(x =&gt; {
     val fields = x.split(<span class="hljs-string">","</span>)
     val a = fields(<span class="hljs-number">1</span>).toInt
     val b = fields(<span class="hljs-number">2</span>).toLong
     filedAcc.add(SumAandB (a, b))
     x
  }).count
}
</code></pre>
<p>最后计数器的结果为（3100, 31）。</p>
<h3>小结</h3>
<p>本课时主要介绍了 Spark 的两种共享变量，注意体会广播变量最后介绍的 map 端 join 的场景，这在实际使用中非常普遍。另外广播变量的大小，按照我的经验，要根据 Executor 和 Worker 资源来确定，几十兆、一个 G 的广播变量在大多数情况不会有什么问题，如果资源充足，那么1G~10G 以内问题也不大。</p>
<p>最后我要给你留一个思考题，请你对数据集进行空行统计。你可以先用普通算子完成后，再用累加器的方式完成，并比较两者的执行效率 ，如果有条件的，可以在生产环境中用真实数据集比较下两者之间的差异，差异会更明显。</p></div>

</body></html>
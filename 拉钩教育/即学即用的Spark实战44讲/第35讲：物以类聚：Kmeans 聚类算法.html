<!DOCTYPE html><html lang="en"><head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>第35讲：物以类聚：Kmeans 聚类算法</title>
<style type="text/css">
:root {
    --control-text-color: #777;
    --select-text-bg-color: rgba(223, 197, 223);  /*#7e66992e;*/
    
    /* side bar */
    --side-bar-bg-color: rgb(255, 255, 255);
    --active-file-text-color: #8163bd;
    --active-file-bg-color: #E9E4F0;
    --item-hover-bg-color: #E9E4F0;
    --active-file-border-color: #8163bd;

    --title-color: #6c549c;
    --font-sans-serif: 'Ubuntu', 'Source Sans Pro', sans-serif !important;
    --font-monospace: 'Fira Code', 'Roboto Mono', monospace !important;
    --purple-1: #8163bd;
    --purple-2: #79589F;
    --purple-3: #fd5eb8;
    --purple-light-1: rgba(99, 99, 172, .05);
    --purple-light-2: rgba(99, 99, 172, .1);
    --purple-light-3: rgba(99, 99, 172, .2);
    --purple-light-4: rgba(129, 99, 189, .3);
    --purple-light-5: #E9E4F0;
    --purple-light-6: rgba(129, 99, 189, .8);
}

/* html {
    font-size: 16px;
} */

body {
    font-family: var(--font-sans-serif);
    color: #34495e;
    -webkit-font-smoothing: antialiased;
    line-height: 1.6rem;
    letter-spacing: 0;
    margin: 0;
    overflow-x: hidden;
}

/* 页边距 和 页面大小 */
#write {
    padding-left: 6ch;
    padding-right: 6ch;
    margin: 0 auto;
}

#write p {
    line-height: 1.6rem;
    word-spacing: .05rem;
}

#write ol li {
    padding-left: 0.5rem;
}

#write > ul:first-child,
#write > ol:first-child {
    margin-top: 30px;
}

body > *:first-child {
    margin-top: 0 !important;
}

body > *:last-child {
    margin-bottom: 0 !important;
}

a {
    color: var(--purple-1);
    padding: 0 2px;
    text-decoration: none;
}
.md-content {
    color: var(--purple-light-6);
}
#write a {
    border-bottom: 1px solid var(--purple-1);
    color: var(--purple-1);
    text-decoration: none;
}

h1,
h2,
h3,
h4,
h5,
h6 {
    position: relative;
    margin-top: 1rem;
    margin-bottom: 0.5rem;
    /* font-weight: bold; */
    font-weight: 500 !important;
    line-height: 1.4;
    cursor: text;
    color: var(--title-color);
    font-family: var(--font-sans-serif);
}

h1:hover a.anchor,
h2:hover a.anchor,
h3:hover a.anchor,
h4:hover a.anchor,
h5:hover a.anchor,
h6:hover a.anchor {
    text-decoration: none;
}

h1 tt,
h1 code {
    font-size: inherit !important;
}
h2 tt,
h2 code {
    font-size: inherit !important;
}
h3 tt,
h3 code {
    font-size: inherit !important;
}
h4 tt,
h4 code {
    font-size: inherit !important;
}
h5 tt,
h5 code {
    font-size: inherit !important;
}
h6 tt,
h6 code {
    font-size: inherit !important;
}


h1 {
    padding-bottom: .4rem;
    font-size: 2.2rem;
    line-height: 1.3;
}
h1 {
    text-align: center;
    padding-bottom: 0.3em;
    font-size: 2.2em;
    line-height: 1.2;
    margin: 2.4em auto 1.2em;
}
h1:after {
    content: '';
    display: block;
    margin: 0.2em auto 0;
    width: 100px;
    height: 2px;
    border-bottom: 2px solid var(--title-color);
}

h2 {
    margin: 1.6em auto 0.5em;
    padding-left: 10px;
    line-height: 1.4;
    font-size: 1.8em;
    border-left: 9px solid var(--title-color);
    border-bottom: 1px solid var(--title-color);
}
h3 {
    font-size: 1.5rem;
    margin: 1.2em auto 0.5em;
}
h4 {
    font-size: 1.3rem;
}
h5 {
    font-size: 1.2rem;
}
h6 {
    font-size: 1.1rem;
}

p,
blockquote,
ul,
ol,
dl,
table {
    margin: 0.8em 0;
}

li > ol,
li > ul {
    margin: 0 0;
}

hr {
    height: 2px;
    padding: 0;
    margin: 16px 0;
    background-color: #e7e7e7;
    border: 0 none;
    overflow: hidden;
    box-sizing: content-box;
}

body > h2:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0;
}

body > h3:first-child,
body > h4:first-child,
body > h5:first-child,
body > h6:first-child {
    margin-top: 0;
    padding-top: 0;
}

a:first-child h1,
a:first-child h2,
a:first-child h3,
a:first-child h4,
a:first-child h5,
a:first-child h6 {
    margin-top: 0;
    padding-top: 0;
}

h1 p,
h2 p,
h3 p,
h4 p,
h5 p,
h6 p {
    margin-top: 0;
}

li p.first {
    display: inline-block;
}

ul,
ol {
    padding-left: 30px;
}

ul:first-child,
ol:first-child {
    margin-top: 0;
}

ul:last-child,
ol:last-child {
    margin-bottom: 0;
}

/* 引用 */
blockquote {
    /* margin-left: 1rem; */
    border-left: 4px solid var(--purple-light-4);
    padding: 10px 15px;
    color: #777;
    background-color: var(--purple-light-1);
}

/* 表格 */
table {
    padding: 0;
    word-break: initial;
}

table tr {
    border-top: 1px solid #dfe2e5;
    margin: 0;
    padding: 0;
}

/* 表格 背景色 */
table tr:nth-child(2n),
thead {
    background-color: var(--purple-light-1);
}
#write table thead th {
    background-color: var(--purple-light-2);
}

table tr th {
    font-weight: bold;
    border: 1px solid #dfe2e5;
    border-bottom: 0;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr td {
    border: 1px solid #dfe2e5;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr th:first-child,
table tr td:first-child {
    margin-top: 0;
}

table tr th:last-child,
table tr td:last-child {
    margin-bottom: 0;
}

/* 粗体 */
#write strong {
    padding: 0 2px;
    color: var(--purple-1);
}

/* 斜体 */
#write em {
    padding: 0 5px 0 2px;
    /* font-style: normal; */
    color: #42b983;
}

/* inline code */
#write code, tt {
    padding: 2px 4px;
    border-radius: 2px;
    font-family: var(--font-monospace);
    font-size: 0.92rem;
    color: var(--purple-3); 
    background-color: rgba(99, 99, 172, .05);
}

tt {
    margin: 0 2px;
}

#write .md-footnote {
    background-color: #f8f8f8;
    color: var(--purple-3);
}

/* heighlight. */
#write mark {
    background-color: #fbd3ea;
    border-radius: 2px;
    padding: 2px 4px;
    margin: 0 2px;
}

#write del {
    padding: 1px 2px;
}

.md-task-list-item > input {
    margin-left: -1.3em;
}

@media print {
    html {
        font-size: 0.9rem;
    }

    table,
    pre {
        page-break-inside: avoid;
    }

    pre {
        word-wrap: break-word;
    }
}

#write pre.md-meta-block {
    padding: 1rem;
    font-size: 85%;
    line-height: 1.45;
    background-color: #f7f7f7;
    border: 0;
    border-radius: 3px;
    color: #777777;
    margin-top: 0 !important;
}

.mathjax-block > .code-tooltip {
    bottom: .375rem;
}

/* 图片 */
.md-image > .md-meta {
    border-radius: 3px;
    font-family: var(--font-monospace);
    padding: 2px 0 0 4px;
    font-size: 0.9em;
    color: inherit;
}
p .md-image:only-child{
    width: auto;
    text-align: left;
    margin-left: 2rem;
}
.md-tag {
    color: inherit;
}
/* 当 “![shadow-随便写]()”写时，会有阴影 */
.md-image img[alt|='shadow'] {
    /* box-shadow: 0 4px 24px -6px #ddd; */
    box-shadow:var(--purple-light-2) 0px 10px 15px;
}

#write a.md-toc-inner {
    line-height: 1.6;
    white-space: pre-line;
    border-bottom: none;
    font-size: 0.9rem;
}

#typora-quick-open {
    border: 1px solid #ddd;
    background-color: #f8f8f8;
}

#typora-quick-open-item {
    background-color: #FAFAFA;
    border-color: #FEFEFE #e5e5e5 #e5e5e5 #eee;
    border-style: solid;
    border-width: 1px;
}

#md-notification:before {
    top: 10px;
}

header,
.context-menu,
.megamenu-content,
footer {
    font-family: var(--font-sans-serif);
}

.file-node-content:hover .file-node-icon,
.file-node-content:hover .file-node-open-state {
    visibility: visible;
}

.md-lang {
    color: #b4654d;
}

.html-for-mac .context-menu {
    --item-hover-bg-color: #E6F0FE;
}

/* 代码框 */
/* CodeMirror 3024 Day theme */

/* 代码段 背景 */
pre {
    --select-text-bg-color: rgba(223, 197, 223) !important;
    margin: .5em 0;
    padding: 1em 1.4em;
    border-radius: 8px;
    background: #f6f8fa;
    overflow-x: auto;
    box-sizing: border-box;
    font-size: 14px;
}

/* 边框 */
.md-fences {
    border: 1px solid #e7eaed;
    border-radius: 3px;
}

.cm-s-inner {
  padding: .25rem;
  border-radius: .25rem;
}

.cm-s-inner.CodeMirror, .cm-s-inner .CodeMirror-gutters {
  background-color: #f8f8f8 !important;
  color: #3a3432 !important;
  border: none;
}

.cm-s-inner .CodeMirror-gutters {
  color: #6d8a88;
}

.cm-s-inner .CodeMirror-cursor {
  border-left: solid thin #5c5855 !important;
}

.cm-s-inner .CodeMirror-linenumber {
  color: #807d7c;
}

.cm-s-inner .CodeMirror-line::selection, .cm-s-inner .CodeMirror-line::-moz-selection,
.cm-s-inner .CodeMirror-line > span::selection,
.cm-s-inner .CodeMirror-line > span::-moz-selection,
.cm-s-inner .CodeMirror-line > span > span::selection,
.cm-s-inner .CodeMirror-line > span > span::-moz-selection {
  background: var(--purple-light-2);
}

.cm-s-inner span.cm-comment {
  color: #cdab53;
}

.cm-s-inner span.cm-string, .cm-s-inner span.cm-string-2 {
  color: #f2b01d;
}

.cm-s-inner span.cm-number {
  color: #a34e8f;
}

.cm-s-inner span.cm-variable {
  color: #01a252;
}

.cm-s-inner span.cm-variable-2 {
  color: #01a0e4;
}

.cm-s-inner span.cm-def {
  /* color: #e8bbd0; */
  color: #e2287f;
}

.cm-s-inner span.cm-operator {
  color: #ff79c6;
}

.cm-s-inner span.cm-keyword {
  color: #db2d20;
}

.cm-s-inner span.cm-atom {
  color: #a34e8f;
}

.cm-s-inner span.cm-meta {
  color: inherit;
}

.cm-s-inner span.cm-tag {
  color: #db2d20;
}

.cm-s-inner span.cm-attribute {
  color: #01a252;
}

.cm-s-inner span.cm-qualifier {
  color: #388aa3;
}

.cm-s-inner span.cm-property {
  color: #01a252;
}

.cm-s-inner span.cm-builtin {
  color: #388aa3;
}

.cm-s-inner span.cm-variable-3, .cm-s-inner span.cm-type {
  color: #ffb86c;
}

.cm-s-inner span.cm-bracket {
  color: #3a3432;
}

.cm-s-inner span.cm-link {
  color: #a34e8f;
}

.cm-s-inner span.cm-error {
  background: #db2d20;
  color: #5c5855;
}

/* .md-fences.md-focus .cm-s-inner .CodeMirror-activeline-background {
  background: var(--purple-light-2);
} */

.cm-s-inner .CodeMirror-matchingbracket {
  text-decoration: underline;
  color: #a34e8f !important;
}

#fences-auto-suggest .active {
  background: #ddd;
}

#write .code-tooltip {
  bottom: initial;
  top: calc(100% - 1px);
  background: #f7f7f7;
  border: 1px solid #ddd;
  border-top: 0;
}

.auto-suggest-container {
  border-color: #b4b4b4;
}

.auto-suggest-container .autoComplt-hint.active {
  background: #b4b4b4;
  color: inherit;
}

/* task list */
#write .md-task-list-item > input {
  -webkit-appearance: initial;
  display: block;
  position: absolute;
  border: 1px solid #b4b4b4;
  border-radius: .25rem;
  margin-top: .1rem;
  margin-left: -1.8rem;
  height: 1.2rem;
  width: 1.2rem;
  transition: background 0.3s;
}

#write .md-task-list-item > input:focus {
  outline: none;
  box-shadow: none;
}

#write .md-task-list-item > input:hover {
  background: #ddd;
}

#write .md-task-list-item > input[checked]::before {
  content: '';
  position: absolute;
  top: 20%;
  left: 50%;
  height: 60%;
  width: 2px;
  transform: rotate(40deg);
  background: #333;
}

#write .md-task-list-item > input[checked]::after {
  content: '';
  position: absolute;
  top: 46%;
  left: 25%;
  height: 30%;
  width: 2px;
  transform: rotate(-40deg);
  background: #333;
}

#write .md-task-list-item > p {
  transition: color 0.3s, opacity 0.3s;
}

#write .md-task-list-item.task-list-done > p {
  color: #b4b4b4;
  text-decoration: line-through;
}

#write .md-task-list-item.task-list-done > p > .md-emoji {
  opacity: .5;
}

#write .md-task-list-item.task-list-done > p > .md-link > a {
  opacity: .6;
}

/* sidebar and outline */
.pin-outline .outline-active {
  color: var(--active-file-text-color); 
}

.file-list-item {
    border-bottom: 1px solid;
    border-color: var(--purple-light-5);
}

.file-list-item-summary {
    font-weight: 400;
}

.file-list-item.active {
    color: var(--active-file-text-color);
    background-color: var(--purple-light-5);
}

.file-tree-node.active>.file-node-background {
    background-color: var(--purple-light-5);
    font-weight: 700;
} 

.file-tree-node.active>.file-node-content {
    color: var(--active-file-text-color);
    font-weight: 700;
}

.file-node-content {
    color: #5e676d;
}

.sidebar-tabs {
    border-bottom: none;
}
.sidebar-tab.active {
    font-weight: 400;
}

.sidebar-content-content {
    font-size: 0.9rem;
}

img {
    max-width: 100%;
}

body {
    background-color: rgb(237, 237, 237);
}
#content {
    width: 836px;
    padding: 50px;
    background: #fff;
    margin: 0 auto;
}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/purple.css*/</style><style type="text/css">.hljs{display:block;overflow-x:auto;padding:.5em;color:#383a42;background:#fafafa}.hljs-comment,.hljs-quote{color:#a0a1a7;font-style:italic}.hljs-doctag,.hljs-formula,.hljs-keyword{color:#a626a4}.hljs-deletion,.hljs-name,.hljs-section,.hljs-selector-tag,.hljs-subst{color:#e45649}.hljs-literal{color:#0184bb}.hljs-addition,.hljs-attribute,.hljs-meta-string,.hljs-regexp,.hljs-string{color:#50a14f}.hljs-built_in,.hljs-class .hljs-title{color:#c18401}.hljs-attr,.hljs-number,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-pseudo,.hljs-template-variable,.hljs-type,.hljs-variable{color:#986801}.hljs-bullet,.hljs-link,.hljs-meta,.hljs-selector-id,.hljs-symbol,.hljs-title{color:#4078f2}.hljs-emphasis{font-style:italic}.hljs-strong{font-weight:700}.hljs-link{text-decoration:underline}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/atom-one-light.min.css*/</style></head>
<body>
  <div id="content"><h1>第35讲：物以类聚：Kmeans 聚类算法</h1><p data-nodeid="89582">在开始之前，先来看看上个课时的思考题。在配置分类器时，我们需要设置的参数主要有：</p>
<ul data-nodeid="89583">
<li data-nodeid="89584">
<p data-nodeid="89585">树的个数；</p>
</li>
<li data-nodeid="89586">
<p data-nodeid="89587">树的最大深度；</p>
</li>
<li data-nodeid="89588">
<p data-nodeid="89589">特征子集选取策略；</p>
</li>
<li data-nodeid="89590">
<p data-nodeid="89591">纯度。</p>
</li>
</ul>
<p data-nodeid="89592">在特征子集的选取策略中可以配置信息增益、信息增益率以及基尼系数。</p>
<p data-nodeid="89593">然后我们开始今天的课程。上一课时中介绍了随机森林和决策树分类器，它们都属于监督学习，本节将介绍聚类算法，它属于机器学习的另一种应用——<strong data-nodeid="89656">无监督学习</strong>。</p>
<h3 data-nodeid="89594">物以类聚</h3>
<p data-nodeid="89595">通俗地说，人们习惯将相似的东西归为一类，这就是“物以类聚”。先来看几个例子，用苹果举例，如下图所示。</p>
<p data-nodeid="89596"><img alt="Drawing 0.png" src="https://s0.lgstatic.com/i/image/M00/40/52/CgqCHl8yU0CALbDUAABrSRl7RCg892.png" data-nodeid="89661"></p>
<p data-nodeid="89597">一共有 6 个苹果，如果将这些苹果分类，我们可以很自然地将其分为两类，因为前 4 个的大小明显和后面不同。再来看看另外 6 个苹果，如下图所示。</p>
<p data-nodeid="89598"><img alt="Drawing 1.png" src="https://s0.lgstatic.com/i/image/M00/40/47/Ciqc1F8yU0eAUStOAAChV1NLmds129.png" data-nodeid="89665"></p>
<p data-nodeid="89599">对这 6 个苹果进行分类，同样很容易分为两类，前 4 个苹果的颜色和后面的明显不同。在上面的两次分类过程中，已经完成了两次聚类，聚类的依据第一次是大小，第二次是颜色。接下来看看最后 6 个苹果，如下图所示。</p>
<p data-nodeid="89600"><img alt="Drawing 2.png" src="https://s0.lgstatic.com/i/image/M00/40/47/Ciqc1F8yU0yAHHBqAAC5gQcgG5E448.png" data-nodeid="89669"></p>
<p data-nodeid="89601">现在还能一口气将这 6 个苹果进行分类吗？这 6 个苹果有大有小，有红有绿，确实令人困惑，如果再加上第 2 个和第 5 个苹果很甜、其余苹果很酸等特征，问题就更棘手了。人对于单一维度的数据很敏感，维度一多就有些力不从心，而计算机恰恰擅长处理这些数据，聚类算法就是“物以类聚”这一朴素思想的数学体现。</p>
<p data-nodeid="89602"><strong data-nodeid="89675">聚类</strong>是把相似的对象通过静态分类的方法分成不同的组别或者更多的子集，使得同一个子集中的成员对象都有相似的一些属性，常见的包括在坐标系中更加短的空间距离。一般把聚类归纳为一种非监督式学习，它与分类算法最大的不同在于训练集没有标签。</p>
<h3 data-nodeid="89603"><em data-nodeid="89680">K</em> 均值聚类算法</h3>
<p data-nodeid="89604">到目前为止，我们对聚类的理解可以用下图来表示。聚类的目标就是将相似的物体进行分组，并将其标注，图中的相似性体现在点与点之间的距离。</p>
<p data-nodeid="89605"><img alt="Drawing 3.png" src="https://s0.lgstatic.com/i/image/M00/40/47/Ciqc1F8yU1iAa_T7AADWSLFVU3A993.png" data-nodeid="89684"></p>
<p data-nodeid="89606"><em data-nodeid="89766">K</em> 均值算法是一种被广泛使用的直接聚类算法，位列数据挖掘十大算法之二，可见其影响力。 <em data-nodeid="89767">K</em> 均值算法是一种<strong data-nodeid="89768">迭代型聚类算法</strong>，它将一个给定的数据集分为用户指定的 <em data-nodeid="89769">K</em> 个聚簇，速度较快，易于修改。从上面这句话可以得出 <em data-nodeid="89770">K</em> 均值算法的输入对象为数据集 <em data-nodeid="89771">D</em> 和一个非常关键的 <em data-nodeid="89772">K</em> 值， <em data-nodeid="89773">K</em> 值也就是用户认为数据集 <em data-nodeid="89774">D</em> 应该被分为几类，数据集 <em data-nodeid="89775">D</em> 可以被认为是 <em data-nodeid="89776">d</em> 维向量空间中的一些点（ <em data-nodeid="89777">D</em> ={ <i>x<sub>i</sub></i> | <em data-nodeid="89778">i</em> = 1,…, <em data-nodeid="89779">N</em> }，其中 <em data-nodeid="89780">x<sub>i</sub>∈Rd</em> 表示数据集 <em data-nodeid="89781">D</em> 中第 <em data-nodeid="89782">i</em> 个对象）。</p>
<p data-nodeid="89607">在 <em data-nodeid="89821">K</em> 均值算法中，每个聚簇都用一个点来代表，这些聚簇用集合 <em data-nodeid="89822">C</em> ={ <i>c<sub>j</sub></i> | <em data-nodeid="89823">j</em> = 1,…, <em data-nodeid="89824">k</em> } 来表示，这 <em data-nodeid="89825">K</em> 个代表聚簇有时也被称为聚簇均值或聚簇中心。聚类算法通常用相似度的概念对点集进行分组，具体到 <em data-nodeid="89826">K</em> 均值算法，默认的相似度标准为欧氏距离。 <em data-nodeid="89827">K</em> 均值的实质是要最小化一个如下的非负代价函数：</p>
<p data-nodeid="89608"><img alt="Drawing 4.png" src="https://s0.lgstatic.com/i/image/M00/40/53/CgqCHl8yU2qAB5lTAABeO6TQn-Y438.png" data-nodeid="89830"></p>
<p data-nodeid="89609">换言之， <em data-nodeid="89854">K</em> 均值的最小化目标是每个点 <i>x<sub>i</sub></i> 和离它最近的聚簇中心 <i>c<sub>j</sub></i> 之间的欧氏距离的平方和，这也是 <em data-nodeid="89855">K</em> 均值的目标函数。</p>
<p data-nodeid="89610"><strong data-nodeid="89864">下面是</strong> K <strong data-nodeid="89865">均值算法的伪代码</strong>：</p>
<p data-nodeid="89611">输入：数据集 D，聚簇数 k</p>
<p data-nodeid="89612">输出：聚簇代表集合 C，聚簇成员向量 m</p>
<p data-nodeid="89613">/<em data-nodeid="89873">初始化聚簇代表 C</em>/</p>
<p data-nodeid="89614">从数据集 D 中随机挑选 k 个数据点3</p>
<p data-nodeid="89615">使用这 k 个数据点构成初始聚簇代表集合 C</p>
<p data-nodeid="89616">repeat</p>
<p data-nodeid="89617">/<em data-nodeid="89882">再分数据</em>/</p>
<p data-nodeid="89618">将 D 中的每个数据点重新分配至与之最近的聚簇均值</p>
<p data-nodeid="89619">更新 m（m<sub>i</sub> 表示D中第 i 个点的聚簇标识）</p>
<p data-nodeid="89620">/<em data-nodeid="89894">重定均值</em>/</p>
<p data-nodeid="89621">更新 C（c<sub>j</sub> 表示第 j 个聚簇均值）</p>
<p data-nodeid="89622">until 目标函数<br>
<img alt="Drawing 5.png" src="https://s0.lgstatic.com/i/image/M00/40/48/Ciqc1F8yU5SAc4YdAABABs5NrzY650.png" data-nodeid="89904"><br>
收敛</p>
<p data-nodeid="89623">从上面的伪代码可以看出，算法主要包括两个交替执行的步骤，即再分数据和重定均值，并且是通过随机选取 <em data-nodeid="89912">K</em> 个点来启动算法。</p>
<p data-nodeid="89624"><strong data-nodeid="89917">再分数据</strong>指的是：将每个数据点分配到当前与之最近的那个聚簇中心，同时打破了上次迭代确定的归属关系。这一步会对全部数据进行一个新的划分。</p>
<p data-nodeid="89625"><strong data-nodeid="89926">重定均值</strong>指的是：重新确定每一个聚簇中心，即计算所有分配给该聚簇的数据点的中心（如算术平均值），这也是 <em data-nodeid="89927">K</em> 均值的名称由来。</p>
<p data-nodeid="89626">当满足收敛条件时，算法停止。</p>
<h3 data-nodeid="89627">鸢尾花数据集进行聚类</h3>
<p data-nodeid="89628">本节将介绍用 <em data-nodeid="89939">K</em> 均值算法对鸢尾花数据集（也就是预处理课时中用到的 iris 数据集）进行聚类的过程，<strong data-nodeid="89940">在聚类之前，需要先对特征用 PCA 进行降维，用 Z 分数进行归一化</strong>。由于鸢尾花数据本身带有标签列（Species，一共有 3 种类型，即 setosa 、 versicolor 和 virginica ），因此最后可以用该列来评估聚类效果，代码如下：</p>
<pre class="lang-scala" data-nodeid="89629"><code data-language="scala"><span class="hljs-keyword">import</span>&nbsp;org.apache.spark.ml.feature.{<span class="hljs-type">PCA</span>,&nbsp;<span class="hljs-type">VectorAssembler</span>} 
<span class="hljs-keyword">import</span>&nbsp;org.apache.spark.sql.{<span class="hljs-type">Dataset</span>,&nbsp;<span class="hljs-type">Row</span>,&nbsp;<span class="hljs-type">SparkSession</span>} 
<span class="hljs-keyword">import</span>&nbsp;org.apache.spark.ml.feature.<span class="hljs-type">StandardScaler</span> 
<span class="hljs-keyword">import</span>&nbsp;org.apache.spark.sql.types.{<span class="hljs-type">DoubleType</span>,&nbsp;<span class="hljs-type">StringType</span>,&nbsp;<span class="hljs-type">StructField</span>,&nbsp;<span class="hljs-type">StructType</span>} 
<span class="hljs-keyword">import</span>&nbsp;org.apache.spark.ml.<span class="hljs-type">Pipeline</span> 
<span class="hljs-keyword">import</span>&nbsp;org.apache.spark.ml.feature.<span class="hljs-type">MinMaxScaler</span> 
<span class="hljs-keyword">import</span>&nbsp;org.apache.spark.ml.clustering.<span class="hljs-type">KMeans</span> 
<span class="hljs-keyword">import</span>&nbsp;org.apache.spark.ml.evaluation.<span class="hljs-type">ClusteringEvaluator</span> 

<span class="hljs-class"><span class="hljs-keyword">object</span><span class="hljs-title">&nbsp;IRISKmeans&nbsp;</span></span>{ 

&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span><span class="hljs-title">&nbsp;main</span></span>(args:&nbsp;<span class="hljs-type">Array</span>[<span class="hljs-type">String</span>]):&nbsp;<span class="hljs-type">Unit</span>&nbsp;=&nbsp;{ 

&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">val</span>&nbsp;spark&nbsp;=&nbsp;<span class="hljs-type">SparkSession</span> 
&nbsp;&nbsp;&nbsp;&nbsp;.builder() 
&nbsp;&nbsp;&nbsp;&nbsp;.master(<span class="hljs-string">"local[2]"</span>) 
&nbsp;&nbsp;&nbsp;&nbsp;.appName(<span class="hljs-string">"IRISKmeans"</span>) 
&nbsp;&nbsp;&nbsp;&nbsp;.getOrCreate() 

&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">//&nbsp;iris数据集数据结构 </span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">val</span>&nbsp;fields&nbsp;=&nbsp;<span class="hljs-type">Array</span>(<span class="hljs-string">"id"</span>,<span class="hljs-string">"SepalLength"</span>,<span class="hljs-string">"SepalWidth"</span>,<span class="hljs-string">"PetalLength"</span>,<span class="hljs-string">"PetalWidth"</span>,<span class="hljs-string">"Species"</span>) 

&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">val</span>&nbsp;fieldsType&nbsp;=&nbsp;fields.map( 
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r&nbsp;=&gt;&nbsp;<span class="hljs-keyword">if</span>&nbsp;(r&nbsp;==&nbsp;<span class="hljs-string">"id"</span>||r&nbsp;==&nbsp;<span class="hljs-string">"Species"</span>) 
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{<span class="hljs-type">StructField</span>(r,&nbsp;<span class="hljs-type">StringType</span>)} 
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">else</span>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{<span class="hljs-type">StructField</span>(r,&nbsp;<span class="hljs-type">DoubleType</span>)} 
&nbsp;&nbsp;&nbsp;&nbsp;) 

&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">val</span>&nbsp;schema&nbsp;=&nbsp;<span class="hljs-type">StructType</span>(fieldsType) 

&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">val</span>&nbsp;featureCols&nbsp;=&nbsp;<span class="hljs-type">Array</span>(<span class="hljs-string">"SepalLength"</span>,<span class="hljs-string">"SepalWidth"</span>,<span class="hljs-string">"PetalLength"</span>,<span class="hljs-string">"PetalWidth"</span>) 

&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">val</span>&nbsp;data&nbsp;=&nbsp;spark.read.schema(schema) 
&nbsp;&nbsp;&nbsp;&nbsp;.option(<span class="hljs-string">"header"</span>,&nbsp;<span class="hljs-literal">false</span>) 
&nbsp;&nbsp;&nbsp;&nbsp;.csv(<span class="hljs-string">"data/iris/"</span>) 

&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">val</span>&nbsp;vectorAssembler&nbsp;=&nbsp;<span class="hljs-keyword">new</span>&nbsp;<span class="hljs-type">VectorAssembler</span>() 
&nbsp;&nbsp;&nbsp;&nbsp;.setInputCols(featureCols) 
&nbsp;&nbsp;&nbsp;&nbsp;.setOutputCol(<span class="hljs-string">"features"</span>) 

&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">val</span>&nbsp;pca&nbsp;=&nbsp;<span class="hljs-keyword">new</span>&nbsp;<span class="hljs-type">PCA</span>() 
&nbsp;&nbsp;&nbsp;&nbsp;.setInputCol(<span class="hljs-string">"features"</span>) 
&nbsp;&nbsp;&nbsp;&nbsp;.setOutputCol(<span class="hljs-string">"pcaFeatures"</span>) 
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">//&nbsp;主成分个数，也就是降维后的维数 </span>
&nbsp;&nbsp;&nbsp;&nbsp;.setK(<span class="hljs-number">2</span>) 

&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">val</span>&nbsp;scaler&nbsp;=&nbsp;<span class="hljs-keyword">new</span>&nbsp;<span class="hljs-type">StandardScaler</span>() 
&nbsp;&nbsp;&nbsp;&nbsp;.setInputCol(<span class="hljs-string">"features"</span>) 
&nbsp;&nbsp;&nbsp;&nbsp;.setOutputCol(<span class="hljs-string">"scaledFeatures"</span>) 
&nbsp;&nbsp;&nbsp;&nbsp;.setWithStd(<span class="hljs-literal">true</span>) 
&nbsp;&nbsp;&nbsp;&nbsp;.setWithMean(<span class="hljs-literal">false</span>) 

&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">//&nbsp;设置Kmeans参数 </span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">val</span>&nbsp;kmeans&nbsp;=&nbsp;<span class="hljs-keyword">new</span>&nbsp;<span class="hljs-type">KMeans</span>() 
&nbsp;&nbsp;&nbsp;&nbsp;.setK(<span class="hljs-number">3</span>) 
&nbsp;&nbsp;&nbsp;&nbsp;.setSeed(<span class="hljs-type">System</span>.currentTimeMillis()) 
&nbsp;&nbsp;&nbsp;&nbsp;.setMaxIter(<span class="hljs-number">10</span>) 

&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">val</span>&nbsp;pipeline&nbsp;=&nbsp;<span class="hljs-keyword">new</span>&nbsp;<span class="hljs-type">Pipeline</span>() 
&nbsp;&nbsp;&nbsp;&nbsp;.setStages(<span class="hljs-type">Array</span>(vectorAssembler,pca,scaler)) 

&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">val</span>&nbsp;model&nbsp;=&nbsp;pipeline.fit(data) 

&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">val</span>&nbsp;predictions&nbsp;=&nbsp;model.transform(data) 

&nbsp;&nbsp;&nbsp;&nbsp;predictions.show() 

&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">val</span>&nbsp;evaluator&nbsp;=&nbsp;<span class="hljs-keyword">new</span>&nbsp;<span class="hljs-type">ClusteringEvaluator</span>() 

&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">val</span>&nbsp;silhouette&nbsp;=&nbsp;evaluator.evaluate(predictions) 

&nbsp;&nbsp;&nbsp;&nbsp;println(<span class="hljs-string">s"Silhouette&nbsp;with&nbsp;squared&nbsp;euclidean&nbsp;distance&nbsp;=&nbsp;<span class="hljs-subst">$silhouette</span>"</span>) 


&nbsp;&nbsp;} 

}
</code></pre>
<p data-nodeid="89630">下面是部分的聚类结果：</p>
<p data-nodeid="89631"><img alt="Drawing 6.png" src="https://s0.lgstatic.com/i/image/M00/40/53/CgqCHl8yU6WAUgR_AAJJxj-Boic557.png" data-nodeid="89944"><br>
……</p>
<p data-nodeid="89632"><img alt="Drawing 7.png" src="https://s0.lgstatic.com/i/image/M00/40/48/Ciqc1F8yU6yAKNibAAIV7Wmjm8U735.png" data-nodeid="89949"><br>
……</p>
<p data-nodeid="89633"><img alt="Drawing 8.png" src="https://s0.lgstatic.com/i/image/M00/40/53/CgqCHl8yU7OAcHxQAAIqHMXe320159.png" data-nodeid="89954"></p>
<p data-nodeid="89634">可以看到，聚类结果为 setosa 类型的样本全部被归到类 1，无一例外；versicolor 类型的样本大部分被归到类 2，极少部分被归到类 0；virginica 类型的样本大部分被归到类 0，少部分被归到类 2，结果基本正确。</p>
<h3 data-nodeid="89635">评估聚类结果</h3>
<p data-nodeid="89636">聚类是一种典型的无监督学习，与监督学习很容易评估模型性能不同，无监督学习通常没有一个标准。那么如何才能判断聚类的结果是优质的，这同样是一个值得讨论的问题。我们先来看一份数据，假设一份数据在数据空间中均匀分布，如下图所示：</p>
<p data-nodeid="89637"><img alt="Drawing 9.png" src="https://s0.lgstatic.com/i/image/M00/40/48/Ciqc1F8yU7qAbdSGAAAxoq-vQ68447.png" data-nodeid="89960"></p>
<p data-nodeid="89638">那么可以想象这份数据的聚类结果质量一定不高，数据的均匀分布导致这些聚簇没有任何实际意义。我们还可以通过霍普金斯统计量来检测变量的空间随机性，这里就不展开讲解了。</p>
<p data-nodeid="89639">一般来说，我们可以通过簇间距离和簇内距离来评估聚类质量，簇间距离指的是两个簇中心之间的距离，而簇内距离是指簇内部成员间的距离。 我们可以这样判断一次优质的聚类结果，如下图所示，有较大的簇间距离和较小的簇内距离，也就是说，优质的聚类是簇中的点尽量紧密，而簇和簇之间尽量远离。</p>
<p data-nodeid="89640"><img alt="Drawing 10.png" src="https://s0.lgstatic.com/i/image/M00/40/53/CgqCHl8yU8OAAiEJAAAyGf6HRaI127.png" data-nodeid="89965"></p>
<p data-nodeid="89641"><img alt="Drawing 11.png" src="https://s0.lgstatic.com/i/image/M00/40/53/CgqCHl8yU8mAfAFoAAAphYBFt9I725.png" data-nodeid="89968"></p>
<h3 data-nodeid="89642">小结</h3>
<p data-nodeid="89643">本课时学习了另一类有代表性的无监督学习算法：聚类算法。在编写 Pipeline 时，我们也用到了前面学习的 Transformer 来进行降维和归一化处理，有了前面的基础，相信同学们对预处理会有更深的理解。</p>
<p data-nodeid="89644">最后给大家留个<strong data-nodeid="89976">思考题</strong>：如果不进行归一化处理，那么会对聚类结果有什么影响呢？</p></div>

</body></html>
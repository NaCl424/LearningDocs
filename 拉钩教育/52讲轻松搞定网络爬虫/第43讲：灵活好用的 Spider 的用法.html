<!DOCTYPE html><html lang="en"><head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>第43讲：灵活好用的 Spider 的用法</title>
<style type="text/css">
:root {
    --control-text-color: #777;
    --select-text-bg-color: rgba(223, 197, 223);  /*#7e66992e;*/
    
    /* side bar */
    --side-bar-bg-color: rgb(255, 255, 255);
    --active-file-text-color: #8163bd;
    --active-file-bg-color: #E9E4F0;
    --item-hover-bg-color: #E9E4F0;
    --active-file-border-color: #8163bd;

    --title-color: #6c549c;
    --font-sans-serif: 'Ubuntu', 'Source Sans Pro', sans-serif !important;
    --font-monospace: 'Fira Code', 'Roboto Mono', monospace !important;
    --purple-1: #8163bd;
    --purple-2: #79589F;
    --purple-3: #fd5eb8;
    --purple-light-1: rgba(99, 99, 172, .05);
    --purple-light-2: rgba(99, 99, 172, .1);
    --purple-light-3: rgba(99, 99, 172, .2);
    --purple-light-4: rgba(129, 99, 189, .3);
    --purple-light-5: #E9E4F0;
    --purple-light-6: rgba(129, 99, 189, .8);
}

/* html {
    font-size: 16px;
} */

body {
    font-family: var(--font-sans-serif);
    color: #34495e;
    -webkit-font-smoothing: antialiased;
    line-height: 1.6rem;
    letter-spacing: 0;
    margin: 0;
    overflow-x: hidden;
}

/* 页边距 和 页面大小 */
#write {
    padding-left: 6ch;
    padding-right: 6ch;
    margin: 0 auto;
}

#write p {
    line-height: 1.6rem;
    word-spacing: .05rem;
}

#write ol li {
    padding-left: 0.5rem;
}

#write > ul:first-child,
#write > ol:first-child {
    margin-top: 30px;
}

body > *:first-child {
    margin-top: 0 !important;
}

body > *:last-child {
    margin-bottom: 0 !important;
}

a {
    color: var(--purple-1);
    padding: 0 2px;
    text-decoration: none;
}
.md-content {
    color: var(--purple-light-6);
}
#write a {
    border-bottom: 1px solid var(--purple-1);
    color: var(--purple-1);
    text-decoration: none;
}

h1,
h2,
h3,
h4,
h5,
h6 {
    position: relative;
    margin-top: 1rem;
    margin-bottom: 0.5rem;
    /* font-weight: bold; */
    font-weight: 500 !important;
    line-height: 1.4;
    cursor: text;
    color: var(--title-color);
    font-family: var(--font-sans-serif);
}

h1:hover a.anchor,
h2:hover a.anchor,
h3:hover a.anchor,
h4:hover a.anchor,
h5:hover a.anchor,
h6:hover a.anchor {
    text-decoration: none;
}

h1 tt,
h1 code {
    font-size: inherit !important;
}
h2 tt,
h2 code {
    font-size: inherit !important;
}
h3 tt,
h3 code {
    font-size: inherit !important;
}
h4 tt,
h4 code {
    font-size: inherit !important;
}
h5 tt,
h5 code {
    font-size: inherit !important;
}
h6 tt,
h6 code {
    font-size: inherit !important;
}


h1 {
    padding-bottom: .4rem;
    font-size: 2.2rem;
    line-height: 1.3;
}
h1 {
    text-align: center;
    padding-bottom: 0.3em;
    font-size: 2.2em;
    line-height: 1.2;
    margin: 2.4em auto 1.2em;
}
h1:after {
    content: '';
    display: block;
    margin: 0.2em auto 0;
    width: 100px;
    height: 2px;
    border-bottom: 2px solid var(--title-color);
}

h2 {
    margin: 1.6em auto 0.5em;
    padding-left: 10px;
    line-height: 1.4;
    font-size: 1.8em;
    border-left: 9px solid var(--title-color);
    border-bottom: 1px solid var(--title-color);
}
h3 {
    font-size: 1.5rem;
    margin: 1.2em auto 0.5em;
}
h4 {
    font-size: 1.3rem;
}
h5 {
    font-size: 1.2rem;
}
h6 {
    font-size: 1.1rem;
}

p,
blockquote,
ul,
ol,
dl,
table {
    margin: 0.8em 0;
}

li > ol,
li > ul {
    margin: 0 0;
}

hr {
    height: 2px;
    padding: 0;
    margin: 16px 0;
    background-color: #e7e7e7;
    border: 0 none;
    overflow: hidden;
    box-sizing: content-box;
}

body > h2:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0;
}

body > h3:first-child,
body > h4:first-child,
body > h5:first-child,
body > h6:first-child {
    margin-top: 0;
    padding-top: 0;
}

a:first-child h1,
a:first-child h2,
a:first-child h3,
a:first-child h4,
a:first-child h5,
a:first-child h6 {
    margin-top: 0;
    padding-top: 0;
}

h1 p,
h2 p,
h3 p,
h4 p,
h5 p,
h6 p {
    margin-top: 0;
}

li p.first {
    display: inline-block;
}

ul,
ol {
    padding-left: 30px;
}

ul:first-child,
ol:first-child {
    margin-top: 0;
}

ul:last-child,
ol:last-child {
    margin-bottom: 0;
}

/* 引用 */
blockquote {
    /* margin-left: 1rem; */
    border-left: 4px solid var(--purple-light-4);
    padding: 10px 15px;
    color: #777;
    background-color: var(--purple-light-1);
}

/* 表格 */
table {
    padding: 0;
    word-break: initial;
}

table tr {
    border-top: 1px solid #dfe2e5;
    margin: 0;
    padding: 0;
}

/* 表格 背景色 */
table tr:nth-child(2n),
thead {
    background-color: var(--purple-light-1);
}
#write table thead th {
    background-color: var(--purple-light-2);
}

table tr th {
    font-weight: bold;
    border: 1px solid #dfe2e5;
    border-bottom: 0;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr td {
    border: 1px solid #dfe2e5;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr th:first-child,
table tr td:first-child {
    margin-top: 0;
}

table tr th:last-child,
table tr td:last-child {
    margin-bottom: 0;
}

/* 粗体 */
#write strong {
    padding: 0 2px;
    color: var(--purple-1);
}

/* 斜体 */
#write em {
    padding: 0 5px 0 2px;
    /* font-style: normal; */
    color: #42b983;
}

/* inline code */
#write code, tt {
    padding: 2px 4px;
    border-radius: 2px;
    font-family: var(--font-monospace);
    font-size: 0.92rem;
    color: var(--purple-3); 
    background-color: rgba(99, 99, 172, .05);
}

tt {
    margin: 0 2px;
}

#write .md-footnote {
    background-color: #f8f8f8;
    color: var(--purple-3);
}

/* heighlight. */
#write mark {
    background-color: #fbd3ea;
    border-radius: 2px;
    padding: 2px 4px;
    margin: 0 2px;
}

#write del {
    padding: 1px 2px;
}

.md-task-list-item > input {
    margin-left: -1.3em;
}

@media print {
    html {
        font-size: 0.9rem;
    }

    table,
    pre {
        page-break-inside: avoid;
    }

    pre {
        word-wrap: break-word;
    }
}

#write pre.md-meta-block {
    padding: 1rem;
    font-size: 85%;
    line-height: 1.45;
    background-color: #f7f7f7;
    border: 0;
    border-radius: 3px;
    color: #777777;
    margin-top: 0 !important;
}

.mathjax-block > .code-tooltip {
    bottom: .375rem;
}

/* 图片 */
.md-image > .md-meta {
    border-radius: 3px;
    font-family: var(--font-monospace);
    padding: 2px 0 0 4px;
    font-size: 0.9em;
    color: inherit;
}
p .md-image:only-child{
    width: auto;
    text-align: left;
    margin-left: 2rem;
}
.md-tag {
    color: inherit;
}
/* 当 “![shadow-随便写]()”写时，会有阴影 */
.md-image img[alt|='shadow'] {
    /* box-shadow: 0 4px 24px -6px #ddd; */
    box-shadow:var(--purple-light-2) 0px 10px 15px;
}

#write a.md-toc-inner {
    line-height: 1.6;
    white-space: pre-line;
    border-bottom: none;
    font-size: 0.9rem;
}

#typora-quick-open {
    border: 1px solid #ddd;
    background-color: #f8f8f8;
}

#typora-quick-open-item {
    background-color: #FAFAFA;
    border-color: #FEFEFE #e5e5e5 #e5e5e5 #eee;
    border-style: solid;
    border-width: 1px;
}

#md-notification:before {
    top: 10px;
}

header,
.context-menu,
.megamenu-content,
footer {
    font-family: var(--font-sans-serif);
}

.file-node-content:hover .file-node-icon,
.file-node-content:hover .file-node-open-state {
    visibility: visible;
}

.md-lang {
    color: #b4654d;
}

.html-for-mac .context-menu {
    --item-hover-bg-color: #E6F0FE;
}

/* 代码框 */
/* CodeMirror 3024 Day theme */

/* 代码段 背景 */
pre {
    --select-text-bg-color: rgba(223, 197, 223) !important;
    margin: .5em 0;
    padding: 1em 1.4em;
    border-radius: 8px;
    background: #f6f8fa;
    overflow-x: auto;
    box-sizing: border-box;
    font-size: 14px;
}

/* 边框 */
.md-fences {
    border: 1px solid #e7eaed;
    border-radius: 3px;
}

.cm-s-inner {
  padding: .25rem;
  border-radius: .25rem;
}

.cm-s-inner.CodeMirror, .cm-s-inner .CodeMirror-gutters {
  background-color: #f8f8f8 !important;
  color: #3a3432 !important;
  border: none;
}

.cm-s-inner .CodeMirror-gutters {
  color: #6d8a88;
}

.cm-s-inner .CodeMirror-cursor {
  border-left: solid thin #5c5855 !important;
}

.cm-s-inner .CodeMirror-linenumber {
  color: #807d7c;
}

.cm-s-inner .CodeMirror-line::selection, .cm-s-inner .CodeMirror-line::-moz-selection,
.cm-s-inner .CodeMirror-line > span::selection,
.cm-s-inner .CodeMirror-line > span::-moz-selection,
.cm-s-inner .CodeMirror-line > span > span::selection,
.cm-s-inner .CodeMirror-line > span > span::-moz-selection {
  background: var(--purple-light-2);
}

.cm-s-inner span.cm-comment {
  color: #cdab53;
}

.cm-s-inner span.cm-string, .cm-s-inner span.cm-string-2 {
  color: #f2b01d;
}

.cm-s-inner span.cm-number {
  color: #a34e8f;
}

.cm-s-inner span.cm-variable {
  color: #01a252;
}

.cm-s-inner span.cm-variable-2 {
  color: #01a0e4;
}

.cm-s-inner span.cm-def {
  /* color: #e8bbd0; */
  color: #e2287f;
}

.cm-s-inner span.cm-operator {
  color: #ff79c6;
}

.cm-s-inner span.cm-keyword {
  color: #db2d20;
}

.cm-s-inner span.cm-atom {
  color: #a34e8f;
}

.cm-s-inner span.cm-meta {
  color: inherit;
}

.cm-s-inner span.cm-tag {
  color: #db2d20;
}

.cm-s-inner span.cm-attribute {
  color: #01a252;
}

.cm-s-inner span.cm-qualifier {
  color: #388aa3;
}

.cm-s-inner span.cm-property {
  color: #01a252;
}

.cm-s-inner span.cm-builtin {
  color: #388aa3;
}

.cm-s-inner span.cm-variable-3, .cm-s-inner span.cm-type {
  color: #ffb86c;
}

.cm-s-inner span.cm-bracket {
  color: #3a3432;
}

.cm-s-inner span.cm-link {
  color: #a34e8f;
}

.cm-s-inner span.cm-error {
  background: #db2d20;
  color: #5c5855;
}

/* .md-fences.md-focus .cm-s-inner .CodeMirror-activeline-background {
  background: var(--purple-light-2);
} */

.cm-s-inner .CodeMirror-matchingbracket {
  text-decoration: underline;
  color: #a34e8f !important;
}

#fences-auto-suggest .active {
  background: #ddd;
}

#write .code-tooltip {
  bottom: initial;
  top: calc(100% - 1px);
  background: #f7f7f7;
  border: 1px solid #ddd;
  border-top: 0;
}

.auto-suggest-container {
  border-color: #b4b4b4;
}

.auto-suggest-container .autoComplt-hint.active {
  background: #b4b4b4;
  color: inherit;
}

/* task list */
#write .md-task-list-item > input {
  -webkit-appearance: initial;
  display: block;
  position: absolute;
  border: 1px solid #b4b4b4;
  border-radius: .25rem;
  margin-top: .1rem;
  margin-left: -1.8rem;
  height: 1.2rem;
  width: 1.2rem;
  transition: background 0.3s;
}

#write .md-task-list-item > input:focus {
  outline: none;
  box-shadow: none;
}

#write .md-task-list-item > input:hover {
  background: #ddd;
}

#write .md-task-list-item > input[checked]::before {
  content: '';
  position: absolute;
  top: 20%;
  left: 50%;
  height: 60%;
  width: 2px;
  transform: rotate(40deg);
  background: #333;
}

#write .md-task-list-item > input[checked]::after {
  content: '';
  position: absolute;
  top: 46%;
  left: 25%;
  height: 30%;
  width: 2px;
  transform: rotate(-40deg);
  background: #333;
}

#write .md-task-list-item > p {
  transition: color 0.3s, opacity 0.3s;
}

#write .md-task-list-item.task-list-done > p {
  color: #b4b4b4;
  text-decoration: line-through;
}

#write .md-task-list-item.task-list-done > p > .md-emoji {
  opacity: .5;
}

#write .md-task-list-item.task-list-done > p > .md-link > a {
  opacity: .6;
}

/* sidebar and outline */
.pin-outline .outline-active {
  color: var(--active-file-text-color); 
}

.file-list-item {
    border-bottom: 1px solid;
    border-color: var(--purple-light-5);
}

.file-list-item-summary {
    font-weight: 400;
}

.file-list-item.active {
    color: var(--active-file-text-color);
    background-color: var(--purple-light-5);
}

.file-tree-node.active>.file-node-background {
    background-color: var(--purple-light-5);
    font-weight: 700;
} 

.file-tree-node.active>.file-node-content {
    color: var(--active-file-text-color);
    font-weight: 700;
}

.file-node-content {
    color: #5e676d;
}

.sidebar-tabs {
    border-bottom: none;
}
.sidebar-tab.active {
    font-weight: 400;
}

.sidebar-content-content {
    font-size: 0.9rem;
}

img {
    max-width: 100%;
}

body {
    background-color: rgb(237, 237, 237);
}
#content {
    width: 836px;
    padding: 50px;
    background: #fff;
    margin: 0 auto;
}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/purple.css*/</style><style type="text/css">.hljs{display:block;overflow-x:auto;padding:.5em;color:#383a42;background:#fafafa}.hljs-comment,.hljs-quote{color:#a0a1a7;font-style:italic}.hljs-doctag,.hljs-formula,.hljs-keyword{color:#a626a4}.hljs-deletion,.hljs-name,.hljs-section,.hljs-selector-tag,.hljs-subst{color:#e45649}.hljs-literal{color:#0184bb}.hljs-addition,.hljs-attribute,.hljs-meta-string,.hljs-regexp,.hljs-string{color:#50a14f}.hljs-built_in,.hljs-class .hljs-title{color:#c18401}.hljs-attr,.hljs-number,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-pseudo,.hljs-template-variable,.hljs-type,.hljs-variable{color:#986801}.hljs-bullet,.hljs-link,.hljs-meta,.hljs-selector-id,.hljs-symbol,.hljs-title{color:#4078f2}.hljs-emphasis{font-style:italic}.hljs-strong{font-weight:700}.hljs-link{text-decoration:underline}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/atom-one-light.min.css*/</style></head>
<body>
  <div id="content"><h1>第43讲：灵活好用的 Spider 的用法</h1><p data-nodeid="41690">在上一节课我们通过实例了解了 Scrapy 的基本使用方法，在这个过程中，我们用到了 Spider 来编写爬虫逻辑，同时用到了一些选择器来对结果进行选择。</p>



<p data-nodeid="40244">在这一节课，我们就对 Spider 和 Selector 的基本用法作一个总结。</p>
<h3 data-nodeid="40245">Spider 的用法</h3>
<p data-nodeid="40246">在 Scrapy 中，要抓取网站的链接配置、抓取逻辑、解析逻辑等其实都是在 Spider 中配置的。在前一节课的实例中，我们发现抓取逻辑也是在 Spider 中完成的。本节课我们就来专门了解一下 Spider 的基本用法。</p>
<h4 data-nodeid="40247">Spider 运行流程</h4>
<p data-nodeid="40248">在实现 Scrapy 爬虫项目时，最核心的类便是 Spider 类了，它定义了如何爬取某个网站的流程和解析方式。简单来讲，Spider 要做的事就是如下两件：</p>
<ul data-nodeid="40249">
<li data-nodeid="40250">
<p data-nodeid="40251">定义爬取网站的动作；</p>
</li>
<li data-nodeid="40252">
<p data-nodeid="40253">分析爬取下来的网页。</p>
</li>
</ul>
<p data-nodeid="40254">对于 Spider 类来说，整个爬取循环如下所述。</p>
<ul data-nodeid="40255">
<li data-nodeid="40256">
<p data-nodeid="40257">以初始的 URL 初始化 Request，并设置回调函数。 当该 Request 成功请求并返回时，将生成 Response，并作为参数传给该回调函数。</p>
</li>
<li data-nodeid="40258">
<p data-nodeid="40259">在回调函数内分析返回的网页内容。返回结果可以有两种形式，一种是解析到的有效结果返回字典或 Item 对象。下一步可经过处理后（或直接）保存，另一种是解析到的下一个（如下一页）链接，可以利用此链接构造 Request 并设置新的回调函数，返回 Request。</p>
</li>
<li data-nodeid="40260">
<p data-nodeid="40261">如果返回的是字典或 Item 对象，可通过 Feed Exports 等形式存入文件，如果设置了 Pipeline 的话，可以经由 Pipeline 处理（如过滤、修正等）并保存。</p>
</li>
<li data-nodeid="40262">
<p data-nodeid="40263">如果返回的是 Reqeust，那么 Request 执行成功得到 Response 之后会再次传递给 Request 中定义的回调函数，可以再次使用选择器来分析新得到的网页内容，并根据分析的数据生成 Item。</p>
</li>
</ul>
<p data-nodeid="40264">通过以上几步循环往复进行，便完成了站点的爬取。</p>
<h4 data-nodeid="40265">Spider 类分析</h4>
<p data-nodeid="40266">在上一节课的例子中我们定义的 Spider 继承自 scrapy.spiders.Spider，这个类是最简单最基本的 Spider 类，每个其他的 Spider 必须继承自这个类，还有后面要说明的一些特殊 Spider 类也都是继承自它。</p>
<p data-nodeid="40267">这个类里提供了 start_requests 方法的默认实现，读取并请求 start_urls 属性，并根据返回的结果调用 parse 方法解析结果。另外它还有一些基础属性，下面对其进行讲解。</p>
<ul data-nodeid="40268">
<li data-nodeid="40269">
<p data-nodeid="40270">name：爬虫名称，是定义 Spider 名字的字符串。Spider 的名字定义了 Scrapy 如何定位并初始化 Spider，所以其必须是唯一的。 不过我们可以生成多个相同的 Spider 实例，这没有任何限制。 name 是 Spider 最重要的属性，而且是必需的。如果该 Spider 爬取单个网站，一个常见的做法是以该网站的域名名称来命名 Spider。例如，如果 Spider 爬取 mywebsite.com，该 Spider 通常会被命名为 mywebsite。</p>
</li>
<li data-nodeid="40271">
<p data-nodeid="40272">allowed_domains：允许爬取的域名，是可选配置，不在此范围的链接不会被跟进爬取。</p>
</li>
<li data-nodeid="40273">
<p data-nodeid="40274">start_urls：起始 URL 列表，当我们没有实现 start_requests 方法时，默认会从这个列表开始抓取。</p>
</li>
<li data-nodeid="40275">
<p data-nodeid="40276">custom_settings：这是一个字典，是专属于本 Spider 的配置，此设置会覆盖项目全局的设置，而且此设置必须在初始化前被更新，所以它必须定义成类变量。</p>
</li>
<li data-nodeid="40277">
<p data-nodeid="40278">crawler：此属性是由 from_crawler 方法设置的，代表的是本 Spider 类对应的 Crawler 对象，Crawler 对象中包含了很多项目组件，利用它我们可以获取项目的一些配置信息，如最常见的就是获取项目的设置信息，即 Settings。</p>
</li>
<li data-nodeid="40279">
<p data-nodeid="40280">settings：是一个 Settings 对象，利用它我们可以直接获取项目的全局设置变量。</p>
</li>
</ul>
<p data-nodeid="40281">除了一些基础属性，Spider 还有一些常用的方法，在此介绍如下。</p>
<ul data-nodeid="40282">
<li data-nodeid="40283">
<p data-nodeid="40284">start_requests：此方法用于生成初始请求，它必须返回一个可迭代对象，此方法会默认使用 start_urls 里面的 URL 来构造 Request，而且 Request 是 GET 请求方式。如果我们想在启动时以 POST 方式访问某个站点，可以直接重写这个方法，发送 POST 请求时我们使用 FormRequest 即可。</p>
</li>
<li data-nodeid="40285">
<p data-nodeid="40286">parse：当 Response 没有指定回调函数时，该方法会默认被调用，它负责处理 Response，处理返回结果，并从中提取出想要的数据和下一步的请求，然后返回。该方法需要返回一个包含 Request 或 Item 的可迭代对象。</p>
</li>
<li data-nodeid="40287">
<p data-nodeid="40288">closed：当 Spider 关闭时，该方法会被调用，在这里一般会定义释放资源的一些操作或其他收尾操作。</p>
</li>
</ul>
<h3 data-nodeid="40289">Selector 的用法</h3>
<p data-nodeid="40290">我们之前介绍了利用 Beautiful Soup、PyQuery，以及正则表达式来提取网页数据，这确实非常方便。而 Scrapy 还提供了自己的数据提取方法，即 Selector（选择器）。</p>
<p data-nodeid="40291">Selector 是基于 lxml 构建的，支持 XPath 选择器、CSS 选择器，以及正则表达式，功能全面，解析速度和准确度非常高。</p>
<p data-nodeid="40292">接下来我们将介绍 Selector 的用法。</p>
<h4 data-nodeid="40293">直接使用</h4>
<p data-nodeid="40294">Selector 是一个可以独立使用的模块。我们可以直接利用 Selector 这个类来构建一个选择器对象，然后调用它的相关方法如 xpath、css 等来提取数据。</p>
<p data-nodeid="40295">例如，针对一段 HTML 代码，我们可以用如下方式构建 Selector 对象来提取数据：</p>
<pre class="lang-java" data-nodeid="42542"><code data-language="java">from scrapy <span class="hljs-keyword">import</span> Selector
​
body = <span class="hljs-string">'&lt;html&gt;&lt;head&gt;&lt;title&gt;Hello World&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt;'</span>
selector = Selector(text=body)
title = selector.xpath(<span class="hljs-string">'//title/text()'</span>).extract_first()
print(title)
</code></pre>


<p data-nodeid="40297">运行结果：</p>
<pre class="lang-java" data-nodeid="43109"><code data-language="java">Hello World
</code></pre>

<p data-nodeid="43676">这里我们没有在 Scrapy 框架中运行，而是把 Scrapy 中的 Selector 单独拿出来使用了，构建的时候传入 text 参数，就生成了一个 Selector 选择器对象，然后就可以像前面我们所用的 Scrapy 中的解析方式一样，调用 xpath、css 等方法来提取了。</p>
<p data-nodeid="43677">在这里我们查找的是源代码中的 title 中的文本，在 XPath 选择器最后加 text 方法就可以实现文本的提取了。</p>

<p data-nodeid="40300">以上内容就是 Selector 的直接使用方式。同 Beautiful Soup 等库类似，Selector 其实也是强大的网页解析库。如果方便的话，我们也可以在其他项目中直接使用 Selector 来提取数据。</p>
<p data-nodeid="40301">接下来，我们用实例来详细讲解 Selector 的用法。</p>
<h4 data-nodeid="40302">Scrapy Shell</h4>
<p data-nodeid="40303">由于 Selector 主要是与 Scrapy 结合使用，如 Scrapy 的回调函数中的参数 response 直接调用 xpath() 或者 css() 方法来提取数据，所以在这里我们借助 Scrapy Shell 来模拟 Scrapy 请求的过程，来讲解相关的提取方法。</p>
<p data-nodeid="40304">我们用官方文档的一个样例页面来做演示：<a href="http://doc.scrapy.org/en/latest/_static/selectors-sample1.html" data-nodeid="40429">http://doc.scrapy.org/en/latest/_static/selectors-sample1.html</a>。</p>
<p data-nodeid="40305">开启 Scrapy Shell，在命令行中输入如下命令：</p>
<pre class="lang-java" data-nodeid="44246"><code data-language="java">scrapy shell http:<span class="hljs-comment">//doc.scrapy.org/en/latest/_static/selectors-sample1.html</span>
</code></pre>

<p data-nodeid="45373">这样我们就进入了 Scrapy Shell 模式。这个过程其实是 Scrapy 发起了一次请求，请求的 URL 就是刚才命令行下输入的 URL，然后把一些可操作的变量传递给我们，如 request、response 等，如图所示。</p>
<p data-nodeid="45374" class=""><img src="https://s0.lgstatic.com/i/image/M00/2E/D0/Ciqc1F8FqLiAdcLhAAESdhrMDNE818.png" alt="image (6).png" data-nodeid="45382"></p>


<p data-nodeid="40308">我们可以在命令行模式下输入命令调用对象的一些操作方法，回车之后实时显示结果。这与 Python 的命令行交互模式是类似的。</p>
<p data-nodeid="40309">接下来，演示的实例都将页面的源码作为分析目标，页面源码如下所示：</p>
<pre class="lang-dart" data-nodeid="48832"><code data-language="dart">&lt;html&gt;
 &lt;head&gt;
 &nbsp;&lt;base href=<span class="hljs-string">'http://example.com/'</span> /&gt;
 &nbsp;&lt;title&gt;Example website&lt;/title&gt;
 &lt;/head&gt;
 &lt;body&gt;
 &nbsp;&lt;div id=<span class="hljs-string">'images'</span>&gt;
 &nbsp; &lt;a href=<span class="hljs-string">'image1.html'</span>&gt;Name: My image <span class="hljs-number">1</span> &lt;br /&gt;&lt;img src=<span class="hljs-string">'image1_thumb.jpg'</span> /&gt;&lt;/a&gt;
 &nbsp; &lt;a href=<span class="hljs-string">'image2.html'</span>&gt;Name: My image <span class="hljs-number">2</span> &lt;br /&gt;&lt;img src=<span class="hljs-string">'image2_thumb.jpg'</span> /&gt;&lt;/a&gt;
 &nbsp; &lt;a href=<span class="hljs-string">'image3.html'</span>&gt;Name: My image <span class="hljs-number">3</span> &lt;br /&gt;&lt;img src=<span class="hljs-string">'image3_thumb.jpg'</span> /&gt;&lt;/a&gt;
 &nbsp; &lt;a href=<span class="hljs-string">'image4.html'</span>&gt;Name: My image <span class="hljs-number">4</span> &lt;br /&gt;&lt;img src=<span class="hljs-string">'image4_thumb.jpg'</span> /&gt;&lt;/a&gt;
 &nbsp; &lt;a href=<span class="hljs-string">'image5.html'</span>&gt;Name: My image <span class="hljs-number">5</span> &lt;br /&gt;&lt;img src=<span class="hljs-string">'image5_thumb.jpg'</span> /&gt;&lt;/a&gt;
 &nbsp;&lt;/div&gt;
 &lt;/body&gt;
&lt;/html&gt;
</code></pre>






<h4 data-nodeid="40311">XPath 选择器</h4>
<p data-nodeid="40312">进入 Scrapy Shell 之后，我们将主要操作 response 变量来进行解析。因为我们解析的是 HTML 代码，Selector 将自动使用 HTML 语法来分析。</p>
<p data-nodeid="40313">response 有一个属性 selector，我们调用 response.selector 返回的内容就相当于用 response 的 text 构造了一个 Selector 对象。通过这个 Selector 对象我们可以调用解析方法如 xpath、css 等，通过向方法传入 XPath 或 CSS 选择器参数就可以实现信息的提取。</p>
<p data-nodeid="40314">我们用一个实例感受一下，如下所示：</p>
<pre class="lang-java" data-nodeid="49407"><code data-language="java">&gt;&gt;&gt; result = response.selector.xpath(<span class="hljs-string">'//a'</span>)
&gt;&gt;&gt; result
[&lt;Selector xpath=<span class="hljs-string">'//a'</span> data=<span class="hljs-string">'&lt;a href="image1.html"&gt;Name: My image 1 &lt;'</span>&gt;,
 &lt;Selector xpath=<span class="hljs-string">'//a'</span> data=<span class="hljs-string">'&lt;a href="image2.html"&gt;Name: My image 2 &lt;'</span>&gt;,
 &lt;Selector xpath=<span class="hljs-string">'//a'</span> data=<span class="hljs-string">'&lt;a href="image3.html"&gt;Name: My image 3 &lt;'</span>&gt;,
 &lt;Selector xpath=<span class="hljs-string">'//a'</span> data=<span class="hljs-string">'&lt;a href="image4.html"&gt;Name: My image 4 &lt;'</span>&gt;,
 &lt;Selector xpath=<span class="hljs-string">'//a'</span> data=<span class="hljs-string">'&lt;a href="image5.html"&gt;Name: My image 5 &lt;'</span>&gt;]
&gt;&gt;&gt; type(result)
scrapy.selector.unified.SelectorList
</code></pre>

<p data-nodeid="49982">打印结果的形式是 Selector 组成的列表，其实它是 SelectorList 类型，SelectorList 和 Selector 都可以继续调用 xpath 和 css 等方法来进一步提取数据。</p>
<p data-nodeid="49983">在上面的例子中，我们提取了 a 节点。接下来，我们尝试继续调用 xpath 方法来提取 a 节点内包含的 img 节点，如下所示：</p>

<pre class="lang-java" data-nodeid="50560"><code data-language="java">&gt;&gt;&gt; result.xpath(<span class="hljs-string">'./img'</span>)
[&lt;Selector xpath=<span class="hljs-string">'./img'</span> data=<span class="hljs-string">'&lt;img src="image1_thumb.jpg"&gt;'</span>&gt;,
 &lt;Selector xpath=<span class="hljs-string">'./img'</span> data=<span class="hljs-string">'&lt;img src="image2_thumb.jpg"&gt;'</span>&gt;,
 &lt;Selector xpath=<span class="hljs-string">'./img'</span> data=<span class="hljs-string">'&lt;img src="image3_thumb.jpg"&gt;'</span>&gt;,
 &lt;Selector xpath=<span class="hljs-string">'./img'</span> data=<span class="hljs-string">'&lt;img src="image4_thumb.jpg"&gt;'</span>&gt;,
 &lt;Selector xpath=<span class="hljs-string">'./img'</span> data=<span class="hljs-string">'&lt;img src="image5_thumb.jpg"&gt;'</span>&gt;]
</code></pre>

<p data-nodeid="51135">我们获得了 a 节点里面的所有 img 节点，结果为 5。</p>
<p data-nodeid="51136">值得注意的是，选择器的最前方加 <code data-backticks="1" data-nodeid="51139">.</code>（点），这代表提取元素内部的数据，如果没有加点，则代表从根节点开始提取。此处我们用了 ./img 的提取方式，则代表从 a 节点里进行提取。如果此处我们用 //img，则还是从 html 节点里进行提取。</p>

<p data-nodeid="40319">我们刚才使用了 response.selector.xpath 方法对数据进行了提取。Scrapy 提供了两个实用的快捷方法，response.xpath 和 response.css，它们二者的功能完全等同于 response.selector.xpath 和 response.selector.css。方便起见，后面我们统一直接调用 response 的 xpath 和 css 方法进行选择。</p>
<p data-nodeid="40320">现在我们得到的是 SelectorList 类型的变量，该变量是由 Selector 对象组成的列表。我们可以用索引单独取出其中某个 Selector 元素，如下所示：</p>
<pre class="lang-java" data-nodeid="51715"><code data-language="java">&gt;&gt;&gt; result[<span class="hljs-number">0</span>]
&lt;Selector xpath=<span class="hljs-string">'//a'</span> data=<span class="hljs-string">'&lt;a href="image1.html"&gt;Name: My image 1 &lt;'</span>&gt;
</code></pre>

<p data-nodeid="40322">我们可以像操作列表一样操作这个 SelectorList。但是现在获取的内容是 Selector 或者 SelectorList 类型，并不是真正的文本内容。那么具体的内容怎么提取呢？<br>
比如我们现在想提取出 a 节点元素，就可以利用 extract 方法，如下所示：</p>
<pre class="lang-java" data-nodeid="52290"><code data-language="java">&gt;&gt;&gt; result.extract()
[<span class="hljs-string">'&lt;a href="image1.html"&gt;Name: My image 1 &lt;br&gt;&lt;img src="image1_thumb.jpg"&gt;&lt;/a&gt;'</span>, <span class="hljs-string">'&lt;a href="image2.html"&gt;Name: My image 2 &lt;br&gt;&lt;img src="image2_thumb.jpg"&gt;&lt;/a&gt;'</span>, <span class="hljs-string">'&lt;a href="image3.html"&gt;Name: My image 3 &lt;br&gt;&lt;img src="image3_thumb.jpg"&gt;&lt;/a&gt;'</span>, <span class="hljs-string">'&lt;a href="image4.html"&gt;Name: My image 4 &lt;br&gt;&lt;img src="image4_thumb.jpg"&gt;&lt;/a&gt;'</span>, <span class="hljs-string">'&lt;a href="image5.html"&gt;Name: My image 5 &lt;br&gt;&lt;img src="image5_thumb.jpg"&gt;&lt;/a&gt;'</span>]
</code></pre>

<p data-nodeid="53440">这里使用了 extract 方法，我们就可以把真实需要的内容获取下来。</p>
<p data-nodeid="53441">我们还可以改写 XPath 表达式，来选取节点的内部文本和属性，如下所示：</p>

<pre class="lang-java" data-nodeid="52865"><code data-language="java">&gt;&gt;&gt; response.xpath(<span class="hljs-string">'//a/text()'</span>).extract()
[<span class="hljs-string">'Name: My image 1 '</span>, <span class="hljs-string">'Name: My image 2 '</span>, <span class="hljs-string">'Name: My image 3 '</span>, <span class="hljs-string">'Name: My image 4 '</span>, <span class="hljs-string">'Name: My image 5 '</span>]
&gt;&gt;&gt; response.xpath(<span class="hljs-string">'//a/@href'</span>).extract()
[<span class="hljs-string">'image1.html'</span>, <span class="hljs-string">'image2.html'</span>, <span class="hljs-string">'image3.html'</span>, <span class="hljs-string">'image4.html'</span>, <span class="hljs-string">'image5.html'</span>]
</code></pre>

<p data-nodeid="54018">我们只需要再加一层 /text() 就可以获取节点的内部文本，或者加一层 /@href 就可以获取节点的 href 属性。其中，@ 符号后面内容就是要获取的属性名称。</p>
<p data-nodeid="54019">现在我们可以用一个规则把所有符合要求的节点都获取下来，返回的类型是列表类型。</p>

<p data-nodeid="40327">但是这里有一个问题：如果符合要求的节点只有一个，那么返回的结果会是什么呢？我们再用一个实例来感受一下，如下所示：</p>
<pre class="lang-java" data-nodeid="54596"><code data-language="java">&gt;&gt;&gt; response.xpath(<span class="hljs-string">'//a[@href="image1.html"]/text()'</span>).extract()
[<span class="hljs-string">'Name: My image 1 '</span>]
</code></pre>

<p data-nodeid="40329">我们用属性限制了匹配的范围，使 XPath 只可以匹配到一个元素。然后用 extract 方法提取结果，其结果还是一个列表形式，其文本是列表的第一个元素。但很多情况下，我们其实想要的数据就是第一个元素内容，这里我们通过加一个索引来获取，如下所示：</p>
<pre class="lang-java" data-nodeid="55171"><code data-language="java"><span class="hljs-string">'Name: My image 1 '</span>
</code></pre>

<p data-nodeid="40331">但是，这个写法很明显是有风险的。一旦 XPath 有问题，那么 extract 后的结果可能是一个空列表。如果我们再用索引来获取，那不就可能会导致数组越界吗？<br>
所以，另外一个方法可以专门提取单个元素，它叫作 extract_first。我们可以改写上面的例子如下所示：</p>
<pre class="lang-java" data-nodeid="55746"><code data-language="java">&gt;&gt;&gt; response.xpath(<span class="hljs-string">'//a[@href="image1.html"]/text()'</span>).extract_first()
<span class="hljs-string">'Name: My image 1 '</span>
</code></pre>

<p data-nodeid="40333">这样，我们直接利用 extract_first 方法将匹配的第一个结果提取出来，同时我们也不用担心数组越界的问题。<br>
另外我们也可以为 extract_first 方法设置一个默认值参数，这样当 XPath 规则提取不到内容时会直接使用默认值。例如将 XPath 改成一个不存在的规则，重新执行代码，如下所示：</p>
<pre class="lang-java" data-nodeid="56321"><code data-language="java">&gt;&gt;&gt; response.xpath(<span class="hljs-string">'//a[@href="image1"]/text()'</span>).extract_first()&gt;&gt;&gt; response.xpath(<span class="hljs-string">'//a[@href="image1"]/text()'</span>).extract_first(<span class="hljs-string">'Default Image'</span>)
<span class="hljs-string">'Default Image'</span>
</code></pre>

<p data-nodeid="56896">这里，如果 XPath 匹配不到任何元素，调用 extract_first 会返回空，也不会报错。在第二行代码中，我们还传递了一个参数当作默认值，如 Default Image。这样如果 XPath 匹配不到结果的话，返回值会使用这个参数来代替，可以看到输出正是如此。</p>
<p data-nodeid="56897">到现在为止，我们了解了 Scrapy 中的 XPath 的相关用法，包括嵌套查询、提取内容、提取单个内容、获取文本和属性等。</p>

<h4 data-nodeid="40336">CSS 选择器</h4>
<p data-nodeid="40337">接下来，我们看看 CSS 选择器的用法。Scrapy 的选择器同时还对接了 CSS 选择器，使用 response.css() 方法可以使用 CSS 选择器来选择对应的元素。</p>
<p data-nodeid="40338">例如在上文我们选取了所有的 a 节点，那么 CSS 选择器同样可以做到，如下所示：</p>
<pre class="lang-java" data-nodeid="57476"><code data-language="java">&gt;&gt;&gt; response.css(<span class="hljs-string">'a'</span>)
[&lt;Selector xpath=<span class="hljs-string">'descendant-or-self::a'</span> data=<span class="hljs-string">'&lt;a href="image1.html"&gt;Name: My image 1 &lt;'</span>&gt;, 
&lt;Selector xpath=<span class="hljs-string">'descendant-or-self::a'</span> data=<span class="hljs-string">'&lt;a href="image2.html"&gt;Name: My image 2 &lt;'</span>&gt;, 
&lt;Selector xpath=<span class="hljs-string">'descendant-or-self::a'</span> data=<span class="hljs-string">'&lt;a href="image3.html"&gt;Name: My image 3 &lt;'</span>&gt;, 
&lt;Selector xpath=<span class="hljs-string">'descendant-or-self::a'</span> data=<span class="hljs-string">'&lt;a href="image4.html"&gt;Name: My image 4 &lt;'</span>&gt;, 
&lt;Selector xpath=<span class="hljs-string">'descendant-or-self::a'</span> data=<span class="hljs-string">'&lt;a href="image5.html"&gt;Name: My image 5 &lt;'</span>&gt;]
</code></pre>

<p data-nodeid="40340">同样，调用 extract 方法就可以提取出节点，如下所示：</p>
<pre class="lang-java" data-nodeid="58051"><code data-language="java">[<span class="hljs-string">'&lt;a href="image1.html"&gt;Name: My image 1 &lt;br&gt;&lt;img src="image1_thumb.jpg"&gt;&lt;/a&gt;'</span>, <span class="hljs-string">'&lt;a href="image2.html"&gt;Name: My image 2 &lt;br&gt;&lt;img src="image2_thumb.jpg"&gt;&lt;/a&gt;'</span>, <span class="hljs-string">'&lt;a href="image3.html"&gt;Name: My image 3 &lt;br&gt;&lt;img src="image3_thumb.jpg"&gt;&lt;/a&gt;'</span>, <span class="hljs-string">'&lt;a href="image4.html"&gt;Name: My image 4 &lt;br&gt;&lt;img src="image4_thumb.jpg"&gt;&lt;/a&gt;'</span>, <span class="hljs-string">'&lt;a href="image5.html"&gt;Name: My image 5 &lt;br&gt;&lt;img src="image5_thumb.jpg"&gt;&lt;/a&gt;'</span>]
</code></pre>

<p data-nodeid="40342">用法和 XPath 选择是完全一样的。另外，我们也可以进行属性选择和嵌套选择，如下所示：</p>
<pre class="lang-java" data-nodeid="58626"><code data-language="java">&gt;&gt;&gt; response.css(<span class="hljs-string">'a[href="image1.html"]'</span>).extract()
[<span class="hljs-string">'&lt;a href="image1.html"&gt;Name: My image 1 &lt;br&gt;&lt;img src="image1_thumb.jpg"&gt;&lt;/a&gt;'</span>]
&gt;&gt;&gt; response.css(<span class="hljs-string">'a[href="image1.html"] img'</span>).extract()
[<span class="hljs-string">'&lt;img src="image1_thumb.jpg"&gt;'</span>]
</code></pre>

<p data-nodeid="59201">这里用 [href="image.html"] 限定了 href 属性，可以看到匹配结果就只有一个了。另外如果想查找 a 节点内的 img 节点，只需要再加一个空格和 img 即可。选择器的写法和标准 CSS 选择器写法如出一辙。</p>
<p data-nodeid="59202">我们也可以使用 extract_first() 方法提取列表的第一个元素，如下所示：</p>

<pre class="lang-java" data-nodeid="59788"><code data-language="java">&gt;&gt;&gt; response.css(<span class="hljs-string">'a[href="image1.html"] img'</span>).extract_first()
<span class="hljs-string">'&lt;img src="image1_thumb.jpg"&gt;'</span>
</code></pre>

<p data-nodeid="40346">接下来的两个用法不太一样。节点的内部文本和属性的获取是这样实现的，如下所示：</p>
<pre class="lang-java" data-nodeid="60363"><code data-language="java">&gt;&gt;&gt; response.css(<span class="hljs-string">'a[href="image1.html"]::text'</span>).extract_first()
<span class="hljs-string">'Name: My image 1 '</span>
&gt;&gt;&gt; response.css(<span class="hljs-string">'a[href="image1.html"] img::attr(src)'</span>).extract_first()
<span class="hljs-string">'image1_thumb.jpg'</span>
</code></pre>

<p data-nodeid="60938">获取文本和属性需要用 ::text 和 ::attr() 的写法。而其他库如 Beautiful Soup 或 PyQuery 都有单独的方法。</p>
<p data-nodeid="60939">另外，CSS 选择器和 XPath 选择器一样可以嵌套选择。我们可以先用 XPath 选择器选中所有 a 节点，再利用 CSS 选择器选中 img 节点，再用 XPath 选择器获取属性。我们用一个实例来感受一下，如下所示：</p>

<pre class="lang-java" data-nodeid="61516"><code data-language="java">&gt;&gt;&gt; response.xpath(<span class="hljs-string">'//a'</span>).css(<span class="hljs-string">'img'</span>).xpath(<span class="hljs-string">'@src'</span>).extract()
[<span class="hljs-string">'image1_thumb.jpg'</span>, <span class="hljs-string">'image2_thumb.jpg'</span>, <span class="hljs-string">'image3_thumb.jpg'</span>, <span class="hljs-string">'image4_thumb.jpg'</span>, <span class="hljs-string">'image5_thumb.jpg'</span>]
</code></pre>

<p data-nodeid="40350">我们成功获取了所有 img 节点的 src 属性。<br>
因此，我们可以随意使用 xpath 和 css 方法二者自由组合实现嵌套查询，二者是完全兼容的。</p>
<h4 data-nodeid="40351">正则匹配</h4>
<p data-nodeid="40352">Scrapy 的选择器还支持正则匹配。比如，在示例的 a 节点中的文本类似于 Name: My image 1，现在我们只想把 Name: 后面的内容提取出来，这时就可以借助 re 方法，实现如下：</p>
<pre class="lang-java" data-nodeid="62091"><code data-language="java">&gt;&gt;&gt; response.xpath(<span class="hljs-string">'//a/text()'</span>).re(<span class="hljs-string">'Name:\s(.*)'</span>)
[<span class="hljs-string">'My image 1 '</span>, <span class="hljs-string">'My image 2 '</span>, <span class="hljs-string">'My image 3 '</span>, <span class="hljs-string">'My image 4 '</span>, <span class="hljs-string">'My image 5 '</span>]
</code></pre>

<p data-nodeid="62666">我们给 re 方法传入一个正则表达式，其中 <code data-backticks="1" data-nodeid="62669">(.*)</code> 就是要匹配的内容，输出的结果就是正则表达式匹配的分组，结果会依次输出。</p>
<p data-nodeid="62667">如果同时存在两个分组，那么结果依然会被按序输出，如下所示：</p>

<pre class="lang-java" data-nodeid="63246"><code data-language="java">&gt;&gt;&gt; response.xpath(<span class="hljs-string">'//a/text()'</span>).re(<span class="hljs-string">'(.*?):\s(.*)'</span>)
[<span class="hljs-string">'Name'</span>, <span class="hljs-string">'My image 1 '</span>, <span class="hljs-string">'Name'</span>, <span class="hljs-string">'My image 2 '</span>, <span class="hljs-string">'Name'</span>, <span class="hljs-string">'My image 3 '</span>, <span class="hljs-string">'Name'</span>, <span class="hljs-string">'My image 4 '</span>, <span class="hljs-string">'Name'</span>, <span class="hljs-string">'My image 5 '</span>]
</code></pre>

<p data-nodeid="40356">类似 extract_first 方法，re_first 方法可以选取列表的第一个元素，用法如下：</p>
<pre class="lang-java" data-nodeid="63821"><code data-language="java">&gt;&gt;&gt; response.xpath(<span class="hljs-string">'//a/text()'</span>).re_first(<span class="hljs-string">'(.*?):\s(.*)'</span>)
<span class="hljs-string">'Name'</span>
&gt;&gt;&gt; response.xpath(<span class="hljs-string">'//a/text()'</span>).re_first(<span class="hljs-string">'Name:\s(.*)'</span>)
<span class="hljs-string">'My image 1 '</span>
</code></pre>

<p data-nodeid="64396">不论正则匹配了几个分组，结果都会等于列表的第一个元素。</p>
<p data-nodeid="64397">值得注意的是，response 对象不能直接调用 re 和 re_first 方法。如果想要对全文进行正则匹配，可以先调用 xpath 方法然后再进行正则匹配，如下所示：</p>

<pre class="lang-java" data-nodeid="64976"><code data-language="java">&gt;&gt;&gt; response.re(<span class="hljs-string">'Name:\s(.*)'</span>)
Traceback (most recent call last):
 &nbsp;File <span class="hljs-string">"&lt;console&gt;"</span>, line <span class="hljs-number">1</span>, in &lt;<span class="hljs-keyword">module</span>&gt;
AttributeError: <span class="hljs-string">'HtmlResponse'</span> object has no attribute <span class="hljs-string">'re'</span>
&gt;&gt;&gt; response.xpath(<span class="hljs-string">'.'</span>).re(<span class="hljs-string">'Name:\s(.*)&lt;br&gt;'</span>)
[<span class="hljs-string">'My image 1 '</span>, <span class="hljs-string">'My image 2 '</span>, <span class="hljs-string">'My image 3 '</span>, <span class="hljs-string">'My image 4 '</span>, <span class="hljs-string">'My image 5 '</span>]
&gt;&gt;&gt; response.xpath(<span class="hljs-string">'.'</span>).re_first(<span class="hljs-string">'Name:\s(.*)&lt;br&gt;'</span>)
<span class="hljs-string">'My image 1 '</span>
</code></pre>

<p data-nodeid="65551">通过上面的例子，我们可以看到，直接调用 re 方法会提示没有 re 属性。但是这里首先调用了 <code data-backticks="1" data-nodeid="65554">xpath('.')</code>选中全文，然后调用 re 和 re_first 方法，就可以进行正则匹配了。</p>
<p data-nodeid="65552">以上内容便是 Scrapy 选择器的用法，它包括两个常用选择器和正则匹配功能。如果你熟练掌握 XPath 语法、CSS 选择器语法、正则表达式语法可以大大提高数据提取效率。</p></div>

</body></html>
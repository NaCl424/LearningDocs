<!DOCTYPE html><html lang="en"><head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>第46讲：遇到动态页面怎么办？详解渲染页面爬取</title>
<style type="text/css">
:root {
    --control-text-color: #777;
    --select-text-bg-color: rgba(223, 197, 223);  /*#7e66992e;*/
    
    /* side bar */
    --side-bar-bg-color: rgb(255, 255, 255);
    --active-file-text-color: #8163bd;
    --active-file-bg-color: #E9E4F0;
    --item-hover-bg-color: #E9E4F0;
    --active-file-border-color: #8163bd;

    --title-color: #6c549c;
    --font-sans-serif: 'Ubuntu', 'Source Sans Pro', sans-serif !important;
    --font-monospace: 'Fira Code', 'Roboto Mono', monospace !important;
    --purple-1: #8163bd;
    --purple-2: #79589F;
    --purple-3: #fd5eb8;
    --purple-light-1: rgba(99, 99, 172, .05);
    --purple-light-2: rgba(99, 99, 172, .1);
    --purple-light-3: rgba(99, 99, 172, .2);
    --purple-light-4: rgba(129, 99, 189, .3);
    --purple-light-5: #E9E4F0;
    --purple-light-6: rgba(129, 99, 189, .8);
}

/* html {
    font-size: 16px;
} */

body {
    font-family: var(--font-sans-serif);
    color: #34495e;
    -webkit-font-smoothing: antialiased;
    line-height: 1.6rem;
    letter-spacing: 0;
    margin: 0;
    overflow-x: hidden;
}

/* 页边距 和 页面大小 */
#write {
    padding-left: 6ch;
    padding-right: 6ch;
    margin: 0 auto;
}

#write p {
    line-height: 1.6rem;
    word-spacing: .05rem;
}

#write ol li {
    padding-left: 0.5rem;
}

#write > ul:first-child,
#write > ol:first-child {
    margin-top: 30px;
}

body > *:first-child {
    margin-top: 0 !important;
}

body > *:last-child {
    margin-bottom: 0 !important;
}

a {
    color: var(--purple-1);
    padding: 0 2px;
    text-decoration: none;
}
.md-content {
    color: var(--purple-light-6);
}
#write a {
    border-bottom: 1px solid var(--purple-1);
    color: var(--purple-1);
    text-decoration: none;
}

h1,
h2,
h3,
h4,
h5,
h6 {
    position: relative;
    margin-top: 1rem;
    margin-bottom: 0.5rem;
    /* font-weight: bold; */
    font-weight: 500 !important;
    line-height: 1.4;
    cursor: text;
    color: var(--title-color);
    font-family: var(--font-sans-serif);
}

h1:hover a.anchor,
h2:hover a.anchor,
h3:hover a.anchor,
h4:hover a.anchor,
h5:hover a.anchor,
h6:hover a.anchor {
    text-decoration: none;
}

h1 tt,
h1 code {
    font-size: inherit !important;
}
h2 tt,
h2 code {
    font-size: inherit !important;
}
h3 tt,
h3 code {
    font-size: inherit !important;
}
h4 tt,
h4 code {
    font-size: inherit !important;
}
h5 tt,
h5 code {
    font-size: inherit !important;
}
h6 tt,
h6 code {
    font-size: inherit !important;
}


h1 {
    padding-bottom: .4rem;
    font-size: 2.2rem;
    line-height: 1.3;
}
h1 {
    text-align: center;
    padding-bottom: 0.3em;
    font-size: 2.2em;
    line-height: 1.2;
    margin: 2.4em auto 1.2em;
}
h1:after {
    content: '';
    display: block;
    margin: 0.2em auto 0;
    width: 100px;
    height: 2px;
    border-bottom: 2px solid var(--title-color);
}

h2 {
    margin: 1.6em auto 0.5em;
    padding-left: 10px;
    line-height: 1.4;
    font-size: 1.8em;
    border-left: 9px solid var(--title-color);
    border-bottom: 1px solid var(--title-color);
}
h3 {
    font-size: 1.5rem;
    margin: 1.2em auto 0.5em;
}
h4 {
    font-size: 1.3rem;
}
h5 {
    font-size: 1.2rem;
}
h6 {
    font-size: 1.1rem;
}

p,
blockquote,
ul,
ol,
dl,
table {
    margin: 0.8em 0;
}

li > ol,
li > ul {
    margin: 0 0;
}

hr {
    height: 2px;
    padding: 0;
    margin: 16px 0;
    background-color: #e7e7e7;
    border: 0 none;
    overflow: hidden;
    box-sizing: content-box;
}

body > h2:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0;
}

body > h3:first-child,
body > h4:first-child,
body > h5:first-child,
body > h6:first-child {
    margin-top: 0;
    padding-top: 0;
}

a:first-child h1,
a:first-child h2,
a:first-child h3,
a:first-child h4,
a:first-child h5,
a:first-child h6 {
    margin-top: 0;
    padding-top: 0;
}

h1 p,
h2 p,
h3 p,
h4 p,
h5 p,
h6 p {
    margin-top: 0;
}

li p.first {
    display: inline-block;
}

ul,
ol {
    padding-left: 30px;
}

ul:first-child,
ol:first-child {
    margin-top: 0;
}

ul:last-child,
ol:last-child {
    margin-bottom: 0;
}

/* 引用 */
blockquote {
    /* margin-left: 1rem; */
    border-left: 4px solid var(--purple-light-4);
    padding: 10px 15px;
    color: #777;
    background-color: var(--purple-light-1);
}

/* 表格 */
table {
    padding: 0;
    word-break: initial;
}

table tr {
    border-top: 1px solid #dfe2e5;
    margin: 0;
    padding: 0;
}

/* 表格 背景色 */
table tr:nth-child(2n),
thead {
    background-color: var(--purple-light-1);
}
#write table thead th {
    background-color: var(--purple-light-2);
}

table tr th {
    font-weight: bold;
    border: 1px solid #dfe2e5;
    border-bottom: 0;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr td {
    border: 1px solid #dfe2e5;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr th:first-child,
table tr td:first-child {
    margin-top: 0;
}

table tr th:last-child,
table tr td:last-child {
    margin-bottom: 0;
}

/* 粗体 */
#write strong {
    padding: 0 2px;
    color: var(--purple-1);
}

/* 斜体 */
#write em {
    padding: 0 5px 0 2px;
    /* font-style: normal; */
    color: #42b983;
}

/* inline code */
#write code, tt {
    padding: 2px 4px;
    border-radius: 2px;
    font-family: var(--font-monospace);
    font-size: 0.92rem;
    color: var(--purple-3); 
    background-color: rgba(99, 99, 172, .05);
}

tt {
    margin: 0 2px;
}

#write .md-footnote {
    background-color: #f8f8f8;
    color: var(--purple-3);
}

/* heighlight. */
#write mark {
    background-color: #fbd3ea;
    border-radius: 2px;
    padding: 2px 4px;
    margin: 0 2px;
}

#write del {
    padding: 1px 2px;
}

.md-task-list-item > input {
    margin-left: -1.3em;
}

@media print {
    html {
        font-size: 0.9rem;
    }

    table,
    pre {
        page-break-inside: avoid;
    }

    pre {
        word-wrap: break-word;
    }
}

#write pre.md-meta-block {
    padding: 1rem;
    font-size: 85%;
    line-height: 1.45;
    background-color: #f7f7f7;
    border: 0;
    border-radius: 3px;
    color: #777777;
    margin-top: 0 !important;
}

.mathjax-block > .code-tooltip {
    bottom: .375rem;
}

/* 图片 */
.md-image > .md-meta {
    border-radius: 3px;
    font-family: var(--font-monospace);
    padding: 2px 0 0 4px;
    font-size: 0.9em;
    color: inherit;
}
p .md-image:only-child{
    width: auto;
    text-align: left;
    margin-left: 2rem;
}
.md-tag {
    color: inherit;
}
/* 当 “![shadow-随便写]()”写时，会有阴影 */
.md-image img[alt|='shadow'] {
    /* box-shadow: 0 4px 24px -6px #ddd; */
    box-shadow:var(--purple-light-2) 0px 10px 15px;
}

#write a.md-toc-inner {
    line-height: 1.6;
    white-space: pre-line;
    border-bottom: none;
    font-size: 0.9rem;
}

#typora-quick-open {
    border: 1px solid #ddd;
    background-color: #f8f8f8;
}

#typora-quick-open-item {
    background-color: #FAFAFA;
    border-color: #FEFEFE #e5e5e5 #e5e5e5 #eee;
    border-style: solid;
    border-width: 1px;
}

#md-notification:before {
    top: 10px;
}

header,
.context-menu,
.megamenu-content,
footer {
    font-family: var(--font-sans-serif);
}

.file-node-content:hover .file-node-icon,
.file-node-content:hover .file-node-open-state {
    visibility: visible;
}

.md-lang {
    color: #b4654d;
}

.html-for-mac .context-menu {
    --item-hover-bg-color: #E6F0FE;
}

/* 代码框 */
/* CodeMirror 3024 Day theme */

/* 代码段 背景 */
pre {
    --select-text-bg-color: rgba(223, 197, 223) !important;
    margin: .5em 0;
    padding: 1em 1.4em;
    border-radius: 8px;
    background: #f6f8fa;
    overflow-x: auto;
    box-sizing: border-box;
    font-size: 14px;
}

/* 边框 */
.md-fences {
    border: 1px solid #e7eaed;
    border-radius: 3px;
}

.cm-s-inner {
  padding: .25rem;
  border-radius: .25rem;
}

.cm-s-inner.CodeMirror, .cm-s-inner .CodeMirror-gutters {
  background-color: #f8f8f8 !important;
  color: #3a3432 !important;
  border: none;
}

.cm-s-inner .CodeMirror-gutters {
  color: #6d8a88;
}

.cm-s-inner .CodeMirror-cursor {
  border-left: solid thin #5c5855 !important;
}

.cm-s-inner .CodeMirror-linenumber {
  color: #807d7c;
}

.cm-s-inner .CodeMirror-line::selection, .cm-s-inner .CodeMirror-line::-moz-selection,
.cm-s-inner .CodeMirror-line > span::selection,
.cm-s-inner .CodeMirror-line > span::-moz-selection,
.cm-s-inner .CodeMirror-line > span > span::selection,
.cm-s-inner .CodeMirror-line > span > span::-moz-selection {
  background: var(--purple-light-2);
}

.cm-s-inner span.cm-comment {
  color: #cdab53;
}

.cm-s-inner span.cm-string, .cm-s-inner span.cm-string-2 {
  color: #f2b01d;
}

.cm-s-inner span.cm-number {
  color: #a34e8f;
}

.cm-s-inner span.cm-variable {
  color: #01a252;
}

.cm-s-inner span.cm-variable-2 {
  color: #01a0e4;
}

.cm-s-inner span.cm-def {
  /* color: #e8bbd0; */
  color: #e2287f;
}

.cm-s-inner span.cm-operator {
  color: #ff79c6;
}

.cm-s-inner span.cm-keyword {
  color: #db2d20;
}

.cm-s-inner span.cm-atom {
  color: #a34e8f;
}

.cm-s-inner span.cm-meta {
  color: inherit;
}

.cm-s-inner span.cm-tag {
  color: #db2d20;
}

.cm-s-inner span.cm-attribute {
  color: #01a252;
}

.cm-s-inner span.cm-qualifier {
  color: #388aa3;
}

.cm-s-inner span.cm-property {
  color: #01a252;
}

.cm-s-inner span.cm-builtin {
  color: #388aa3;
}

.cm-s-inner span.cm-variable-3, .cm-s-inner span.cm-type {
  color: #ffb86c;
}

.cm-s-inner span.cm-bracket {
  color: #3a3432;
}

.cm-s-inner span.cm-link {
  color: #a34e8f;
}

.cm-s-inner span.cm-error {
  background: #db2d20;
  color: #5c5855;
}

/* .md-fences.md-focus .cm-s-inner .CodeMirror-activeline-background {
  background: var(--purple-light-2);
} */

.cm-s-inner .CodeMirror-matchingbracket {
  text-decoration: underline;
  color: #a34e8f !important;
}

#fences-auto-suggest .active {
  background: #ddd;
}

#write .code-tooltip {
  bottom: initial;
  top: calc(100% - 1px);
  background: #f7f7f7;
  border: 1px solid #ddd;
  border-top: 0;
}

.auto-suggest-container {
  border-color: #b4b4b4;
}

.auto-suggest-container .autoComplt-hint.active {
  background: #b4b4b4;
  color: inherit;
}

/* task list */
#write .md-task-list-item > input {
  -webkit-appearance: initial;
  display: block;
  position: absolute;
  border: 1px solid #b4b4b4;
  border-radius: .25rem;
  margin-top: .1rem;
  margin-left: -1.8rem;
  height: 1.2rem;
  width: 1.2rem;
  transition: background 0.3s;
}

#write .md-task-list-item > input:focus {
  outline: none;
  box-shadow: none;
}

#write .md-task-list-item > input:hover {
  background: #ddd;
}

#write .md-task-list-item > input[checked]::before {
  content: '';
  position: absolute;
  top: 20%;
  left: 50%;
  height: 60%;
  width: 2px;
  transform: rotate(40deg);
  background: #333;
}

#write .md-task-list-item > input[checked]::after {
  content: '';
  position: absolute;
  top: 46%;
  left: 25%;
  height: 30%;
  width: 2px;
  transform: rotate(-40deg);
  background: #333;
}

#write .md-task-list-item > p {
  transition: color 0.3s, opacity 0.3s;
}

#write .md-task-list-item.task-list-done > p {
  color: #b4b4b4;
  text-decoration: line-through;
}

#write .md-task-list-item.task-list-done > p > .md-emoji {
  opacity: .5;
}

#write .md-task-list-item.task-list-done > p > .md-link > a {
  opacity: .6;
}

/* sidebar and outline */
.pin-outline .outline-active {
  color: var(--active-file-text-color); 
}

.file-list-item {
    border-bottom: 1px solid;
    border-color: var(--purple-light-5);
}

.file-list-item-summary {
    font-weight: 400;
}

.file-list-item.active {
    color: var(--active-file-text-color);
    background-color: var(--purple-light-5);
}

.file-tree-node.active>.file-node-background {
    background-color: var(--purple-light-5);
    font-weight: 700;
} 

.file-tree-node.active>.file-node-content {
    color: var(--active-file-text-color);
    font-weight: 700;
}

.file-node-content {
    color: #5e676d;
}

.sidebar-tabs {
    border-bottom: none;
}
.sidebar-tab.active {
    font-weight: 400;
}

.sidebar-content-content {
    font-size: 0.9rem;
}

img {
    max-width: 100%;
}

body {
    background-color: rgb(237, 237, 237);
}
#content {
    width: 836px;
    padding: 50px;
    background: #fff;
    margin: 0 auto;
}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/purple.css*/</style><style type="text/css">.hljs{display:block;overflow-x:auto;padding:.5em;color:#383a42;background:#fafafa}.hljs-comment,.hljs-quote{color:#a0a1a7;font-style:italic}.hljs-doctag,.hljs-formula,.hljs-keyword{color:#a626a4}.hljs-deletion,.hljs-name,.hljs-section,.hljs-selector-tag,.hljs-subst{color:#e45649}.hljs-literal{color:#0184bb}.hljs-addition,.hljs-attribute,.hljs-meta-string,.hljs-regexp,.hljs-string{color:#50a14f}.hljs-built_in,.hljs-class .hljs-title{color:#c18401}.hljs-attr,.hljs-number,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-pseudo,.hljs-template-variable,.hljs-type,.hljs-variable{color:#986801}.hljs-bullet,.hljs-link,.hljs-meta,.hljs-selector-id,.hljs-symbol,.hljs-title{color:#4078f2}.hljs-emphasis{font-style:italic}.hljs-strong{font-weight:700}.hljs-link{text-decoration:underline}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/atom-one-light.min.css*/</style></head>
<body>
  <div id="content"><h1>第46讲：遇到动态页面怎么办？详解渲染页面爬取</h1><p data-nodeid="165308">前面我们已经介绍了 Scrapy 的一些常见用法，包括服务端渲染页面的抓取和 API 的抓取，Scrapy 发起 Request 之后，返回的 Response 里面就包含了想要的结果。</p>



<p data-nodeid="163554">但是现在越来越多的网页都已经演变为 SPA 页面，其页面在浏览器中呈现的结果是经过 JavaScript 渲染得到的，如果我们使用 Scrapy 直接对其进行抓取的话，其结果和使用 requests 没有什么区别。</p>
<p data-nodeid="163555">那我们真的要使用 Scrapy 完成对 JavaScript 渲染页面的抓取应该怎么办呢？</p>
<p data-nodeid="163556">之前我们介绍了 Selenium 和 Pyppeteer 都可以实现 JavaScript 渲染页面的抓取，那用了 Scrapy 之后应该这么办呢？Scrapy 能和 Selenium 或 Pyppeteer 一起使用吗？答案是肯定的，我们可以将 Selenium 或 Pyppeteer 通过 Downloader Middleware 和 Scrapy 融合起来，实现 JavaScript 渲染页面的抓取，本节我们就来了解下它的实现吧。</p>
<h3 data-nodeid="165800" class="">回顾</h3>

<p data-nodeid="163558">在前面我们介绍了 Downloader Middleware 的用法，在 Downloader Middleware 中有三个我们可以实现的方法 process_request、process_response 以及 process_exception 方法。</p>
<p data-nodeid="163559">我们再看下 process_request 方法和其不同的返回值的效果：</p>
<ul data-nodeid="163560">
<li data-nodeid="163561">
<p data-nodeid="163562">当返回为 None 时，Scrapy 将继续处理该 Request，接着执行其他 Downloader Middleware 的 process_request 方法，一直到 Downloader 把 Request 执行完后得到 Response 才结束。这个过程其实就是修改 Request 的过程，不同的 Downloader Middleware 按照设置的优先级顺序依次对 Request 进行修改，最后送至 Downloader 执行。</p>
</li>
<li data-nodeid="163563">
<p data-nodeid="163564">当返回为 Response 对象时，更低优先级的 Downloader Middleware 的 process_request 和 process_exception 方法就不会被继续调用，每个 Downloader Middleware 的 process_response 方法转而被依次调用。调用完毕之后，直接将 Response 对象发送给 Spider 来处理。</p>
</li>
<li data-nodeid="163565">
<p data-nodeid="163566">当返回为 Request 对象时，更低优先级的 Downloader Middleware 的 process_request 方法会停止执行。这个 Request 会重新放到调度队列里，其实它就是一个全新的 Request，等待被调度。如果被 Scheduler 调度了，那么所有的 Downloader Middleware 的 process_request 方法都会被重新按照顺序执行。</p>
</li>
<li data-nodeid="163567">
<p data-nodeid="163568">如果 IgnoreRequest 异常抛出，则所有的 Downloader Middleware 的 process_exception 方法会依次执行。如果没有一个方法处理这个异常，那么 Request 的 errorback 方法就会回调。如果该异常还没有被处理，那么它便会被忽略。</p>
</li>
</ul>
<p data-nodeid="163569">这里我们注意到第二个选项，当返回结果为 Response 对象时，低优先级的 process_request 方法就不会被继续调用了，这个 Response 对象会直接经由 process_response 方法处理后转交给 Spider 来解析。</p>
<p data-nodeid="163570">然后再接着想一想，process_request 接收的参数是 request，即 Request 对象，怎么会返回 Response 对象呢？原因可想而知了，这个 Request 对象不再经由 Scrapy 的 Downloader 来处理了，而是在 process_request 方法里面直接就完成了 Request 的发送操作，然后在得到了对应的 Response 结果后再将其返回就好了。</p>
<p data-nodeid="163571">那么对于 JavaScript 渲染的页面来说，照这个方法来做，我们就可以把 Selenium 或 Pyppeteer 加载页面的过程在 process_request 方法里面实现，得到网页渲染完后的源代码后直接构造 Response 返回即可，这样我们就完成了借助 Downloader Middleware 实现 Scrapy 爬取动态渲染页面的过程。</p>
<h3 data-nodeid="166292" class="">案例</h3>

<p data-nodeid="163573">本节我们就用实例来讲解一下 Scrapy 和 Pyppeteer 实现 JavaScript 渲染页面抓取的流程。</p>
<p data-nodeid="167272">本节使用的实例网站为 <a href="https://dynamic5.scrape.center/" data-nodeid="167277">https://dynamic5.scrape.center/</a>，这是一个 JavaScript 渲染页面，其内容是一本本的图书信息。</p>
<p data-nodeid="167273" class=""><img src="https://s0.lgstatic.com/i/image/M00/34/22/Ciqc1F8RXwWARdOHABEEvYwMNOY314.png" alt="image.png" data-nodeid="167281"></p>



<p data-nodeid="163576">同时这个网站的页面带有分页功能，只需要在 URL 加上 <code data-backticks="1" data-nodeid="163693">/page/</code> 和页码就可以跳转到下一页，如 <a href="https://dynamic5.scrape.center/page/2" data-nodeid="163697">https://dynamic5.scrape.center/page/2</a> 就是第二页内容，<a href="https://dynamic5.scrape.center/page/3" data-nodeid="163701">https://dynamic5.scrape.center/page/3</a> 就是第三页内容。</p>
<p data-nodeid="163577">那我们这个案例就来试着爬取前十页的图书信息吧。</p>
<h3 data-nodeid="167772" class="">实现</h3>

<p data-nodeid="163579">首先我们来新建一个项目，叫作 scrapypyppeteer，命令如下：</p>
<pre class="lang-java" data-nodeid="169737"><code data-language="java">scrapy startproject scrapypyppeteer
</code></pre>




<p data-nodeid="163581">接着进入项目，然后新建一个 Spider，名称为 book，命令如下：</p>
<pre class="lang-java" data-nodeid="170228"><code data-language="java">cd scrapypyppeteer
scrapy genspider book dynamic5.scrape.center
</code></pre>

<p data-nodeid="163583">这时候可以发现在项目的 spiders 文件夹下就出现了一个名为 spider.py 的文件，内容如下：</p>
<pre class="lang-dart" data-nodeid="176857"><code data-language="dart"># -*- coding: utf<span class="hljs-number">-8</span> -*-
<span class="hljs-keyword">import</span> scrapy
​
​
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BookSpider</span>(<span class="hljs-title">scrapy</span>.<span class="hljs-title">Spider</span>):
 &nbsp; &nbsp;<span class="hljs-title">name</span> = '<span class="hljs-title">book</span>'
 &nbsp; &nbsp;<span class="hljs-title">allowed_domains</span> = ['<span class="hljs-title">dynamic5</span>.<span class="hljs-title">scrape</span>.<span class="hljs-title">center</span>']
 &nbsp; &nbsp;<span class="hljs-title">start_urls</span> = ['<span class="hljs-title">http</span>://<span class="hljs-title">dynamic5</span>.<span class="hljs-title">scrape</span>.<span class="hljs-title">center</span>/']
​
 &nbsp; &nbsp;<span class="hljs-title">def</span> <span class="hljs-title">parse</span>(<span class="hljs-title">self</span>, <span class="hljs-title">response</span>):
 &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-title">pass</span>
</span></code></pre>














<p data-nodeid="163585">首先我们构造列表页的初始请求，实现一个 start_requests 方法，如下所示：</p>
<pre class="lang-go" data-nodeid="191096"><code data-language="go"># -*- coding: utf<span class="hljs-number">-8</span> -*-
from scrapy <span class="hljs-keyword">import</span> Request, Spider
​
​
class BookSpider(Spider):
 &nbsp; &nbsp;name = <span class="hljs-string">'book'</span>
 &nbsp; &nbsp;allowed_domains = [<span class="hljs-string">'dynamic5.scrape.center'</span>]
 &nbsp; &nbsp;
 &nbsp; &nbsp;base_url = <span class="hljs-string">'https://dynamic5.scrape.center/page/{page}'</span>
 &nbsp; &nbsp;max_page = <span class="hljs-number">10</span>
 &nbsp; &nbsp;
 &nbsp; &nbsp;def start_requests(self):
 &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-keyword">for</span> page in <span class="hljs-keyword">range</span>(<span class="hljs-number">1</span>, self.max_page + <span class="hljs-number">1</span>):
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;url = self.base_url.format(page=page)
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;yield Request(url, callback=self.parse_index)
 &nbsp; &nbsp;
 &nbsp; &nbsp;def parse_index(self, response):
 &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-built_in">print</span>(response.text)
</code></pre>





























<p data-nodeid="192069">这时如果我们直接运行这个 Spider，在 parse_index 方法里面打印输出 Response 的内容，结果如下：</p>
<p data-nodeid="192070" class=""><img src="https://s0.lgstatic.com/i/image/M00/34/2D/CgqCHl8RX0iADQnIAAJk6NIEDak825.png" alt="image (1).png" data-nodeid="192080"></p>


<p data-nodeid="163589">我们可以发现所得到的内容并不是页面渲染后的真正 HTML 代码。此时如果我们想要获取 HTML 渲染结果的话就得使用 Downloader Middleware 实现了。</p>
<p data-nodeid="163590">这里我们直接以一个我已经写好的组件来演示了，组件的名称叫作 GerapyPyppeteer，组件里已经写好了 Scrapy 和 Pyppeteer 结合的中间件，下面我们来详细介绍下。</p>
<p data-nodeid="163591">我们可以借助于 pip3 来安装组件，命令如下：</p>
<pre class="lang-java" data-nodeid="192579"><code data-language="java">pip3 install gerapy-pyppeteer
</code></pre>

<p data-nodeid="163593">GerapyPyppeteer 提供了两部分内容，一部分是 Downloader Middleware，一部分是 Request。<br>
首先我们需要开启中间件，在 settings 里面开启 PyppeteerMiddleware，配置如下：</p>
<pre class="lang-java" data-nodeid="193078"><code data-language="java">DOWNLOADER_MIDDLEWARES = {
 &nbsp; &nbsp;<span class="hljs-string">'gerapy_pyppeteer.downloadermiddlewares.PyppeteerMiddleware'</span>: <span class="hljs-number">543</span>,
}
</code></pre>

<p data-nodeid="163595">然后我们把上文定义的 Request 修改为 PyppeteerRequest 即可：</p>
<pre class="lang-go" data-nodeid="197569"><code data-language="go"># -*- coding: utf<span class="hljs-number">-8</span> -*-
from gerapy_pyppeteer <span class="hljs-keyword">import</span> PyppeteerRequest
from scrapy <span class="hljs-keyword">import</span> Request, Spider
​
​
class BookSpider(Spider):
 &nbsp; &nbsp;name = <span class="hljs-string">'book'</span>
 &nbsp; &nbsp;allowed_domains = [<span class="hljs-string">'dynamic5.scrape.center'</span>]
 &nbsp; &nbsp;
 &nbsp; &nbsp;base_url = <span class="hljs-string">'https://dynamic5.scrape.center/page/{page}'</span>
 &nbsp; &nbsp;max_page = <span class="hljs-number">10</span>
 &nbsp; &nbsp;
 &nbsp; &nbsp;def start_requests(self):
 &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-keyword">for</span> page in <span class="hljs-keyword">range</span>(<span class="hljs-number">1</span>, self.max_page + <span class="hljs-number">1</span>):
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;url = self.base_url.format(page=page)
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;yield PyppeteerRequest(url, callback=self.parse_index, wait_for=<span class="hljs-string">'.item .name'</span>)
 &nbsp; &nbsp;
 &nbsp; &nbsp;def parse_index(self, response):
 &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-built_in">print</span>(response.text)
</code></pre>









<p data-nodeid="163597">这样其实就完成了 Pyppeteer 的对接了，非常简单。<br>
这里 PyppeteerRequest 和原本的 Request 多提供了一个参数，就是 wait_for，通过这个参数我们可以指定 Pyppeteer 需要等待特定的内容加载出来才算结束，然后才返回对应的结果。</p>
<p data-nodeid="163598">为了方便观察效果，我们把并发限制修改得小一点，然后把 Pyppeteer 的 Headless 模式设置为 False：</p>
<pre class="lang-java" data-nodeid="198068"><code data-language="java">CONCURRENT_REQUESTS = <span class="hljs-number">3</span>
GERAPY_PYPPETEER_HEADLESS = False
</code></pre>

<p data-nodeid="199057">这时我们重新运行 Spider，就可以看到在爬取的过程中，Pyppeteer 对应的 Chromium 浏览器就弹出来了，并逐个加载对应的页面内容，加载完成之后浏览器关闭。<br>
另外观察下控制台，我们发现对应的结果也就被提取出来了，如图所示：</p>
<p data-nodeid="199058" class=""><img src="https://s0.lgstatic.com/i/image/M00/34/2D/CgqCHl8RX2SAAVD5AAK2ktEbgAQ066.png" alt="image (2).png" data-nodeid="199068"></p>


<p data-nodeid="163602">这时候我们再重新修改下 parse_index 方法，提取对应的每本书的名称和作者即可：</p>
<pre class="lang-java" data-nodeid="201096"><code data-language="java"><span class="hljs-function">def <span class="hljs-title">parse_index</span><span class="hljs-params">(self, response)</span>:
 &nbsp; &nbsp;<span class="hljs-keyword">for</span> item in response.<span class="hljs-title">css</span><span class="hljs-params">(<span class="hljs-string">'.item'</span>)</span>:
 &nbsp; &nbsp; &nbsp; &nbsp;name </span>= item.css(<span class="hljs-string">'.name::text'</span>).extract_first()
 &nbsp; &nbsp; &nbsp; &nbsp;authors = item.css(<span class="hljs-string">'.authors::text'</span>).extract_first()
 &nbsp; &nbsp; &nbsp; &nbsp;name = name.strip() <span class="hljs-keyword">if</span> name <span class="hljs-keyword">else</span> None
 &nbsp; &nbsp; &nbsp; &nbsp;authors = authors.strip() <span class="hljs-keyword">if</span> authors <span class="hljs-keyword">else</span> None
 &nbsp; &nbsp; &nbsp; &nbsp;yield {
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-string">'name'</span>: name,
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-string">'authors'</span>: authors
 &nbsp; &nbsp; &nbsp;  }
</code></pre>




<p data-nodeid="202354">重新运行，即可发现对应的名称和作者就被提取出来了，运行结果如下：</p>
<p data-nodeid="202355" class=""><img src="https://s0.lgstatic.com/i/image/M00/34/2E/CgqCHl8RX4OAK3y6AAOIS7PLohc610.png" alt="image (3).png" data-nodeid="202363"></p>

<p data-nodeid="202102">这样我们就借助 GerapyPyppeteer 完成了 JavaScript 渲染页面的爬取。</p>



<h4 data-nodeid="202878" class="">原理分析</h4>

<p data-nodeid="163608">但上面仅仅是我们借助 GerapyPyppeteer 实现了 Scrapy 和 Pyppeteer 的对接，但其背后的原理是怎样的呢？</p>
<p data-nodeid="163609">我们可以详细分析它的源码，其 GitHub 地址为 <a href="https://github.com/Gerapy/GerapyPyppeteer" data-nodeid="163749">https://github.com/Gerapy/GerapyPyppeteer</a>。</p>
<p data-nodeid="163610">首先通过分析可以发现其最核心的内容就是实现了一个 PyppeteerMiddleware，这是一个 Downloader Middleware，这里最主要的就是 process_request  的实现，核心代码如下所示：</p>
<pre class="lang-java" data-nodeid="203394"><code data-language="java"><span class="hljs-function">def <span class="hljs-title">process_request</span><span class="hljs-params">(self, request, spider)</span>:
 &nbsp; &nbsp;logger.<span class="hljs-title">debug</span><span class="hljs-params">(<span class="hljs-string">'processing request %s'</span>, request)</span> &nbsp;
 &nbsp; &nbsp;return <span class="hljs-title">as_deferred</span><span class="hljs-params">(self._process_request(request, spider)</span>)
</span></code></pre>

<p data-nodeid="204424">这里其实就是调用了一个 _process_request 方法，这个方法的返回结果被 as_deferred 方法调用了。</p>
<p data-nodeid="204425">这个 as_deferred 是怎么定义的呢？代码如下：</p>

<pre class="lang-java" data-nodeid="203909"><code data-language="java"><span class="hljs-keyword">import</span> asyncio
from twisted.internet.defer <span class="hljs-keyword">import</span> Deferred
​
<span class="hljs-function">def <span class="hljs-title">as_deferred</span><span class="hljs-params">(f)</span>:
 &nbsp; &nbsp;return Deferred.<span class="hljs-title">fromFuture</span><span class="hljs-params">(asyncio.ensure_future(f)</span>)
</span></code></pre>

<p data-nodeid="204950">这个方法接收的就是一个 asyncio 库的 Future 对象，然后通过 fromFuture 方法转化成了 twisted 里面的 Deferred 对象。这是因为 Scrapy 本身的异步是借助 twisted 实现的，一个个的异步任务对应的就是一个个 Deferred 对象，而 Pyppeteer 又是基于 asyncio 的，它的异步任务是 Future 对象，所以这里我们需要借助 Deferred 的 fromFuture 方法将 Future 转为 Deferred 对象。</p>
<p data-nodeid="204951">另外为了支持这个功能，我们还需要在 Scrapy 中修改 reactor 对象，修改为 AsyncioSelectorReactor，实现如下：</p>

<pre class="lang-dart" data-nodeid="210618"><code data-language="dart"><span class="hljs-keyword">import</span> sys
from twisted.internet.asyncioreactor <span class="hljs-keyword">import</span> AsyncioSelectorReactor
<span class="hljs-keyword">import</span> twisted.internet
​
reactor = AsyncioSelectorReactor(asyncio.get_event_loop())
​
# install AsyncioSelectorReactor
twisted.internet.reactor = reactor
sys.modules[<span class="hljs-string">'twisted.internet.reactor'</span>] = reactor
</code></pre>











<p data-nodeid="163616">这段代码已经在 PyppeteerMiddleware 里面定义好了，在 Scrapy 正式开始爬取之前这段代码就会被执行，将 Scrapy 中的 reactor 修改为 AsyncioSelectorReactor，从而实现 Future 的调度。<br>
接下来我们再来看下 _process_request 方法，实现如下：</p>
<pre class="lang-dart" data-nodeid="218343"><code data-language="dart"><span class="hljs-keyword">async</span> def _process_request(self, request: PyppeteerRequest, spider):
 &nbsp; &nbsp;<span class="hljs-string">"""
 &nbsp;  use pyppeteer to process spider
 &nbsp;  :param request:
 &nbsp;  :param spider:
 &nbsp;  :return:
 &nbsp;  """</span>
 &nbsp; &nbsp;options = {
 &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-string">'headless'</span>: self.headless,
 &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-string">'dumpio'</span>: self.dumpio,
 &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-string">'devtools'</span>: self.devtools,
 &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-string">'args'</span>: [
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;f<span class="hljs-string">'--window-size={self.window_width},{self.window_height}'</span>,
 &nbsp; &nbsp; &nbsp;  ]
 &nbsp;  }
 &nbsp; &nbsp;<span class="hljs-keyword">if</span> self.executable_path: options[<span class="hljs-string">'executable_path'</span>] = self.executable_path
 &nbsp; &nbsp;<span class="hljs-keyword">if</span> self.disable_extensions: options[<span class="hljs-string">'args'</span>].append(<span class="hljs-string">'--disable-extensions'</span>)
 &nbsp; &nbsp;<span class="hljs-keyword">if</span> self.hide_scrollbars: options[<span class="hljs-string">'args'</span>].append(<span class="hljs-string">'--hide-scrollbars'</span>)
 &nbsp; &nbsp;<span class="hljs-keyword">if</span> self.mute_audio: options[<span class="hljs-string">'args'</span>].append(<span class="hljs-string">'--mute-audio'</span>)
 &nbsp; &nbsp;<span class="hljs-keyword">if</span> self.no_sandbox: options[<span class="hljs-string">'args'</span>].append(<span class="hljs-string">'--no-sandbox'</span>)
 &nbsp; &nbsp;<span class="hljs-keyword">if</span> self.disable_setuid_sandbox: options[<span class="hljs-string">'args'</span>].append(<span class="hljs-string">'--disable-setuid-sandbox'</span>)
 &nbsp; &nbsp;<span class="hljs-keyword">if</span> self.disable_gpu: options[<span class="hljs-string">'args'</span>].append(<span class="hljs-string">'--disable-gpu'</span>)
 &nbsp; &nbsp;
 &nbsp; &nbsp;# <span class="hljs-keyword">set</span> proxy
 &nbsp; &nbsp;proxy = request.proxy
 &nbsp; &nbsp;<span class="hljs-keyword">if</span> not proxy:
 &nbsp; &nbsp; &nbsp; &nbsp;proxy = request.meta.<span class="hljs-keyword">get</span>(<span class="hljs-string">'proxy'</span>)
 &nbsp; &nbsp;<span class="hljs-keyword">if</span> proxy: options[<span class="hljs-string">'args'</span>].append(f<span class="hljs-string">'--proxy-server={proxy}'</span>)
 &nbsp; &nbsp;
 &nbsp; &nbsp;logger.debug(<span class="hljs-string">'set options %s'</span>, options)
 &nbsp; &nbsp;
 &nbsp; &nbsp;browser = <span class="hljs-keyword">await</span> launch(options)
 &nbsp; &nbsp;page = <span class="hljs-keyword">await</span> browser.newPage()
 &nbsp; &nbsp;<span class="hljs-keyword">await</span> page.setViewport({<span class="hljs-string">'width'</span>: self.window_width, <span class="hljs-string">'height'</span>: self.window_height})
 &nbsp; &nbsp;
 &nbsp; &nbsp;# <span class="hljs-keyword">set</span> cookies
 &nbsp; &nbsp;<span class="hljs-keyword">if</span> isinstance(request.cookies, dict):
 &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-keyword">await</span> page.setCookie(*[
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  {<span class="hljs-string">'name'</span>: k, <span class="hljs-string">'value'</span>: v}
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> request.cookies.items()
 &nbsp; &nbsp; &nbsp;  ])
 &nbsp; &nbsp;<span class="hljs-keyword">else</span>:
 &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-keyword">await</span> page.setCookie(request.cookies)
 &nbsp; &nbsp;
 &nbsp; &nbsp;# the headers must be <span class="hljs-keyword">set</span> using request interception
 &nbsp; &nbsp;<span class="hljs-keyword">await</span> page.setRequestInterception(True)
 &nbsp; &nbsp;
 &nbsp; &nbsp;<span class="hljs-meta">@page</span>.<span class="hljs-keyword">on</span>(<span class="hljs-string">'request'</span>)
 &nbsp; &nbsp;<span class="hljs-keyword">async</span> def _handle_interception(pu_request):
 &nbsp; &nbsp; &nbsp; &nbsp;# handle headers
 &nbsp; &nbsp; &nbsp; &nbsp;overrides = {
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-string">'headers'</span>: {
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;k.decode(): <span class="hljs-string">','</span>.join(map(lambda v: v.decode(), v))
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> request.headers.items()
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  }
 &nbsp; &nbsp; &nbsp;  }
 &nbsp; &nbsp; &nbsp; &nbsp;# handle resource types
 &nbsp; &nbsp; &nbsp; &nbsp;_ignore_resource_types = self.ignore_resource_types
 &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-keyword">if</span> request.ignore_resource_types <span class="hljs-keyword">is</span> not None:
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;_ignore_resource_types = request.ignore_resource_types
 &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-keyword">if</span> pu_request.resourceType <span class="hljs-keyword">in</span> _ignore_resource_types:
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-keyword">await</span> pu_request.abort()
 &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-keyword">else</span>:
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-keyword">await</span> pu_request.continue_(overrides)
 &nbsp; &nbsp;
 &nbsp; &nbsp;timeout = self.download_timeout
 &nbsp; &nbsp;<span class="hljs-keyword">if</span> request.timeout <span class="hljs-keyword">is</span> not None:
 &nbsp; &nbsp; &nbsp; &nbsp;timeout = request.timeout
 &nbsp; &nbsp;
 &nbsp; &nbsp;logger.debug(<span class="hljs-string">'crawling %s'</span>, request.url)
 &nbsp; &nbsp;
 &nbsp; &nbsp;response = None
 &nbsp; &nbsp;<span class="hljs-keyword">try</span>:
 &nbsp; &nbsp; &nbsp; &nbsp;options = {
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-string">'timeout'</span>: <span class="hljs-number">1000</span> * timeout,
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-string">'waitUntil'</span>: request.wait_until
 &nbsp; &nbsp; &nbsp;  }
 &nbsp; &nbsp; &nbsp; &nbsp;logger.debug(<span class="hljs-string">'request %s with options %s'</span>, request.url, options)
 &nbsp; &nbsp; &nbsp; &nbsp;response = <span class="hljs-keyword">await</span> page.goto(
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;request.url,
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;options=options
 &nbsp; &nbsp; &nbsp;  )
 &nbsp; &nbsp;except (PageError, TimeoutError):
 &nbsp; &nbsp; &nbsp; &nbsp;logger.error(<span class="hljs-string">'error rendering url %s using pyppeteer'</span>, request.url)
 &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-keyword">await</span> page.close()
 &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-keyword">await</span> browser.close()
 &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-keyword">return</span> self._retry(request, <span class="hljs-number">504</span>, spider)
 &nbsp; &nbsp;
 &nbsp; &nbsp;<span class="hljs-keyword">if</span> request.wait_for:
 &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-keyword">try</span>:
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;logger.debug(<span class="hljs-string">'waiting for %s finished'</span>, request.wait_for)
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-keyword">await</span> page.waitFor(request.wait_for)
 &nbsp; &nbsp; &nbsp; &nbsp;except TimeoutError:
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;logger.error(<span class="hljs-string">'error waiting for %s of %s'</span>, request.wait_for, request.url)
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-keyword">await</span> page.close()
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-keyword">await</span> browser.close()
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-keyword">return</span> self._retry(request, <span class="hljs-number">504</span>, spider)
 &nbsp; &nbsp;
 &nbsp; &nbsp;# evaluate script
 &nbsp; &nbsp;<span class="hljs-keyword">if</span> request.script:
 &nbsp; &nbsp; &nbsp; &nbsp;logger.debug(<span class="hljs-string">'evaluating %s'</span>, request.script)
 &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-keyword">await</span> page.evaluate(request.script)
 &nbsp; &nbsp;
 &nbsp; &nbsp;# sleep
 &nbsp; &nbsp;<span class="hljs-keyword">if</span> request.sleep <span class="hljs-keyword">is</span> not None:
 &nbsp; &nbsp; &nbsp; &nbsp;logger.debug(<span class="hljs-string">'sleep for %ss'</span>, request.sleep)
 &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-keyword">await</span> asyncio.sleep(request.sleep)
 &nbsp; &nbsp;
 &nbsp; &nbsp;content = <span class="hljs-keyword">await</span> page.content()
 &nbsp; &nbsp;body = str.encode(content)
 &nbsp; &nbsp;
 &nbsp; &nbsp;# close page and browser
 &nbsp; &nbsp;logger.debug(<span class="hljs-string">'close pyppeteer'</span>)
 &nbsp; &nbsp;<span class="hljs-keyword">await</span> page.close()
 &nbsp; &nbsp;<span class="hljs-keyword">await</span> browser.close()
 &nbsp; &nbsp;
 &nbsp; &nbsp;<span class="hljs-keyword">if</span> not response:
 &nbsp; &nbsp; &nbsp; &nbsp;logger.error(<span class="hljs-string">'get null response by pyppeteer of url %s'</span>, request.url)
 &nbsp; &nbsp;
 &nbsp; &nbsp;# Necessary to bypass the compression middleware (?)
 &nbsp; &nbsp;response.headers.pop(<span class="hljs-string">'content-encoding'</span>, None)
 &nbsp; &nbsp;response.headers.pop(<span class="hljs-string">'Content-Encoding'</span>, None)
 &nbsp; &nbsp;
 &nbsp; &nbsp;<span class="hljs-keyword">return</span> HtmlResponse(
 &nbsp; &nbsp; &nbsp; &nbsp;page.url,
 &nbsp; &nbsp; &nbsp; &nbsp;status=response.status,
 &nbsp; &nbsp; &nbsp; &nbsp;headers=response.headers,
 &nbsp; &nbsp; &nbsp; &nbsp;body=body,
 &nbsp; &nbsp; &nbsp; &nbsp;encoding=<span class="hljs-string">'utf-8'</span>,
 &nbsp; &nbsp; &nbsp; &nbsp;request=request
 &nbsp;  )
</code></pre>















<p data-nodeid="218858">代码内容比较多，我们慢慢来说。</p>
<p data-nodeid="218859">首先最开始的部分是定义 Pyppeteer 的一些启动参数：</p>

<pre class="lang-java" data-nodeid="219376"><code data-language="java">options = {
 &nbsp; &nbsp;<span class="hljs-string">'headless'</span>: self.headless,
 &nbsp; &nbsp;<span class="hljs-string">'dumpio'</span>: self.dumpio,
 &nbsp; &nbsp;<span class="hljs-string">'devtools'</span>: self.devtools,
 &nbsp; &nbsp;<span class="hljs-string">'args'</span>: [
 &nbsp; &nbsp; &nbsp; &nbsp;f<span class="hljs-string">'--window-size={self.window_width},{self.window_height}'</span>,
 &nbsp;  ]
}
<span class="hljs-keyword">if</span> self.executable_path: options[<span class="hljs-string">'executable_path'</span>] = self.executable_path
<span class="hljs-keyword">if</span> self.disable_extensions: options[<span class="hljs-string">'args'</span>].append(<span class="hljs-string">'--disable-extensions'</span>)
<span class="hljs-keyword">if</span> self.hide_scrollbars: options[<span class="hljs-string">'args'</span>].append(<span class="hljs-string">'--hide-scrollbars'</span>)
<span class="hljs-keyword">if</span> self.mute_audio: options[<span class="hljs-string">'args'</span>].append(<span class="hljs-string">'--mute-audio'</span>)
<span class="hljs-keyword">if</span> self.no_sandbox: options[<span class="hljs-string">'args'</span>].append(<span class="hljs-string">'--no-sandbox'</span>)
<span class="hljs-keyword">if</span> self.disable_setuid_sandbox: options[<span class="hljs-string">'args'</span>].append(<span class="hljs-string">'--disable-setuid-sandbox'</span>)
<span class="hljs-keyword">if</span> self.disable_gpu: options[<span class="hljs-string">'args'</span>].append(<span class="hljs-string">'--disable-gpu'</span>)
</code></pre>

<p data-nodeid="219891">这些参数来自 from_crawler 里面读取项目 settings 的内容，如配置 Pyppeteer 对应浏览器的无头模式、窗口大小、是否隐藏滚动条、是否弃用沙箱，等等。</p>
<p data-nodeid="219892">紧接着就是利用 options 来启动 Pyppeteer：</p>

<pre class="lang-java" data-nodeid="220411"><code data-language="java">browser = <span class="hljs-function">await <span class="hljs-title">launch</span><span class="hljs-params">(options)</span>
page </span>= await browser.newPage()
await page.setViewport({<span class="hljs-string">'width'</span>: self.window_width, <span class="hljs-string">'height'</span>: self.window_height})
</code></pre>

<p data-nodeid="220926">这里启动了 Pyppeteer 对应的浏览器，将其赋值为 browser，然后新建了一个选项卡，赋值为 page，然后通过 setViewport 方法设定了窗口的宽高。</p>
<p data-nodeid="220927">接下来就是对一些 Cookies 进行处理，如果 Request 带有 Cookies 的话会被赋值到 Pyppeteer 中：</p>

<pre class="lang-dart" data-nodeid="226594"><code data-language="dart"># <span class="hljs-keyword">set</span> cookies
<span class="hljs-keyword">if</span> isinstance(request.cookies, dict):
 &nbsp; &nbsp;<span class="hljs-keyword">await</span> page.setCookie(*[
 &nbsp; &nbsp; &nbsp;  {<span class="hljs-string">'name'</span>: k, <span class="hljs-string">'value'</span>: v}
 &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> request.cookies.items()
 &nbsp;  ])
<span class="hljs-keyword">else</span>:
 &nbsp; &nbsp;<span class="hljs-keyword">await</span> page.setCookie(request.cookies)
</code></pre>











<p data-nodeid="163624">再然后关键的步骤就是进行页面的加载了：</p>
<pre class="lang-java" data-nodeid="227109"><code data-language="java"><span class="hljs-keyword">try</span>:
 &nbsp; &nbsp;options = {
 &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-string">'timeout'</span>: <span class="hljs-number">1000</span> * timeout,
 &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-string">'waitUntil'</span>: request.wait_until
 &nbsp;  }
 &nbsp; &nbsp;logger.debug(<span class="hljs-string">'request %s with options %s'</span>, request.url, options)
 &nbsp; &nbsp;response = await page.goto(
 &nbsp; &nbsp; &nbsp; &nbsp;request.url,
 &nbsp; &nbsp; &nbsp; &nbsp;options=options
 &nbsp;  )
except (PageError, TimeoutError):
 &nbsp; &nbsp;logger.error(<span class="hljs-string">'error rendering url %s using pyppeteer'</span>, request.url)
 &nbsp; &nbsp;await page.close()
 &nbsp; &nbsp;await browser.close()
 &nbsp; &nbsp;<span class="hljs-keyword">return</span> self._retry(request, <span class="hljs-number">504</span>, spider)
</code></pre>

<p data-nodeid="227624">这里我们首先制定了加载超时时间 timeout 还有要等待完成的事件 waitUntil，接着调用 page 的 goto 方法访问对应的页面，同时进行了异常检测，如果发生错误就关闭浏览器并重新发起一次重试请求。</p>
<p data-nodeid="227625">在页面加载出来之后，我们还需要判定我们期望的结果是不是加载出来了，所以这里又增加了 waitFor 的调用：</p>

<pre class="lang-java" data-nodeid="228142"><code data-language="java"><span class="hljs-keyword">if</span> request.wait_for:
 &nbsp; &nbsp;<span class="hljs-keyword">try</span>:
 &nbsp; &nbsp; &nbsp; &nbsp;logger.debug(<span class="hljs-string">'waiting for %s finished'</span>, request.wait_for)
 &nbsp; &nbsp; &nbsp; &nbsp;await page.waitFor(request.wait_for)
 &nbsp; &nbsp;except TimeoutError:
 &nbsp; &nbsp; &nbsp; &nbsp;logger.error(<span class="hljs-string">'error waiting for %s of %s'</span>, request.wait_for, request.url)
 &nbsp; &nbsp; &nbsp; &nbsp;await page.close()
 &nbsp; &nbsp; &nbsp; &nbsp;await browser.close()
 &nbsp; &nbsp; &nbsp; &nbsp;<span class="hljs-keyword">return</span> self._retry(request, <span class="hljs-number">504</span>, spider)
</code></pre>

<p data-nodeid="228657">这里 request 有个 wait_for 属性，就可以定义想要加载的节点的选择器，如 <code data-backticks="1" data-nodeid="228662">.item .name</code> 等，这样如果页面在规定时间内加载出来就会继续向下执行，否则就会触发 TimeoutError 并被捕获，关闭浏览器并重新发起一次重试请求。</p>
<p data-nodeid="228658">等想要的结果加载出来之后，我们还可以执行一些自定义的 JavaScript 代码完成我们想要自定义的功能：</p>

<pre class="lang-dart" data-nodeid="234329"><code data-language="dart"># evaluate script
<span class="hljs-keyword">if</span> request.script:
 &nbsp; &nbsp;logger.debug(<span class="hljs-string">'evaluating %s'</span>, request.script)
 &nbsp; &nbsp;<span class="hljs-keyword">await</span> page.evaluate(request.script)
</code></pre>











<p data-nodeid="163630">最后关键的一步就是将当前页面的源代码打印出来，然后构造一个 HtmlResponse 返回即可：</p>
<pre class="lang-dart te-preview-highlight" data-nodeid="239994"><code data-language="dart">content = <span class="hljs-keyword">await</span> page.content()
body = str.encode(content)
​
# close page and browser
logger.debug(<span class="hljs-string">'close pyppeteer'</span>)
<span class="hljs-keyword">await</span> page.close()
<span class="hljs-keyword">await</span> browser.close()
​
<span class="hljs-keyword">if</span> not response:
 &nbsp; &nbsp;logger.error(<span class="hljs-string">'get null response by pyppeteer of url %s'</span>, request.url)
​
# Necessary to bypass the compression middleware (?)
response.headers.pop(<span class="hljs-string">'content-encoding'</span>, None)
response.headers.pop(<span class="hljs-string">'Content-Encoding'</span>, None)
​
<span class="hljs-keyword">return</span> HtmlResponse(
 &nbsp; &nbsp;page.url,
 &nbsp; &nbsp;status=response.status,
 &nbsp; &nbsp;headers=response.headers,
 &nbsp; &nbsp;body=body,
 &nbsp; &nbsp;encoding=<span class="hljs-string">'utf-8'</span>,
 &nbsp; &nbsp;request=request
)
</code></pre>











<p data-nodeid="164806">所以，如果代码可以执行到最后，返回到就是一个 Response 对象，这个 Resposne 对象的 body 就是 Pyppeteer  渲染页面后的结果，因此这个 Response 对象再传给 Spider 解析，就是 JavaScript 渲染后的页面结果了。</p>
<p data-nodeid="164807">这样我们就通过 Downloader Middleware 通过对接 Pyppeteer 完成 JavaScript 动态渲染页面的抓取了。</p></div>

</body></html>
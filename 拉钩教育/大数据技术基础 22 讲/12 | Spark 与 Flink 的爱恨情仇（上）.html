<!DOCTYPE html><html lang="en"><head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>12 | Spark 与 Flink 的爱恨情仇（上）</title>
<style type="text/css">
:root {
    --control-text-color: #777;
    --select-text-bg-color: rgba(223, 197, 223);  /*#7e66992e;*/
    
    /* side bar */
    --side-bar-bg-color: rgb(255, 255, 255);
    --active-file-text-color: #8163bd;
    --active-file-bg-color: #E9E4F0;
    --item-hover-bg-color: #E9E4F0;
    --active-file-border-color: #8163bd;

    --title-color: #6c549c;
    --font-sans-serif: 'Ubuntu', 'Source Sans Pro', sans-serif !important;
    --font-monospace: 'Fira Code', 'Roboto Mono', monospace !important;
    --purple-1: #8163bd;
    --purple-2: #79589F;
    --purple-3: #fd5eb8;
    --purple-light-1: rgba(99, 99, 172, .05);
    --purple-light-2: rgba(99, 99, 172, .1);
    --purple-light-3: rgba(99, 99, 172, .2);
    --purple-light-4: rgba(129, 99, 189, .3);
    --purple-light-5: #E9E4F0;
    --purple-light-6: rgba(129, 99, 189, .8);
}

/* html {
    font-size: 16px;
} */

body {
    font-family: var(--font-sans-serif);
    color: #34495e;
    -webkit-font-smoothing: antialiased;
    line-height: 1.6rem;
    letter-spacing: 0;
    margin: 0;
    overflow-x: hidden;
}

/* 页边距 和 页面大小 */
#write {
    padding-left: 6ch;
    padding-right: 6ch;
    margin: 0 auto;
}

#write p {
    line-height: 1.6rem;
    word-spacing: .05rem;
}

#write ol li {
    padding-left: 0.5rem;
}

#write > ul:first-child,
#write > ol:first-child {
    margin-top: 30px;
}

body > *:first-child {
    margin-top: 0 !important;
}

body > *:last-child {
    margin-bottom: 0 !important;
}

a {
    color: var(--purple-1);
    padding: 0 2px;
    text-decoration: none;
}
.md-content {
    color: var(--purple-light-6);
}
#write a {
    border-bottom: 1px solid var(--purple-1);
    color: var(--purple-1);
    text-decoration: none;
}

h1,
h2,
h3,
h4,
h5,
h6 {
    position: relative;
    margin-top: 1rem;
    margin-bottom: 0.5rem;
    /* font-weight: bold; */
    font-weight: 500 !important;
    line-height: 1.4;
    cursor: text;
    color: var(--title-color);
    font-family: var(--font-sans-serif);
}

h1:hover a.anchor,
h2:hover a.anchor,
h3:hover a.anchor,
h4:hover a.anchor,
h5:hover a.anchor,
h6:hover a.anchor {
    text-decoration: none;
}

h1 tt,
h1 code {
    font-size: inherit !important;
}
h2 tt,
h2 code {
    font-size: inherit !important;
}
h3 tt,
h3 code {
    font-size: inherit !important;
}
h4 tt,
h4 code {
    font-size: inherit !important;
}
h5 tt,
h5 code {
    font-size: inherit !important;
}
h6 tt,
h6 code {
    font-size: inherit !important;
}


h1 {
    padding-bottom: .4rem;
    font-size: 2.2rem;
    line-height: 1.3;
}
h1 {
    text-align: center;
    padding-bottom: 0.3em;
    font-size: 2.2em;
    line-height: 1.2;
    margin: 2.4em auto 1.2em;
}
h1:after {
    content: '';
    display: block;
    margin: 0.2em auto 0;
    width: 100px;
    height: 2px;
    border-bottom: 2px solid var(--title-color);
}

h2 {
    margin: 1.6em auto 0.5em;
    padding-left: 10px;
    line-height: 1.4;
    font-size: 1.8em;
    border-left: 9px solid var(--title-color);
    border-bottom: 1px solid var(--title-color);
}
h3 {
    font-size: 1.5rem;
    margin: 1.2em auto 0.5em;
}
h4 {
    font-size: 1.3rem;
}
h5 {
    font-size: 1.2rem;
}
h6 {
    font-size: 1.1rem;
}

p,
blockquote,
ul,
ol,
dl,
table {
    margin: 0.8em 0;
}

li > ol,
li > ul {
    margin: 0 0;
}

hr {
    height: 2px;
    padding: 0;
    margin: 16px 0;
    background-color: #e7e7e7;
    border: 0 none;
    overflow: hidden;
    box-sizing: content-box;
}

body > h2:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0;
}

body > h3:first-child,
body > h4:first-child,
body > h5:first-child,
body > h6:first-child {
    margin-top: 0;
    padding-top: 0;
}

a:first-child h1,
a:first-child h2,
a:first-child h3,
a:first-child h4,
a:first-child h5,
a:first-child h6 {
    margin-top: 0;
    padding-top: 0;
}

h1 p,
h2 p,
h3 p,
h4 p,
h5 p,
h6 p {
    margin-top: 0;
}

li p.first {
    display: inline-block;
}

ul,
ol {
    padding-left: 30px;
}

ul:first-child,
ol:first-child {
    margin-top: 0;
}

ul:last-child,
ol:last-child {
    margin-bottom: 0;
}

/* 引用 */
blockquote {
    /* margin-left: 1rem; */
    border-left: 4px solid var(--purple-light-4);
    padding: 10px 15px;
    color: #777;
    background-color: var(--purple-light-1);
}

/* 表格 */
table {
    padding: 0;
    word-break: initial;
}

table tr {
    border-top: 1px solid #dfe2e5;
    margin: 0;
    padding: 0;
}

/* 表格 背景色 */
table tr:nth-child(2n),
thead {
    background-color: var(--purple-light-1);
}
#write table thead th {
    background-color: var(--purple-light-2);
}

table tr th {
    font-weight: bold;
    border: 1px solid #dfe2e5;
    border-bottom: 0;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr td {
    border: 1px solid #dfe2e5;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr th:first-child,
table tr td:first-child {
    margin-top: 0;
}

table tr th:last-child,
table tr td:last-child {
    margin-bottom: 0;
}

/* 粗体 */
#write strong {
    padding: 0 2px;
    color: var(--purple-1);
}

/* 斜体 */
#write em {
    padding: 0 5px 0 2px;
    /* font-style: normal; */
    color: #42b983;
}

/* inline code */
#write code, tt {
    padding: 2px 4px;
    border-radius: 2px;
    font-family: var(--font-monospace);
    font-size: 0.92rem;
    color: var(--purple-3); 
    background-color: rgba(99, 99, 172, .05);
}

tt {
    margin: 0 2px;
}

#write .md-footnote {
    background-color: #f8f8f8;
    color: var(--purple-3);
}

/* heighlight. */
#write mark {
    background-color: #fbd3ea;
    border-radius: 2px;
    padding: 2px 4px;
    margin: 0 2px;
}

#write del {
    padding: 1px 2px;
}

.md-task-list-item > input {
    margin-left: -1.3em;
}

@media print {
    html {
        font-size: 0.9rem;
    }

    table,
    pre {
        page-break-inside: avoid;
    }

    pre {
        word-wrap: break-word;
    }
}

#write pre.md-meta-block {
    padding: 1rem;
    font-size: 85%;
    line-height: 1.45;
    background-color: #f7f7f7;
    border: 0;
    border-radius: 3px;
    color: #777777;
    margin-top: 0 !important;
}

.mathjax-block > .code-tooltip {
    bottom: .375rem;
}

/* 图片 */
.md-image > .md-meta {
    border-radius: 3px;
    font-family: var(--font-monospace);
    padding: 2px 0 0 4px;
    font-size: 0.9em;
    color: inherit;
}
p .md-image:only-child{
    width: auto;
    text-align: left;
    margin-left: 2rem;
}
.md-tag {
    color: inherit;
}
/* 当 “![shadow-随便写]()”写时，会有阴影 */
.md-image img[alt|='shadow'] {
    /* box-shadow: 0 4px 24px -6px #ddd; */
    box-shadow:var(--purple-light-2) 0px 10px 15px;
}

#write a.md-toc-inner {
    line-height: 1.6;
    white-space: pre-line;
    border-bottom: none;
    font-size: 0.9rem;
}

#typora-quick-open {
    border: 1px solid #ddd;
    background-color: #f8f8f8;
}

#typora-quick-open-item {
    background-color: #FAFAFA;
    border-color: #FEFEFE #e5e5e5 #e5e5e5 #eee;
    border-style: solid;
    border-width: 1px;
}

#md-notification:before {
    top: 10px;
}

header,
.context-menu,
.megamenu-content,
footer {
    font-family: var(--font-sans-serif);
}

.file-node-content:hover .file-node-icon,
.file-node-content:hover .file-node-open-state {
    visibility: visible;
}

.md-lang {
    color: #b4654d;
}

.html-for-mac .context-menu {
    --item-hover-bg-color: #E6F0FE;
}

/* 代码框 */
/* CodeMirror 3024 Day theme */

/* 代码段 背景 */
pre {
    --select-text-bg-color: rgba(223, 197, 223) !important;
    margin: .5em 0;
    padding: 1em 1.4em;
    border-radius: 8px;
    background: #f6f8fa;
    overflow-x: auto;
    box-sizing: border-box;
    font-size: 14px;
}

/* 边框 */
.md-fences {
    border: 1px solid #e7eaed;
    border-radius: 3px;
}

.cm-s-inner {
  padding: .25rem;
  border-radius: .25rem;
}

.cm-s-inner.CodeMirror, .cm-s-inner .CodeMirror-gutters {
  background-color: #f8f8f8 !important;
  color: #3a3432 !important;
  border: none;
}

.cm-s-inner .CodeMirror-gutters {
  color: #6d8a88;
}

.cm-s-inner .CodeMirror-cursor {
  border-left: solid thin #5c5855 !important;
}

.cm-s-inner .CodeMirror-linenumber {
  color: #807d7c;
}

.cm-s-inner .CodeMirror-line::selection, .cm-s-inner .CodeMirror-line::-moz-selection,
.cm-s-inner .CodeMirror-line > span::selection,
.cm-s-inner .CodeMirror-line > span::-moz-selection,
.cm-s-inner .CodeMirror-line > span > span::selection,
.cm-s-inner .CodeMirror-line > span > span::-moz-selection {
  background: var(--purple-light-2);
}

.cm-s-inner span.cm-comment {
  color: #cdab53;
}

.cm-s-inner span.cm-string, .cm-s-inner span.cm-string-2 {
  color: #f2b01d;
}

.cm-s-inner span.cm-number {
  color: #a34e8f;
}

.cm-s-inner span.cm-variable {
  color: #01a252;
}

.cm-s-inner span.cm-variable-2 {
  color: #01a0e4;
}

.cm-s-inner span.cm-def {
  /* color: #e8bbd0; */
  color: #e2287f;
}

.cm-s-inner span.cm-operator {
  color: #ff79c6;
}

.cm-s-inner span.cm-keyword {
  color: #db2d20;
}

.cm-s-inner span.cm-atom {
  color: #a34e8f;
}

.cm-s-inner span.cm-meta {
  color: inherit;
}

.cm-s-inner span.cm-tag {
  color: #db2d20;
}

.cm-s-inner span.cm-attribute {
  color: #01a252;
}

.cm-s-inner span.cm-qualifier {
  color: #388aa3;
}

.cm-s-inner span.cm-property {
  color: #01a252;
}

.cm-s-inner span.cm-builtin {
  color: #388aa3;
}

.cm-s-inner span.cm-variable-3, .cm-s-inner span.cm-type {
  color: #ffb86c;
}

.cm-s-inner span.cm-bracket {
  color: #3a3432;
}

.cm-s-inner span.cm-link {
  color: #a34e8f;
}

.cm-s-inner span.cm-error {
  background: #db2d20;
  color: #5c5855;
}

/* .md-fences.md-focus .cm-s-inner .CodeMirror-activeline-background {
  background: var(--purple-light-2);
} */

.cm-s-inner .CodeMirror-matchingbracket {
  text-decoration: underline;
  color: #a34e8f !important;
}

#fences-auto-suggest .active {
  background: #ddd;
}

#write .code-tooltip {
  bottom: initial;
  top: calc(100% - 1px);
  background: #f7f7f7;
  border: 1px solid #ddd;
  border-top: 0;
}

.auto-suggest-container {
  border-color: #b4b4b4;
}

.auto-suggest-container .autoComplt-hint.active {
  background: #b4b4b4;
  color: inherit;
}

/* task list */
#write .md-task-list-item > input {
  -webkit-appearance: initial;
  display: block;
  position: absolute;
  border: 1px solid #b4b4b4;
  border-radius: .25rem;
  margin-top: .1rem;
  margin-left: -1.8rem;
  height: 1.2rem;
  width: 1.2rem;
  transition: background 0.3s;
}

#write .md-task-list-item > input:focus {
  outline: none;
  box-shadow: none;
}

#write .md-task-list-item > input:hover {
  background: #ddd;
}

#write .md-task-list-item > input[checked]::before {
  content: '';
  position: absolute;
  top: 20%;
  left: 50%;
  height: 60%;
  width: 2px;
  transform: rotate(40deg);
  background: #333;
}

#write .md-task-list-item > input[checked]::after {
  content: '';
  position: absolute;
  top: 46%;
  left: 25%;
  height: 30%;
  width: 2px;
  transform: rotate(-40deg);
  background: #333;
}

#write .md-task-list-item > p {
  transition: color 0.3s, opacity 0.3s;
}

#write .md-task-list-item.task-list-done > p {
  color: #b4b4b4;
  text-decoration: line-through;
}

#write .md-task-list-item.task-list-done > p > .md-emoji {
  opacity: .5;
}

#write .md-task-list-item.task-list-done > p > .md-link > a {
  opacity: .6;
}

/* sidebar and outline */
.pin-outline .outline-active {
  color: var(--active-file-text-color); 
}

.file-list-item {
    border-bottom: 1px solid;
    border-color: var(--purple-light-5);
}

.file-list-item-summary {
    font-weight: 400;
}

.file-list-item.active {
    color: var(--active-file-text-color);
    background-color: var(--purple-light-5);
}

.file-tree-node.active>.file-node-background {
    background-color: var(--purple-light-5);
    font-weight: 700;
} 

.file-tree-node.active>.file-node-content {
    color: var(--active-file-text-color);
    font-weight: 700;
}

.file-node-content {
    color: #5e676d;
}

.sidebar-tabs {
    border-bottom: none;
}
.sidebar-tab.active {
    font-weight: 400;
}

.sidebar-content-content {
    font-size: 0.9rem;
}

img {
    max-width: 100%;
}

body {
    background-color: rgb(237, 237, 237);
}
#content {
    width: 836px;
    padding: 50px;
    background: #fff;
    margin: 0 auto;
}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/purple.css*/</style><style type="text/css">.hljs{display:block;overflow-x:auto;padding:.5em;color:#383a42;background:#fafafa}.hljs-comment,.hljs-quote{color:#a0a1a7;font-style:italic}.hljs-doctag,.hljs-formula,.hljs-keyword{color:#a626a4}.hljs-deletion,.hljs-name,.hljs-section,.hljs-selector-tag,.hljs-subst{color:#e45649}.hljs-literal{color:#0184bb}.hljs-addition,.hljs-attribute,.hljs-meta-string,.hljs-regexp,.hljs-string{color:#50a14f}.hljs-built_in,.hljs-class .hljs-title{color:#c18401}.hljs-attr,.hljs-number,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-pseudo,.hljs-template-variable,.hljs-type,.hljs-variable{color:#986801}.hljs-bullet,.hljs-link,.hljs-meta,.hljs-selector-id,.hljs-symbol,.hljs-title{color:#4078f2}.hljs-emphasis{font-style:italic}.hljs-strong{font-weight:700}.hljs-link{text-decoration:underline}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/atom-one-light.min.css*/</style></head>
<body>
  <div id="content"><h1>12 | Spark 与 Flink 的爱恨情仇（上）</h1><p data-nodeid="1457" class="">前面我们相对完整地介绍了 Hadoop 架构，并且在上一讲讲解了 Hadoop 中的计算框架 MapReduce 的基本思想。我们已经知道，MapReduce 的主要功能就是<strong data-nodeid="1558">并行计算</strong>，但是它也不是十全十美的，MapReduce 高成本的硬伤使得它已经不能很好地解决新时代的问题。</p>
<p data-nodeid="1458"><img src="https://s0.lgstatic.com/i/image6/M00/18/36/Cgp9HWBIlC-ASvztAAV5KV3DBYA200.png" alt="（大数据12金句.png" data-nodeid="1561"></p>
<p data-nodeid="1459">这一讲我们所要介绍的 Spark 就是由 MapReduce 思想衍生出来的新的分布式计算框架，但是它又不仅仅是一个 MapReduce 的升级版。接下来就让我们看一下，Spark 到底是一个什么样的工具。</p>
<h3 data-nodeid="1460">什么是 Spark</h3>
<p data-nodeid="1461">打开 Spark 的官网，我们看到的第一句话就是对 Spark 的定义：<strong data-nodeid="1577">Spark 是用于大规模数据处理的通用分析引擎</strong>。当然，原文是英文的，这句是我翻译过来的。这句话非常简洁明了地讲解了 Spark 的功能，一个是<strong data-nodeid="1578">针对大规模数据</strong>，一个是<strong data-nodeid="1579">通用分析引擎</strong>。</p>
<p data-nodeid="1462">让我们简单回顾一下 Spark 的发展历程。</p>
<p data-nodeid="1463">在 2009 年，加州大学伯克利分校的 RAD 实验室（AMP 实验室前身）推出了 Spark 框架，并表明 Spark 是一个类似 MapReduce 的通用并行框架，<strong data-nodeid="1586">可用来构建大型的、低延迟的数据分析应用程序</strong>。实验室的研究人员在使用 MapReduce 时发现它在迭代计算和交互计算上效率低下，于是开始设计 Spark。很快，Spark 在一些任务上的效率就已经比 MapReduce 提升了 10 倍以上。</p>
<p data-nodeid="1464">这里需要提到 Spark 的一个特点，那就是<strong data-nodeid="1592">低延迟</strong>。从一开始 Spark 就瞄准了低延迟这样一个目标，这也为它后来能够进入工业界并广泛地应用于生产奠定了基础。</p>
<p data-nodeid="1465">在 2013 年的时候，Spark 项目加入了 Apache，并在 2014 年的 Gray&nbsp;sort&nbsp;Benchmark 比赛上全面超越了 Hadoop 拿下了当年的冠军。这个比赛是对 100TB 的数据进行排序操作：</p>
<ul data-nodeid="1466">
<li data-nodeid="1467">
<p data-nodeid="1468">Spark 使用了 206 台 EC2 机器在 23 分钟内完成了操作；</p>
</li>
<li data-nodeid="1469">
<p data-nodeid="1470">而 Hadoop 的 MapReduce 则使用了 2100 个机器并耗费了 72 分钟。</p>
</li>
</ul>
<p data-nodeid="1471">在后来的一段时间里，Spark 在互联网公司的大数据架构中逐渐成为<strong data-nodeid="1601">主流计算框架</strong>。</p>
<h3 data-nodeid="1472"><strong data-nodeid="1605">Spark 的特色</strong></h3>
<p data-nodeid="1473">在 Spark 的官网上我们也可以看到，Spark 的特色有五个方面。</p>
<p data-nodeid="1474">（1）<strong data-nodeid="1611">高速</strong></p>
<p data-nodeid="1475">Spark 使用了最新的 DAG 调度方案，查询、优化和物理执行引擎，在批处理和“流”处理上都表现优异。这里，我给“流”处理加了引号，在后面我们会解释为什么这里会加一个引号。在官方给出的示例中，在 Spark 框架中执行逻辑回归运算要比 MapReduce 快一百多倍。</p>
<p data-nodeid="1476">（2）<strong data-nodeid="1617">易用</strong></p>
<p data-nodeid="1477">Spark 提供了 80 多种<strong data-nodeid="1623">高阶操作</strong>，构建应用更加方便。Spark 还提供了多种语言支持，使用 Java、Scala、Python、R 甚至是 SQL 都可以非常容易地编写 Spark 程序。</p>
<p data-nodeid="1478">（3）<strong data-nodeid="1628">通用</strong></p>
<p data-nodeid="1479">如下图所示，Spark 除了提供计算框架以外还整合了 SQL、流式处理，以及机器学习算法库和图操作算法库。其中 Spark&nbsp;SQL 支持使用 HiveQL 和 Spark 进行交互。</p>
<p data-nodeid="1480"><img src="https://s0.lgstatic.com/i/image6/M01/16/E2/CioPOWBHD7-AREhMAAGqR6vGaeg851.png" alt="图片1.png" data-nodeid="1632"></p>
<p data-nodeid="1481">（4）<strong data-nodeid="1637">多平台支持</strong></p>
<p data-nodeid="1482">Spark 本身是可以独立运行的，当然，它也可以运行在 Hadoop、Mesos、Kubernetes，甚至是云平台上。它还支持访问各种不同的数据源，比如 HDFS、HBase、Hive、Cassandra 都是可以的。</p>
<p data-nodeid="1483">（5）<strong data-nodeid="1643">内存化</strong></p>
<p data-nodeid="1484">这点在官网上没有，但是很重要。在运算流程上，Spark 和 MapReduce 基本上是一致的，但是有一个很大的不同就是中间结果的存储：</p>
<ul data-nodeid="1485">
<li data-nodeid="1486">
<p data-nodeid="1487"><strong data-nodeid="1649">MapReduce 所有的中间结果都是保存在磁盘上</strong>；</p>
</li>
<li data-nodeid="1488">
<p data-nodeid="1489"><strong data-nodeid="1654">而 Spark 的中间结果是保存在内存中的</strong>。</p>
</li>
</ul>
<p data-nodeid="1490">这你也就明白了为什么 Spark 的运算速度要快那么多，内存起到了很重要的作用，同样的，由于使用内存存储， Spark 处理的数据规模相对来说就会小一些，但是幸运的是现在内存也不是很贵，公司也都愿意多花点钱从而节约点时间。</p>
<h3 data-nodeid="1491">Spark 基础</h3>
<h4 data-nodeid="1492">RDD</h4>
<p data-nodeid="1493">RDD 是 Resillient Distributed Dataset（弹性分布式数据集）的简称，它是 Spark 的一个基本数据结构，也是<strong data-nodeid="1663">Spark 最核心的数据结构</strong>。</p>
<p data-nodeid="1494">Spark 在运行时，会将 RDD 分割成不同的 Partition（分区），并把这些分区投放到不同的计算节点下面，进行并行运算。实际上，Spark 程序的整个生命流程，就是对这些数据的处理，创建 RDD、转换 RDD、调用 RDD 操作计算各种结果等。所以，理解了 RDD 的各种操作基本上就了解了 Spark 的核心，对这部分感兴趣的同学可以寻找更多的资料来进行学习。</p>
<h4 data-nodeid="1495">两种操作</h4>
<p data-nodeid="1496">在我们的运算中，通常包含两种操作，一个是<strong data-nodeid="1687">Transformation</strong>（<strong data-nodeid="1688">转换操作</strong>），一个是<strong data-nodeid="1689">Action</strong>（<strong data-nodeid="1690">行动操作</strong>）。这两个操作最大的区别是 Spark 对它们的<strong data-nodeid="1691">处理逻辑</strong>是不一样的。</p>
<p data-nodeid="1497">对于转换操作，比如说 Filter（过滤），这些操作是对 RDD 本身的一些操作，其结果是数据的规模发生变化，而数据的类型或者说内容不会发生变化。</p>
<p data-nodeid="1498">对于这种操作 Spark 是进行<strong data-nodeid="1702">惰性运算</strong>，也就是说 Spark 只是记录下这个操作，而不会真的去执行它。只有当 Spark 遇到了行动操作，才会把之前的转换操作进行统一的处理，我们可以认为行动操作是一些产生结果的操作，它的输出是<strong data-nodeid="1703">非 RDD 对象</strong>。这么做的好处是减少了不必要的存储开销，毕竟 Spark 是使用内存来进行中间结果的存储。</p>
<p data-nodeid="1499">这么说可能有点迷茫了，我们写两行代码再来解释一下。</p>
<blockquote data-nodeid="1500">
<p data-nodeid="1501">val RDD1 = sc.textFile("data.txt")<br>
val RDD2 = RDD1.map(x =&gt; x+1)<br>
val RDD3 = RDD2.filter(lambda x: "Python" in x)<br>
val RDD4 = RDD3.reduceByKey((x,y) =&gt; x + y)</p>
<blockquote data-nodeid="1502">
<p data-nodeid="1503">val RDD5 = RDD2.filter(lambda x: "Java" in x)<br>
RDD5.count</p>
</blockquote>
</blockquote>
<p data-nodeid="1504">根据这几行代码，我们可以得出如下图的一个执行逻辑。</p>
<p data-nodeid="1505"><img src="https://s0.lgstatic.com/i/image6/M01/16/E5/Cgp9HWBHD8uAdDXAAAEIkWLgGpg729.png" alt="图片2.png" data-nodeid="1730"></p>
<ul data-nodeid="1821">
<li data-nodeid="1822">
<p data-nodeid="1823" class="te-preview-highlight">首先，我们从文件中读取数据，这时候形成 RDD1。</p>
</li>
<li data-nodeid="1824">
<p data-nodeid="1825">后面两步执行了 map、filter 和 reduceByKey 操作，map 操作给所有值加了 1，而 filter 操作过滤出带有 Python 的数据，reduceByKey 对 x 和 y 进行相加。这几个操作都属于 Transformation 操作，输出的结果都仍然是 RDD。</p>
</li>
<li data-nodeid="1826">
<p data-nodeid="1827">而最后一行执行了 count 操作，count 就是一个 Action 操作，它返回的是 RDD5 中的数据元素个数。</p>
</li>
</ul>

<p data-nodeid="1513">如果 Spark 对每一步都认真执行，那么第一步读取文件后，就已经把全量的数据存储在了内存中，但实际这并没有什么用，当 Spark 根据上面的执行逻辑分析了运算流程之后，会对 Transformation 操作进行整合，直到遇到 Action 操作才真正去进行运算。不知道这样解释，你有没有明白一些。</p>
<h4 data-nodeid="1514">两种依赖关系</h4>
<p data-nodeid="1515">由于在 Spark 中流转的数据通常都是<strong data-nodeid="1741">RDD 格式</strong>，从我们的代码可以看出，每一步生成的 RDD 都会依赖于上一步的 RDD，所以，具备上下联系的 RDD 产生的关系被称为依赖关系。</p>
<p data-nodeid="1516">根据不同情况又分成<strong data-nodeid="1751">窄依赖关系</strong>和<strong data-nodeid="1752">宽依赖关系</strong>两种：</p>
<ul data-nodeid="1517">
<li data-nodeid="1518">
<p data-nodeid="1519">窄依赖关系指的是生成下级 RDD 不会引起数据在不同的分区（Partition）之间进行迁移（Shuffle）；</p>
</li>
<li data-nodeid="1520">
<p data-nodeid="1521">宽依赖指的是要生成的 RDD 依赖于多个分区的数据，很明显这会导致处理速度的下降。</p>
</li>
</ul>
<p data-nodeid="1522">接下来，我们再来看一下 Spark 整体的运行架构。</p>
<p data-nodeid="1523"><img src="https://s0.lgstatic.com/i/image6/M01/16/E6/Cgp9HWBHD9WAWOAiAAHtErtXIXA457.png" alt="图片3.png" data-nodeid="1758"></p>
<p data-nodeid="1524">如上图，这是一个不太完整的运行架构，但是我们可以借此大概了解一下其中的概念。</p>
<p data-nodeid="1525">当我们编写了一个 Spark 程序，也就是一个 Application 时：</p>
<ul data-nodeid="1526">
<li data-nodeid="1527">
<p data-nodeid="1528">这个 Application 以 Action 操作为界限，被划分成多个 Job；</p>
</li>
<li data-nodeid="1529">
<p data-nodeid="1530">一个 Job 以 Shuffle 为界限被划分成多个 Stage；</p>
</li>
<li data-nodeid="1531">
<p data-nodeid="1532">而一个 Stage 又会分成多个 Task，Stage 的划分和调度是由 DAGScheduler 来负责的，而 Task 由 TASKScheduler 来进行调度。</p>
</li>
</ul>
<p data-nodeid="1533">这些调度的终极目标就是<strong data-nodeid="1769">根据依赖的关系找出开销最小的调度方法</strong>。最终，这些任务被分派到不同的 Worker 上进行运算。</p>
<p data-nodeid="1534"><img src="https://s0.lgstatic.com/i/image6/M01/16/E2/CioPOWBHD92ASZUGAAHQghdzsQg687.png" alt="图片4.png" data-nodeid="1772"></p>
<p data-nodeid="1535">我们再把视野放得稍微高一点，来看看运行架构。如上图所示，这里的 Driver 也就是我们在代码中常说的 main 函数，当它被执行时会创建一个 SparkContext 对象，这个对象会与服务器中的 Cluster&nbsp;Manager 进行通信，从而申请任务所需要的资源。当成功获得资源之后，它的 Task 会被分配到 Worker 的执行器中，从而处理对应的运算。</p>
<h3 data-nodeid="1536"><strong data-nodeid="1777">开发时需要注意的问题</strong></h3>
<p data-nodeid="1537">正是由于 Spark 所具备的这些特性，在开发的时候也会引起一些问题。</p>
<p data-nodeid="1538">（1）<strong data-nodeid="1783">数据倾斜</strong></p>
<p data-nodeid="1539">由于 RDD 数据会被分配到不同的分区，存在常见的问题就是<strong data-nodeid="1789">数据倾斜</strong>，某些分区分配了过多的数据，而另外的一些分区则分配了很少的数据，这会导致一些节点的运算过于缓慢。</p>
<p data-nodeid="1540">（2）<strong data-nodeid="1794">过多地使用 Action 操作</strong></p>
<p data-nodeid="1541">由于 Action 操作会引发真正的运算，并对数据进行缓存，所以，如果 Action 操作太多会造成内存的大量消耗，从而占用过多的资源。</p>
<p data-nodeid="1542">（3）<strong data-nodeid="1800">宽依赖过多</strong></p>
<p data-nodeid="1543">前面我们讲到，宽依赖会引发 Shuffle，将不同 Partition 的数据迁移到同一个 Partition 中去，所以这个操作也会消耗很多时间。</p>
<p data-nodeid="1544">这几个问题是我们在开发一个 Spark 程序时需要注意的问题。</p>
<h3 data-nodeid="1545">总结</h3>
<p data-nodeid="1546">在这一讲中，我对 Spark 的基本概念和发展历程做了简单的介绍，然后对其中比较重要的一些概念进行了说明。你是否对 Spark 框架已经有了一个基本了解，我想至少应该了解了 Spark 是什么。</p>
<p data-nodeid="1547">至于说如何使用 Spark 并运用自如，那可能需要你在课下不断地去练习，甚至需要有一个落地的场景，在应用中去学习。有任何心得或者问题，都欢迎和我交流。</p>
<p data-nodeid="1548">下一讲，我们将介绍一个新的计算框架 Flink，一起来看一看，跟 Spark 比起来，Flink 又有什么样的不同呢？</p>
<hr data-nodeid="1549">
<p data-nodeid="1550"><a href="https://shenceyun.lagou.com/r/rJs" data-nodeid="1811"><img src="https://s0.lgstatic.com/i/image6/M00/00/6D/Cgp9HWAaHaOAI85HAAUCrlmIuEw966.png" alt="Drawing 2.png" data-nodeid="1810"></a></p>
<p data-nodeid="1551"><strong data-nodeid="1815">《大数据开发高薪训练营》</strong></p>
<p data-nodeid="1552" class="">PB 级企业大数据项目实战 + 拉勾硬核内推，5 个月全面掌握大数据核心技能。<a href="https://shenceyun.lagou.com/r/rJs" data-nodeid="1819">点击链接</a>，全面赋能！</p></div>

</body></html>
<!DOCTYPE html><html lang="en"><head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>第29讲：大数据平台的硬件规划、网络调优、架构设计、节点规划</title>
<style type="text/css">
:root {
    --control-text-color: #777;
    --select-text-bg-color: rgba(223, 197, 223);  /*#7e66992e;*/
    
    /* side bar */
    --side-bar-bg-color: rgb(255, 255, 255);
    --active-file-text-color: #8163bd;
    --active-file-bg-color: #E9E4F0;
    --item-hover-bg-color: #E9E4F0;
    --active-file-border-color: #8163bd;

    --title-color: #6c549c;
    --font-sans-serif: 'Ubuntu', 'Source Sans Pro', sans-serif !important;
    --font-monospace: 'Fira Code', 'Roboto Mono', monospace !important;
    --purple-1: #8163bd;
    --purple-2: #79589F;
    --purple-3: #fd5eb8;
    --purple-light-1: rgba(99, 99, 172, .05);
    --purple-light-2: rgba(99, 99, 172, .1);
    --purple-light-3: rgba(99, 99, 172, .2);
    --purple-light-4: rgba(129, 99, 189, .3);
    --purple-light-5: #E9E4F0;
    --purple-light-6: rgba(129, 99, 189, .8);
}

/* html {
    font-size: 16px;
} */

body {
    font-family: var(--font-sans-serif);
    color: #34495e;
    -webkit-font-smoothing: antialiased;
    line-height: 1.6rem;
    letter-spacing: 0;
    margin: 0;
    overflow-x: hidden;
}

/* 页边距 和 页面大小 */
#write {
    padding-left: 6ch;
    padding-right: 6ch;
    margin: 0 auto;
}

#write p {
    line-height: 1.6rem;
    word-spacing: .05rem;
}

#write ol li {
    padding-left: 0.5rem;
}

#write > ul:first-child,
#write > ol:first-child {
    margin-top: 30px;
}

body > *:first-child {
    margin-top: 0 !important;
}

body > *:last-child {
    margin-bottom: 0 !important;
}

a {
    color: var(--purple-1);
    padding: 0 2px;
    text-decoration: none;
}
.md-content {
    color: var(--purple-light-6);
}
#write a {
    border-bottom: 1px solid var(--purple-1);
    color: var(--purple-1);
    text-decoration: none;
}

h1,
h2,
h3,
h4,
h5,
h6 {
    position: relative;
    margin-top: 1rem;
    margin-bottom: 0.5rem;
    /* font-weight: bold; */
    font-weight: 500 !important;
    line-height: 1.4;
    cursor: text;
    color: var(--title-color);
    font-family: var(--font-sans-serif);
}

h1:hover a.anchor,
h2:hover a.anchor,
h3:hover a.anchor,
h4:hover a.anchor,
h5:hover a.anchor,
h6:hover a.anchor {
    text-decoration: none;
}

h1 tt,
h1 code {
    font-size: inherit !important;
}
h2 tt,
h2 code {
    font-size: inherit !important;
}
h3 tt,
h3 code {
    font-size: inherit !important;
}
h4 tt,
h4 code {
    font-size: inherit !important;
}
h5 tt,
h5 code {
    font-size: inherit !important;
}
h6 tt,
h6 code {
    font-size: inherit !important;
}


h1 {
    padding-bottom: .4rem;
    font-size: 2.2rem;
    line-height: 1.3;
}
h1 {
    text-align: center;
    padding-bottom: 0.3em;
    font-size: 2.2em;
    line-height: 1.2;
    margin: 2.4em auto 1.2em;
}
h1:after {
    content: '';
    display: block;
    margin: 0.2em auto 0;
    width: 100px;
    height: 2px;
    border-bottom: 2px solid var(--title-color);
}

h2 {
    margin: 1.6em auto 0.5em;
    padding-left: 10px;
    line-height: 1.4;
    font-size: 1.8em;
    border-left: 9px solid var(--title-color);
    border-bottom: 1px solid var(--title-color);
}
h3 {
    font-size: 1.5rem;
    margin: 1.2em auto 0.5em;
}
h4 {
    font-size: 1.3rem;
}
h5 {
    font-size: 1.2rem;
}
h6 {
    font-size: 1.1rem;
}

p,
blockquote,
ul,
ol,
dl,
table {
    margin: 0.8em 0;
}

li > ol,
li > ul {
    margin: 0 0;
}

hr {
    height: 2px;
    padding: 0;
    margin: 16px 0;
    background-color: #e7e7e7;
    border: 0 none;
    overflow: hidden;
    box-sizing: content-box;
}

body > h2:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0;
}

body > h3:first-child,
body > h4:first-child,
body > h5:first-child,
body > h6:first-child {
    margin-top: 0;
    padding-top: 0;
}

a:first-child h1,
a:first-child h2,
a:first-child h3,
a:first-child h4,
a:first-child h5,
a:first-child h6 {
    margin-top: 0;
    padding-top: 0;
}

h1 p,
h2 p,
h3 p,
h4 p,
h5 p,
h6 p {
    margin-top: 0;
}

li p.first {
    display: inline-block;
}

ul,
ol {
    padding-left: 30px;
}

ul:first-child,
ol:first-child {
    margin-top: 0;
}

ul:last-child,
ol:last-child {
    margin-bottom: 0;
}

/* 引用 */
blockquote {
    /* margin-left: 1rem; */
    border-left: 4px solid var(--purple-light-4);
    padding: 10px 15px;
    color: #777;
    background-color: var(--purple-light-1);
}

/* 表格 */
table {
    padding: 0;
    word-break: initial;
}

table tr {
    border-top: 1px solid #dfe2e5;
    margin: 0;
    padding: 0;
}

/* 表格 背景色 */
table tr:nth-child(2n),
thead {
    background-color: var(--purple-light-1);
}
#write table thead th {
    background-color: var(--purple-light-2);
}

table tr th {
    font-weight: bold;
    border: 1px solid #dfe2e5;
    border-bottom: 0;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr td {
    border: 1px solid #dfe2e5;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr th:first-child,
table tr td:first-child {
    margin-top: 0;
}

table tr th:last-child,
table tr td:last-child {
    margin-bottom: 0;
}

/* 粗体 */
#write strong {
    padding: 0 2px;
    color: var(--purple-1);
}

/* 斜体 */
#write em {
    padding: 0 5px 0 2px;
    /* font-style: normal; */
    color: #42b983;
}

/* inline code */
#write code, tt {
    padding: 2px 4px;
    border-radius: 2px;
    font-family: var(--font-monospace);
    font-size: 0.92rem;
    color: var(--purple-3); 
    background-color: rgba(99, 99, 172, .05);
}

tt {
    margin: 0 2px;
}

#write .md-footnote {
    background-color: #f8f8f8;
    color: var(--purple-3);
}

/* heighlight. */
#write mark {
    background-color: #fbd3ea;
    border-radius: 2px;
    padding: 2px 4px;
    margin: 0 2px;
}

#write del {
    padding: 1px 2px;
}

.md-task-list-item > input {
    margin-left: -1.3em;
}

@media print {
    html {
        font-size: 0.9rem;
    }

    table,
    pre {
        page-break-inside: avoid;
    }

    pre {
        word-wrap: break-word;
    }
}

#write pre.md-meta-block {
    padding: 1rem;
    font-size: 85%;
    line-height: 1.45;
    background-color: #f7f7f7;
    border: 0;
    border-radius: 3px;
    color: #777777;
    margin-top: 0 !important;
}

.mathjax-block > .code-tooltip {
    bottom: .375rem;
}

/* 图片 */
.md-image > .md-meta {
    border-radius: 3px;
    font-family: var(--font-monospace);
    padding: 2px 0 0 4px;
    font-size: 0.9em;
    color: inherit;
}
p .md-image:only-child{
    width: auto;
    text-align: left;
    margin-left: 2rem;
}
.md-tag {
    color: inherit;
}
/* 当 “![shadow-随便写]()”写时，会有阴影 */
.md-image img[alt|='shadow'] {
    /* box-shadow: 0 4px 24px -6px #ddd; */
    box-shadow:var(--purple-light-2) 0px 10px 15px;
}

#write a.md-toc-inner {
    line-height: 1.6;
    white-space: pre-line;
    border-bottom: none;
    font-size: 0.9rem;
}

#typora-quick-open {
    border: 1px solid #ddd;
    background-color: #f8f8f8;
}

#typora-quick-open-item {
    background-color: #FAFAFA;
    border-color: #FEFEFE #e5e5e5 #e5e5e5 #eee;
    border-style: solid;
    border-width: 1px;
}

#md-notification:before {
    top: 10px;
}

header,
.context-menu,
.megamenu-content,
footer {
    font-family: var(--font-sans-serif);
}

.file-node-content:hover .file-node-icon,
.file-node-content:hover .file-node-open-state {
    visibility: visible;
}

.md-lang {
    color: #b4654d;
}

.html-for-mac .context-menu {
    --item-hover-bg-color: #E6F0FE;
}

/* 代码框 */
/* CodeMirror 3024 Day theme */

/* 代码段 背景 */
pre {
    --select-text-bg-color: rgba(223, 197, 223) !important;
    margin: .5em 0;
    padding: 1em 1.4em;
    border-radius: 8px;
    background: #f6f8fa;
    overflow-x: auto;
    box-sizing: border-box;
    font-size: 14px;
}

/* 边框 */
.md-fences {
    border: 1px solid #e7eaed;
    border-radius: 3px;
}

.cm-s-inner {
  padding: .25rem;
  border-radius: .25rem;
}

.cm-s-inner.CodeMirror, .cm-s-inner .CodeMirror-gutters {
  background-color: #f8f8f8 !important;
  color: #3a3432 !important;
  border: none;
}

.cm-s-inner .CodeMirror-gutters {
  color: #6d8a88;
}

.cm-s-inner .CodeMirror-cursor {
  border-left: solid thin #5c5855 !important;
}

.cm-s-inner .CodeMirror-linenumber {
  color: #807d7c;
}

.cm-s-inner .CodeMirror-line::selection, .cm-s-inner .CodeMirror-line::-moz-selection,
.cm-s-inner .CodeMirror-line > span::selection,
.cm-s-inner .CodeMirror-line > span::-moz-selection,
.cm-s-inner .CodeMirror-line > span > span::selection,
.cm-s-inner .CodeMirror-line > span > span::-moz-selection {
  background: var(--purple-light-2);
}

.cm-s-inner span.cm-comment {
  color: #cdab53;
}

.cm-s-inner span.cm-string, .cm-s-inner span.cm-string-2 {
  color: #f2b01d;
}

.cm-s-inner span.cm-number {
  color: #a34e8f;
}

.cm-s-inner span.cm-variable {
  color: #01a252;
}

.cm-s-inner span.cm-variable-2 {
  color: #01a0e4;
}

.cm-s-inner span.cm-def {
  /* color: #e8bbd0; */
  color: #e2287f;
}

.cm-s-inner span.cm-operator {
  color: #ff79c6;
}

.cm-s-inner span.cm-keyword {
  color: #db2d20;
}

.cm-s-inner span.cm-atom {
  color: #a34e8f;
}

.cm-s-inner span.cm-meta {
  color: inherit;
}

.cm-s-inner span.cm-tag {
  color: #db2d20;
}

.cm-s-inner span.cm-attribute {
  color: #01a252;
}

.cm-s-inner span.cm-qualifier {
  color: #388aa3;
}

.cm-s-inner span.cm-property {
  color: #01a252;
}

.cm-s-inner span.cm-builtin {
  color: #388aa3;
}

.cm-s-inner span.cm-variable-3, .cm-s-inner span.cm-type {
  color: #ffb86c;
}

.cm-s-inner span.cm-bracket {
  color: #3a3432;
}

.cm-s-inner span.cm-link {
  color: #a34e8f;
}

.cm-s-inner span.cm-error {
  background: #db2d20;
  color: #5c5855;
}

/* .md-fences.md-focus .cm-s-inner .CodeMirror-activeline-background {
  background: var(--purple-light-2);
} */

.cm-s-inner .CodeMirror-matchingbracket {
  text-decoration: underline;
  color: #a34e8f !important;
}

#fences-auto-suggest .active {
  background: #ddd;
}

#write .code-tooltip {
  bottom: initial;
  top: calc(100% - 1px);
  background: #f7f7f7;
  border: 1px solid #ddd;
  border-top: 0;
}

.auto-suggest-container {
  border-color: #b4b4b4;
}

.auto-suggest-container .autoComplt-hint.active {
  background: #b4b4b4;
  color: inherit;
}

/* task list */
#write .md-task-list-item > input {
  -webkit-appearance: initial;
  display: block;
  position: absolute;
  border: 1px solid #b4b4b4;
  border-radius: .25rem;
  margin-top: .1rem;
  margin-left: -1.8rem;
  height: 1.2rem;
  width: 1.2rem;
  transition: background 0.3s;
}

#write .md-task-list-item > input:focus {
  outline: none;
  box-shadow: none;
}

#write .md-task-list-item > input:hover {
  background: #ddd;
}

#write .md-task-list-item > input[checked]::before {
  content: '';
  position: absolute;
  top: 20%;
  left: 50%;
  height: 60%;
  width: 2px;
  transform: rotate(40deg);
  background: #333;
}

#write .md-task-list-item > input[checked]::after {
  content: '';
  position: absolute;
  top: 46%;
  left: 25%;
  height: 30%;
  width: 2px;
  transform: rotate(-40deg);
  background: #333;
}

#write .md-task-list-item > p {
  transition: color 0.3s, opacity 0.3s;
}

#write .md-task-list-item.task-list-done > p {
  color: #b4b4b4;
  text-decoration: line-through;
}

#write .md-task-list-item.task-list-done > p > .md-emoji {
  opacity: .5;
}

#write .md-task-list-item.task-list-done > p > .md-link > a {
  opacity: .6;
}

/* sidebar and outline */
.pin-outline .outline-active {
  color: var(--active-file-text-color); 
}

.file-list-item {
    border-bottom: 1px solid;
    border-color: var(--purple-light-5);
}

.file-list-item-summary {
    font-weight: 400;
}

.file-list-item.active {
    color: var(--active-file-text-color);
    background-color: var(--purple-light-5);
}

.file-tree-node.active>.file-node-background {
    background-color: var(--purple-light-5);
    font-weight: 700;
} 

.file-tree-node.active>.file-node-content {
    color: var(--active-file-text-color);
    font-weight: 700;
}

.file-node-content {
    color: #5e676d;
}

.sidebar-tabs {
    border-bottom: none;
}
.sidebar-tab.active {
    font-weight: 400;
}

.sidebar-content-content {
    font-size: 0.9rem;
}

img {
    max-width: 100%;
}

body {
    background-color: rgb(237, 237, 237);
}
#content {
    width: 836px;
    padding: 50px;
    background: #fff;
    margin: 0 auto;
}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/purple.css*/</style><style type="text/css">.hljs{display:block;overflow-x:auto;padding:.5em;color:#383a42;background:#fafafa}.hljs-comment,.hljs-quote{color:#a0a1a7;font-style:italic}.hljs-doctag,.hljs-formula,.hljs-keyword{color:#a626a4}.hljs-deletion,.hljs-name,.hljs-section,.hljs-selector-tag,.hljs-subst{color:#e45649}.hljs-literal{color:#0184bb}.hljs-addition,.hljs-attribute,.hljs-meta-string,.hljs-regexp,.hljs-string{color:#50a14f}.hljs-built_in,.hljs-class .hljs-title{color:#c18401}.hljs-attr,.hljs-number,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-pseudo,.hljs-template-variable,.hljs-type,.hljs-variable{color:#986801}.hljs-bullet,.hljs-link,.hljs-meta,.hljs-selector-id,.hljs-symbol,.hljs-title{color:#4078f2}.hljs-emphasis{font-style:italic}.hljs-strong{font-weight:700}.hljs-link{text-decoration:underline}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/atom-one-light.min.css*/</style></head>
<body>
  <div id="content"><h1>第29讲：大数据平台的硬件规划、网络调优、架构设计、节点规划</h1><p data-nodeid="15424" class="">这一课时，我将向你介绍 Hadoop 大数据平台的硬件选型、网络方面的架构设计和存储规划等内容。</p>


<h3 data-nodeid="18701" class="">大数据平台硬件选型</h3>




<p data-nodeid="14194">要对 Hadoop 大数据平台进行硬件选型，首先需要了解 Hadoop 的运行架构以及每个角色的功能。在一个典型的 Hadoop 架构中，通常有 5 个角色，分别是 NameNode、Standby NameNode、ResourceManager、NodeManager、DataNode 以及外围机。</p>
<p data-nodeid="14195">其中 <strong data-nodeid="14334">NameNode</strong> 负责协调集群上的数据存储，<strong data-nodeid="14335">Standby NameNode</strong> 属于 NameNode 的热备份，<strong data-nodeid="14336">ResourceManager</strong> 负责协调计算分析，这三者属于管理角色，一般部署在独立的服务器上。</p>
<p data-nodeid="14196">而 <strong data-nodeid="14346">NodeManager</strong> 和 <strong data-nodeid="14347">DataNode</strong> 角色主要用于计算和存储，为了获得更好的性能，通常将 NodeManager 和 DataNode 部署在一起。</p>
<h4 data-nodeid="14197">1.对 NameNode、ResourceManager 及其 Standby NameNode 节点硬件配置</h4>
<p data-nodeid="14198">由于角色的不同，以及部署位置的差别，对硬件的需求也不相同，推荐对 NameNode、ResourceManager 及其 Standby NameNode 节点选择统一的硬件配置，基础配置推荐如下表所示：</p>
<table data-nodeid="14200">
<thead data-nodeid="14201">
<tr data-nodeid="14202">
<th data-org-content="**硬件**" data-nodeid="14204"><strong data-nodeid="14353">硬件</strong></th>
<th data-org-content="**配置**" data-nodeid="14205"><strong data-nodeid="14357">配置</strong></th>
</tr>
</thead>
<tbody data-nodeid="14208">
<tr data-nodeid="14209">
<td data-org-content="CPU" data-nodeid="14210">CPU</td>
<td data-org-content="推荐 2 路 8 核、2 路 10 核或 2 路 12 核等，主频至少 2~2.5GHz" data-nodeid="14211">推荐 2 路 8 核、2 路 10 核或 2 路 12 核等，主频至少 2~2.5GHz</td>
</tr>
<tr data-nodeid="14212">
<td data-org-content="内存" data-nodeid="14213">内存</td>
<td data-org-content="推荐 64~256GB" data-nodeid="14214">推荐 64~256GB</td>
</tr>
<tr data-nodeid="14215">
<td data-org-content="磁盘" data-nodeid="14216">磁盘</td>
<td data-org-content="分为 2 组，即系统盘和数据盘，系统盘 2T*2，做 raid1；数据盘 2-4T 左右，数据盘的数量取决于你想冗余备份元数据的份数" data-nodeid="14217">分为 2 组，即系统盘和数据盘，系统盘 2T*2，做 raid1；数据盘 2-4T 左右，数据盘的数量取决于你想冗余备份元数据的份数</td>
</tr>
<tr data-nodeid="14218">
<td data-org-content="网卡" data-nodeid="14219">网卡</td>
<td data-org-content="万兆网卡（光纤卡）" data-nodeid="14220">万兆网卡（光纤卡）</td>
</tr>
<tr data-nodeid="14221">
<td data-org-content="电源" data-nodeid="14222">电源</td>
<td data-org-content="均配置冗余电源" data-nodeid="14223">均配置冗余电源</td>
</tr>
</tbody>
</table>
<p data-nodeid="14224">对于 <strong data-nodeid="14379">CPU</strong>，可根据资金预算，选择 8 核、10 核或者 12 核。</p>
<p data-nodeid="14225">对于<strong data-nodeid="14385">内存</strong>，常用的计算公式是集群中 100 万个块（HDFS blocks）对应 NameNode 需要 1GB 内存，如果你的集群规模在 100 台以内，NameNode 服务器的内存配置一般选择 128GB 即可。</p>
<p data-nodeid="14226">由于 NameNode 以及 Standby NameNode 两个节点需要存储 HDFS 的元数据，所以需要配置<strong data-nodeid="14391">数据盘</strong>，数据盘建议至少配置 4 块，每两块做 raid1，做两组 raid1；然后将元数据分别镜像存储到这两个 raid1 磁盘组中。而对于 ResourceManager，由于不需要存储重要数据，因而，数据盘可不配置。</p>
<p data-nodeid="14227">网络方面，为了不让网络传输成为瓶颈，建议配备光纤接口<strong data-nodeid="14397">网卡</strong>，节点之间带宽要保证在 10GB左右。</p>
<p data-nodeid="14228">最后，主机<strong data-nodeid="14403">电源</strong>推荐都是用双电源，虽然有一些费电，但可保证这些重要节点的稳定性，不至于出现电源故障直接宕机的情况。</p>
<h4 data-nodeid="14229">2.对 NodeManager、DataNode 节点服务器硬件配置</h4>
<p data-nodeid="14230">下面再说下企业通用和主流的 NodeManager、DataNode 节点服务器硬件配置，如下表所示：</p>
<table data-nodeid="14232">
<thead data-nodeid="14233">
<tr data-nodeid="14234">
<th data-org-content="**硬件**" data-nodeid="14236"><strong data-nodeid="14409">硬件</strong></th>
<th data-org-content="**配置**" data-nodeid="14237"><strong data-nodeid="14413">配置</strong></th>
</tr>
</thead>
<tbody data-nodeid="14240">
<tr data-nodeid="14241">
<td data-org-content="CPU" data-nodeid="14242">CPU</td>
<td data-org-content="推荐 2 路 10 核、2 路 12 核或 2 路 14 核等，主频至少 2~2.5GHz" data-nodeid="14243">推荐 2 路 10 核、2 路 12 核或 2 路 14 核等，主频至少 2~2.5GHz</td>
</tr>
<tr data-nodeid="14244">
<td data-org-content="内存" data-nodeid="14245">内存</td>
<td data-org-content="推荐 64~512GB" data-nodeid="14246">推荐 64~512GB</td>
</tr>
<tr data-nodeid="14247">
<td data-org-content="磁盘" data-nodeid="14248">磁盘</td>
<td data-org-content="分为 2 组，系统盘和数据盘，系统盘 2T*2，做 raid1；数据盘 4~8T 左右，数据盘单盘使用，无须做 raid" data-nodeid="14249">分为 2 组，系统盘和数据盘，系统盘 2T*2，做 raid1；数据盘 4~8T 左右，数据盘单盘使用，无须做 raid</td>
</tr>
<tr data-nodeid="14250">
<td data-org-content="网卡" data-nodeid="14251">网卡</td>
<td data-org-content="万兆网卡（光纤卡），存储越多，网络吞吐就要求越高" data-nodeid="14252">万兆网卡（光纤卡），存储越多，网络吞吐就要求越高</td>
</tr>
<tr data-nodeid="14253">
<td data-org-content="电源" data-nodeid="14254">电源</td>
<td data-org-content="最好配置冗余电源，如预算不足，也可使用单电源" data-nodeid="14255">最好配置冗余电源，如预算不足，也可使用单电源</td>
</tr>
</tbody>
</table>
<p data-nodeid="14256">由于 NodeManager、DataNode 主要用于计算和存储，所以对 <strong data-nodeid="14437">CPU</strong> 性能要求会比较高，推荐 2 路 14 核。</p>
<p data-nodeid="14257"><strong data-nodeid="14442">内存</strong>方面，如果分布式计算中涉及 Spark、HBase 组件，那么建议配置大内存，每个节点 256GB 内存是个不错的配置。</p>
<p data-nodeid="14258"><strong data-nodeid="14447">磁盘</strong>方面，DataNode 节点主要用来存储数据，所以需要配置大量磁盘，磁盘单盘使用，无须做 raid，磁盘大小推荐每块 8T。不建议使用更大的单盘，当然如果有条件，也可采购 SSD 磁盘，但是 SSD 磁盘成本太高，需要根据预算来定。</p>
<p data-nodeid="14259">每个 DataNode 建议配置 8 ~ 10 块<strong data-nodeid="14459">硬盘</strong>，具体数量，需要根据总共需要的存储空间而定。例如，假设总共需要存储 800TB 的数据，HDFS 的块副本数为 3，如果每个 DataNode 配置 10 块 8T 的硬盘，那么，采购 30 台 DataNode 服务器即可。NodeManager 节点也会存储一些分析任务的中间结果以及日志等临时数据，建议这些数据的存储路径和 HDFS 的数据存储路径分开，单独规划 3~5 块 4~8T 磁盘来存储这些临时数据即可，同理，这些磁盘也无须做 raid，单盘使用即可。</p>
<p data-nodeid="14260">在网络方面，也建议 NodeManager 和 DataNode 采购光纤接口<strong data-nodeid="14465">网卡</strong>，所有 NodeManager、DataNode 节点连接到光纤交换机，保证节点之间 10GB 高速网络传输。</p>
<p data-nodeid="14261">最后，在<strong data-nodeid="14471">电源</strong>方面，可根据预算，决定是否采购双电源，在集群模式下，NodeManager 或 DataNode 某个节点故障对 Hadoop 影响不大，所以使用单电源也是可行的。</p>
<h3 data-nodeid="21954" class="">大数据平台网络架构设计</h3>




<h4 data-nodeid="25183" class="">1.Hadoop 基础网络架构</h4>




<p data-nodeid="14264">普通的 Hadoop 网络一般由两层结构组成：接入交换机和汇聚交换机（或者核心交换机），在具体布线上采用 TOR 方式，在一个 42U 的标准服务器机柜的最上面安装接入交换机，每个服务器的光纤网口都接入到机柜上部的光交换机上，这个接入交换机再通过光纤，接入到网络机柜的汇聚或核心交换机上。</p>
<p data-nodeid="26777">基本架构如下图所示：</p>
<p data-nodeid="28384" class=""><img src="https://s0.lgstatic.com/i/image/M00/3C/95/CgqCHl8n2fCALEHDAALxZENuMJ0771.png" alt="5.png" data-nodeid="28387"></p>




<p data-nodeid="14267">在上图中，列出了三个机柜，在每个机柜上有两个 10GE 的 TOR 交换机，这两个交换机为主、备模式，然后这些主、被交换机在通过光纤接入到上层的 100GE 汇聚交换机上。这种部署默认可以最大限度地保证网络的传输质量和稳定性。</p>
<p data-nodeid="14268">在每个机柜中都可部署相应的 Hadoop 服务，可以看出，机柜 1 和 2 分别部署了 NameNode 的主、被节点，这两个主、备节点分开部署到不同的机柜，可以最大限度保证 NameNode 的可靠性，不建议将主、备节点部署到同一个机柜中，因为如果某个机柜发生故障（电源故障、网络故障），那么主、备将失去存在的意义。</p>
<p data-nodeid="14269">同理，ResourceManager 节点也部署了主、备的 HA 功能，这两个节点也不能在一个机柜中，这是一个基本常识。此外，在每个机柜中，都分布着 NodeManager 和 DataNode 节点，并且这两个服务是部署在一起的。</p>
<p data-nodeid="14270">此外，在三个机柜中，还有 Hadoop gateway 节点，这些节点相当于用户与 Hadoop 的交互接口，通过这些节点提交任务到 Hadoop 集群中，通常这些节点也可以有多个，建议分布在多个机柜中。</p>
<h4 data-nodeid="31992" class="">2.Hadoop 机架感知机制</h4>





<p data-nodeid="14272">所谓<strong data-nodeid="14498">机架感知就是自动了解 Hadoop 集群中每个机器节点所属的机架</strong>，某个 Datanode 节点是属于哪个机柜并非智能感知的，而是需要 Hadoop 的管理者人为地告知 Hadoop 哪台机器属于哪个机柜。</p>
<p data-nodeid="14273">这样在 Hadoop 的 Namenode 启动初始化时，会将这些机器与机柜的对应信息保存在内存中，用来作为 HDFS 写数据块操作分配 Datanode 列表时（比如 3 个 block 对应三台 Datanode）选择 DataNode 的策略。</p>
<p data-nodeid="14274">比如，要写三个数据块到对应的三台 Datanode，那么通过机架感知策略，可以尽量将三个副本分布到不同的机柜上。</p>
<p data-nodeid="14275">默认情况下，Hadoop 的机架感知功能没有启用。所以，通常情况下，Hadoop 集群的 HDFS 在选机器时，是随机选择的，这在某些情况下会影响 HDFS 读写性能，进而影响作业的性能以至于整个集群的服务。</p>
<p data-nodeid="14276">而在开启了机架感知后，不同节点之间的通信能够尽量发生在同一个机架之内，而不是跨机架，同时，为了提高容错能力，Namenode 节点会尽可能把数据块的副本放到多个机架上，进而提升数据的安全性。</p>
<p data-nodeid="14277">要查看当前集群机架配置情况，可执行如下命令：</p>
<pre class="lang-java" data-nodeid="36763"><code data-language="java">[hadoop<span class="hljs-meta">@namenodemaster</span> conf]$ hdfs dfsadmin -printTopology 
Rack: /<span class="hljs-keyword">default</span>-rack 
   <span class="hljs-number">172.16</span>.<span class="hljs-number">213.103</span>:<span class="hljs-number">9866</span> (slave002) 
   <span class="hljs-number">172.16</span>.<span class="hljs-number">213.169</span>:<span class="hljs-number">9866</span> (slave003) 
   <span class="hljs-number">172.16</span>.<span class="hljs-number">213.70</span>:<span class="hljs-number">9866</span> (slave001) 
</code></pre>






<p data-nodeid="14279">可以看到默认所有节点都是一个机架 default-rack，此时没有配置机架感知。要配置机架感知，首先需要<strong data-nodeid="14509">自定义机器机架位置</strong>，编写机架配置文件 rack.data，内容如下：</p>
<pre class="lang-java" data-nodeid="39943"><code data-language="java"><span class="hljs-number">172.16</span>.<span class="hljs-number">213.103</span>  slave002        /switch1/rack2 
<span class="hljs-number">172.16</span>.<span class="hljs-number">213.70</span>   slave001        /switch1/rack1 
<span class="hljs-number">172.16</span>.<span class="hljs-number">213.169</span>  slave003        /switch1/rack3 
</code></pre>




<p data-nodeid="14281">这里将三个节点分别放到三个不同的机柜中。<br>
然后还需要<strong data-nodeid="14517">配置一个机架感知脚本</strong>，假定脚本名称为 rack.sh，内容如下：</p>
<pre class="lang-dart" data-nodeid="46303"><code data-language="dart">#!/bin/bash 
HADOOP_CONF=/etc/hadoop/conf/ 
<span class="hljs-keyword">while</span> [ $# -gt <span class="hljs-number">0</span> ] ; 
<span class="hljs-keyword">do</span> 
   nodeArg=$<span class="hljs-number">1</span> 
   exec&lt;\${HADOOP_CONF}/rack.data 
   result=<span class="hljs-string">""</span> 
   <span class="hljs-keyword">while</span> read line 
        <span class="hljs-keyword">do</span> 
                ar=( $line ) 
                <span class="hljs-keyword">if</span> [ <span class="hljs-string">"<span class="hljs-subst">\${ar[<span class="hljs-number">0</span>]}</span>"</span> = <span class="hljs-string">"<span class="hljs-subst">$nodeArg</span>"</span> ]||[ <span class="hljs-string">"<span class="hljs-subst">\${ar[<span class="hljs-number">1</span>]}</span>"</span> = <span class="hljs-string">"<span class="hljs-subst">$nodeArg</span>"</span> ] 
                then 
                        result=<span class="hljs-string">"<span class="hljs-subst">\${ar[<span class="hljs-number">2</span>]}</span>"</span> 
                fi 
        done 
        shift 
        <span class="hljs-keyword">if</span> [ -z <span class="hljs-string">"<span class="hljs-subst">$result</span>"</span> ] 
        then 
                echo -n <span class="hljs-string">"/default-rack"</span> 
        <span class="hljs-keyword">else</span> 
                echo -n <span class="hljs-string">"<span class="hljs-subst">$result</span>"</span> 
        fi 
done 
</code></pre>








<p data-nodeid="14283">将此脚本放大 Hadoop 配置文件目录下即可，并授予可执行权限。</p>
<p data-nodeid="14284">最后一步，还需要修改 core-site.xml 文件，<strong data-nodeid="14524">添加机架感知脚本</strong>，添加如下内容：</p>
<pre class="lang-js" data-nodeid="47893"><code data-language="js">&lt;property&gt; 
        <span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>net.topology.script.file.name<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span></span> 
        <span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/etc/hadoop/conf/rack.sh<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span></span> 
&lt;/property&gt; 
</code></pre>


<p data-nodeid="48688">配置完成后，需要重启 NameNode 服务，配置才能生效。</p>
<p data-nodeid="48689">重启服务后，要验证机架感知配置是否生效，可执行如下命令：</p>

<pre class="lang-java" data-nodeid="49486"><code data-language="java">[hadoop<span class="hljs-meta">@namenodemaster</span> conf]$ hdfs dfsadmin -printTopology 
Rack: /switch1/rack1 
   <span class="hljs-number">172.16</span>.<span class="hljs-number">213.70</span>:<span class="hljs-number">9866</span> (slave001) 
Rack: /switch1/rack2 
   <span class="hljs-number">172.16</span>.<span class="hljs-number">213.103</span>:<span class="hljs-number">9866</span> (slave002) 
Rack: /switch1/rack3 
   <span class="hljs-number">172.16</span>.<span class="hljs-number">213.169</span>:<span class="hljs-number">9866</span> (slave003) 
</code></pre>

<p data-nodeid="14288">可以看出，HDFS 的机架感知配置已经成功。</p>
<h4 data-nodeid="53064" class="">3.大数据平台架构设计要点</h4>





<p data-nodeid="14290">在构建大数据平台之前，首先要考虑需要的存储容量、计算能力、是否有实时分析的需求、数据的存储周期等因素，然后再根据这些需求进行平台的架构设计。</p>
<p data-nodeid="14291">同时，还要考虑平台的<strong data-nodeid="14539">健壮性</strong>，例如，任意一个节点宕机都不会影响平台的正常使用，任何一个磁盘的损坏都不会导致数据丢失等。</p>
<p data-nodeid="14292">针对 Hadoop 大数据平台的基础架构，最基本的要求是保证 NameNode、ResourceManager 这些管理节点的<strong data-nodeid="14549">高可用性</strong>，因此这些节点<strong data-nodeid="14550">必须要做 HA</strong>。</p>
<p data-nodeid="14293">此外，为了保障 <strong data-nodeid="14556">HDFS 数据的安全性</strong>，对 Hadoop 块存储一定要设置合适的副本数。例如，设置 3 个副本，那么集群中任意 2 个 datanode 节点故障宕机，都不会丢失数据。</p>
<p data-nodeid="14294">在网络方面，建议每个节点的服务器采用<strong data-nodeid="14562">双网卡绑定</strong>，网络设置为冗余模式，并和交换机做冗余绑定，做到单个网卡故障或者单个交换机故障，都能保证此节点网络正常运行。</p>
<p data-nodeid="57406">下面是一个典型的 Hadoop 大数据平台部署拓扑，如下图所示：</p>
<p data-nodeid="57407"><img src="https://s0.lgstatic.com/i/image/M00/3C/95/CgqCHl8n2laAXAKaAAG23nqsd0g066.png" alt="6.png" data-nodeid="57411"></p>







<p data-nodeid="14297">从图中可以看出，NameNode、ResourceManager 节点都部署了高可用功能，任何一个节点故障都不会影响集群的存储和计算。此外，DataNode 节点可根据存储周期、存储容量、计算任务数进行扩容和缩容，并且扩容、缩容可在线直接进行，不影响集群运行。</p>
<p data-nodeid="14298">此外，在 Hadoop 集群之外，还要跟 Hadoop 配合的一些外围应用，例如 ambari，用来自动化运维、监控 Hadoop 集群，Hadoop gateway 用于和 Hadoop 集群的交互接口，而 DNS server 和 NTP server 主要用于 Hadoop 集群内部的主机名解析与时间同步。Zookeeper Server 用于 Hadoop 集群中的仲裁和协调调度。</p>
<h3 data-nodeid="64949" class="">大数据平台存储、计算节点规划</h3>










<p data-nodeid="14300">对大数据平台存储和计算资源的规划，需要根据实际应用需求判断，例如，现有的和日增长的数据量、数据的存储周期、每天计算任务的中间结果数据量，以及数据冗余空间，比如保持几个副本等实际应用需求。</p>
<p data-nodeid="14301">我以一个实际案例举例说明：目前有数据量 500TB，每天数据量增长 2T 左右，数据块副本为 3，所有数据存储周期为 2 年，根据这个需求，就可以算出需要的存储节点数。</p>
<ul data-nodeid="66531">
<li data-nodeid="66532">
<p data-nodeid="66533" class="">2 年数据量需要的存储空间：(2*3)*(365*2)=4380TB</p>
</li>
<li data-nodeid="66534">
<p data-nodeid="66535">总共需要的存储空间：4380TB+(500*3)TB=5880TB</p>
</li>
</ul>


<p data-nodeid="14307">如果以一个存储节点 12 块 4T 硬盘来计算，则需要约（5880TB/48TB=147）123 个存储节点；而如果采用一个存储节点 10 块 8T 硬盘来计算，需要约（5880TB/80TB=147）74 个存储节点即可。</p>
<p data-nodeid="14308" class="">那么此时如何选择每个节点硬盘的大小呢？这就要看大数据平台需要的计算资源有多少了，很显然，按照 4T 硬盘 12 块来规划的话，可获得更多的计算资源（CPU、内存），但此方案需要采购 123 台服务器，成本较高；反之，如果采用 10块 8T 硬盘来规划的话，那么只需要 74 台服务器即可，此时可计算 74 台服务器是否能满足计算资源的要求，如果能满足，那么这个磁盘规划就是最合适的。</p>
<p data-nodeid="14309">对于计算资源规划，要看都运行哪些应用，如果是 Spark、HBase、ElasticSearch 这类吃内存的大数据组件，那么建议计算节点所选的服务器的内存一定要大，最好 64GB 起，能有 128GB 更好。由于前期对计算资源需求很难评估，所以可根据上面这个原则去配置 CPU 和内存即可，如果遇到计算性能瓶颈，可以在后期进行水平扩展，非常方便。</p>
<p data-nodeid="14310"><strong data-nodeid="14597">大数据平台对硬件的规划原则：</strong> 如果能够确切地知道存储和计算的资源需要，那么就按照这个需求来配置即可；但如果无法准确地评估出存储和计算资源需求量，那么一定要<strong data-nodeid="14598">留下可扩展的余地</strong>，比如留下足够的机柜位置、网络接口、磁盘接口等。在实际应用中，存储容量一般很好预估，但计算资源很难预估，因此留下足够的扩展接口，是必须要考虑的一个问题。</p>
<h3 data-nodeid="14311">小结</h3>
<p data-nodeid="67326">本课时主要介绍了 Hadoop 大数据平台的硬件选项、网络方面的架构设计和存储规划等内容。其中如何对大数据平台做好存储、计算等资源的规划，至关重要，它也是运维大数据平台的第一步，如果前期规划不当，到后期发现架构不合理，那么需要修改或者扩展将非常困难，所以这部分内容需要你反复练习揣摩。</p></div>

</body></html>
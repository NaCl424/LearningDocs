<!DOCTYPE html><html lang="en"><head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>第05讲：手动模式构建双 Namenode+Yarn 的 Hadoop 集群（上）</title>
<style type="text/css">.hljs{display:block;overflow-x:auto;padding:.5em;color:#383a42;background:#fafafa}.hljs-comment,.hljs-quote{color:#a0a1a7;font-style:italic}.hljs-doctag,.hljs-formula,.hljs-keyword{color:#a626a4}.hljs-deletion,.hljs-name,.hljs-section,.hljs-selector-tag,.hljs-subst{color:#e45649}.hljs-literal{color:#0184bb}.hljs-addition,.hljs-attribute,.hljs-meta-string,.hljs-regexp,.hljs-string{color:#50a14f}.hljs-built_in,.hljs-class .hljs-title{color:#c18401}.hljs-attr,.hljs-number,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-pseudo,.hljs-template-variable,.hljs-type,.hljs-variable{color:#986801}.hljs-bullet,.hljs-link,.hljs-meta,.hljs-selector-id,.hljs-symbol,.hljs-title{color:#4078f2}.hljs-emphasis{font-style:italic}.hljs-strong{font-weight:700}.hljs-link{text-decoration:underline}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/atom-one-light.min.css*/</style><style type="text/css">/*
 * Copyright (C) 2018 Drake, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

:root {
    --monospace: "JetBrains Mono", HYZhengYuan, "Fira Code", Menlo, "Ubuntu Mono", Consolas; /*code font*/
    --text-font: var(--monospace); /*default font*/
    --title-font: var(--monospace); /*title font*/

    --text-color: #333333;
    --bg-color: #ffffff;
    --control-text-color: var(--text-color);
    --meta-content-color: var(--text-color);
    --active-file-border-color: var(--drake-accent);
    --rawblock-edit-panel-bd: var(--code-block-bg-color);
    --item-hover-bg-color: #E5E5E596;
    --active-file-bg-color: var(--item-hover-bg-color);

    --drake-accent: #e95f59;
    --drake-highlight: #d63200;
    --a-color: #036aca;
    --variable-color: var(--drake-highlight);
    --outline-active-color: var(--a-color);
    --code-block-bg-color: #2b2b2b;
    --code-block-color: #A9B7C6;
    --title-color: #135ce0;
    --blockquote-border-color: #b2aec5;
    --blockquote-color: #595959;
    --blockquote-bg-color: #fff9f9;
    --strong-color: var(--title-color);
    --h2-underline-color: var(--title-color);
    --horizontal-divider-color: var(--title-color);
    --height-light-color: var(--drake-highlight);
    --height-light-border-color: var(--drake-highlight);
    --yaml-color: #777777;
    --yaml-bg-color: #f7f7f7;
    --footnotes-bg-color: #3c3d3e;
    --footnotes-highlight: #FFD760;
    --table-border-color: #dfe2e5;
    --table-header-bg-color: #f6f8fa;
    --table-bg-color: var(--bg-color);
    --table-n2-bg-color: #f6f8fa;
    --input-bg-color: var(--item-hover-bg-color);
    --btn-hover-bg-color: var(--item-hover-bg-color);
    --checkbox-checked: url("data:image/svg+xml,%3Csvg class='icon' viewBox='0 0 1024 1024' xmlns='http://www.w3.org/2000/svg' width='200' height='200'%3E%3Cpath d='M425.984 726.016l384-384-59.99-61.995-324.01 324.011-152.021-152.021L213.973 512zm384-598.016q36.01 0 61.013 25.984T896 213.974v596.01q0 34.005-25.003 59.99t-61.013 25.983h-596.01q-36.011 0-61.014-25.984t-25.003-59.989v-596.01q0-34.006 25.003-59.99T213.973 128h596.011z' fill='%2365b73b'/%3E%3C/svg%3E");
    --checkbox-unchecked: url("data:image/svg+xml,%3Csvg class='icon' viewBox='0 0 1024 1024' xmlns='http://www.w3.org/2000/svg' width='200' height='200'%3E%3Cpath d='M810.667 213.333v597.334H213.333V213.333h597.334m0-85.333H213.333C166.4 128 128 166.4 128 213.333v597.334C128 857.6 166.4 896 213.333 896h597.334C857.6 896 896 857.6 896 810.667V213.333C896 166.4 857.6 128 810.667 128z' fill='%23333333'/%3E%3C/svg%3E");
}

html {
    font-size: 15px;
}

body {
    font-family: var(--text-font) !important;
    color: var(--text-color);
    -webkit-font-feature-settings: "liga" on, "calt" on;
    -webkit-font-smoothing: subpixel-antialiased;
    text-rendering: optimizeLegibility;
    letter-spacing: 0;
    margin: 0;
    overflow-x: hidden;
    line-height: 1.8rem;
}

img {
    max-width: 100%;
}

#write {
    background-image: linear-gradient(
            90deg
            ,rgba(60,10,30,.04) 3%,transparent 0),linear-gradient(
            1turn
            ,rgba(60,10,30,.04) 3%,transparent 0);
    background-size: 20px 20px;
    background-position: 50%;
}

/*code block*/
#write .md-fences {
    font-size: 1rem;
    padding: 0.5rem !important;
    border-radius: 2px;
    word-wrap: normal;
    background-color: var(--code-block-bg-color);
    color: var(--code-block-color);
    border: none;
}

/*code snippet*/
#write code, tt {
    border-radius: 2px;
    color: var(--drake-highlight);
}

/*variable*/
var {
    color: var(--variable-color);
    font-weight: bold;
}

/*raw block*/
.md-rawblock-control:not(.md-rawblock-tooltip) {
    border-radius: 2px 0 2px 2px;
    padding: 0.2rem !important;
}
.md-rawblock:hover > .md-rawblock-container {
    background: none;
}
.md-rawblock-input {
    font-size: 1rem;
}
.md-rawblock-tooltip-btn:hover {
    background: none;
}
.md-rawblock:hover > .md-rawblock-tooltip {
    border-radius: 2px 2px 0 0;
    margin-bottom: 2px !important;
}
.md-rawblock-tooltip.md-rawblock-control {
    border-radius: 2px 2px 0 0;
    color: var(--code-block-color);
}
.md-rawblock-tooltip-name {
    color: var(--code-block-color);
    opacity: 1;
}

/*quote block*/
blockquote:before {
    display: block;
    position: absolute;
    content: '';
    width: 4px;
    left: 0;
    top: 0;
    height: 100%;
    background-color: var(--blockquote-border-color);
    border-radius: 2px;
}

blockquote {
    color: var(--blockquote-color);
    border-radius: 2px;
    padding: 10px 16px;
    background-color: var(--blockquote-bg-color);
    position: relative;
    border-left: none;
}

#write strong {
    color: var(--strong-color);
    font-weight: bold;
}
#write blockquote strong {
    color: var(--blockquote-color);
}

/*link*/
#write a {
    color: var(--a-color);
    text-decoration: none;
}
#write a .md-plain, .md-htmlblock-container a:hover {
    border-bottom: .1rem solid var(--a-color);
}
[md-inline=link] a {
    margin: 0 .2rem;
}
a:any-link {
    color: var(--a-color);
}

img {
    border-left: none;
    border-right: none;
    vertical-align: baseline;
    border-radius: 2px;
}

#write {
    max-width: 1200px;
    margin: 0 auto;
    padding: 20px 30px 100px;
}
#typora-source .CodeMirror-lines {
    max-width: 1200px;
}

#write p {
    word-spacing: .05rem;
}

#write > ul:first-child,
#write > ol:first-child {
    margin-top: 30px;
}

body > *:first-child {
    margin-top: 0 !important;
}

body > *:last-child {
    margin-bottom: 0 !important;
}

h1,
h2,
h3,
h4,
h5,
h6 {
    font-family: var(--title-font);
    position: relative;
    margin-top: 2rem;
    margin-bottom: 1rem;
    font-weight: bold;
    cursor: text;
    color: var(--title-color);
}

h3.md-focus:before, h4.md-focus:before, h5.md-focus:before, h6.md-focus:before {
    visibility: hidden;
}

h1 {
    font-size: 1.6rem;
    text-align: center;
    margin-top: 0;
}

h2.md-end-block.md-heading {
    font-size: 1.6rem;
    display: inline-block;
}

h2.md-end-block.md-heading:after {
    display: block;
    content: '';
    height: 2px;
    margin-top: 4px;
    background-color: var(--h2-underline-color);
    border-radius: 2px;
}

h3 {
    font-size: 1.4rem;
}

h4 {
    font-size: 1.2rem;
}

h5 {
    font-size: 1rem;
}

h6 {
    font-size: 1rem;
}

h1:hover a.anchor,
h2:hover a.anchor,
h3:hover a.anchor,
h4:hover a.anchor,
h5:hover a.anchor,
h6:hover a.anchor {
    text-decoration: none;
}

h1 tt,
h1 code {
    font-size: inherit !important;
}

h2 tt,
h2 code {
    font-size: inherit !important;
}

h3 tt,
h3 code {
    font-size: inherit !important;
}

h4 tt,
h4 code {
    font-size: inherit !important;
}

h5 tt,
h5 code {
    font-size: inherit !important;
}

h6 tt,
h6 code {
    font-size: inherit !important;
}

blockquote,
ul,
ol,
dl,
table {
    margin: 0.8em 0;
}
p {
    margin: 0;
}

li > ol,
li > ul {
    margin: 0 0;
}

hr {
    height: 2px;
    padding: 0;
    margin: 16px 0;
    background-color: var(--horizontal-divider-color);
    border: 0 none;
    overflow: hidden;
    box-sizing: content-box;
}

body > h2:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0;
}

body > h3:first-child,
body > h4:first-child,
body > h5:first-child,
body > h6:first-child {
    margin-top: 0;
    padding-top: 0;
}

a:first-child h1,
a:first-child h2,
a:first-child h3,
a:first-child h4,
a:first-child h5,
a:first-child h6 {
    margin-top: 0;
    padding-top: 0;
}

h1 p,
h2 p,
h3 p,
h4 p,
h5 p,
h6 p {
    margin-top: 0;
}

li p.first {
    display: inline-block;
}

ul, ol {
    padding-inline-start: 2em;
}

ul:first-child,
ol:first-child {
    margin-top: 0;
}

ul:last-child,
ol:last-child {
    margin-bottom: 0;
}

table {
    padding: 0;
    word-break: initial;
    background-color: var(--table-bg-color);
}
table tr {
    border-top: .1em solid var(--table-border-color);
    margin: 0;
    padding: 0;
}
table th {
    font-weight: bold;
    border: .1em solid var(--table-border-color);
    border-bottom: 0;
    margin: 0;
    padding: 6px 13px;
}
table td {
    border: .1em solid var(--table-border-color);
    margin: 0;
    padding: 6px 13px;
}
table thead {
    background-color: var(--table-header-bg-color);
}
table tr:nth-child(2n) {
    background-color: var(--table-n2-bg-color);
}
table tr th:first-child,
table tr td:first-child {
    margin-top: 0;
}
table tr th:last-child,
table tr td:last-child {
    margin-bottom: 0;
}

#write em {
    padding: 0 5px 0 2px;
}

/* height light */
#write mark {
    border: .1em solid var(--height-light-border-color);
    color: var(--height-light-color);
    background-color: transparent;
    padding: .1rem .5rem;
    border-radius: 2rem;
    margin: 0 .2rem;
    font-size: .95rem;
}

/*shortcut*/
kbd {
    border: .1em solid #5b5b5e;
    background: transparent;
    color: var(--text-color);
    margin: 0 .4rem;
    font-size: .95rem;
    padding: .3em .4em;
    border-radius: .4em;
    vertical-align: top;
    box-shadow: .1em .1em .2em rgba(0, 0, 0, 0.3);
}

#write del {
    padding: 1px 2px;
}

.md-task-list-item > input {
    margin-left: -1.3em;
}

@media print {
    html {
        font-size: 12px;
    }

    table,
    pre {
        page-break-inside: avoid;
    }

    pre {
        word-wrap: break-word;
    }
}

/*YAML*/
#write pre.md-meta-block {
    padding: 1rem;
    font-size: 1rem;
    background-color: var(--yaml-bg-color);
    border: 0;
    border-radius: 2px;
    color: var(--yaml-color);
    margin-top: 0 !important;
}

.mathjax-block > .code-tooltip {
    bottom: .375rem;
}

#write > h3.md-focus:before {
    left: -1.5625rem;
    top: .375rem;
}

#write > h4.md-focus:before {
    left: -1.5625rem;
    top: .285714286rem;
}

#write > h5.md-focus:before {
    left: -1.5625rem;
    top: .285714286rem;
}

#write > h6.md-focus:before {
    left: -1.5625rem;
    top: .285714286rem;
}

.md-image > .md-meta {
    border-radius: 2px;
    font-family: initial;
    padding: 2px 0 0 4px;
    color: inherit;
}

.md-tag {
    color: inherit;
}

.md-toc {
    margin-top: 20px;
    padding-bottom: 20px;
}

.typora-quick-open-item {
    font-size: 1rem !important;
    height: 50px;
    padding-left: 8px;
    padding-top: 4px;
    padding-bottom: 4px;
}

#typora-quick-open {
    box-shadow: 0 0 8px #00000045;
    padding: 0;
}

.ty-quick-open-category.ty-has-prev .ty-quick-open-category-title {
    border-top: none;
}

#typora-quick-open-input {
    margin: 8px;
    box-shadow: none;
    border-radius: 2px;
}

#typora-quick-open-input input {
    font-size: 1rem;
    box-shadow: none;
    padding-top: 2px;
    padding-left: 10px;
    padding-right: 10px;
    line-height: 32px;
    max-height: 32px;
    border: none;
}

.modal-dialog#typora-quick-open {
    border-radius: 8px;
}

.ty-quick-open-category-title {
    padding-left: 8px;
    color: #BEBEBE;
    font-size: 0.8rem;
    margin-bottom: 4px;
}

.typora-quick-open-item-path {
    font-size: 0.8rem;
    text-overflow: ellipsis;
    white-space: nowrap;
    margin-top: 1px;
}

/*search input*/
.form-control {
    border: none;
    border-radius: 2px;
    box-shadow: none;
}

#md-searchpanel .btn {
    border-radius: 2px;
}

#search-panel-replaceall-btn {
    padding-right: 5px !important;
    text-align: center !important;
}

#search-panel-replace-btn {
    text-align: center !important;
}

#md-searchpanel input {
    background: var(--input-bg-color);
    border-radius: 2px;
}

.searchpanel-search-option-btn {
    border-radius: 2px;
    border: none;
    background: transparent;
    color: var(--text-color);
}

.searchpanel-search-option-btn.active {
    background: var(--text-color);
    color: var(--bg-color);
}

.form-control:focus {
    box-shadow: none;
}

#md-notification:before {
    top: 10px;
}

/** focus mode */
.on-focus-mode blockquote {
    border-left-color: rgba(85, 85, 85, 0.12);
}

header,
.context-menu,
.megamenu-content,
footer {
    font-family: initial;
}

/*sidebar*/
.file-node-content:hover .file-node-icon,
.file-node-content:hover .file-node-open-state {
    visibility: visible;
}

#typora-sidebar {
    font-size: 1.1rem;
}

.sidebar-tabs {
    border-bottom: none;
}

.file-list-item-summary, .file-list-item-parent-loc, .file-list-item-time, .file-list-item-summary {
    font-size: 0.9rem !important;
    font-family: var(--text-font);
}

.file-list-item-file-ext-part {
    display: none;
}

.outline-item {
    font-size: 1rem;
}

/*footnotes mark*/
#write .md-footnote {
    background-color: inherit;
    color: var(--drake-highlight);
    font-size: 0.9rem;
    border-radius: 0.9rem;
    padding-left: 0;
}

#write .md-footnote:before {
    content: "[";
}

#write .md-footnote:after {
    content: "]";
}

/*footnotes content*/
.md-hover-tip .code-tooltip-content {
    border-radius: 2px;
}

/*footnotes title*/
span.md-def-name {
    padding-right: 3ch;
    padding-left: 0;
    position: relative;
    font-weight: normal;
}

/*footnotes desc*/
.footnotes {
    font-size: 1rem;
    font-weight: normal;
    color: var(--text-color);
    position: relative;
}

/*footnotes tooltip text*/
.code-tooltip-content .md-plain {
    font-size: 0.9rem;
    font-family: inherit;
}

.code-tooltip-content code {
    padding: 0 2px;
    font-family: inherit;
    color: var(--footnotes-highlight);
    background-color: inherit;
}

.code-tooltip-content a {
    color: var(--footnotes-highlight);
}

div.code-tooltip-content {
    box-shadow: 0 0 8px #00000045;
    background: var(--footnotes-bg-color);
}

.footnotes {
    opacity: 1;
}

.md-def-name:after {
    content: ". ^";
    color: var(--text-color);
}

.md-def-footnote .md-def-name:before {
    content: "";
    color: var(--text-color);
    position: absolute;
}

.md-def-name:before {
    content: "";
    color: var(--text-color);
    position: absolute;
}

.md-content.md-url, .md-def-content.md-def-url.md-auto-disp {
    text-decoration: none;
    border-bottom: .1rem solid var(--text-color);
}

.CodeMirror-scroll::-webkit-scrollbar {
    display: none;
}

.file-list-item-summary {
    font-size: 1em;
}

.pin-outline #outline-content .outline-active strong, .pin-outline .outline-active {
    font-weight: 500;
    color: var(--outline-active-color);
}

.file-list-item.active {
    border-left: 4px solid var(--drake-accent);
}

#md-searchpanel .btn:not(.close-btn):hover {
    box-shadow: none;
    background: var(--btn-hover-bg-color);
}

/*checkbox*/
#write input[type=checkbox] {
    opacity: 0;
    height: 1.6rem;
    width: 1.6rem;
    margin-left: -2em;
    margin-top: 0;
    top: 0;
}

#write .ul-list li.md-task-list-item.task-list-done::before {
    content: "";
    background: var(--checkbox-checked) 0 0 no-repeat;
    background-size: 100%;
    display: inline-block;
    position: absolute;
    height: 1.6rem;
    width: 1.6rem;
    margin-left: -2em;
}

#write .ul-list li.md-task-list-item.task-list-not-done::before {
    content: "";
    background: var(--checkbox-unchecked) 0 0 no-repeat;
    background-size: 100%;
    display: inline-block;
    position: absolute;
    height: 1.6rem;
    width: 1.6rem;
    margin-left: -2em;
}

/*insert table*/
.btn {
    border-radius: 2px;
}

.modal-content {
    border-radius: 8px;
}

.btn-primary:hover, .btn-primary:active {
    background-color: var(--btn-hover-bg-color);
    color: var(--drake-highlight);
}

.btn-primary {
    background-color: transparent;
    color: var(--drake-highlight);
}

.btn-default {
    background-color: transparent;
}

.btn:active {
    box-shadow: none;
    border-color: transparent;
}

.modal-footer {
    border-top: none;
}

#table-insert-col, #table-insert-row {
    background: var(--input-bg-color);
    border-radius: 2px;
}

/*preference panel*/
#megamenu-content {
    background-image: none !important;
    background-color: var(--bg-color);
}
#top-titlebar {
    height: inherit;
    background-color: var(--bg-color);
}
#megamenu-menu-sidebar {
    background-color: var(--bg-color);
    color: var(--text-color);
}
.long-btn {
    width: inherit;
    min-width: 300px;
    border: 1px solid var(--text-color);
    border-radius: 6px;
}
.megamenu-menu-panel h1 {
    margin-bottom: 3rem;
    text-align: left;
}
.megamenu-menu-panel h1, .megamenu-menu-panel h2 {
    font-weight: normal;
}
#recent-file-panel-search-input {
    height: 45px;
    border: none;
    border-bottom: 1px solid var(--text-color);
    padding-left: 8px;
}
#recent-file-panel-search-input::placeholder {
    color: var(--text-color);
    opacity: .5;
}
.megamenu-menu-header {
    border-bottom: none;
}
#recent-file-panel-action-btn {
    background: none;
    border: none;
}
#recent-file-panel-action-btn-container {
    float: none;
    display: inline-block;
}
#top-titlebar .toolbar-icon.btn.hover, #top-titlebar .toolbar-icon.btn:hover {
    background-color: var(--btn-hover-bg-color);
    color: var(--text-color);
}
.megamenu-menu-panel .btn:hover {
    background-color: var(--btn-hover-bg-color) !important;
    color: var(--text-color);
}
#recent-file-panel tbody tr:nth-child(2n-1),
.megamenu-menu-panel table thead,
.megamenu-menu-panel table tr {
    background-color: transparent;
}
.megamenu-menu-panel table {
    font-weight: normal;
}
#megamenu-back-btn {
    color: var(--text-color);
    border: 1px solid var(--text-color);
}
.megamenu-menu-header #megamenu-menu-header-title {
    color: var(--text-color);
}
header, .context-menu, .megamenu-content, footer {
    font-family: var(--text-font);
}
.ty-preferences select {
    padding-left: 2px;
}
.preference-item-hint {
    font-size: 14px;
}
a.ty-link {
    color: var(--a-color);
    margin: 0 .2rem;
}

/**
    code render
    Name: IntelliJ IDEA darcula theme
    From IntelliJ IDEA by JetBrains
 */
.cm-s-inner.CodeMirror {
    background: var(--code-block-bg-color);
    color: var(--code-block-color);
}

.cm-s-inner span.cm-meta {
    color: #BBB529;
}

.cm-s-inner span.cm-number {
    color: #6897BB;
}

.cm-s-inner span.cm-keyword {
    color: #CC7832;
}

.cm-s-inner span.cm-def {
    color: #FFD760;
}

.cm-s-inner span.cm-variable {
    color: var(--code-block-color);
}

.cm-s-inner span.cm-variable-2 {
    color: var(--code-block-color);
}

.cm-s-inner span.cm-variable-3 {
    color: #9876AA;
}

.cm-s-inner span.cm-type {
    color: #AABBCC;
}

.cm-s-inner span.cm-property {
    color: #FFC66D;
}

.cm-s-inner span.cm-operator {
    color: var(--code-block-color);
}

.cm-s-inner span.cm-string {
    color: #6A8759;
}

.cm-s-inner span.cm-string-2 {
    color: #6A8759;
}

.cm-s-inner span.cm-comment {
    color: #787878;
}

.cm-s-inner span.cm-link {
    color: #CC7832;
}

.cm-s-inner span.cm-atom {
    color: #CC7832;
}

.cm-s-inner span.cm-error {
    color: #BC3F3C;
}

.cm-s-inner span.cm-tag {
    color: #E8BF6A;
}

.cm-s-inner span.cm-quote {
    color: #a6e22e;
}

.cm-s-inner span.cm-attribute {
    color: #9876AA;
}

.cm-s-inner span.cm-qualifier {
    color: #6A8759;
}

.cm-s-inner span.cm-bracket {
    color: #E8BF6A;
}

.cm-s-inner span.cm-builtin {
    color: #FF9E59;
}

.cm-s-inner span.cm-special {
    color: #FF9E59;
}

.cm-s-inner span.cm-matchhighlight {
    color: #FFFFFF;
    background-color: rgba(50, 89, 48, .7);
    font-weight: normal;
}

.cm-s-inner span.cm-searching {
    color: #FFFFFF;
    background-color: rgba(61, 115, 59, .7);
    font-weight: normal;
}

.cm-s-inner .CodeMirror-gutters {
    border-right: 1px solid rgba(120, 120, 120, 0.3);
}

.cm-s-inner .CodeMirror-linenumber {
    color: #585b5d;
}

.cm-s-inner .CodeMirror-matchingbracket {
    background-color: #3B514D;
    color: #FFEF28 !important;
}

.cm-s-inner .CodeMirror-selected {
    background: #214283 !important;
}

.cm-s-inner .CodeMirror-selectedtext {
    background: #214283 !important;
}

.cm-s-typora-default .CodeMirror-selectedtext {
    background: var(--select-text-bg-color) !important;
}

.cm-overlay.CodeMirror-selectedtext {
    background: var(--select-text-bg-color) !important;
}

.cm-s-inner div.CodeMirror-cursor {
    border-left: 1px solid var(--code-block-color);
}/*# sourceURL=/Users/didi/Documents/Codes/Fun/lagou/public/drake-juejin.css*/</style></head>
<body>
  <div id="write"><h1>第05讲：手动模式构建双 Namenode+Yarn 的 Hadoop 集群（上）</h1><p>本课时主要讲“手动模式构建双 NameNode + Yarn 的 Hadoop 集群”的内容。</p>
<h3>双 NameNode 实现原理与应用架构</h3>
<p>前面铺垫了那么多，现在是时候开始进入 Hadoop 的内容了，学习大数据运维，首先从安装、部署入手，这是大数据运维的基础，本课时将重点讲述如何构建企业级大数据应用平台。</p>
<h4>1. 什么是双 NameNode</h4>
<p>在分布式文件系统 HDFS 中，NameNode 是 master 角色，当 NameNode 出现故障后，整个 HDFS 将不可用，所以保证 NameNode 的稳定性至关重要。在 Hadoop1.x 版本中，HDFS 只支持一个 NameNode，为了保证稳定性，只能靠 SecondaryNameNode 来实现，而 SecondaryNameNode 不能做到热备，而且恢复的数据也不是最新的元数据。基于此，从 Hadoop2.x 版本开始，HDFS 开始支持多个 NameNode，这样不但可以实现 HDFS 的高可用，而且还可以横行扩容 HDFS 的存储规模。</p>
<p>在实际的企业应用中，使用最多的是双 NameNode 架构，也就是一个 NameNode 处于 <strong>Active（活跃） 状态</strong>，另一个 NameNode 处于 <strong>Standby（备用）状态</strong>，通过这种机制，实现 NameNode 的<strong>双机热备高可用功能</strong>。</p>
<h4>2. 双 NameNode 的运行原理</h4>
<p>在高可用的 NameNode 体系结构中，只有 Active 状态的 NameNode 是正常工作的，Standby 状态的 NameNode 处于随时待命状态，它时刻去同步 Active 状态 NameNode 的元数据。一旦 Active 状态的 NameNode 不能工作，可以通过手工或者自动切换方式将 Standby 状态的 NameNode 转变为 Active 状态，保持 NameNode 持续工作。这就是<strong>两个高可靠的 NameNode 的实现机制</strong>。</p>
<p>NameNode 主、备之间的切换可以通过手动或者自动方式来实现，作为线上大数据环境，都是通过自动方式来实现切换的，为保证自动切换，NameNode 使用 ZooKeeper 集群进行仲裁选举。基本的思路是 HDFS 集群中的两个 NameNode 都在 ZooKeeper 中注册，当 Active 状态的 NameNode 出故障时，ZooKeeper 能马上检测到这种情况，它会自动把 Standby 状态切换为 Active 状态。</p>
<p>ZooKeeper（ZK）集群作为一个高可靠系统，能够为集群协作数据提供监控，并将数据的更改随时反馈给客户端。HDFS 的热备功能依赖 ZK 提供的两个特性：错误监测、活动节点选举。HDFS 通过 ZK 实现高可用的机制如下。</p>
<p>每个 NameNode 都会在 ZK 中注册并且持久化一个 session 标识，一旦 NameNode 失效了，那么 session 也将过期，而 ZK 也会通知其他的 NameNode 发起一个失败切换。ZK 提供了一个简单的机制来保证只有一个 NameNode 是活动的，那就是独占锁，如果当前的活动 NameNode 失效了，那么另一个 NameNode 将获取 ZK 中的<strong>独占锁</strong>，表明自己是活动的节点。</p>
<p>ZKFailoverController（ZKFC）是 ZK 集群的客户端，用来监控 NN 的状态信息，每个运行 NameNode 的节点必须要运行一个 ZKFC。ZKFC 提供以下功能：</p>
<ul>
<li>健康检查，ZKFC 定期对本地的 NN 发起 health-check 的命令，如果 NN 正确返回，那么 NN 被认为是 OK 的，否则被认为是失效节点；</li>
<li>session管理，当本地 NN 是健康的时候，ZKFC 将会在 ZK 中持有一个 session，如果本地 NN 又正好是 Active，那么 ZKFC 将持有一个短暂的节点作为锁，一旦本地 NN 失效了，那么这个节点就会被自动删除；</li>
<li>基础选举，如果本地 NN 是健康的，并且 ZKFC 发现没有其他 NN 持有这个独占锁，那么它将试图去获取该锁，一旦成功，那么它就开始执行 Failover，然后变成 Active 状态的 NN 节点；Failover 的过程分两步，首先对之前的 NameNode 执行隔离（如果需要的话），然后将本地 NameNode 切换到 Active 状态。</li>
</ul>
<h4>3. 双 NameNode 架构中元数据一致性如何保证</h4>
<p>聪明的你可能要问了，两个 NameNode 架构之间的元数据是如何共享的呢？</p>
<p>从 Hadoop2.x 版本后，HDFS 采用了一种全新的元数据共享机制，即通过 Quorum Journal Node（JournalNode）集群或者 network File System（NFS）进行数据共享。NFS 是操作系统层面的，而 JournalNode 是 Hadoop 层面的，成熟可靠、使用简单方便，所以，这里我们采用 JournalNode 集群进行元数据共享。</p>
<p>JournalNode 集群以及与 NameNode 之间如何共享元数据，可参照下图所示。</p>
<p><img src="https://s0.lgstatic.com/i/image/M00/07/4E/CgqCHl65FrmAJkEYAADp0NN0xGw607.png" alt="01.png"></p>
<p>由图可知，JournalNode 集群可以几乎实时的去 NameNode 上拉取元数据，然后保存元数据到 JournalNode 集群；同时，处于 standby 状态的 NameNode 也会实时的去 JournalNode 集群上同步 JNS 数据，通过这种方式，就实现了两个 NameNode 之间的数据同步。</p>
<p>那么，JournalNode 集群内部是如何实现的呢？</p>
<p>两个 NameNode 为了数据同步，会通过一组称作 JournalNodes 的独立进程进行相互通信。当 Active 状态的 NameNode 元数据有任何修改时，会告知大部分的 JournalNodes 进程。同时，Standby 状态的 NameNode 也会读取 JNs 中的变更信息，并且一直监控 EditLog （事务日志）的变化，并把变化应用于自己的命名空间。Standby 可以确保在集群出错时，元数据状态已经完全同步了。</p>
<p>下图是 JournalNode 集群的内部运行架构图。</p>
<p><img src="https://s0.lgstatic.com/i/image/M00/07/4E/CgqCHl65FsmAReOgAACOMp8vfYQ648.png" alt="02.png"></p>
<p>由图可知，JN1、JN2、JN3 等是 JournalNode 集群的节点，QJM（Qurom Journal Manager）的基本原理是用 2N+1 台 JournalNode 存储 EditLog，每次写数据操作有 N/2+1 个节点返回成功，那么本次写操作才算成功，保证数据高可用。当然这个算法所能容忍的是最多有 N 台机器挂掉，如果多于 N 台挂掉，算法就会失效。</p>
<p>ANN 表示处于 Archive 状态的 NameNode，SNN 表示处于 Standbye 状态的 NameNode，QJM 从 ANN 读取数据写入 EditLog 中，然后 SNN 从 EditLog 中读取数据，进而应用到自身。</p>
<h4>4. 双 NameNode 高可用 Hadoop 集群架构</h4>
<p>作为 Hadoop 的第二个版本，Hadoop2.x 最大的变化是 NameNode 可实现高可用，以及计算资源管理器 Yarn。本课时我们将重点介绍下如何构建一个线上高可用的 Hadoop 集群系统，这里有两个重点，一是 NameNode 高可用的构建，二是资源管理器 Yarn 的实现，通过 Yarn 实现真正的分布式计算和多种计算框架的融合。</p>
<p>下图是一个高可用的 Hadoop 集群运行原理图。</p>
<p><img src="https://s0.lgstatic.com/i/image/M00/07/55/Ciqc1F65G7aAKwckAADqfdUc2EA969.png" alt="03.png"></p>
<p>此架构主要解决了两个问题，一是 NameNode 元数据同步问题，二是主备 NameNode 切换问题，由图可知，解决主、备 NameNode 元数据同步是通过 JournalNode 集群来完成的，而解决主、备 NameNode 切换可通过 ZooKeeper 来完成。</p>
<p>ZooKeeper 是一个独立的集群，在两个 NameNode 上还需要启动一个 failoverController（zkfc）进程，该进程作为 ZooKeeper 集群的客户端存在，通过 zkfc 可以实现与 ZooKeeper 集群的交互和状态监测。</p>
<h3>双 NameNode + Yarn 构建 HDFS 高可用 Hadoop 集群过程</h3>
<h4>1. 部署前主机、软件功能、磁盘存储规划</h4>
<p>双 NameNode 的 Hadoop 集群环境涉及到的角色有 Namenode、datanode、resourcemanager、nodemanager、historyserver、ZooKeeper、JournalNode 和 zkfc，这些角色可以单独运行在一台服务器上，也可以将某些角色合并在一起运行在一台机器上。</p>
<p>一般情况下，NameNode 服务要独立部署，这样两个 NameNode 就需要两台服务器，而 datanode 和 nodemanager 服务建议部署在一台服务器上，resourcemanager 服务跟 NameNode 类似，也建议独立部署在一台服务器上，而 historyserver 一般和 resourcemanager 服务放在一起。ZooKeeper 和 JournalNode 服务是基于集群架构的，因此至少需要 3 个集群节点，即需要 3 台服务器，不过 ZooKeeper 和 JournalNode 集群可以放在一起，共享 3 台服务器资源。最后，zkfc 是对 NameNode 进行资源仲裁的，所以它必须和 NameNode 服务运行在一起，这样 zkfc 就不需要占用独立的服务器了。</p>
<p>本着节约成本、优化资源、合理配置的原则，下面的部署通过 5 台独立的服务器来实现，操作系统均采用 Centos7.7 版本，每个服务器主机名、IP 地址以及功能角色如下表所示：</p>
<p><img src="https://s0.lgstatic.com/i/image/M00/07/55/CgqCHl65G9OAUprTAADj0vKtWPY235.png" alt="图片1.png"></p>
<p>由表可知，namenodemaster 和 yarnserver 是作为 NameNode 的主、备两个节点，同时 yarnserver 还充当了 ResourceManager 和 JobHistoryServer 的角色。如果服务器资源充足，可以将 ResourceManager 和 JobHistoryServer 服务放在一台独立的机器上。</p>
<p>此外，slave001、slave002 和 slave003 三台主机上部署了 ZooKeeper 集群、JournalNode 集群，还充当了 DataNode 和 NodeManager 的角色。</p>
<p>在软件部署上，每个软件采用的版本如下表所示：</p>
<p><img src="https://s0.lgstatic.com/i/image/M00/07/56/CgqCHl65G-SAIyUlAABHEvoc-ZI303.png" alt="图片2.png"></p>
<p>最后，还需要考虑<strong>磁盘存储规划</strong>，HDFS 文件系统的数据块都存储在本地的每个 datanode 节点上。因此，每个 datanode 节点要有大容量的磁盘，磁盘类型可以是普通的机械硬盘，有条件的话 SSD 硬盘最好，单块硬盘推荐 4T 或者 8T，这些硬盘无需做 RAID，单盘使用即可，因为 HDFS 本身已经有了副本容错机制。</p>
<p>在本课时介绍的环境中，我的每个 datanode 节点均有 2 块大容量硬盘用来存储 HDFS 数据块。此外，NameNode 节点所在的主机要存储 HDFS 的元数据信息，这些元数据控制着整个 HDFS 集群中的存储与读写，一旦丢失，那么 HDFS 将丢失数据甚至无法使用，所以保证 NameNode 节点 HDFS 元数据安全性至关重要。</p>
<p>在 NameNode 节点建议配置 4 块大小一样的磁盘，每两块做一个 raid1，共做两组 raid1，然后将元数据镜像存储在这两个 raid1 上。</p>
<h4>2. 自动化安装系统基础环境</h4>
<p>在进行 Hadoop 集群部署之前，先需要对系统的基础环境进行配置， 包含主机名、本地解析 hosts 文件、ansible 管理机到集群节点建立 ssh 信任、系统参数修改（ulimit 资源配置、关闭 selinux）、创建 Hadoop 用户五个方面。 这五个方面可以通过 ansible playbook 脚本自动化完成，下面依次介绍。</p>
<p>（1）建立管理机到集群节点 ssh 无密码登录</p>
<p>在大数据运维中，操作系统安装基本是自动化完成的，系统安装完成后，所有主机的密码也是相同的，为了自动化运维方便，需要将 ansilbe 管理机与 Hadoop 集群所有节点之间建立单向无密码登录权限。</p>
<p>首先，修改 ansible 的配置文件 hosts（本例为 /etc/ansible/hosts）添加主机组信息，内容如下：</p>
<pre><code data-language="java" class="lang-java hljs">[hadoophosts]
<span class="hljs-number">172.16</span><span class="hljs-number">.213</span><span class="hljs-number">.31</span>   hostname=namenodemaster
<span class="hljs-number">172.16</span><span class="hljs-number">.213</span><span class="hljs-number">.41</span>   hostname=yarnserver
<span class="hljs-number">172.16</span><span class="hljs-number">.213</span><span class="hljs-number">.70</span>   hostname=slave001 myid=<span class="hljs-number">1</span>
<span class="hljs-number">172.16</span><span class="hljs-number">.213</span><span class="hljs-number">.103</span>  hostname=slave002 myid=<span class="hljs-number">2</span>
<span class="hljs-number">172.16</span><span class="hljs-number">.213</span><span class="hljs-number">.169</span>  hostname=slave003 myid=<span class="hljs-number">3</span>
</code></pre>
<p>此主机组中，前面是 IP 地址，后面是每个主机的主机名，通过定义 hostname 变量，可实现通过 ansible 自动修改主机名。</p>
<p>接着，创建 /etc/ansible/roles/vars/main.yml 文件，内容如下：</p>
<pre><code data-language="java" class="lang-java hljs">zk1_hostname: <span class="hljs-number">172.16</span><span class="hljs-number">.213</span><span class="hljs-number">.70</span>
zk2_hostname: <span class="hljs-number">172.16</span><span class="hljs-number">.213</span><span class="hljs-number">.103</span>
zk3_hostname: <span class="hljs-number">172.16</span><span class="hljs-number">.213</span><span class="hljs-number">.169</span>
AnsibleDir: /etc/ansible
BigdataDir: /opt/bigdata
hadoopconfigfile: /etc/hadoop
</code></pre>
<p>这里面定义了 6 个角色变量，在后面 playbook 中会用到。最后，编写 playbook 脚本，内容如下：</p>
<pre><code data-language="SQL" class="lang-SQL hljs">- hosts: hadoophosts
  gather_facts: no
  roles:
   - roles
  tasks:
   - name: close ssh yes/no <span class="hljs-keyword">check</span>
     lineinfile: <span class="hljs-keyword">path</span>=/etc/ssh/ssh_config regexp=<span class="hljs-string">'(.*)StrictHostKeyChecking(.*)'</span> line=<span class="hljs-string">"StrictHostKeyCheck
ing no"</span>
   - <span class="hljs-keyword">name</span>: <span class="hljs-keyword">delete</span> /root/.ssh/
     <span class="hljs-keyword">file</span>: <span class="hljs-keyword">path</span>=/root/.ssh/ state=absent
   - <span class="hljs-keyword">name</span>: <span class="hljs-keyword">create</span> .ssh <span class="hljs-keyword">directory</span>
     <span class="hljs-keyword">file</span>: dest=/root/.ssh <span class="hljs-keyword">mode</span>=<span class="hljs-number">0600</span> state=<span class="hljs-keyword">directory</span>
   - <span class="hljs-keyword">name</span>: generating <span class="hljs-keyword">local</span> <span class="hljs-keyword">public</span>/<span class="hljs-keyword">private</span> rsa <span class="hljs-keyword">key</span> pair
     local_action: shell ssh-keygen -t rsa -b <span class="hljs-number">2048</span> -N <span class="hljs-string">''</span> -y -f /root/.ssh/id_rsa
   - <span class="hljs-keyword">name</span>: <span class="hljs-keyword">view</span> id_rsa.pub
     local_action: shell cat /root/.ssh/id_rsa.pub
     <span class="hljs-keyword">register</span>: sshinfo
   - set_fact: sshpub={{sshinfo.stdout}}
   - <span class="hljs-keyword">name</span>: <span class="hljs-keyword">add</span> ssh <span class="hljs-built_in">record</span>
     local_action: shell echo {{sshpub}} &gt; {{AnsibleDir}}/<span class="hljs-keyword">roles</span>/templates/authorized_keys.j2
   - <span class="hljs-keyword">name</span>: copy authorized_keys.j2 <span class="hljs-keyword">to</span> <span class="hljs-keyword">all</span>
     <span class="hljs-keyword">template</span>: src={{AnsibleDir}}/<span class="hljs-keyword">roles</span>/templates/authorized_keys.j2 dest=/root/.ssh/authorized_keys <span class="hljs-keyword">mode</span>
=<span class="hljs-number">0600</span>
     tags:
     - <span class="hljs-keyword">install</span> ssh
</code></pre>
<p>将此playbook脚本命名为sshk.yml，然后在命令行执行如下命令完成ssh单向信任：</p>
<pre><code data-language="SQL" class="lang-SQL hljs">[root@server239 ansible]<span class="hljs-comment"># pwd</span>
/etc/ansible
[root@server239 ansible]<span class="hljs-comment"># ansible-playbook  sshk.yml -k</span>
</code></pre>
<p>注意，这里添加了一个“-k”参数，因为现在管理机和 Hadoop 节点之间还没有建立 ssh 信任，所以需要指定此参数手动输入密码，但这个操作仅需执行一次，后面的操作就可以无需输入密码了。</p>
<p>（2）自动修改主机名</p>
<p>紧接上面的 ansible 配置环境，要实现批量自动修改主机名，执行如下 playbook 脚本即可：</p>
<pre><code data-language="SQL" class="lang-SQL hljs">- hosts: hadoophosts
  remote_user: root
  tasks:
  - name: <span class="hljs-keyword">change</span> <span class="hljs-keyword">name</span>
    shell: <span class="hljs-string">"echo {{hostname}} &gt; /etc/hostname"</span>
  - <span class="hljs-keyword">name</span>:
    shell: hostname {{hostname|quote}}
</code></pre>
<p>将此 playbook 脚本命名为 hostname.yml，然后在命令行执行如下命令完成主机名修改：</p>
<pre><code data-language="SQL" class="lang-SQL hljs"> [root@server239 ansible]<span class="hljs-comment"># ansible-playbook  hostname.yml</span>
</code></pre>
<p>（3）自动构建本地解析hosts文件</p>
<p>紧接上面的 ansible 配置环境，要自动构建本地解析 hosts 文件，可通过如下 playbook 脚本实现：</p>
<pre><code data-language="java" class="lang-java hljs">- hosts: hadoophosts
  remote_user: root
  roles:
  - roles
  tasks:
   - name: add localhost
     local_action: shell echo <span class="hljs-string">"127.0.0.1   localhost"</span> &gt; {{AnsibleDir}}/roles/templates/hosts.j2
     run_once: <span class="hljs-keyword">true</span>
   - set_fact: ipaddress={{inventory_hostname}}
   - set_fact: hostname={{hostname}}
   - name: add host record
     local_action: shell echo {{ipaddress}} {{hostname}} &gt;&gt; {{AnsibleDir}}/roles/templates/hosts.j2
   - name: copy hosts.j2 to all host
     template: src={{AnsibleDir}}/roles/templates/hosts.j2 dest=/etc/hosts
</code></pre>
<p>将 playbook 脚本命名为 hosts.yml，然后在命令行执行如下命令，完成构建本地解析 hosts 文件并分发集群每个节点：</p>
<pre><code data-language="SQL" class="lang-SQL hljs">[root@server239 ansible]<span class="hljs-comment"># pwd</span>
/etc/ansible
[root@server239 ansible]<span class="hljs-comment"># ansible-playbook  hosts.yml</span>
</code></pre>
<p>（4）自动修改优化系统参数</p>
<p>紧接上面的 ansible 配置环境，系统参数优化主要有关闭 selinux、关闭防火墙 firewalld、iptables、添加 ulimit 资源限制、添加时间同步服务器等，要实现自动优化系统参数，可通过如下 playbook 脚本实现：</p>
<pre><code data-language="java" class="lang-java hljs">- hosts: hadoophosts
  remote_user: root
  gather_facts: <span class="hljs-keyword">false</span>
  tasks:
   - name: selinux disabled
     lineinfile: dest=/etc/selinux/config regexp=<span class="hljs-string">'SELINUX=(.*)'</span> line=<span class="hljs-string">'SELINUX=disabled'</span>
   - name:
     lineinfile: dest=/etc/security/limits.conf line=<span class="hljs-string">"{{item.value}}"</span>
     with_items:
     - {value: <span class="hljs-string">"*         soft    nofile         655360"</span>}
     - {value: <span class="hljs-string">"*         hard    nofile         655360"</span>}
   - name: disabled iptables and firewalld
     shell: systemctl stop firewalld&amp;&amp;systemctl disable firewalld&amp;&amp;iptables –F
   - name: cron ntpdate
     cron: name=ntpdate minute=*/<span class="hljs-number">5</span> user=root job=<span class="hljs-string">"source /etc/profile;/usr/sbin/ntpdate -u 172.16.213.154;/sbin/hwclock -w"</span>
</code></pre>
<p>playbook 脚本依次执行了关闭 selinux、添加用户资源配置、关闭防火墙和增加时间同步服务器，其中 172.16.213.154 是我内网的时间同步服务器，如果没有这个时间服务器，也可以使用外网时间同步时钟，但要<strong>保证机器能够访问互联网</strong>。</p>
<p>将 playbook 脚本命名为 os.yml，然后在命令行执行如下命令，完成优化系统参数：</p>
<pre><code data-language="SQL" class="lang-SQL hljs">[root@server239 ansible]<span class="hljs-comment"># ansible-playbook  os.yml</span>
</code></pre>
<p>（5）自动化批量创建 Hadoop 用户</p>
<p>Hadoop 用户作为集群的管理员用户，需要在每个集群节点进行创建，此用户不需要密码，仅创建一个用户即可，后面所有服务的启动，均是通过 Hadoop 用户来完成的。如下 playbook 脚本可自动完成创建用户的工作，脚本内容如下：</p>
<pre><code data-language="java" class="lang-java hljs">- name: create user
  hosts: hadoophosts
  remote_user: root
  gather_facts: <span class="hljs-keyword">true</span>
  vars:
    user1: hadoop
  tasks:
   - name: start createuser
     user: name=<span class="hljs-string">"{{user1}}"</span>
</code></pre>
<p>将 playbook 脚本命名为 adduser.yml，然后在命令行执行如下命令完成用户创建：</p>
<pre><code data-language="SQL" class="lang-SQL hljs">[root@server239 ansible]<span class="hljs-comment"># ansible-playbook  adduser.yml</span>
</code></pre>
<h4>3. 自动化安装 JDK、ZooKeeper 及 Hadoop</h4>
<p>整个 Hadoop 集群的安装部署需要三个步骤， 即安装 JDK 并设置 Java 环境变量、ZooKeeper 集群的安装部署以及 Hadoop 集群的安装和部署。</p>
<p>软件的部署一般分为安装和配置，若通过自动化工具来进行部署的话，一般是将软件下载好，然后修改配置文件，最后将程序和配置进行打包压缩，这样，一个自动化部署程序就包装好了。将包装好的程序放在 ansible 管理机对应的目录下，进行调用即可。</p>
<p>这里我们将 JDK、ZooKeeper 和 Hadoop 都安装在服务器的 /opt/bigdata 目录下。先从最简单的 JDK 安装部署开始，仍然采用编写 ansible-playbook 脚本的方式进行，编写好的自动化安装 JDK 脚本内容如下：</p>
<pre><code data-language="java" class="lang-java hljs">- hosts: hadoophosts
  remote_user: root
  roles:
  - roles
  tasks:
   - name: mkdir jdk directory
     file: path={{BigdataDir}} state=directory mode=<span class="hljs-number">0755</span>
   - name: copy and unzip jdk
     unarchive: src={{AnsibleDir}}/roles/files/jdk.tar.gz dest={{BigdataDir}}
   - name: chmod bin
     file: dest={{BigdataDir}}/jdk/bin mode=<span class="hljs-number">0755</span> recurse=yes
   - name: set jdk env
     lineinfile: dest=/home/hadoop/.bash_profile line=<span class="hljs-string">"{{item.value}}"</span> state=present
     with_items:
     - {value: <span class="hljs-string">"export JAVA_HOME={{BigdataDir}}/jdk"</span>}
     - {value: <span class="hljs-string">"export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar"</span>}
     - {value: <span class="hljs-string">"export PATH=$JAVA_HOME/bin:$PATH"</span>}
</code></pre>
<p>此脚本仍然使用了角色变量 BigdataDir 和 AnsibleDir，其中，jdk.tar.gz 是包装好的 JDK 安装程序，只需要拷贝到集群每个节点解压即可完成安装。</p>
<p>将 playbook 脚本命名为 jdk.yml，然后在命令行执行如下命令完成 JDK 安装：</p>
<pre><code data-language="SQL" class="lang-SQL hljs">[root@server239 ansible]<span class="hljs-comment"># ansible-playbook  jdk.yml</span>
</code></pre>
<p>接着，编写自动化安装 ZooKeeper 集群的脚本，内容如下：</p>
<pre><code data-language="java" class="lang-java hljs"> - hosts: hadoophosts
  remote_user: root
  roles:
  - roles
  tasks:
   - name: mkdir directory <span class="hljs-keyword">for</span> bigdata data
     file: dest={{BigdataDir}} mode=<span class="hljs-number">0755</span> state=directory
   - name: install zookeeper
     unarchive: src={{AnsibleDir}}/roles/files/zookeeper.tar.gz dest={{BigdataDir}}
   - name: install configuration file <span class="hljs-keyword">for</span> zookeeper
     template: src={{AnsibleDir}}/roles/templates/zoo.cfg.j2 dest={{BigdataDir}}/zookeeper/current/conf/zoo.cfg
   - name: create data and log directory
     file: dest={{BigdataDir}}/zookeeper/current/{{item}} mode=<span class="hljs-number">0755</span> state=directory
     with_items:
     - dataLogDir
     - data
   - name: add myid file
     shell: echo {{ myid }} &gt; {{BigdataDir}}/zookeeper/current/data/myid
   - name: chown hadoop <span class="hljs-keyword">for</span> zk directory
     file: dest={{BigdataDir}}/zookeeper owner=hadoop group=hadoop state=directory recurse=yes
</code></pre>
<p>此脚本引用了一个模板文件 zoo.cfg.j2，它位于管理机上 /etc/ansible/roles/templates/ 路径下，此文件内容如下：</p>
<pre><code data-language="java" class="lang-java hljs">tickTime=<span class="hljs-number">2000</span>
initLimit=<span class="hljs-number">20</span>
syncLimit=<span class="hljs-number">10</span>
dataDir={{BigdataDir}}/zookeeper/current/data
dataLogDir={{BigdataDir}}/zookeeper/current/dataLogDir
clientPort=<span class="hljs-number">2181</span>
quorumListenOnAllIPs=<span class="hljs-keyword">true</span>
server<span class="hljs-number">.1</span>={{zk1_hostname}}:<span class="hljs-number">2888</span>:<span class="hljs-number">3888</span>
server<span class="hljs-number">.2</span>={{zk2_hostname}}:<span class="hljs-number">2888</span>:<span class="hljs-number">3888</span>
server<span class="hljs-number">.3</span>={{zk3_hostname}}:<span class="hljs-number">2888</span>:<span class="hljs-number">3888</span>
</code></pre>
<p>在这个模板文件中，也引用了几个角色变量 BigdataDir、zk1_hostname、zk2_hostname 和 zk3_hostname，这些变量都在 roles 文件夹中 vars 子文件夹下的 main.yml 文件中定义。</p>
<p>将 playbook 脚本命名为 zk.yml，然后在命令行执行如下命令，完成 ZooKeeper 的自动化安装与配置：</p>
<pre><code data-language="SQL" class="lang-SQL hljs">[root@server239 ansible]<span class="hljs-comment"># ansible-playbook  zk.yml</span>
</code></pre>
<p>最后，重点内容来了，即编写自动化安装 Hadoop 脚本，我们采用 Hadoop3.2.1 版本，下载二进制安装包进行，其实就是将包装好的 Hadoop 安装程序打包成 hadoop.tar.gz 这种压缩格式，然后从管理机自动拷贝到集群每个节点，playbook 文件内容如下：</p>
<pre><code data-language="java" class="lang-java hljs"> - hosts: hadoophosts
  remote_user: root
  roles:
  - roles
  tasks:
   - name: create hadoop user
     user: name=hadoop state=present
   - name: mkdir directory <span class="hljs-keyword">for</span> bigdata directory
     file: dest={{BigdataDir}} mode=<span class="hljs-number">0755</span> state=directory
   - name: mkdir directory <span class="hljs-keyword">for</span> bigdata configfiles
     file: dest={{hadoopconfigfile}} mode=<span class="hljs-number">0755</span> state=directory
   - name: install hadoop
     unarchive: src={{AnsibleDir}}/roles/files/hadoop.tar.gz dest={{BigdataDir}}
   - name: chown hadoop configfiles directory
     file: dest={{BigdataDir}}/hadoop owner=hadoop group=hadoop state=directory
   - name: install configuration file <span class="hljs-keyword">for</span> hadoop
     unarchive: src={{AnsibleDir}}/roles/files/conf.tar.gz dest={{hadoopconfigfile}}
   - name: chown hadoop configfiles directory
     file: dest={{hadoopconfigfile}}/conf owner=hadoop group=hadoop state=directory
   - name: set hadoop env
     lineinfile: dest=/home/hadoop/.bash_profile insertafter=<span class="hljs-string">"{{item.position}}"</span> line=<span class="hljs-string">"{{item.value}}"</span> st
ate=present
     with_items:
     - {position: EOF, value: <span class="hljs-string">"export HADOOP_HOME={{BigdataDir}}/hadoop/current"</span>}
     - {position: EOF, value: <span class="hljs-string">"export HADOOP_MAPRED_HOME=\${HADOOP_HOME}"</span>}
     - {position: EOF, value: <span class="hljs-string">"export HADOOP_COMMON_HOME=\${HADOOP_HOME}"</span>}
     - {position: EOF, value: <span class="hljs-string">"export HADOOP_HDFS_HOME=\${HADOOP_HOME}"</span>}
     - {position: EOF, value: <span class="hljs-string">"export HADOOP_YARN_HOME=\${HADOOP_HOME}"</span>}
     - {position: EOF, value: <span class="hljs-string">"export HTTPFS_CATALINA_HOME=\${HADOOP_HOME}/share/hadoop/httpfs/tomcat"</span>}
     - {position: EOF, value: <span class="hljs-string">"export CATALINA_BASE=\${HTTPFS_CATALINA_HOME}"</span>}
     - {position: EOF, value: <span class="hljs-string">"export HADOOP_CONF_DIR={{hadoopconfigfile}}/conf"</span>}
     - {position: EOF, value: <span class="hljs-string">"export HTTPFS_CONFIG={{hadoopconfigfile}}/conf"</span>}
     - {position: EOF, value: <span class="hljs-string">"export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin"</span>}
   - name: enforce env
     shell: source /home/hadoop/.bash_profile
</code></pre>
<p>将此 playbook 脚本命名为 hadoop.yml，然后在命令行执行如下命令，完成 Hadoop 的自动化安装与配置：</p>
<pre><code data-language="SQL" class="lang-SQL hljs">[root@server239 ansible]<span class="hljs-comment"># ansible-playbook  hadoop.yml</span>
</code></pre></div>

</body></html>
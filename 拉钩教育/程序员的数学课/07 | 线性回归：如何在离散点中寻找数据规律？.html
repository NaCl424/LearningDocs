<!DOCTYPE html><html lang="en"><head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>07 | 线性回归：如何在离散点中寻找数据规律？</title>
<style type="text/css">
:root {
    --control-text-color: #777;
    --select-text-bg-color: rgba(223, 197, 223);  /*#7e66992e;*/
    
    /* side bar */
    --side-bar-bg-color: rgb(255, 255, 255);
    --active-file-text-color: #8163bd;
    --active-file-bg-color: #E9E4F0;
    --item-hover-bg-color: #E9E4F0;
    --active-file-border-color: #8163bd;

    --title-color: #6c549c;
    --font-sans-serif: 'Ubuntu', 'Source Sans Pro', sans-serif !important;
    --font-monospace: 'Fira Code', 'Roboto Mono', monospace !important;
    --purple-1: #8163bd;
    --purple-2: #79589F;
    --purple-3: #fd5eb8;
    --purple-light-1: rgba(99, 99, 172, .05);
    --purple-light-2: rgba(99, 99, 172, .1);
    --purple-light-3: rgba(99, 99, 172, .2);
    --purple-light-4: rgba(129, 99, 189, .3);
    --purple-light-5: #E9E4F0;
    --purple-light-6: rgba(129, 99, 189, .8);
}

/* html {
    font-size: 16px;
} */

body {
    font-family: var(--font-sans-serif);
    color: #34495e;
    -webkit-font-smoothing: antialiased;
    line-height: 1.6rem;
    letter-spacing: 0;
    margin: 0;
    overflow-x: hidden;
}

/* 页边距 和 页面大小 */
#write {
    padding-left: 6ch;
    padding-right: 6ch;
    margin: 0 auto;
}

#write p {
    line-height: 1.6rem;
    word-spacing: .05rem;
}

#write ol li {
    padding-left: 0.5rem;
}

#write > ul:first-child,
#write > ol:first-child {
    margin-top: 30px;
}

body > *:first-child {
    margin-top: 0 !important;
}

body > *:last-child {
    margin-bottom: 0 !important;
}

a {
    color: var(--purple-1);
    padding: 0 2px;
    text-decoration: none;
}
.md-content {
    color: var(--purple-light-6);
}
#write a {
    border-bottom: 1px solid var(--purple-1);
    color: var(--purple-1);
    text-decoration: none;
}

h1,
h2,
h3,
h4,
h5,
h6 {
    position: relative;
    margin-top: 1rem;
    margin-bottom: 0.5rem;
    /* font-weight: bold; */
    font-weight: 500 !important;
    line-height: 1.4;
    cursor: text;
    color: var(--title-color);
    font-family: var(--font-sans-serif);
}

h1:hover a.anchor,
h2:hover a.anchor,
h3:hover a.anchor,
h4:hover a.anchor,
h5:hover a.anchor,
h6:hover a.anchor {
    text-decoration: none;
}

h1 tt,
h1 code {
    font-size: inherit !important;
}
h2 tt,
h2 code {
    font-size: inherit !important;
}
h3 tt,
h3 code {
    font-size: inherit !important;
}
h4 tt,
h4 code {
    font-size: inherit !important;
}
h5 tt,
h5 code {
    font-size: inherit !important;
}
h6 tt,
h6 code {
    font-size: inherit !important;
}


h1 {
    padding-bottom: .4rem;
    font-size: 2.2rem;
    line-height: 1.3;
}
h1 {
    text-align: center;
    padding-bottom: 0.3em;
    font-size: 2.2em;
    line-height: 1.2;
    margin: 2.4em auto 1.2em;
}
h1:after {
    content: '';
    display: block;
    margin: 0.2em auto 0;
    width: 100px;
    height: 2px;
    border-bottom: 2px solid var(--title-color);
}

h2 {
    margin: 1.6em auto 0.5em;
    padding-left: 10px;
    line-height: 1.4;
    font-size: 1.8em;
    border-left: 9px solid var(--title-color);
    border-bottom: 1px solid var(--title-color);
}
h3 {
    font-size: 1.5rem;
    margin: 1.2em auto 0.5em;
}
h4 {
    font-size: 1.3rem;
}
h5 {
    font-size: 1.2rem;
}
h6 {
    font-size: 1.1rem;
}

p,
blockquote,
ul,
ol,
dl,
table {
    margin: 0.8em 0;
}

li > ol,
li > ul {
    margin: 0 0;
}

hr {
    height: 2px;
    padding: 0;
    margin: 16px 0;
    background-color: #e7e7e7;
    border: 0 none;
    overflow: hidden;
    box-sizing: content-box;
}

body > h2:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0;
}

body > h3:first-child,
body > h4:first-child,
body > h5:first-child,
body > h6:first-child {
    margin-top: 0;
    padding-top: 0;
}

a:first-child h1,
a:first-child h2,
a:first-child h3,
a:first-child h4,
a:first-child h5,
a:first-child h6 {
    margin-top: 0;
    padding-top: 0;
}

h1 p,
h2 p,
h3 p,
h4 p,
h5 p,
h6 p {
    margin-top: 0;
}

li p.first {
    display: inline-block;
}

ul,
ol {
    padding-left: 30px;
}

ul:first-child,
ol:first-child {
    margin-top: 0;
}

ul:last-child,
ol:last-child {
    margin-bottom: 0;
}

/* 引用 */
blockquote {
    /* margin-left: 1rem; */
    border-left: 4px solid var(--purple-light-4);
    padding: 10px 15px;
    color: #777;
    background-color: var(--purple-light-1);
}

/* 表格 */
table {
    padding: 0;
    word-break: initial;
}

table tr {
    border-top: 1px solid #dfe2e5;
    margin: 0;
    padding: 0;
}

/* 表格 背景色 */
table tr:nth-child(2n),
thead {
    background-color: var(--purple-light-1);
}
#write table thead th {
    background-color: var(--purple-light-2);
}

table tr th {
    font-weight: bold;
    border: 1px solid #dfe2e5;
    border-bottom: 0;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr td {
    border: 1px solid #dfe2e5;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr th:first-child,
table tr td:first-child {
    margin-top: 0;
}

table tr th:last-child,
table tr td:last-child {
    margin-bottom: 0;
}

/* 粗体 */
#write strong {
    padding: 0 2px;
    color: var(--purple-1);
}

/* 斜体 */
#write em {
    padding: 0 5px 0 2px;
    /* font-style: normal; */
    color: #42b983;
}

/* inline code */
#write code, tt {
    padding: 2px 4px;
    border-radius: 2px;
    font-family: var(--font-monospace);
    font-size: 0.92rem;
    color: var(--purple-3); 
    background-color: rgba(99, 99, 172, .05);
}

tt {
    margin: 0 2px;
}

#write .md-footnote {
    background-color: #f8f8f8;
    color: var(--purple-3);
}

/* heighlight. */
#write mark {
    background-color: #fbd3ea;
    border-radius: 2px;
    padding: 2px 4px;
    margin: 0 2px;
}

#write del {
    padding: 1px 2px;
}

.md-task-list-item > input {
    margin-left: -1.3em;
}

@media print {
    html {
        font-size: 0.9rem;
    }

    table,
    pre {
        page-break-inside: avoid;
    }

    pre {
        word-wrap: break-word;
    }
}

#write pre.md-meta-block {
    padding: 1rem;
    font-size: 85%;
    line-height: 1.45;
    background-color: #f7f7f7;
    border: 0;
    border-radius: 3px;
    color: #777777;
    margin-top: 0 !important;
}

.mathjax-block > .code-tooltip {
    bottom: .375rem;
}

/* 图片 */
.md-image > .md-meta {
    border-radius: 3px;
    font-family: var(--font-monospace);
    padding: 2px 0 0 4px;
    font-size: 0.9em;
    color: inherit;
}
p .md-image:only-child{
    width: auto;
    text-align: left;
    margin-left: 2rem;
}
.md-tag {
    color: inherit;
}
/* 当 “![shadow-随便写]()”写时，会有阴影 */
.md-image img[alt|='shadow'] {
    /* box-shadow: 0 4px 24px -6px #ddd; */
    box-shadow:var(--purple-light-2) 0px 10px 15px;
}

#write a.md-toc-inner {
    line-height: 1.6;
    white-space: pre-line;
    border-bottom: none;
    font-size: 0.9rem;
}

#typora-quick-open {
    border: 1px solid #ddd;
    background-color: #f8f8f8;
}

#typora-quick-open-item {
    background-color: #FAFAFA;
    border-color: #FEFEFE #e5e5e5 #e5e5e5 #eee;
    border-style: solid;
    border-width: 1px;
}

#md-notification:before {
    top: 10px;
}

header,
.context-menu,
.megamenu-content,
footer {
    font-family: var(--font-sans-serif);
}

.file-node-content:hover .file-node-icon,
.file-node-content:hover .file-node-open-state {
    visibility: visible;
}

.md-lang {
    color: #b4654d;
}

.html-for-mac .context-menu {
    --item-hover-bg-color: #E6F0FE;
}

/* 代码框 */
/* CodeMirror 3024 Day theme */

/* 代码段 背景 */
pre {
    --select-text-bg-color: rgba(223, 197, 223) !important;
    margin: .5em 0;
    padding: 1em 1.4em;
    border-radius: 8px;
    background: #f6f8fa;
    overflow-x: auto;
    box-sizing: border-box;
    font-size: 14px;
}

/* 边框 */
.md-fences {
    border: 1px solid #e7eaed;
    border-radius: 3px;
}

.cm-s-inner {
  padding: .25rem;
  border-radius: .25rem;
}

.cm-s-inner.CodeMirror, .cm-s-inner .CodeMirror-gutters {
  background-color: #f8f8f8 !important;
  color: #3a3432 !important;
  border: none;
}

.cm-s-inner .CodeMirror-gutters {
  color: #6d8a88;
}

.cm-s-inner .CodeMirror-cursor {
  border-left: solid thin #5c5855 !important;
}

.cm-s-inner .CodeMirror-linenumber {
  color: #807d7c;
}

.cm-s-inner .CodeMirror-line::selection, .cm-s-inner .CodeMirror-line::-moz-selection,
.cm-s-inner .CodeMirror-line > span::selection,
.cm-s-inner .CodeMirror-line > span::-moz-selection,
.cm-s-inner .CodeMirror-line > span > span::selection,
.cm-s-inner .CodeMirror-line > span > span::-moz-selection {
  background: var(--purple-light-2);
}

.cm-s-inner span.cm-comment {
  color: #cdab53;
}

.cm-s-inner span.cm-string, .cm-s-inner span.cm-string-2 {
  color: #f2b01d;
}

.cm-s-inner span.cm-number {
  color: #a34e8f;
}

.cm-s-inner span.cm-variable {
  color: #01a252;
}

.cm-s-inner span.cm-variable-2 {
  color: #01a0e4;
}

.cm-s-inner span.cm-def {
  /* color: #e8bbd0; */
  color: #e2287f;
}

.cm-s-inner span.cm-operator {
  color: #ff79c6;
}

.cm-s-inner span.cm-keyword {
  color: #db2d20;
}

.cm-s-inner span.cm-atom {
  color: #a34e8f;
}

.cm-s-inner span.cm-meta {
  color: inherit;
}

.cm-s-inner span.cm-tag {
  color: #db2d20;
}

.cm-s-inner span.cm-attribute {
  color: #01a252;
}

.cm-s-inner span.cm-qualifier {
  color: #388aa3;
}

.cm-s-inner span.cm-property {
  color: #01a252;
}

.cm-s-inner span.cm-builtin {
  color: #388aa3;
}

.cm-s-inner span.cm-variable-3, .cm-s-inner span.cm-type {
  color: #ffb86c;
}

.cm-s-inner span.cm-bracket {
  color: #3a3432;
}

.cm-s-inner span.cm-link {
  color: #a34e8f;
}

.cm-s-inner span.cm-error {
  background: #db2d20;
  color: #5c5855;
}

/* .md-fences.md-focus .cm-s-inner .CodeMirror-activeline-background {
  background: var(--purple-light-2);
} */

.cm-s-inner .CodeMirror-matchingbracket {
  text-decoration: underline;
  color: #a34e8f !important;
}

#fences-auto-suggest .active {
  background: #ddd;
}

#write .code-tooltip {
  bottom: initial;
  top: calc(100% - 1px);
  background: #f7f7f7;
  border: 1px solid #ddd;
  border-top: 0;
}

.auto-suggest-container {
  border-color: #b4b4b4;
}

.auto-suggest-container .autoComplt-hint.active {
  background: #b4b4b4;
  color: inherit;
}

/* task list */
#write .md-task-list-item > input {
  -webkit-appearance: initial;
  display: block;
  position: absolute;
  border: 1px solid #b4b4b4;
  border-radius: .25rem;
  margin-top: .1rem;
  margin-left: -1.8rem;
  height: 1.2rem;
  width: 1.2rem;
  transition: background 0.3s;
}

#write .md-task-list-item > input:focus {
  outline: none;
  box-shadow: none;
}

#write .md-task-list-item > input:hover {
  background: #ddd;
}

#write .md-task-list-item > input[checked]::before {
  content: '';
  position: absolute;
  top: 20%;
  left: 50%;
  height: 60%;
  width: 2px;
  transform: rotate(40deg);
  background: #333;
}

#write .md-task-list-item > input[checked]::after {
  content: '';
  position: absolute;
  top: 46%;
  left: 25%;
  height: 30%;
  width: 2px;
  transform: rotate(-40deg);
  background: #333;
}

#write .md-task-list-item > p {
  transition: color 0.3s, opacity 0.3s;
}

#write .md-task-list-item.task-list-done > p {
  color: #b4b4b4;
  text-decoration: line-through;
}

#write .md-task-list-item.task-list-done > p > .md-emoji {
  opacity: .5;
}

#write .md-task-list-item.task-list-done > p > .md-link > a {
  opacity: .6;
}

/* sidebar and outline */
.pin-outline .outline-active {
  color: var(--active-file-text-color); 
}

.file-list-item {
    border-bottom: 1px solid;
    border-color: var(--purple-light-5);
}

.file-list-item-summary {
    font-weight: 400;
}

.file-list-item.active {
    color: var(--active-file-text-color);
    background-color: var(--purple-light-5);
}

.file-tree-node.active>.file-node-background {
    background-color: var(--purple-light-5);
    font-weight: 700;
} 

.file-tree-node.active>.file-node-content {
    color: var(--active-file-text-color);
    font-weight: 700;
}

.file-node-content {
    color: #5e676d;
}

.sidebar-tabs {
    border-bottom: none;
}
.sidebar-tab.active {
    font-weight: 400;
}

.sidebar-content-content {
    font-size: 0.9rem;
}

img {
    max-width: 100%;
}

body {
    background-color: rgb(237, 237, 237);
}
#content {
    width: 836px;
    padding: 50px;
    background: #fff;
    margin: 0 auto;
}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/purple.css*/</style><style type="text/css">.hljs{display:block;overflow-x:auto;padding:.5em;color:#383a42;background:#fafafa}.hljs-comment,.hljs-quote{color:#a0a1a7;font-style:italic}.hljs-doctag,.hljs-formula,.hljs-keyword{color:#a626a4}.hljs-deletion,.hljs-name,.hljs-section,.hljs-selector-tag,.hljs-subst{color:#e45649}.hljs-literal{color:#0184bb}.hljs-addition,.hljs-attribute,.hljs-meta-string,.hljs-regexp,.hljs-string{color:#50a14f}.hljs-built_in,.hljs-class .hljs-title{color:#c18401}.hljs-attr,.hljs-number,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-pseudo,.hljs-template-variable,.hljs-type,.hljs-variable{color:#986801}.hljs-bullet,.hljs-link,.hljs-meta,.hljs-selector-id,.hljs-symbol,.hljs-title{color:#4078f2}.hljs-emphasis{font-style:italic}.hljs-strong{font-weight:700}.hljs-link{text-decoration:underline}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/atom-one-light.min.css*/</style></head>
<body>
  <div id="content"><h1>07 | 线性回归：如何在离散点中寻找数据规律？</h1><p data-nodeid="6043" class="">经过前面几节课，我们讨论了对问题的形式化定义和对目标函数极值的几种求解方法，以及在大数据多变量环境中对数据计算的方法。</p>
<p data-nodeid="6044">而这一课时，我们就把这些知识用在线性回归上，看一下它们是如何在实际工作中应用的。</p>
<p data-nodeid="6045">假设大漂亮是公司负责增长营销策略的工程师，她利用公司的大数据分析了某件商品的销售情况。她发现这件商品的购买率（购买量除以浏览量）和它的折扣率（折后价除以原价）有着非常强的关系。</p>
<p data-nodeid="7441" class="">因此，她把这件商品最近一周的数据都提取出来，并且以每天一个样本点，尝试分析购买率和折扣率的关系，她的原始数据如下表所示：<br>
<img src="https://s0.lgstatic.com/i/image/M00/6D/A2/Ciqc1F-uZjmAHQy8AADL0NYNwR4921.png" alt="1.png" data-nodeid="7446"><br>
我们可以直观看出，折扣率越低，购买率越高。那么除此之外，我们还能分析出其他信息吗？比如，这里的趋势和关系如何用数学语言描述呢？以及可以如何用来指导补贴的投放方法？这些问题就需要用线性回归的知识来分析了。</p>




<h3 data-nodeid="6049">什么是线性回归？</h3>
<p data-nodeid="6050"><strong data-nodeid="6139">回归（也称作拟合），通常是指利用某个函数，尽可能把数据样本点“串”在一起，用于描述输入变量和输出变量间的变化关系。</strong></p>
<p data-nodeid="6051">在回归中最常用的就是<strong data-nodeid="6145">线性回归</strong>了，这是因为线性回归与人类“越怎样...越怎样...”的思维方式更一致。线性回归的特点是，用来把数据“串”起来的那个函数是线性的。线性回归可分为一元线性回归（ 一个自变量）和多元线性回归（至少两个自变量）。</p>
<p data-nodeid="6052">围绕上面的概念，我们尝试写出线性回归的方程。一个线性函数的通式为 y =<i><strong data-nodeid="6153">k·x</strong></i>+b 或者</p>
<p data-nodeid="6053">y =<i><strong data-nodeid="6169">k</strong></i><sup>T</sup><i><strong data-nodeid="6170">x</strong></i>+b。</p>
<blockquote data-nodeid="6054">
<p data-nodeid="6055">其中，<i><strong data-nodeid="6184">x</strong></i> 是 nx1 维的自变量向量，<i><strong data-nodeid="6185">k</strong></i> 是 nx1 维的权重。y 是输出变量，b 是个常数。如果是一元线性回归，则 n 为 1。</p>
</blockquote>
<p data-nodeid="6056">上面两种表达方法殊途同归，区别仅在于形式。前者是把变量当作了向量，通过向量的点乘得到结果；而后者是把向量视作一个特殊的矩阵，通过矩阵的乘法得到结果。</p>
<p data-nodeid="6057">线性回归的目标是，尽可能把数据样本点“串”在一起。也就是说，要求解出 <i><strong data-nodeid="6194">k</strong></i> 和 b，让这个函数尽可能把数据都拟合起来。</p>
<p data-nodeid="6058">接下来，我们以大漂亮遇到的问题为例，试着用线性回归帮帮她。</p>
<h3 data-nodeid="6059">线性回归的形式化定义</h3>
<p data-nodeid="6060">我们先前总结过解决问题的通用方法，包括两步：首先要进行形式化定义，接着对形式化定义的问题进行最优化求解。</p>
<p data-nodeid="6061">形式化定义，是要用数学语言来描述清楚问题的目标是什么。我们前面分析到，<strong data-nodeid="6203">问题的目标是尽可能把数据样本点“串”在一起</strong>。那么如何用数学语言来描述呢？</p>
<p data-nodeid="6062">在线性回归中，通常用平方误差来衡量拟合的效果。平方误差的定义是，真实值和预测值之差的平方，即 (ŷ-y)<sup>2</sup>。值得一提的是，我们采用 ŷ 来代表真实值，用 y 来代表回归拟合的预测值。</p>
<p data-nodeid="6063">有了这些背景知识后，我们回到大漂亮的问题。大漂亮想用一个线性函数去拟合购买率和折扣率，不妨用 y 表示购买率，x 表示折扣率，那么线性函数的表达式就是 y = kx + b。</p>
<p data-nodeid="6064">此时，大漂亮面对的是一元线性回归问题，要做的事情就是求解出 k 和 b 的值。假设大漂亮已经有了 k 和 b，那么就能根据输入的 x，拟合出 y 的值了，<strong data-nodeid="6215">而线性回归的目标是尽可能让“串”在一起的平方误差最小</strong>。因此，平方误差函数在这里的形式就是：</p>
<p data-nodeid="6065"><img src="https://s0.lgstatic.com/i/image/M00/6D/AE/CgqCHl-uZk2AHa4KAABgsVJP-X4148.png" alt="图片1.png" data-nodeid="6218"></p>
<p data-nodeid="6066">其中求和的 1 到 7，表示的是大漂亮获得的数据集中 7 个样本。公式的含义就是，每个样本的预测值和真实值的平方误差，再求和。大漂亮遇到的问题定性描述是，通过线性回归，让数据尽可能“串”在一起。<strong data-nodeid="6223">其形式化定义，就是找到能让平方误差函数最小的 k 和 b 的值。</strong></p>
<h3 data-nodeid="6067">线性回归的求解方法</h3>
<p data-nodeid="6068">有了形式化定义的问题之后，就是求解问题的最优化过程。根据形式化定义，你会发现，这不就是个求解最值的问题嘛，我们已经学过了很多求解方法了。是的，绝大多数的问题，只要形式化定义清楚之后，就是个求解最值的过程。</p>
<p data-nodeid="6069">对于线性回归而言，我们可以通过求导法来进行计算。不过要注意，此时我们是在向量的环境中求导，这就要用到上一讲的知识了。</p>
<p data-nodeid="6070">我们先将平方误差函数用向量的形式进行表达，则有：</p>
<p data-nodeid="6071"><img src="https://s0.lgstatic.com/i/image/M00/6D/AE/CgqCHl-uZlqAcJC0AACpnmMI6Nk502.png" alt="图片2.png" data-nodeid="6230"></p>
<p data-nodeid="6072">其中，<i><strong data-nodeid="6268">ŷ</strong></i> 表示真实值的向量，<i><strong data-nodeid="6269">y</strong></i> 为拟合的预测值的向量，他们的维度都是 7×1。同时别忘了，拟合函数是个线性函数，每个样本都满足 y<sub>i</sub> = kx<sub>i</sub>+b，可以改写为：<br>
<img src="https://s0.lgstatic.com/i/image/M00/6D/A2/Ciqc1F-uZmWAGjTeAABwJWEc9tU571.png" alt="图片3.png" data-nodeid="6255"><br>
<img src="https://s0.lgstatic.com/i/image/M00/70/8C/CgqCHl-7RPeASXGfAAD5hXSU4Do990.png" alt="WechatIMG970.png" data-nodeid="6259"><br>
则 7 个样本合在一起的预测值的向量表示为 <i><strong data-nodeid="6270">y = Xw</strong></i>。</p>
<p data-nodeid="8377" class="">我们把这些条件都带入平方误差函数中，则有：<br>
<img src="https://s0.lgstatic.com/i/image/M00/70/8A/CgqCHl-7QDCACVOoAACGmQ8IQFw122.png" alt="WechatIMG967.png" data-nodeid="8382"><br>
接下来问题就是，如何求解平方误差函数的最小值。我们利用求导法，则有<br>
<img src="https://s0.lgstatic.com/i/image/M00/6D/AE/CgqCHl-uZpGAVpbZAACVc_zaCHc331.png" alt="图片5.png" data-nodeid="8388"><br>
这样，我们就得到了 <i><strong data-nodeid="8397">w</strong></i> 的值啦。</p>


<h3 data-nodeid="6075">线性回归编程实战</h3>
<p data-nodeid="6076">好了，到这里呢，我们已经掌握了全部线性回归拟合数据的精要。接着，我们尝试用代码来帮助大漂亮进行数据拟合的开发。</p>
<p data-nodeid="6077">说到代码，你可能会感觉很恐怖，难道我要把先前的推导过程也要在代码里面重新开发一遍吗？其实完全不需要！对于代码开发而言，唯一需要用到的仅仅是最后的结论，即 <i><strong data-nodeid="6328">w</strong></i>=(<i><strong data-nodeid="6329">X</strong></i><sup>T</sup><i><strong data-nodeid="6330">X</strong></i>)<sup>-1</sup><em data-nodeid="6332"><strong data-nodeid="6331">x</strong></em><sup>T</sup><i><strong data-nodeid="6333">ŷ</strong></i>。</p>
<p data-nodeid="6078">换句话说，如果你会用 Python 的 NumPy 库，导入数据后，一行命令计算矩阵乘法和求逆运算就可以了。我们给出代码如下：</p>
<pre class="lang-python" data-nodeid="6079"><code data-language="python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">main</span>():</span>
	x = np.array([[<span class="hljs-number">0.80</span>,<span class="hljs-number">1</span>],[<span class="hljs-number">0.85</span>,<span class="hljs-number">1</span>],[<span class="hljs-number">0.89</span>,<span class="hljs-number">1</span>],[<span class="hljs-number">0.87</span>,<span class="hljs-number">1</span>],[<span class="hljs-number">0.82</span>,<span class="hljs-number">1</span>],[<span class="hljs-number">0.74</span>,<span class="hljs-number">1</span>],[<span class="hljs-number">0.77</span>,<span class="hljs-number">1</span>]])
	yhat = np.array([[<span class="hljs-number">0.25</span>],[<span class="hljs-number">0.23</span>],[<span class="hljs-number">0.18</span>],[<span class="hljs-number">0.21</span>],[<span class="hljs-number">0.23</span>],[<span class="hljs-number">0.32</span>],[<span class="hljs-number">0.29</span>]])
	xtx = np.dot(x.T,x)
	xtx_1 = np.linalg.inv(xtx)
	w = xtx_1.dot(x.T).dot(yhat)
	<span class="hljs-keyword">print</span> <span class="hljs-string">'k: '</span> + str(w[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>])
	<span class="hljs-keyword">print</span> <span class="hljs-string">'b: '</span> + str(w[<span class="hljs-number">1</span>][<span class="hljs-number">0</span>])
<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
	main()
</code></pre>
<p data-nodeid="9326" class="">我们对代码进行解读：</p>
<ul data-nodeid="9327">
<li data-nodeid="9328">
<p data-nodeid="9329">第 4 行，导入数据得到矩阵 <i><strong data-nodeid="9350">X</strong></i>。为了还能求解出 b，我们需要对每个 x<sub>i</sub> 补充一个“1”；</p>
</li>
<li data-nodeid="9330">
<p data-nodeid="9331">第 5 行，导入数据得到真实值向量 <i><strong data-nodeid="9358">ŷ</strong></i>。接下来，按照公式进行求解就可以了；</p>
</li>
<li data-nodeid="9332">
<p data-nodeid="9333">第 6 行，计算了 <i><strong data-nodeid="9374">X</strong></i><sup>T</sup><i><strong data-nodeid="9375">X</strong></i> 的结果；</p>
</li>
<li data-nodeid="9334">
<p data-nodeid="9335">第 7 行，对其求逆，得到了（<i><strong data-nodeid="9395">X</strong></i><sup>T</sup><i><strong data-nodeid="9396">X</strong></i>）<sup>-1</sup>；</p>
</li>
<li data-nodeid="9336">
<p data-nodeid="9337">第 8 行，再来对 <i><strong data-nodeid="9417">X</strong></i><sup>T</sup> 和 <strong data-nodeid="9418">ŷ</strong> 计算矩阵乘法，得到最终的 <i><strong data-nodeid="9419">w</strong></i>。</p>
</li>
</ul>


<p data-nodeid="10818" class="">最后，第 9 和 10 行打印结果，程序执行后的结果如下图：<br>
<img src="https://s0.lgstatic.com/i/image/M00/6D/AE/CgqCHl-uZqyAa1uCAAK7kLHPl4Q127.png" alt="图片6.png" data-nodeid="10823"><br>
因此，我们帮助大漂亮进行开发后，得到的结果为 y = kx + b = -0.86x + 0.95</p>




<p data-nodeid="6095">我们用 Excel 的散点拟合功能，来校验一下我们的结果。Excel 的结果如下图，这与我们的结果完全一致。</p>
<p data-nodeid="6096"><img src="https://s0.lgstatic.com/i/image/M00/6D/A2/Ciqc1F-uZraAZ6fpAAFb_jSg-GA178.png" alt="图片7.png" data-nodeid="6425"></p>
<h3 data-nodeid="6097">思维发散</h3>
<p data-nodeid="6098">通过大漂亮遇到的难题，我们可以尝试着去发散一下，看看能得到哪些启发。</p>
<ul data-nodeid="6099">
<li data-nodeid="6100">
<p data-nodeid="6101">普通程序员会写代码，一流的程序员懂数学。</p>
</li>
</ul>
<p data-nodeid="6102">如果你只是个普通的程序员，光看我们给的 13 行代码，想必很难知道最终打印的结果到底代表什么含义。只知道代码进行了一些矩阵运算，然后得到了一个向量，最后打印了两个变量的值。可是这两个值到底代表了什么含义，却一无所知。</p>
<p data-nodeid="6103">这是因为，最终的结果算式的背后，有着非常复杂的数学原理。这些计算过程的证明和推导，是不需要在代码中被重复计算的。</p>
<ul data-nodeid="6104">
<li data-nodeid="6105">
<p data-nodeid="6106">既然 Excel 这么强大，我能否不学数学，而用 Excel 来打天下呢？</p>
</li>
</ul>
<p data-nodeid="6107">面对简单问题时，的确可以；而面对复杂问题时，则不行。例如，一元线性回归，我们可以通过散点图和 Excel 的趋势线功能拟合；而多元线性回归，则只能通过以数学为基石的代码来完成。</p>
<p data-nodeid="6108">我们举个例子，假设大漂亮经过分析后又发现，购买率还跟商品前一天的好评率有关。那么数据集就变成了下面的表格：</p>
<p data-nodeid="6109"><img src="https://s0.lgstatic.com/i/image/M00/6D/AE/CgqCHl-uZsGAUYmGAAEXObJND8k452.png" alt="图片8.png" data-nodeid="6436"></p>
<p data-nodeid="6110">现在，大漂亮想用线性回归来描述折扣率、好评率共同影响购买率的关系，并且比较两个自变量之间影响程度的大小。我们还可以继续用上面的代码，只不过导入的数据进行调整就可以了：</p>
<pre class="lang-python" data-nodeid="6111"><code data-language="python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">main</span>():</span>
	x = np.array([[<span class="hljs-number">0.80</span>,<span class="hljs-number">0.72</span>,<span class="hljs-number">1</span>],[<span class="hljs-number">0.85</span>,<span class="hljs-number">0.81</span>,<span class="hljs-number">1</span>],[<span class="hljs-number">0.89</span>,<span class="hljs-number">0.75</span>,<span class="hljs-number">1</span>],[<span class="hljs-number">0.87</span>,<span class="hljs-number">0.82</span>,<span class="hljs-number">1</span>],[<span class="hljs-number">0.82</span>,<span class="hljs-number">0.74</span>,<span class="hljs-number">1</span>],[<span class="hljs-number">0.74</span>,<span class="hljs-number">0.85</span>,<span class="hljs-number">1</span>],[<span class="hljs-number">0.77</span>,<span class="hljs-number">0.83</span>,<span class="hljs-number">1</span>]])
	yhat = np.array([[<span class="hljs-number">0.25</span>],[<span class="hljs-number">0.23</span>],[<span class="hljs-number">0.18</span>],[<span class="hljs-number">0.21</span>],[<span class="hljs-number">0.23</span>],[<span class="hljs-number">0.32</span>],[<span class="hljs-number">0.29</span>]])
	xtx = np.dot(x.T,x)
	xtx_1 = np.linalg.inv(xtx)
	w = xtx_1.dot(x.T).dot(yhat)
	<span class="hljs-keyword">print</span> <span class="hljs-string">'k1: '</span> + str(w[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>])
	<span class="hljs-keyword">print</span> <span class="hljs-string">'k2: '</span> + str(w[<span class="hljs-number">1</span>][<span class="hljs-number">0</span>])
	<span class="hljs-keyword">print</span> <span class="hljs-string">'b: '</span> + str(w[<span class="hljs-number">2</span>][<span class="hljs-number">0</span>])
<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
	main()
</code></pre>
<p data-nodeid="12700" class="">执行后，程序的运行结果为：<br>
<img src="https://s0.lgstatic.com/i/image/M00/6D/A2/Ciqc1F-uZsqATnvQAAN6iO5Lo_E494.png" alt="图片9.png" data-nodeid="12705"><br>
可见 y = -0.79 x<sub>1</sub>+ 0.2x<sub>2</sub> + 0.73。由于 0.79 大于 0.2，因此 x<sub>1</sub> 的折扣率对 y 的影响更大。</p>




<p data-nodeid="6115">根据这个例子可以发现，用代码化的方法来进行线性回归，一方面可以减少工作量，另一方面对复杂问题的适应性也会更好。</p>
<h3 data-nodeid="6116">小结</h3>
<p data-nodeid="6117">我们对这个课时的内容进行总结。在面对实际的、陌生的复杂问题时，一个最基础的解决方案就是形式化定义加最优化求解，这个套路能帮助你解决绝大多数的工作或生活的问题。</p>
<p data-nodeid="6118">在这一讲中，我们以线性回归去拟合散点为例，先对回归进行形式化定义。我们讲述了回归的定性目标是用个线性函数去把散点“串”起来；而定量的形式化目标，则是平方误差最小化。</p>
<p data-nodeid="6119">我们利用向量的方式把问题的形式化定义方程写出来后，就需要进行最优化求解了。在这里，我们还不需要用梯度下降法那么复杂的算法，用求导法就能求出结果了。最终会发现，拟合的结果 就是 <i><strong data-nodeid="6495">w</strong></i>=(<i><strong data-nodeid="6496">X</strong></i><sup>T</sup><i><strong data-nodeid="6497">X</strong></i>)<sup>-1</sup><em data-nodeid="6499"><strong data-nodeid="6498">x</strong></em><sup>T</sup><i><strong data-nodeid="6500">ŷ</strong></i> 这么一个简单的表达式。利用 NumPy 库，我们自主地编写了线性回归的代码，并且在一元回归和多元回归分别进行应用。</p>
<p data-nodeid="6120">最后，我们留两个课后作业吧：</p>
<ul data-nodeid="6121">
<li data-nodeid="6122">
<p data-nodeid="6123">自己去造一些数据，分别利用 Excel 和自己写的代码，亲自试一下线性回归的拟合；</p>
</li>
<li data-nodeid="6124">
<p data-nodeid="6125">如果我们不采用求导法，而采用梯度下降法，试着写一下代码吧。</p>
</li>
</ul>
<p data-nodeid="13648" class="te-preview-highlight">下一课时，我将向你讲解“08 | 加乘法则：如何计算复杂事件发生的概率？”别忘来听课～</p></div>

</body></html>
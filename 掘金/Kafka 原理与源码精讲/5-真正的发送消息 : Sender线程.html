<!DOCTYPE html><html lang="en"><head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>第 01 讲：设计一份吸引面试官的简历</title>
<style type="text/css">
:root {
    --control-text-color: #777;
    --select-text-bg-color: rgba(223, 197, 223);  /*#7e66992e;*/
    
    /* side bar */
    --side-bar-bg-color: rgb(255, 255, 255);
    --active-file-text-color: #8163bd;
    --active-file-bg-color: #E9E4F0;
    --item-hover-bg-color: #E9E4F0;
    --active-file-border-color: #8163bd;

    --title-color: #6c549c;
    --font-sans-serif: 'Ubuntu', 'Source Sans Pro', sans-serif !important;
    --font-monospace: 'Fira Code', 'Roboto Mono', monospace !important;
    --purple-1: #8163bd;
    --purple-2: #79589F;
    --purple-3: #fd5eb8;
    --purple-light-1: rgba(99, 99, 172, .05);
    --purple-light-2: rgba(99, 99, 172, .1);
    --purple-light-3: rgba(99, 99, 172, .2);
    --purple-light-4: rgba(129, 99, 189, .3);
    --purple-light-5: #E9E4F0;
    --purple-light-6: rgba(129, 99, 189, .8);
}

/* html {
    font-size: 16px;
} */

body {
    font-family: var(--font-sans-serif);
    color: #34495e;
    -webkit-font-smoothing: antialiased;
    line-height: 1.6rem;
    letter-spacing: 0;
    margin: 0;
    overflow-x: hidden;
}

/* 页边距 和 页面大小 */
#write {
    padding-left: 6ch;
    padding-right: 6ch;
    margin: 0 auto;
}

#write p {
    line-height: 1.6rem;
    word-spacing: .05rem;
}

#write ol li {
    padding-left: 0.5rem;
}

#write > ul:first-child,
#write > ol:first-child {
    margin-top: 30px;
}

body > *:first-child {
    margin-top: 0 !important;
}

body > *:last-child {
    margin-bottom: 0 !important;
}

a {
    color: var(--purple-1);
    padding: 0 2px;
    text-decoration: none;
}
.md-content {
    color: var(--purple-light-6);
}
#write a {
    border-bottom: 1px solid var(--purple-1);
    color: var(--purple-1);
    text-decoration: none;
}

h1,
h2,
h3,
h4,
h5,
h6 {
    position: relative;
    margin-top: 1rem;
    margin-bottom: 0.5rem;
    /* font-weight: bold; */
    font-weight: 500 !important;
    line-height: 1.4;
    cursor: text;
    color: var(--title-color);
    font-family: var(--font-sans-serif);
}

h1:hover a.anchor,
h2:hover a.anchor,
h3:hover a.anchor,
h4:hover a.anchor,
h5:hover a.anchor,
h6:hover a.anchor {
    text-decoration: none;
}

h1 tt,
h1 code {
    font-size: inherit !important;
}
h2 tt,
h2 code {
    font-size: inherit !important;
}
h3 tt,
h3 code {
    font-size: inherit !important;
}
h4 tt,
h4 code {
    font-size: inherit !important;
}
h5 tt,
h5 code {
    font-size: inherit !important;
}
h6 tt,
h6 code {
    font-size: inherit !important;
}


h1 {
    padding-bottom: .4rem;
    font-size: 2.2rem;
    line-height: 1.3;
}
h1 {
    text-align: center;
    padding-bottom: 0.3em;
    font-size: 2.2em;
    line-height: 1.2;
    margin: 2.4em auto 1.2em;
}
h1:after {
    content: '';
    display: block;
    margin: 0.2em auto 0;
    width: 100px;
    height: 2px;
    border-bottom: 2px solid var(--title-color);
}

h2 {
    margin: 1.6em auto 0.5em;
    padding-left: 10px;
    line-height: 1.4;
    font-size: 1.8em;
    border-left: 9px solid var(--title-color);
    border-bottom: 1px solid var(--title-color);
}
h3 {
    font-size: 1.5rem;
    margin: 1.2em auto 0.5em;
}
h4 {
    font-size: 1.3rem;
}
h5 {
    font-size: 1.2rem;
}
h6 {
    font-size: 1.1rem;
}

p,
blockquote,
ul,
ol,
dl,
table {
    margin: 0.8em 0;
}

li > ol,
li > ul {
    margin: 0 0;
}

hr {
    height: 2px;
    padding: 0;
    margin: 16px 0;
    background-color: #e7e7e7;
    border: 0 none;
    overflow: hidden;
    box-sizing: content-box;
}

body > h2:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0;
}

body > h3:first-child,
body > h4:first-child,
body > h5:first-child,
body > h6:first-child {
    margin-top: 0;
    padding-top: 0;
}

a:first-child h1,
a:first-child h2,
a:first-child h3,
a:first-child h4,
a:first-child h5,
a:first-child h6 {
    margin-top: 0;
    padding-top: 0;
}

h1 p,
h2 p,
h3 p,
h4 p,
h5 p,
h6 p {
    margin-top: 0;
}

li p.first {
    display: inline-block;
}

ul,
ol {
    padding-left: 30px;
}

ul:first-child,
ol:first-child {
    margin-top: 0;
}

ul:last-child,
ol:last-child {
    margin-bottom: 0;
}

/* 引用 */
blockquote {
    /* margin-left: 1rem; */
    border-left: 4px solid var(--purple-light-4);
    padding: 10px 15px;
    color: #777;
    background-color: var(--purple-light-1);
}

/* 表格 */
table {
    padding: 0;
    word-break: initial;
}

table tr {
    border-top: 1px solid #dfe2e5;
    margin: 0;
    padding: 0;
}

/* 表格 背景色 */
table tr:nth-child(2n),
thead {
    background-color: var(--purple-light-1);
}
#write table thead th {
    background-color: var(--purple-light-2);
}

table tr th {
    font-weight: bold;
    border: 1px solid #dfe2e5;
    border-bottom: 0;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr td {
    border: 1px solid #dfe2e5;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr th:first-child,
table tr td:first-child {
    margin-top: 0;
}

table tr th:last-child,
table tr td:last-child {
    margin-bottom: 0;
}

/* 粗体 */
#write strong {
    padding: 0 2px;
    color: var(--purple-1);
}

/* 斜体 */
#write em {
    padding: 0 5px 0 2px;
    /* font-style: normal; */
    color: #42b983;
}

/* inline code */
#write code, tt {
    padding: 2px 4px;
    border-radius: 2px;
    font-family: var(--font-monospace);
    font-size: 0.92rem;
    color: var(--purple-3); 
    background-color: rgba(99, 99, 172, .05);
}

tt {
    margin: 0 2px;
}

#write .md-footnote {
    background-color: #f8f8f8;
    color: var(--purple-3);
}

/* heighlight. */
#write mark {
    background-color: #fbd3ea;
    border-radius: 2px;
    padding: 2px 4px;
    margin: 0 2px;
}

#write del {
    padding: 1px 2px;
}

.md-task-list-item > input {
    margin-left: -1.3em;
}

@media print {
    html {
        font-size: 0.9rem;
    }

    table,
    pre {
        page-break-inside: avoid;
    }

    pre {
        word-wrap: break-word;
    }
}

#write pre.md-meta-block {
    padding: 1rem;
    font-size: 85%;
    line-height: 1.45;
    background-color: #f7f7f7;
    border: 0;
    border-radius: 3px;
    color: #777777;
    margin-top: 0 !important;
}

.mathjax-block > .code-tooltip {
    bottom: .375rem;
}

/* 图片 */
.md-image > .md-meta {
    border-radius: 3px;
    font-family: var(--font-monospace);
    padding: 2px 0 0 4px;
    font-size: 0.9em;
    color: inherit;
}
p .md-image:only-child{
    width: auto;
    text-align: left;
    margin-left: 2rem;
}
.md-tag {
    color: inherit;
}
/* 当 “![shadow-随便写]()”写时，会有阴影 */
.md-image img[alt|='shadow'] {
    /* box-shadow: 0 4px 24px -6px #ddd; */
    box-shadow:var(--purple-light-2) 0px 10px 15px;
}

#write a.md-toc-inner {
    line-height: 1.6;
    white-space: pre-line;
    border-bottom: none;
    font-size: 0.9rem;
}

#typora-quick-open {
    border: 1px solid #ddd;
    background-color: #f8f8f8;
}

#typora-quick-open-item {
    background-color: #FAFAFA;
    border-color: #FEFEFE #e5e5e5 #e5e5e5 #eee;
    border-style: solid;
    border-width: 1px;
}

#md-notification:before {
    top: 10px;
}

header,
.context-menu,
.megamenu-content,
footer {
    font-family: var(--font-sans-serif);
}

.file-node-content:hover .file-node-icon,
.file-node-content:hover .file-node-open-state {
    visibility: visible;
}

.md-lang {
    color: #b4654d;
}

.html-for-mac .context-menu {
    --item-hover-bg-color: #E6F0FE;
}

/* 代码框 */
/* CodeMirror 3024 Day theme */

/* 代码段 背景 */
pre {
    --select-text-bg-color: rgba(223, 197, 223) !important;
    margin: .5em 0;
    padding: 1em 1.4em;
    border-radius: 8px;
    background: #f6f8fa;
    overflow-x: auto;
    box-sizing: border-box;
    font-size: 14px;
}

/* 边框 */
.md-fences {
    border: 1px solid #e7eaed;
    border-radius: 3px;
}

.cm-s-inner {
  padding: .25rem;
  border-radius: .25rem;
}

.cm-s-inner.CodeMirror, .cm-s-inner .CodeMirror-gutters {
  background-color: #f8f8f8 !important;
  color: #3a3432 !important;
  border: none;
}

.cm-s-inner .CodeMirror-gutters {
  color: #6d8a88;
}

.cm-s-inner .CodeMirror-cursor {
  border-left: solid thin #5c5855 !important;
}

.cm-s-inner .CodeMirror-linenumber {
  color: #807d7c;
}

.cm-s-inner .CodeMirror-line::selection, .cm-s-inner .CodeMirror-line::-moz-selection,
.cm-s-inner .CodeMirror-line > span::selection,
.cm-s-inner .CodeMirror-line > span::-moz-selection,
.cm-s-inner .CodeMirror-line > span > span::selection,
.cm-s-inner .CodeMirror-line > span > span::-moz-selection {
  background: var(--purple-light-2);
}

.cm-s-inner span.cm-comment {
  color: #cdab53;
}

.cm-s-inner span.cm-string, .cm-s-inner span.cm-string-2 {
  color: #f2b01d;
}

.cm-s-inner span.cm-number {
  color: #a34e8f;
}

.cm-s-inner span.cm-variable {
  color: #01a252;
}

.cm-s-inner span.cm-variable-2 {
  color: #01a0e4;
}

.cm-s-inner span.cm-def {
  /* color: #e8bbd0; */
  color: #e2287f;
}

.cm-s-inner span.cm-operator {
  color: #ff79c6;
}

.cm-s-inner span.cm-keyword {
  color: #db2d20;
}

.cm-s-inner span.cm-atom {
  color: #a34e8f;
}

.cm-s-inner span.cm-meta {
  color: inherit;
}

.cm-s-inner span.cm-tag {
  color: #db2d20;
}

.cm-s-inner span.cm-attribute {
  color: #01a252;
}

.cm-s-inner span.cm-qualifier {
  color: #388aa3;
}

.cm-s-inner span.cm-property {
  color: #01a252;
}

.cm-s-inner span.cm-builtin {
  color: #388aa3;
}

.cm-s-inner span.cm-variable-3, .cm-s-inner span.cm-type {
  color: #ffb86c;
}

.cm-s-inner span.cm-bracket {
  color: #3a3432;
}

.cm-s-inner span.cm-link {
  color: #a34e8f;
}

.cm-s-inner span.cm-error {
  background: #db2d20;
  color: #5c5855;
}

/* .md-fences.md-focus .cm-s-inner .CodeMirror-activeline-background {
  background: var(--purple-light-2);
} */

.cm-s-inner .CodeMirror-matchingbracket {
  text-decoration: underline;
  color: #a34e8f !important;
}

#fences-auto-suggest .active {
  background: #ddd;
}

#write .code-tooltip {
  bottom: initial;
  top: calc(100% - 1px);
  background: #f7f7f7;
  border: 1px solid #ddd;
  border-top: 0;
}

.auto-suggest-container {
  border-color: #b4b4b4;
}

.auto-suggest-container .autoComplt-hint.active {
  background: #b4b4b4;
  color: inherit;
}

/* task list */
#write .md-task-list-item > input {
  -webkit-appearance: initial;
  display: block;
  position: absolute;
  border: 1px solid #b4b4b4;
  border-radius: .25rem;
  margin-top: .1rem;
  margin-left: -1.8rem;
  height: 1.2rem;
  width: 1.2rem;
  transition: background 0.3s;
}

#write .md-task-list-item > input:focus {
  outline: none;
  box-shadow: none;
}

#write .md-task-list-item > input:hover {
  background: #ddd;
}

#write .md-task-list-item > input[checked]::before {
  content: '';
  position: absolute;
  top: 20%;
  left: 50%;
  height: 60%;
  width: 2px;
  transform: rotate(40deg);
  background: #333;
}

#write .md-task-list-item > input[checked]::after {
  content: '';
  position: absolute;
  top: 46%;
  left: 25%;
  height: 30%;
  width: 2px;
  transform: rotate(-40deg);
  background: #333;
}

#write .md-task-list-item > p {
  transition: color 0.3s, opacity 0.3s;
}

#write .md-task-list-item.task-list-done > p {
  color: #b4b4b4;
  text-decoration: line-through;
}

#write .md-task-list-item.task-list-done > p > .md-emoji {
  opacity: .5;
}

#write .md-task-list-item.task-list-done > p > .md-link > a {
  opacity: .6;
}

/* sidebar and outline */
.pin-outline .outline-active {
  color: var(--active-file-text-color); 
}

.file-list-item {
    border-bottom: 1px solid;
    border-color: var(--purple-light-5);
}

.file-list-item-summary {
    font-weight: 400;
}

.file-list-item.active {
    color: var(--active-file-text-color);
    background-color: var(--purple-light-5);
}

.file-tree-node.active>.file-node-background {
    background-color: var(--purple-light-5);
    font-weight: 700;
} 

.file-tree-node.active>.file-node-content {
    color: var(--active-file-text-color);
    font-weight: 700;
}

.file-node-content {
    color: #5e676d;
}

.sidebar-tabs {
    border-bottom: none;
}
.sidebar-tab.active {
    font-weight: 400;
}

.sidebar-content-content {
    font-size: 0.9rem;
}

img {
    max-width: 100%;
}

body {
    background-color: rgb(237, 237, 237);
}
#content {
    width: 836px;
    padding: 50px;
    background: #fff;
    margin: 0 auto;
}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/purple.css*/</style><style type="text/css">.hljs{display:block;overflow-x:auto;padding:.5em;color:#383a42;background:#fafafa}.hljs-comment,.hljs-quote{color:#a0a1a7;font-style:italic}.hljs-doctag,.hljs-formula,.hljs-keyword{color:#a626a4}.hljs-deletion,.hljs-name,.hljs-section,.hljs-selector-tag,.hljs-subst{color:#e45649}.hljs-literal{color:#0184bb}.hljs-addition,.hljs-attribute,.hljs-meta-string,.hljs-regexp,.hljs-string{color:#50a14f}.hljs-built_in,.hljs-class .hljs-title{color:#c18401}.hljs-attr,.hljs-number,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-pseudo,.hljs-template-variable,.hljs-type,.hljs-variable{color:#986801}.hljs-bullet,.hljs-link,.hljs-meta,.hljs-selector-id,.hljs-symbol,.hljs-title{color:#4078f2}.hljs-emphasis{font-style:italic}.hljs-strong{font-weight:700}.hljs-link{text-decoration:underline}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/atom-one-light.min.css*/</style></head>
<body>
<div id="content"><h1>真正的发送消息 : Sender线程</h1>
<blockquote>
<p>这节课我提供了视频讲解，在源码讲解的基础上增加了原理解析和架构学习的部分，对应的视频地址如下
<a href="https://www.bilibili.com/video/BV1dF411T7kt" target="_blank" rel="nofollow noopener noreferrer">https://www.bilibili.com/video/BV1dF411T7kt</a></p>
</blockquote>
<p>上节课我们分析了生产端用于批量发送消息的暂存类RecordAccumulator，类RecordAccumulator并没有真正的网络IO，<code>真正的网络IO是由Sender类完成的</code>。</p>
<p>Sender类是我们学习生产者相关核心类的最后一个，学完它我们就完成了生产者相关类的最后一块“拼图”，这里我会把消息生产的整体流程以一张流程图的形式展示给你，你可以初步了解一下Sender类的基本功能以及发送消息的处理流程，同时还可以和前面几节课的内容串起来加深理解。</p>
<p>首先，我们还是用一个<strong>思维导图</strong>来概括下今天要讲解的内容：</p>
<p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/31de43fcd2e14a3fa410e0dc5645cb10~tplv-k3u1fbpfcp-watermark.image?" alt="07ED7272-6FFA-424A-A1F8-88E7DA009B69.png"></p>
<h2>流程讲解</h2>
<p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/85c81fd8cefa457eb15c59295b5664d4~tplv-k3u1fbpfcp-watermark.image?" alt="2B179866-BC5C-4B54-80AE-9337ED5C1996.png"></p>
<p>我简单解释一下，Sender的处理流程分两大部分：<strong>发送请求</strong>和<strong>接收响应</strong>。</p>
<h3>发送请求</h3>
<p>发送请求分为两步。</p>
<p>第一步是<code>消息预发送</code>，Sender会从RecordAccumulator拉取要发送的消息集合，封装客户端请求ClientRequest，把ClientRequest类对象发送给NetworkClient。NetworkClient主要有两个工作，首先会根据收到的ClientRequest类对象构造InFlightRequest类对象，InFlightRequest类对象被视为已经发送但响应还没回来的请求。同时根据收到的ClientRequest类对象构造NetworkSend类对象，并放入到KafkaChannel的缓存里，这时消息预发送结束。</p>
<p>下一步是<code>真正的网络发送</code>，Sender会调用Selector的poll()方法把请求真正发送到broker节点。</p>
<h3>接收响应</h3>
<p>接下来，Selector会收到broker的响应，Sender根据响应会找到对应的请求，然后调用ProducerBatch内的回调方法完成整个发送响应的流程。</p>
<p>了解完这整个流程之后，接下来我们进入源码讲解的环节。</p>
<h2>源码讲解</h2>
<p>Sender类是一个线程类，主线程创建并被标识为后台线程。下面我会为你详细讲解其相关的重要字段和方法。</p>
<h3><strong>字段</strong></h3>
<p>下面是类Sender的重要字段的源码：</p>
<pre><code>public class Sender implements Runnable {          
  private final KafkaClient client;
                                         //管理网络连接，操作网络读写       
  private final RecordAccumulator accumulator;//消息积聚器       
  private final ProducerMetadata metadata;//生产者的元数据       
  private final boolean guaranteeMessageOrder;//是否保证消息在服务端的顺序性       
  private final int maxRequestSize;//向服务端生产消息时，最大请求字节数。       
  private final short acks;//producer的消息发送确认机制       
  private final int retries;//发送失败后的重试次数。默认是0次       
  private volatile boolean running;//Sender线程是否还在运行中       
  private final int requestTimeoutMs;//等待服务端响应的最大时间。默认30s       
  private final long retryBackoffMs;//失败重试退避时间       
  private final ApiVersions apiVersions;//所有node支持的api版本。       
  private final Map&#x3C;TopicPartition, List&#x3C;ProducerBatch>> inFlightBatches;//key为分区，value是List&#x3C;ProducerBatch>的集合。  
</code></pre>
<p>其重要字段的含义和要点可总结为如下。</p>
<ul>
<li><code>client</code>：KafkaClient类型，是一个接口，Sender具体用的是KafkaClient接口的实现类NetworkClient。这个字段为Sender提供了网络连接管理和网络读写操作的功能。</li>
<li><code>accumulator</code>：RecordAccumulator类型。即上节课我们讲的RecordAccumulator类的对象。Sender类用它获取待发送的node和待发送的消息等功能。</li>
<li><code>metadata</code>：ProducerMetadata类型，MetaData接口的实现类。生产者元数据。发送消息时要知道分区leader在哪些节点，以及节点的地址、主题分区的情况等。MetaData接口对应的还有消费者元数据类，后面我们讲到消费者部分的时候会详细讲解。</li>
<li><code>guaranteeMessageOrder</code>：bool类型。是否保证消息在服务端的顺序性。</li>
<li><code>maxRequestSize</code>：int类型。请求的最大字节数，默认值是1M。该设置将限制生产者在单个请求中发送的记录批数，以避免发送大量请求。</li>
<li><code>acks</code>：short类型。producer的消息发送确认机制。ack有3个可选值，分别是1、0 和 -1。默认值是 -1。这里我也简单介绍下这3个值的含义：1）ack=1，producer只要收到一个副本成功写入的通知就认为推送消息成功了。这个副本必须是leader副本，只有leader副本成功写入了，producer才会认为消息发送成功。2）ack=0，producer发送了就任务发送成功，不管是否发送成功。3）ack=-1，producer只有收到分区内所有副本成功写入的通知才认为推送消息成功了。</li>
<li><code>retries</code>：int类型。生产者发送失败后的重试次数。默认是0次。</li>
<li><code>running</code>：bool类型。Sender线程是否还在运行中。</li>
<li><code>requestTimeoutMs</code>：int类型。默认值30,000，即30秒。生产者发送请求后等待服务端响应的最大时间。过了最大响应时间如果配置了重试，生产者会再次发送这个请求。重试用完还在这个时间内返回响应则认为是请求失败。</li>
<li><code>retryBackoffMs</code>：long类型。默认是100。生产者发送请求失败后可能会引起重新发送失败的请求，这个参数的目的是防止重发过快造成服务端压力过大。</li>
<li><code>apiVersions</code>：ApiVersions类的对象，内部保存了每个node支持的api版本。</li>
<li><code>inFlightBatches</code>：发送中请求的Map集合。分区是Key，<code>List&#x3C;ProducerBatch></code>是value。</li>
</ul>
<h3><strong>方法</strong></h3>
<p>Sender类的相关方法也有不少，下面我们一一介绍和说明。</p>
<p><strong>runOnce()</strong></p>
<pre><code>void runOnce() {     ......忽略       long currentTimeMs = time.milliseconds();     //1.发送消息到KafkaChanel缓存     long pollTimeout = sendProducerData(currentTimeMs);     //2.发送消息到网络     client.poll(pollTimeout, currentTimeMs); } 
</code></pre>
<p>runOnce()被Sender线程run()方法调用，而且在字段running为true的情况下，run()方法会一直轮询调用runOnce()。</p>
<p>这个方法很简单，首先获取当前时间戳，然后调用sendProducerData()方法发送消息，但这里的发送不是真正的发送，只是把消息作为缓存保存在NetworkClient的send字段里。最后再调用NetworkClient的poll()方法读取send字段内容实现真正的网络发送。</p>
<p><strong>sendProducerData(long now)</strong></p>
<p>这个方法主要是在发送前对要发送的消息进行收集、过滤，然后调用真正的消息发送方法，最后返回poll()方法的超时时间。现在看一下源码：</p>
<pre><code>//消息发送到暂存类中，并返回poll超时时间。 
// 因为send和poll在一个线程中，poll的 
// 超时时间过长可能会造成不能及时send消息 
private long sendProducerData(long now) {     
//1.获取元数据     
Cluster cluster = metadata.fetch();     
//2.请求已经准备好的节点     
RecordAccumulator.ReadyCheckResult result = this.accumulator.ready(cluster, now);       
//3.如果任何leader分区不存在，就要求更新元数据     
  if (!result.unknownLeaderTopics.isEmpty()) {         
    for (String topic : result.unknownLeaderTopics)             
      this.metadata.add(topic, now);          
    log.debug("Requesting metadata update due to unknown leader topics from the batched records: {}",             
              result.unknownLeaderTopics);         
    this.metadata.requestUpdate();     }       
  // remove any nodes we aren't ready to send to     
  //4.在result返回的node集合的基础上再检查客户端和node连接是否正常。     
  Iterator&#x3C;Node> iter = result.readyNodes.iterator();     
  long notReadyTimeout = Long.MAX_VALUE;     
  while (iter.hasNext()) {         
    Node node = iter.next();         
                          //检查node连接是否可用，并且是否可用往这个节点发送数据         
    if (!this.client.ready(node, now)) {             
      iter.remove();             
      notReadyTimeout = Math.min(notReadyTimeout, this.client.pollDelayMs(node, now));         
    }     
  }      
  // create produce requests    
  //5.获取要发送的请求集合     
  Map&#x3C;Integer, List&#x3C;ProducerBatch>> batches = this.accumulator.drain(cluster, result.readyNodes, this.maxRequestSize, now);     
  addToInflightBatches(batches);    
  if (guaranteeMessageOrder) {         
    // Mute all the partitions drained         
    for (List&#x3C;ProducerBatch> batchList : batches.values()) {             
      for (ProducerBatch batch : batchList)                 this.accumulator.mutePartition(batch.topicPartition);         
    }    
  }      
  accumulator.resetNextBatchExpiryTime();     
  //6.收集过期的batch     
  //Sender自定义inflightBatches集合里过期的batch     List&#x3C;ProducerBatch> expiredInflightBatches = getExpiredInflightBatches(now);     
  //accumulator定义的batches集合里过期的batch    
  List&#x3C;ProducerBatch> expiredBatches = this.accumulator.expiredBatches(now);     expiredBatches.addAll(expiredInflightBatches);     
  //7.处理过期batch     
  if (!expiredBatches.isEmpty())         
  log.trace("Expired {} batches in accumulator", expiredBatches.size());     
  for (ProducerBatch expiredBatch : expiredBatches) {         
  String errorMessage = "Expiring " + expiredBatch.recordCount + " record(s) for " + expiredBatch.topicPartition             + ":" + (now - expiredBatch.createdMs) + " ms has passed since batch creation";        
  failBatch(expiredBatch, -1, NO_TIMESTAMP, new TimeoutException(errorMessage), false);         
if (transactionManager != null &#x26;&#x26; expiredBatch.inRetry()) {             
  transactionManager.markSequenceUnresolved(expiredBatch);        
}   
}     
  sensors.updateProduceRequestMetrics(batches);     
  long pollTimeout = Math.min(result.nextReadyCheckDelayMs, notReadyTimeout);     
  pollTimeout = Math.min(pollTimeout, this.accumulator.nextExpiryTimeMs() - now);     
  pollTimeout = Math.max(pollTimeout, 0);    
  if (!result.readyNodes.isEmpty()) {        
    log.trace("Nodes with data ready to send: {}", result.readyNodes);         
    pollTimeout = 0;     }     
  //8.发送消息     
  sendProduceRequests(batches, now);     
  return pollTimeout; } 
</code></pre>
<p>我把方法执行的步骤给你讲解一下。</p>
<ol>
<li>获取元数据。元数据根据更新机制会近实时地保证数据的准确性。</li>
<li>调用accumulator的ready()方法，这个方法会用发送记录对应的节点和元数据作比较，方法返回包括两个重要的集合，包括：readyNodes，准备好发送的节点集合；unknownLeaderTopic，找不到某个leader分区的主题。</li>
<li>如果任何leader分区不存在，就要求更新元数据。</li>
<li>检查readyNodes集合里的node和客户端的网络连接是否正常。NetworkClient类维护了客户端和所有node的连接，这样根据连接的状态来判断连接是否是正常的。</li>
<li>获取要发送的请求集合。accumulator.drain(）方法会返回把按分区收集的请求集合转换为按节点收集的请求集合，<code>Map&#x3C;Integer, List&#x3C;ProducerBatch>></code>，key是nodeId，value是<code>List&#x3C;ProducerBatch></code>。为什么Sender要做这个集合的转换呢？我下面解释一下，如下图所示：</li>
</ol>
<p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/391efab3113b4d859fb915f841d1fffe~tplv-k3u1fbpfcp-watermark.image?" alt="A67DB93A-3B3B-42EB-998D-A3E4B6D5790B.png"></p>
<p>假设有两台服务端机器，一个主题有6个分区，每台机器有3个分区。如果按照分区发送就会有6个请求，而按节点发送总共就有两个请求。<strong>按节点发送可以大大减少网络的开销</strong>。</p>
<ol start="6">
<li>收集和处理过期的批次。在有些情况下，消息很久都没发送出去，我们不可能让消息批次一直等待，要有对应的超时批次的处理逻辑。先看下详细代码：</li>
</ol>
<pre><code>     private List&#x3C;ProducerBatch> getExpiredInflightBatches(long now) {     
       //1.创建过期批次集合     
       List&#x3C;ProducerBatch> expiredBatches = new ArrayList&#x3C;>();     
       //2.遍历inFlightBatches    
       for (Iterator&#x3C;Map.Entry&#x3C;TopicPartition, List&#x3C;ProducerBatch>>> batchIt = inFlightBatches.entrySet().iterator(); batchIt.hasNext();) { 
         Map.Entry&#x3C;TopicPartition, List&#x3C;ProducerBatch>> entry = batchIt.next();         List&#x3C;ProducerBatch> partitionInFlightBatches = entry.getValue();         
    if (partitionInFlightBatches != null) {            
      Iterator&#x3C;ProducerBatch> iter = partitionInFlightBatches.iterator();             
       //3.遍历某个分区的生产者批量发送列表           
      while (iter.hasNext()) {               
      ProducerBatch batch = iter.next();                 
        //4.判断batch是否投递超时。默认消息投递过期时间是2 minutes                
        if (batch.hasReachedDeliveryTimeout(accumulator.getDeliveryTimeoutMs(), now)) {                     //5.删除投递过期的batch                     
          iter.remove();                     
          //6.如果 batch 没有最终的状态，就把batch加入到expiredBatches集合                     
          if (!batch.isDone()) {                        
          expiredBatches.add(batch);                    
          } else {                         
            throw new IllegalStateException(batch.topicPartition + " batch created at " +                             batch.createdMs + " gets unexpected final state " + batch.finalState());                    
          }                 
        } else {                     
          //更新下一个Batch的超时时间。                     accumulator.maybeUpdateNextBatchExpiryTime(batch);                     
          break;                 
        }             
      }             
      if (partitionInFlightBatches.isEmpty()) {                 
        batchIt.remove();             
      }        
    }     
       }     
       return expiredBatches; } 
</code></pre>
<p>首先创建过期批次的集合expiredBatches，然后遍历inFlightBatches，拿到分区对应的<code>List&#x3C;ProducerBatch></code>后，再遍历<code>List&#x3C;ProducerBatch></code>，如果发现ProducerBatch存留的时间超过accumulator.getDeliveryTimeoutMs()就认为该批次过期了，DeliveryTimeoutMs的默认值是120s。如果发送的消息很多而且不太在意消息的延迟，可以考虑把这个参数适当增加。对于过期的批次，会从inFlightBatches里删除。</p>
<ol start="7">
<li>处理过期的批次。</li>
</ol>
<p>通过调用failBatch()方法实现对过期批次的处理，然后把过期的批次放入expiredBatches集合里。</p>
<pre><code>//失败batch的处理
private void failBatch(ProducerBatch batch,
                       long baseOffset,
                       long logAppendTime,
                       RuntimeException exception,
                       boolean adjustSequenceNumbers) {
    if (transactionManager != null) {
        transactionManager.handleFailedBatch(batch, exception, adjustSequenceNumbers);
    }


    this.sensors.recordErrors(batch.topicPartition.topic(), batch.recordCount);
    //超时调用回调
    if (batch.done(baseOffset, logAppendTime, exception)) {
        maybeRemoveAndDeallocateBatch(batch);
    }
}
</code></pre>
<p>这个方法最关键的是代码里调用batch.done(）。具体是调用了batch里的回调方法。也就是说对于超时的批次不会发送给服务端了，而是直接执行回调方法完成请求。执行成功后删除批次并释放批次占用的空间。</p>
<ol start="8">
<li>调用sendProduceRequests(batches, now）。我们看下这个方法：</li>
</ol>
<pre><code>      private void sendProduceRequests(Map&#x3C;Integer, List&#x3C;ProducerBatch>> collated, long now) {    
      for (Map.Entry&#x3C;Integer, List&#x3C;ProducerBatch>> 
      entry : collated.entrySet())     
      sendProduceRequest(now, entry.getKey(), acks, requestTimeoutMs, entry.getValue()); 
      }
</code></pre>
<p>本质上是轮询过滤完的批次集合去调用sendProduceRequest()方法，因为key是节点，所以每调用一次就是向某个节点发送请求，而且是批量发送，因为value是<code>List&#x3C;ProducerBatch></code>。下面我们来介绍sendProduceRequest()方法，源码如下：</p>
<pre><code>/**
 * Create a produce request from the given record batches
 * 把ProducerBatch类型转换成ClientRequest，并把clientRequest放到KafkaChannel的缓存里。
 */
private void sendProduceRequest(long now, int destination, short acks, int timeout, List&#x3C;ProducerBatch> batches) {
    if (batches.isEmpty())
        return;
    //1.初始化两个集合，produceRecordsByPartition用于构建请求，recordsByPartition用于构建回调方法
    Map&#x3C;TopicPartition, MemoryRecords> produceRecordsByPartition = new HashMap&#x3C;>(batches.size());
    final Map&#x3C;TopicPartition, ProducerBatch> recordsByPartition = new HashMap&#x3C;>(batches.size());


   ......忽略
    //2.按分区填充produceRecordsByPartition和recordsByPartition两个集合。
    for (ProducerBatch batch : batches) {
        TopicPartition tp = batch.topicPartition;
        MemoryRecords records = batch.records();


        if (!records.hasMatchingMagic(minUsedMagic))
            records = batch.records().downConvert(minUsedMagic, 0, time).records();
        produceRecordsByPartition.put(tp, records);
        recordsByPartition.put(tp, batch);
    }
......
    //3.创建requestBuilder对象。
    ProduceRequest.Builder requestBuilder = ProduceRequest.Builder.forMagic(minUsedMagic, acks, timeout,
            produceRecordsByPartition, transactionalId);
    //4.创建回调
    RequestCompletionHandler callback = response -> handleProduceResponse(response, recordsByPartition, time.milliseconds());
    String  = Integer.toString(destination);
    //5.创建clientRequest
    ClientRequest clientRequest = client.newClientRequest(nodeId, requestBuilder, now, acks != 0,
            requestTimeoutMs, callback);
    //6.把clientRequest发送给NetworkClient，完成消息的预发送。
    client.send(clientRequest, now);
    log.trace("Sent produce request to {}: {}", nodeId, requestBuilder);
}
</code></pre>
<p>第一步，初始化两个集合，produceRecordsByPartition用于构建请求，recordsByPartition用于构建回调。</p>
<p>第二步，按分区填充这两个集合。</p>
<p>第三步，创建requestBuilder对象。</p>
<p>第四步，创建callback对象。实际上是实例化回调接口RequestCompletionHandler，接口RequestCompletionHandler就一个方法onComplete()，callback对onComplete()的实现方式是用返回的response当参数调用handleProduceResponse()方法。消息发送的时候不会把callback方法发送到服务器，而是把callback放在NetworkClient里等待响应回来后根据响应调用callback。</p>
<p>第五步，创建clientRequest。用produceRecordsByPartition集合构建clientRequest，也就是说一个clientRequest对象里有多个消息批次。</p>
<p>第六步，把clientRequest交给NetworkClient，NetworkClient会调用相关方法把clientRequest保存在kakfaChannel的send字段里，也就是说预发送的最小单位是一个<code>List&#x3C;produceBatch></code>，也就是一个批次集合，而真正能不能一次就发送一个批次要看当时的网络环境。</p>
<p>好，到这里完成消息的预发送。</p>
<p><code>发送消息</code>涉及到的类和方法就介绍完了，接下来继续介绍<code>收到响应后Sender线程是如何处理的</code>。</p>
<p><strong>handleProduceResponse(ClientResponse response, Map&#x3C;TopicPartition, ProducerBatch> batches, long now)</strong></p>
<pre><code>/**  * Handle a produce response  * 处理服务端发来的response。  
*/ 
private void handleProduceResponse(ClientResponse response, Map&#x3C;TopicPartition, ProducerBatch> batches, long now) {     
  RequestHeader requestHeader = response.requestHeader();     
  int correlationId = requestHeader.correlationId();     
  //连接失败     
  if (response.wasDisconnected()) {         
    log.trace("Cancelled request with header {} due to node {} being disconnected",   
              requestHeader, response.destination());         
    for (ProducerBatch batch : batches.values())             
      completeBatch(batch, new ProduceResponse.PartitionResponse(Errors.NETWORK_EXCEPTION), correlationId, now);    
    //处理版本不匹配     
  } else if (response.versionMismatch() != null) {        
    log.warn("Cancelled request {} due to a version mismatch with node {}",                
             response, response.destination(), response.versionMismatch());       
    for (ProducerBatch batch : batches.values())             
      completeBatch(batch, new
                    ProduceResponse.PartitionResponse(Errors.UNSUPPORTED_VERSION), correlationId, now);             
    //处理正常响应     
  } else {         
    log.trace("Received produce response from node {} with correlation id {}", response.destination(), correlationId);         
    // if we have a response, parse it         
    // 有响应         
    if (response.hasResponse()) {            
      ProduceResponse produceResponse = (ProduceResponse) response.responseBody();             
      for (Map.Entry&#x3C;TopicPartition, ProduceResponse.PartitionResponse> entry : 
           produceResponse.responses().entrySet()) {                
        TopicPartition tp = entry.getKey();                 
        ProduceResponse.PartitionResponse partResp = entry.getValue();                 
        ProducerBatch batch = batches.get(tp);                 
        //调用completeBatch()方法处理。                 
        completeBatch(batch, partResp, correlationId, now);             
      }             this.sensors.recordLatency(response.destination(), response.requestLatencyMs()); 
    } else {             
      //无响应，ack=0时的处理             
      for (ProducerBatch batch : batches.values()) {    
        completeBatch(batch, new ProduceResponse.PartitionResponse(Errors.NONE), correlationId, now);             
      }       
    }     
  } 
} 
</code></pre>
<p>一个响应是某一个节点发给客户端的，一个节点每次向客户端发送的响应也是批量的，一个响应就有可能包含多个分区的响应信息。我们还要调用回调方法告诉生产者发送结果，而回调方法并没有在响应里，这要求我们要从请求的batch集合里拿到回调方法。于是，前面定义的recordsByPartition集合在处理响应的时候就有用了。</p>
<p>客户端接到响应后会根据响应的结果分情况处理：处理方法是completeBatch()，只是根据具体情况配置的参数不同。</p>
<p>首先会处理两个失败的场景：如果连接失败会设定异常Errors.NETWORK_EXCEPTION，客户端和服务端api版本不匹配会设定异常Errors.UNSUPPORTED_VERSION。</p>
<p>正常响应也分两种情况：有返回值的响应和无返回值的响应。</p>
<ul>
<li>响应有返回值。根据响应集合里的分区找到recordsByPartition集合里对应的batch，然后把batch和响应信息当参数调用completeBatch()方法。</li>
<li>对应响应无返回值的场景是，当发送时设定的ack=0时，生产端只管发送而不去管响应结果，所以不用考虑响应的返回值，也是调用completeBatch()方法。</li>
</ul>
<p>好，<strong>最终还是要调用completeBatch()方法</strong>，那我们下面看一下completeBatch()方法。</p>
<p><strong>completeBatch()</strong></p>
<p>completeBatch()方法源码如下：</p>
<pre><code>private void completeBatch(ProducerBatch batch, ProduceResponse.PartitionResponse response, long correlationId, long now) {     
  Errors error = response.error;     
  //单调消息过长的消息，会把单条消息分成多个batch发送。     
  if (error == Errors.MESSAGE_TOO_LARGE &#x26;&#x26; batch.recordCount > 1 &#x26;&#x26; !batch.isDone() &#x26;&#x26;             (batch.magic() >= RecordBatch.MAGIC_VALUE_V2 || batch.isCompressed())) {              
    log.warn(  "Got error produce response in correlation id {} on topic-partition {}, splitting and retrying ({} attempts left). Error: {}",   correlationId,             batch.topicPartition,             this.retries - batch.attempts(),  error);        
    if (transactionManager != null)             
      transactionManager.removeInFlightBatch(batch);         
    this.accumulator.splitAndReenqueue(batch);         maybeRemoveAndDeallocateBatch(batch);         
    this.sensors.recordBatchSplit();     } else if (error != Errors.NONE) {         
      //能否再次发送         if (canRetry(batch, response, now)) {             log.warn(                 "Got error produce response with correlation id {} on topic-partition {}, retrying ({} attempts left). Error: {}",                 correlationId,                 batch.topicPartition,                 this.retries - batch.attempts() - 1,                 error);             //再次入对             reenqueueBatch(batch, now);             //重复发送         } else if (error == Errors.DUPLICATE_SEQUENCE_NUMBER) {             //序列化重复的处理             completeBatch(batch, response);         } else {             final RuntimeException exception;             //主题没有权限             if (error == Errors.TOPIC_AUTHORIZATION_FAILED)                 exception = new TopicAuthorizationException(Collections.singleton(batch.topicPartition.topic()));             //集群没有权限             else if (error == Errors.CLUSTER_AUTHORIZATION_FAILED)                 exception = new ClusterAuthorizationException("The producer is not authorized to do idempotent sends");             
      //直接返回响应的错误信息            
      else                 
      exception = error.exception(response.errorMessage);            
      failBatch(batch, response, exception, batch.attempts() &#x3C; this.retries);         
    }         
  //无效的元数据异常        
  if (error.exception() instanceof InvalidMetadataException) {             
    //无对应主题或分区的异常            
    if (error.exception() instanceof UnknownTopicOrPartitionException) {                 log.warn("Received unknown topic or partition error in produce request on partition {}. The " +                         "topic-partition may not exist or the user may not have Describe access to it",                     batch.topicPartition);                     
 //其它元数据异常，直接返回响应的错误信息。 } else { 
log.warn("Received invalid metadata error in produce request on partition {} due to {}. Going " +                         "to request metadata update now", batch.topicPartition,error.exception(response.errorMessage).toString());            
}            
    metadata.requestUpdate();       
  }    
} else {         
  //正常执行回调         
  completeBatch(batch, response);    
}       
// Unmute the completed partition.     
if (guaranteeMessageOrder)         
  this.accumulator.unmutePartition(batch.topicPartition); } 
</code></pre>
<p>首先，我们分析一下各种<code>异常</code>的处理。</p>
<ol>
<li><strong>单调消息过长的异常。</strong> 需要同时满足四个条件：</li>
</ol>
<ul>
<li>响应返回MESSAGE_TOO_LARGE异常。</li>
<li>batch中只有一条消息</li>
<li>batch没有完成。</li>
<li>消息的格式大于等于V2版本或消息是压缩的。</li>
</ul>
<p>满足条件后进入if语句，因为消息太长了就分成多个批次发送，然后从集合中删除此batch，最后释放暂存器里此batch占用的空间。</p>
<ol start="2">
<li><strong>能再次入队等待发送的异常</strong>。 只要满足<code>canRetry()</code>方法就可以再次尝试发送。canRetry()方法代码在下面，我给你讲解一下：</li>
</ol>
<pre><code>private boolean canRetry(ProducerBatch batch, ProduceResponse.PartitionResponse response, long now) {
    return !batch.hasReachedDeliveryTimeout(accumulator.getDeliveryTimeoutMs(), now) &#x26;&#x26;
        batch.attempts() &#x3C; this.retries &#x26;&#x26;
        !batch.isDone() &#x26;&#x26;
        (transactionManager == null ?
                response.error.exception() instanceof RetriableException :
                transactionManager.canRetry(response, batch));
}
</code></pre>
<p>要同时满足四个条件，才能重新发送：</p>
<ul>
<li>没有到投递的超时时间。</li>
<li>batch重试次数没超过设定的次数。</li>
<li>批次没结束。</li>
<li>如果不被事务管理响应的异常属于可重试的异常，如果被事务管理调用事务管理器自定义的判断器判断是否能重试。</li>
</ul>
<ol start="3">
<li><strong>序列化重复的异常</strong>。说明消息重复发送了，不用做任何处理。</li>
<li><strong>主题没有权限的异常</strong>。集群没有权限的异常。已经其他异常，统一调用方法failBatch（）处理。</li>
<li><strong>元数据的异常</strong>。包括找不到对应分区及其他的元数据异常。这两个异常除了打印对应的异常日志都会设定元数据需要更新的标识，因为响应已经报元数据异常了，就应该及时更新元数据。</li>
<li><strong>响应没有异常</strong>。调用completeBatch(batch, response)完成响应处理。</li>
</ol>
<p>接下来我们讨论处理<code>正常响应</code>的方法completeBatch(batch, response)。</p>
<p><strong>completeBatch(batch, response)</strong></p>
<pre><code>private void completeBatch(ProducerBatch batch, ProduceResponse.PartitionResponse response) {     if (transactionManager != null) {         
  transactionManager.handleCompletedBatch(batch, response);     
}      
//执行回调，并释放 accumular 的空间     
 if (batch.done(response.baseOffset, response.logAppendTime, null)) {         
  maybeRemoveAndDeallocateBatch(batch);    
    } 
         } 
</code></pre>
<p>这个方法就两个部分，调用batch的done()方法，然后从集合中删除batch并释放batch占用的内存。</p>
<p>好了，到目前为止，Sender类<strong>从发送消息到处理响应的主要方法</strong>都分析完了。</p>
<h2>总结</h2>
<p>Sender类是一个线程类，如果不主动关闭Sender会一直执行下去。</p>
<p>这一节课我们讲解了Sender处理消息的流程，包括消息的发送和消息的响应处理。消息的发送还包括消息预发送和真正的网络发送。</p>
<p>另外，我们还分析了Sender类的相关字段和方法。Sender类用到了很多其他组件，包括NetworkClient用于网络IO，RecordAccumulator用于获取要发送的消息。MetaData用于获取元数据。sendProducerData及相关方法用于消息的预发送。调用NetworkClient类的poll()方法用于真正的网络发送。completeBatch()方法包含了各种异常响应和正常响应的处理。handleProduceResponse()方法是回调方法的处理逻辑。</p></div>
</body></html>
<!DOCTYPE html><html lang="en"><head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>第 01 讲：设计一份吸引面试官的简历</title>
<style type="text/css">
:root {
    --control-text-color: #777;
    --select-text-bg-color: rgba(223, 197, 223);  /*#7e66992e;*/
    
    /* side bar */
    --side-bar-bg-color: rgb(255, 255, 255);
    --active-file-text-color: #8163bd;
    --active-file-bg-color: #E9E4F0;
    --item-hover-bg-color: #E9E4F0;
    --active-file-border-color: #8163bd;

    --title-color: #6c549c;
    --font-sans-serif: 'Ubuntu', 'Source Sans Pro', sans-serif !important;
    --font-monospace: 'Fira Code', 'Roboto Mono', monospace !important;
    --purple-1: #8163bd;
    --purple-2: #79589F;
    --purple-3: #fd5eb8;
    --purple-light-1: rgba(99, 99, 172, .05);
    --purple-light-2: rgba(99, 99, 172, .1);
    --purple-light-3: rgba(99, 99, 172, .2);
    --purple-light-4: rgba(129, 99, 189, .3);
    --purple-light-5: #E9E4F0;
    --purple-light-6: rgba(129, 99, 189, .8);
}

/* html {
    font-size: 16px;
} */

body {
    font-family: var(--font-sans-serif);
    color: #34495e;
    -webkit-font-smoothing: antialiased;
    line-height: 1.6rem;
    letter-spacing: 0;
    margin: 0;
    overflow-x: hidden;
}

/* 页边距 和 页面大小 */
#write {
    padding-left: 6ch;
    padding-right: 6ch;
    margin: 0 auto;
}

#write p {
    line-height: 1.6rem;
    word-spacing: .05rem;
}

#write ol li {
    padding-left: 0.5rem;
}

#write > ul:first-child,
#write > ol:first-child {
    margin-top: 30px;
}

body > *:first-child {
    margin-top: 0 !important;
}

body > *:last-child {
    margin-bottom: 0 !important;
}

a {
    color: var(--purple-1);
    padding: 0 2px;
    text-decoration: none;
}
.md-content {
    color: var(--purple-light-6);
}
#write a {
    border-bottom: 1px solid var(--purple-1);
    color: var(--purple-1);
    text-decoration: none;
}

h1,
h2,
h3,
h4,
h5,
h6 {
    position: relative;
    margin-top: 1rem;
    margin-bottom: 0.5rem;
    /* font-weight: bold; */
    font-weight: 500 !important;
    line-height: 1.4;
    cursor: text;
    color: var(--title-color);
    font-family: var(--font-sans-serif);
}

h1:hover a.anchor,
h2:hover a.anchor,
h3:hover a.anchor,
h4:hover a.anchor,
h5:hover a.anchor,
h6:hover a.anchor {
    text-decoration: none;
}

h1 tt,
h1 code {
    font-size: inherit !important;
}
h2 tt,
h2 code {
    font-size: inherit !important;
}
h3 tt,
h3 code {
    font-size: inherit !important;
}
h4 tt,
h4 code {
    font-size: inherit !important;
}
h5 tt,
h5 code {
    font-size: inherit !important;
}
h6 tt,
h6 code {
    font-size: inherit !important;
}


h1 {
    padding-bottom: .4rem;
    font-size: 2.2rem;
    line-height: 1.3;
}
h1 {
    text-align: center;
    padding-bottom: 0.3em;
    font-size: 2.2em;
    line-height: 1.2;
    margin: 2.4em auto 1.2em;
}
h1:after {
    content: '';
    display: block;
    margin: 0.2em auto 0;
    width: 100px;
    height: 2px;
    border-bottom: 2px solid var(--title-color);
}

h2 {
    margin: 1.6em auto 0.5em;
    padding-left: 10px;
    line-height: 1.4;
    font-size: 1.8em;
    border-left: 9px solid var(--title-color);
    border-bottom: 1px solid var(--title-color);
}
h3 {
    font-size: 1.5rem;
    margin: 1.2em auto 0.5em;
}
h4 {
    font-size: 1.3rem;
}
h5 {
    font-size: 1.2rem;
}
h6 {
    font-size: 1.1rem;
}

p,
blockquote,
ul,
ol,
dl,
table {
    margin: 0.8em 0;
}

li > ol,
li > ul {
    margin: 0 0;
}

hr {
    height: 2px;
    padding: 0;
    margin: 16px 0;
    background-color: #e7e7e7;
    border: 0 none;
    overflow: hidden;
    box-sizing: content-box;
}

body > h2:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0;
}

body > h3:first-child,
body > h4:first-child,
body > h5:first-child,
body > h6:first-child {
    margin-top: 0;
    padding-top: 0;
}

a:first-child h1,
a:first-child h2,
a:first-child h3,
a:first-child h4,
a:first-child h5,
a:first-child h6 {
    margin-top: 0;
    padding-top: 0;
}

h1 p,
h2 p,
h3 p,
h4 p,
h5 p,
h6 p {
    margin-top: 0;
}

li p.first {
    display: inline-block;
}

ul,
ol {
    padding-left: 30px;
}

ul:first-child,
ol:first-child {
    margin-top: 0;
}

ul:last-child,
ol:last-child {
    margin-bottom: 0;
}

/* 引用 */
blockquote {
    /* margin-left: 1rem; */
    border-left: 4px solid var(--purple-light-4);
    padding: 10px 15px;
    color: #777;
    background-color: var(--purple-light-1);
}

/* 表格 */
table {
    padding: 0;
    word-break: initial;
}

table tr {
    border-top: 1px solid #dfe2e5;
    margin: 0;
    padding: 0;
}

/* 表格 背景色 */
table tr:nth-child(2n),
thead {
    background-color: var(--purple-light-1);
}
#write table thead th {
    background-color: var(--purple-light-2);
}

table tr th {
    font-weight: bold;
    border: 1px solid #dfe2e5;
    border-bottom: 0;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr td {
    border: 1px solid #dfe2e5;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr th:first-child,
table tr td:first-child {
    margin-top: 0;
}

table tr th:last-child,
table tr td:last-child {
    margin-bottom: 0;
}

/* 粗体 */
#write strong {
    padding: 0 2px;
    color: var(--purple-1);
}

/* 斜体 */
#write em {
    padding: 0 5px 0 2px;
    /* font-style: normal; */
    color: #42b983;
}

/* inline code */
#write code, tt {
    padding: 2px 4px;
    border-radius: 2px;
    font-family: var(--font-monospace);
    font-size: 0.92rem;
    color: var(--purple-3); 
    background-color: rgba(99, 99, 172, .05);
}

tt {
    margin: 0 2px;
}

#write .md-footnote {
    background-color: #f8f8f8;
    color: var(--purple-3);
}

/* heighlight. */
#write mark {
    background-color: #fbd3ea;
    border-radius: 2px;
    padding: 2px 4px;
    margin: 0 2px;
}

#write del {
    padding: 1px 2px;
}

.md-task-list-item > input {
    margin-left: -1.3em;
}

@media print {
    html {
        font-size: 0.9rem;
    }

    table,
    pre {
        page-break-inside: avoid;
    }

    pre {
        word-wrap: break-word;
    }
}

#write pre.md-meta-block {
    padding: 1rem;
    font-size: 85%;
    line-height: 1.45;
    background-color: #f7f7f7;
    border: 0;
    border-radius: 3px;
    color: #777777;
    margin-top: 0 !important;
}

.mathjax-block > .code-tooltip {
    bottom: .375rem;
}

/* 图片 */
.md-image > .md-meta {
    border-radius: 3px;
    font-family: var(--font-monospace);
    padding: 2px 0 0 4px;
    font-size: 0.9em;
    color: inherit;
}
p .md-image:only-child{
    width: auto;
    text-align: left;
    margin-left: 2rem;
}
.md-tag {
    color: inherit;
}
/* 当 “![shadow-随便写]()”写时，会有阴影 */
.md-image img[alt|='shadow'] {
    /* box-shadow: 0 4px 24px -6px #ddd; */
    box-shadow:var(--purple-light-2) 0px 10px 15px;
}

#write a.md-toc-inner {
    line-height: 1.6;
    white-space: pre-line;
    border-bottom: none;
    font-size: 0.9rem;
}

#typora-quick-open {
    border: 1px solid #ddd;
    background-color: #f8f8f8;
}

#typora-quick-open-item {
    background-color: #FAFAFA;
    border-color: #FEFEFE #e5e5e5 #e5e5e5 #eee;
    border-style: solid;
    border-width: 1px;
}

#md-notification:before {
    top: 10px;
}

header,
.context-menu,
.megamenu-content,
footer {
    font-family: var(--font-sans-serif);
}

.file-node-content:hover .file-node-icon,
.file-node-content:hover .file-node-open-state {
    visibility: visible;
}

.md-lang {
    color: #b4654d;
}

.html-for-mac .context-menu {
    --item-hover-bg-color: #E6F0FE;
}

/* 代码框 */
/* CodeMirror 3024 Day theme */

/* 代码段 背景 */
pre {
    --select-text-bg-color: rgba(223, 197, 223) !important;
    margin: .5em 0;
    padding: 1em 1.4em;
    border-radius: 8px;
    background: #f6f8fa;
    overflow-x: auto;
    box-sizing: border-box;
    font-size: 14px;
}

/* 边框 */
.md-fences {
    border: 1px solid #e7eaed;
    border-radius: 3px;
}

.cm-s-inner {
  padding: .25rem;
  border-radius: .25rem;
}

.cm-s-inner.CodeMirror, .cm-s-inner .CodeMirror-gutters {
  background-color: #f8f8f8 !important;
  color: #3a3432 !important;
  border: none;
}

.cm-s-inner .CodeMirror-gutters {
  color: #6d8a88;
}

.cm-s-inner .CodeMirror-cursor {
  border-left: solid thin #5c5855 !important;
}

.cm-s-inner .CodeMirror-linenumber {
  color: #807d7c;
}

.cm-s-inner .CodeMirror-line::selection, .cm-s-inner .CodeMirror-line::-moz-selection,
.cm-s-inner .CodeMirror-line > span::selection,
.cm-s-inner .CodeMirror-line > span::-moz-selection,
.cm-s-inner .CodeMirror-line > span > span::selection,
.cm-s-inner .CodeMirror-line > span > span::-moz-selection {
  background: var(--purple-light-2);
}

.cm-s-inner span.cm-comment {
  color: #cdab53;
}

.cm-s-inner span.cm-string, .cm-s-inner span.cm-string-2 {
  color: #f2b01d;
}

.cm-s-inner span.cm-number {
  color: #a34e8f;
}

.cm-s-inner span.cm-variable {
  color: #01a252;
}

.cm-s-inner span.cm-variable-2 {
  color: #01a0e4;
}

.cm-s-inner span.cm-def {
  /* color: #e8bbd0; */
  color: #e2287f;
}

.cm-s-inner span.cm-operator {
  color: #ff79c6;
}

.cm-s-inner span.cm-keyword {
  color: #db2d20;
}

.cm-s-inner span.cm-atom {
  color: #a34e8f;
}

.cm-s-inner span.cm-meta {
  color: inherit;
}

.cm-s-inner span.cm-tag {
  color: #db2d20;
}

.cm-s-inner span.cm-attribute {
  color: #01a252;
}

.cm-s-inner span.cm-qualifier {
  color: #388aa3;
}

.cm-s-inner span.cm-property {
  color: #01a252;
}

.cm-s-inner span.cm-builtin {
  color: #388aa3;
}

.cm-s-inner span.cm-variable-3, .cm-s-inner span.cm-type {
  color: #ffb86c;
}

.cm-s-inner span.cm-bracket {
  color: #3a3432;
}

.cm-s-inner span.cm-link {
  color: #a34e8f;
}

.cm-s-inner span.cm-error {
  background: #db2d20;
  color: #5c5855;
}

/* .md-fences.md-focus .cm-s-inner .CodeMirror-activeline-background {
  background: var(--purple-light-2);
} */

.cm-s-inner .CodeMirror-matchingbracket {
  text-decoration: underline;
  color: #a34e8f !important;
}

#fences-auto-suggest .active {
  background: #ddd;
}

#write .code-tooltip {
  bottom: initial;
  top: calc(100% - 1px);
  background: #f7f7f7;
  border: 1px solid #ddd;
  border-top: 0;
}

.auto-suggest-container {
  border-color: #b4b4b4;
}

.auto-suggest-container .autoComplt-hint.active {
  background: #b4b4b4;
  color: inherit;
}

/* task list */
#write .md-task-list-item > input {
  -webkit-appearance: initial;
  display: block;
  position: absolute;
  border: 1px solid #b4b4b4;
  border-radius: .25rem;
  margin-top: .1rem;
  margin-left: -1.8rem;
  height: 1.2rem;
  width: 1.2rem;
  transition: background 0.3s;
}

#write .md-task-list-item > input:focus {
  outline: none;
  box-shadow: none;
}

#write .md-task-list-item > input:hover {
  background: #ddd;
}

#write .md-task-list-item > input[checked]::before {
  content: '';
  position: absolute;
  top: 20%;
  left: 50%;
  height: 60%;
  width: 2px;
  transform: rotate(40deg);
  background: #333;
}

#write .md-task-list-item > input[checked]::after {
  content: '';
  position: absolute;
  top: 46%;
  left: 25%;
  height: 30%;
  width: 2px;
  transform: rotate(-40deg);
  background: #333;
}

#write .md-task-list-item > p {
  transition: color 0.3s, opacity 0.3s;
}

#write .md-task-list-item.task-list-done > p {
  color: #b4b4b4;
  text-decoration: line-through;
}

#write .md-task-list-item.task-list-done > p > .md-emoji {
  opacity: .5;
}

#write .md-task-list-item.task-list-done > p > .md-link > a {
  opacity: .6;
}

/* sidebar and outline */
.pin-outline .outline-active {
  color: var(--active-file-text-color); 
}

.file-list-item {
    border-bottom: 1px solid;
    border-color: var(--purple-light-5);
}

.file-list-item-summary {
    font-weight: 400;
}

.file-list-item.active {
    color: var(--active-file-text-color);
    background-color: var(--purple-light-5);
}

.file-tree-node.active>.file-node-background {
    background-color: var(--purple-light-5);
    font-weight: 700;
} 

.file-tree-node.active>.file-node-content {
    color: var(--active-file-text-color);
    font-weight: 700;
}

.file-node-content {
    color: #5e676d;
}

.sidebar-tabs {
    border-bottom: none;
}
.sidebar-tab.active {
    font-weight: 400;
}

.sidebar-content-content {
    font-size: 0.9rem;
}

img {
    max-width: 100%;
}

body {
    background-color: rgb(237, 237, 237);
}
#content {
    width: 836px;
    padding: 50px;
    background: #fff;
    margin: 0 auto;
}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/purple.css*/</style><style type="text/css">.hljs{display:block;overflow-x:auto;padding:.5em;color:#383a42;background:#fafafa}.hljs-comment,.hljs-quote{color:#a0a1a7;font-style:italic}.hljs-doctag,.hljs-formula,.hljs-keyword{color:#a626a4}.hljs-deletion,.hljs-name,.hljs-section,.hljs-selector-tag,.hljs-subst{color:#e45649}.hljs-literal{color:#0184bb}.hljs-addition,.hljs-attribute,.hljs-meta-string,.hljs-regexp,.hljs-string{color:#50a14f}.hljs-built_in,.hljs-class .hljs-title{color:#c18401}.hljs-attr,.hljs-number,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-pseudo,.hljs-template-variable,.hljs-type,.hljs-variable{color:#986801}.hljs-bullet,.hljs-link,.hljs-meta,.hljs-selector-id,.hljs-symbol,.hljs-title{color:#4078f2}.hljs-emphasis{font-style:italic}.hljs-strong{font-weight:700}.hljs-link{text-decoration:underline}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/atom-one-light.min.css*/</style></head>
<body>
<div id="content"><h1>高吞吐利器之一：生产者缓冲区</h1>
<blockquote>
<p>这节课我提供了视频讲解，在源码讲解的基础上增加了原理解析和架构学习的部分，对应的视频地址如下
<a href="https://www.bilibili.com/video/BV1cZ4y1y7C5" target="_blank" rel="nofollow noopener noreferrer">https://www.bilibili.com/video/BV1cZ4y1y7C5</a></p>
</blockquote>
<p>从这一讲开始我们就来学习生产者客户端的缓冲区。</p>
<p>我们知道 Kafka 是一个吞吐量很高的消息队列，在生产者这里也有体现。其实，高吞吐最普遍的实现是<strong>异步</strong>、<strong>批量</strong>和<strong>压缩</strong>。从这节课开始在讲解的过程中，会涉及 Kafka 生产端发送消息时实现<strong>异步</strong>、<strong>批量</strong>和<strong>压缩的代码设计</strong>。下面给大家简单讲一下生产者发送消息时是如何实现异步发送和批量发送的。</p>
<ul>
<li><code>异步发送</code>：对于生产者异步发送来说，<strong>Kafka生产者有同步和异步两种方式来发送消息，但实际上都是通过异步方式实现的</strong>。也就是说，生产者主线程发送后不会阻塞，而是继续发送下条消息，并通过回调方法异步处理响应从而判断消息是否发送成功，而真正发送消息的是Sender 的子线程。这样设计的好处是业务发送消息和网络发送消息解耦，能够提升消息发送的速度。</li>
<li><code>批量发送</code>：Kafka生产者会把消息暂时保存在缓冲区中，然后满足一定条件时， Sender 的子线程把消息批量发送给 Kafka 服务端。批量发送的好处是能够减少网络请求的次数，进而提升网络吞吐量。</li>
<li><code>消息压缩</code>：生产者负责根据配置的压缩算法，消费者拉取消息时进行解压，服务端存储的消息都是压缩过得。通过消息压缩减少了网络带宽和磁盘的使用效率。</li>
</ul>
<p>那缓冲区的消息都在哪里呢？它们又是怎样被管理的呢？</p>
<h2>RecordAccumulator 类</h2>
<p>缓存的消息主要位于 RecordAccumulator 类中，所以在学习消息缓冲之前你还得先了解下RecordAccumulator处理消息缓冲的流程，如下图所示：</p>
<p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9b1a364f856e4481804520aa54e27e37~tplv-k3u1fbpfcp-watermark.image?" alt="0E59E8D4-B1BF-46B7-926E-34DEE3E9C545.png"></p>
<p>从流程图中，我们可以得出以下信息：</p>
<ul>
<li>在RecordAccumulator中有一个CopyOnWriteMap集合batches。key是主题分区，value是ProducerBatch队列，每个分区都对应一个队列。<strong>队列中的元素是批次 ProducerBatch，消息就是封装在这些批次里进行缓存的</strong>。</li>
<li>当生产者生产消息时，消息会通过分区器Partitioner保存在不同的队列里。如果消息的大小比一个批次的空间小，那么一个批次里就会有多个消息。</li>
<li>要通过ProducerBatch缓存数据，那我们就需要申请内存空间，内存空间的申请是通过内存缓存池bufferPool实现的。</li>
</ul>
<p>从以上的讲解我们可以看出，RecordAccumulator中有三个重要的组件：消息批次ProducerBatch、Kafka自定义的保存批次的集合CopyOnWriteMap和缓存池BufferPool。</p>
<p>今天这一讲我们会重点讲解其中的消息批次ProducerBatch以及ProducerBatch底层依赖的类，这是消息缓冲的最小单位，也是发送消息的最小单位。另外两个组件会在下一节课讲解，这两个组件分别是：</p>
<ol>
<li><code>CopyOnWriteMap</code>。实现了对缓冲区的管理，同时在并发场景下性能很好。</li>
<li><code>缓冲池bufferPool</code>。缓冲池bufferPool预先申请了固定大小的内存，缓冲区需要内存的时候可以从bufferPool申请内存，内存用完了可以释放回bufferPool，这样的设计可以避免内存对象反复申请和销毁，从而提升性能。</li>
</ol>
<p>好，我们开始学习表示消息批次的类 ProducerBatch，我们先看一下ProducerBatch相关类的关系图：</p>
<p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/97713431e79d435ca698eadd89678384~tplv-k3u1fbpfcp-watermark.image?" alt="155A4F44-B82E-497F-A7C1-3EA5779CA896.png"></p>
<p>我来讲解一下这个类图：RecordAccumulator通过ProducerBatch保存一批消息，ProducerBatch依赖MemoryRecordBuilder构建MemoryRecords用来保存数据，所以<strong>MemoryRecords才是真正保存消息的地方</strong>。</p>
<p>也就是说，<code>要想理解消息批次ProducerBatch，我们还要理解MemoryRecords、MemoryRecordBuilder</code>。因此，这里我们先讲解MemoryRecords，然后讲解MemoryRecordBuilder，最后讲解ProducerBatch。</p>
<p>好，我们开始讲解MemoryRecords 类</p>
<h2>MemoryRecords类</h2>
<p><strong>MemoryRecords类是保存了多个消息的集合，底层封装了JavaNIO的ByteBuffer用来存储消息数据。</strong></p>
<p>MemoryRecordsBuilder类的创建就是依赖于MemoryRecords里的方法builder()。builder() 方法的源码如下：</p>
<pre><code>public static MemoryRecordsBuilder builder(ByteBuffer buffer,
                                           byte magic,
                                           CompressionType compressionType,
                                           TimestampType timestampType,
                                           long baseOffset,
                                           long logAppendTime,
                                           long producerId,
                                           short producerEpoch,
                                           int baseSequence,
                                           boolean isTransactional,
                                           boolean isControlBatch,
                                           int partitionLeaderEpoch) {
    return new MemoryRecordsBuilder(buffer, magic, compressionType, timestampType, baseOffset,
            logAppendTime, producerId, producerEpoch, baseSequence, isTransactional, isControlBatch, partitionLeaderEpoch,
            buffer.remaining());
}
</code></pre>
<p>这段代码还是比较好理解的，可以看到，builder()方法会根据分配到的ByteBuffer、消息版本、消息压缩类型、基本位移等参数构建出MemoryRecordsBuilder类。</p>
<h2>MemoryRecordsBuilder类</h2>
<p><strong>MemoryRecordsBuilder类封装了向ByteBuffer里写数据的功能</strong>。我们先学习相关字段和构造方法，再通过学习重要方法学习这个类具体做了哪些事情。</p>
<h3>字段</h3>
<p>关于 MemoryRecordsBuilder 对应的字段，你可以参考下面这段代码：</p>
<pre><code>public class MemoryRecordsBuilder implements AutoCloseable {
    //禁止写入的输出流
    private static final DataOutputStream CLOSED_STREAM = new DataOutputStream(new OutputStream() {
        @Override
        public void write(int b) {
            throw new IllegalStateException("MemoryRecordsBuilder is closed for record appends");
        }
    });
    //消息压缩类型
    private final CompressionType compressionType;
    // kafka对OutputStream接口的实现类，实现了对bytebuffer的扩容
    private final ByteBufferOutputStream bufferStream;
    // 消息的版本
    private final byte magic;
    // ByteBuffer的初始位置
    private final int initialPosition;
    //基本位移
    private final long baseOffset;
    //追加消息的时间
    private final long logAppendTime;
    //是否是控制类的批次
    private final boolean isControlBatch;
    //分区leader的版本
    private final int partitionLeaderEpoch;
    //写模型下的limit
    private final int writeLimit;
    //batch头大小
    private final int batchHeaderSizeInBytes;
    // 评估压缩率
    private float estimatedCompressionRatio = 1.0F;
    // 给ByteBuffer增加压缩的功能
    private DataOutputStream appendStream;
    // 这个批次是否是事务的一部分
    private boolean isTransactional;
    // 生产者id
    private long producerId;
    // 生产者版本
    private short producerEpoch;
    // 批次序列号
    private int baseSequence;
    // 压缩前要写入的消息体大小
    private int uncompressedRecordsSizeInBytes = 0; 
    // 记录数
    private int numRecords = 0;
    // 实际压缩率
    private float actualCompressionRatio = 1;
    //最后的偏移量
    private Long lastOffset = null;
    //第一次追加消息的时间戳
    private Long firstTimestamp = null;
    //真正保存消息的地方
    private MemoryRecords builtRecords;
    //是否终止
    private boolean aborted = false;
</code></pre>
<p>这里我们只讲解其中的几个重点字段，其他的都比较好理解，这里我就不赘述了。</p>
<ul>
<li><code>CLOSED_STREAM</code>：写操作关闭的输出流。在关闭某个ByteBuffer的时候会把ByteBuffer对应的输出流设置为CLOSED_STREAM，防止再向 ByteBuffer 中写数据，否则就会抛出异常。</li>
<li><code>CompressionType</code>：枚举类。指消息的压缩类型。有5 种压缩类型：NONE、GZIP、SNAPPY、LZ4、ZSTD。NONE表示数据不压缩，其他4个分别对应不同的压缩类型。</li>
<li><code>bufferStream</code>：类型是ByteBufferOutputStream类。ByteBufferOutputStream继承了OutputStream并封装了ByteBuffer，除了对ByteBuffer基本操作的封装，还增加了对ByteBuffer扩容的功能。</li>
</ul>
<p>ByteBuffer 扩容的功能是ByteBufferOutputStream 类对OutputStream类的一个增强功能，实现了对ByteBuffer的扩容，代码如下：</p>
<pre><code>     private void expandBuffer(int remainingRequired) {
    //1.评估需要多少空间
    int expandSize = Math.max((int) (buffer.limit() * REALLOCATION_FACTOR), buffer.position() + remainingRequired);
    //2.申请新的ByteBuffer
    ByteBuffer temp = ByteBuffer.allocate(expandSize);
    //3.获得写模式的limit
    int limit = limit();
    //4.把写状态转换为读状态
    buffer.flip();
    //5.读到temp里
    temp.put(buffer);
    //6.改成写时候的limit
    buffer.limit(limit);
    //7.更新原来的buffer的position，防止重复消费
    buffer.position(initialPosition);
    buffer = temp;
     }
</code></pre>
<p>第一步，计算需要扩容多少，在扩容因子（默认1.1倍）和真正需要多少字节之间选择最大值。因为扩容需要耗费一定的系统资源，如果每次按实际数据大小扩容每次没有预先分配的空间，这样会造成频繁扩容而浪费资源，有个扩容因子避免了这种情况。</p>
<p>第二步，根据扩容多少申请新的ByteBuffer，所谓扩容就是按照扩容后大小重新申请一个空的ByteBuffer，再把原来ByteBuffer的数据拷贝进去。</p>
<p>最后，把ByteBuffer的引用buffer指向新申请的ByteBuffer。
 </p>
<h3>构造方法</h3>
<p><strong>MemoryRecordsBuilder 类</strong>的构造方法初始化了几个重要的参数，我给你分析一下：</p>
<pre><code>public MemoryRecordsBuilder(ByteBufferOutputStream bufferStream,
                            byte magic,
                            CompressionType compressionType,
                            TimestampType timestampType,
                            long baseOffset,
                            long logAppendTime,
                            long producerId,
                            short producerEpoch,
                            int baseSequence,
                            boolean isTransactional,
                            boolean isControlBatch,
                            int partitionLeaderEpoch,
                            int writeLimit) {
    ......忽略
    //1.计算Batch头的长度
    this.batchHeaderSizeInBytes = AbstractRecords.recordBatchHeaderSizeInBytes(magic, compressionType);
    //调整position
    bufferStream.position(initialPosition + batchHeaderSizeInBytes);
    this.bufferStream = bufferStream;
    //增加压缩的功能
    this.appendStream = new DataOutputStream(compressionType.wrapForOutput(this.bufferStream, magic));
}
</code></pre>
<p>首先计算Batch头的长度，因为不同消息版本batch头的大小都是固定的，所有调整bufferStream的position，让position跳过batch的头部，这样就可以直接写消息的数据了。appendStream为bufferStream增加了压缩功能，ByteBuffer、bufferStream和appendStream三者的关系我用下面这张图来表示：</p>
<p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/24a4aa1711f244ec9567543a3691b49e~tplv-k3u1fbpfcp-watermark.image?" alt="BA3D3457-30C9-4994-918D-4F6B4CC1A968.png"></p>
<p>这是典型的装饰模式的应用，bufferStream对ByteBuffer的装饰实现了自动扩容功能，appendStream对bufferStream的装饰实现了压缩功能。</p>
<h3>重要方法</h3>
<p><strong>appendDefaultRecord()是向缓存写入消息体的方法</strong>，代码如下：</p>
<pre><code>private void appendDefaultRecord(long offset, long timestamp, ByteBuffer key, ByteBuffer value,
                                 Header[] headers) throws IOException {
    //1.检查是否可以写
    ensureOpenForRecordAppend();
    //2.计算要写多少偏移量
    int offsetDelta = (int) (offset - baseOffset);
    //3.计算这次写和第一次写之间的时间差
    long timestampDelta = timestamp - firstTimestamp;
    //4.把消息写入appendStream，并返回压缩前的消息大小
    int sizeInBytes = DefaultRecord.writeTo(appendStream, offsetDelta, timestampDelta, key, value, headers);
    //5.消息写入成功后更新相关的数据
    recordWritten(offset, timestamp, sizeInBytes);
}
</code></pre>
<p>首先，判断是否可写，再计算要写的位移大小，以及这次写入和第一次写的时间差。然后，把位移大小、时间差、key、value、头信息写入appendStream，并返回写入的字节大小。最后，更新相关的数据，如写入消息数、byteBuffer里未压缩前的消息大小、追加信息的时间戳等。</p>
<h2>ProducerBatch类</h2>
<p>好了，现在来分析ProducerBatch。在介绍 ProducerBatch 之前，我们先介绍下 ProducerBatch 依赖的一个重要组件 ProduceRequestResult。</p>
<h3>ProduceRequestResult类</h3>
<p>ProduceRequestResult是异步获取消息生产结果的类。</p>
<p>ProduceRequestResult、FutureRecordMetadata、RecordMetadata 是配合起来给 ProducerBatch 使用的。类关系图如下：</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5322ae1c692048e5a8e743f24ac4af62~tplv-k3u1fbpfcp-watermark.image?" alt="809CC43A-CB4F-44C5-BECC-A9401CD95DDC.png"></p>
<p>ProduceRequestResult 并没有实现 java.util.concurrent.Future 的接口，但是通过一个 count 为 1 的 CountDownLatch 对象间接地实现了 Future 的功能。</p>
<p>当生产者同步发送消息时会调用 FutureRecordMetadata 的 get() 方法，get() 方法会间接调用 ProduceRequestResult.await()，线程就会等待服务端的响应。当服务端响应来到的时候，无论 ProducerBatch 正常响应或非正常响应都会调用 ProduceRequestResult.done() 方法，而 ProduceRequestResult.done() 方法又是调用了 CountDownLatch 的 countDown() 唤醒了阻塞的主线程。流程图如下：</p>
<p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/22a72609060d4c0ab3be4beb5c75cbd5~tplv-k3u1fbpfcp-watermark.image?" alt="39D10A92-447F-4AFC-8A90-86BE607D41F5.png"></p>
<p><strong>producerBatch是生产者消息缓存的最小单位，一个producerBatch会存放一个或多个消息，我们也把producerBatch称为批次。</strong></p>
<h3>字段</h3>
<p>我们先分析相关字段：</p>
<pre><code>//批次最终状态
private enum FinalState { ABORTED, FAILED, SUCCEEDED }
//批次创建时间
final long createdMs;
//批次对应的分区
final TopicPartition topicPartition;
//请求结果的 future
final ProduceRequestResult produceFuture;
//生产者消息的回调方法保存在这里
private final List&#x3C;Thunk> thunks = new ArrayList&#x3C;>();
//封装了MemoryRecords对象，用来存储消息
private final MemoryRecordsBuilder recordsBuilder;
//batch的失败重试次数
private final AtomicInteger attempts = new AtomicInteger(0);
//是否是分裂后的批次
private final boolean isSplitBatch;
//ProducerBatch的最终状态
private final AtomicReference&#x3C;FinalState> finalState = new AtomicReference&#x3C;>(null);
//保存Record的个数
int recordCount;
//最大Record字节数
int maxRecordSize;
//最后一次失败重试发送的时间戳
private long lastAttemptMs;
//最后一次发送的时间戳
private long lastAppendTime;
//Sender线程拉取批次的时间
private long drainedMs;
//是否失败重试过
private boolean retry;
</code></pre>
<p>重点字段的解释如下：</p>
<ul>
<li>topicPartition：批次对应的分区。</li>
<li>produceFuture：ProduceRequestResult类对象。</li>
<li>thunks：<code>List&#x3C;Thunk></code>类型。Thunk是用来存储消息的callback和响应数据的。</li>
<li>recordsBuilder：封装了用来存储消息的ByteBuffer。</li>
<li>attempts：batch的失败重试次数。</li>
<li>isSplitBatch：Bool类型。表示是否是因单个消息过大一个而ProducerBatch存不下，而分裂成多个ProducerBatch存储的情况。</li>
<li>retry：是否失败重试过。</li>
</ul>
<h3>重要方法</h3>
<p>关于 ProducerBatch 的方法，这里我们重点讲解以下三个：tryAppend()、done() 和 completeFutureAndFireCallbacks()。</p>
<p><strong>tryAppend()是向producerBatch追加消息的方法</strong>，源码如下：</p>
<pre><code>public FutureRecordMetadata tryAppend(long timestamp, byte[] key, byte[] value, Header[] headers, Callback callback, long now) {
    //1.检验是否有空间
    if (!recordsBuilder.hasRoomFor(timestamp, key, value, headers)) {
        return null;
    } else {
        //2.把消息加入ProducerBatch对应的MemoryRecords中
        Long checksum = this.recordsBuilder.append(timestamp, key, value, headers);
        this.maxRecordSize = Math.max(this.maxRecordSize, AbstractRecords.estimateSizeInBytesUpperBound(magic(),
                recordsBuilder.compressionType(), key, value, headers));
        this.lastAppendTime = now;
        //3.构建FutureRecordMetadata对象
        FutureRecordMetadata future = new FutureRecordMetadata(this.produceFuture, this.recordCount,
                                                               timestamp, checksum,
                                                               key == null ? -1 : key.length,
                                                               value == null ? -1 : value.length,
                                                               Time.SYSTEM);
       
        //4.加入thunks
        thunks.add(new Thunk(callback, future));
        this.recordCount++;
        return future;
    }
}
</code></pre>
<p>可以看到 tryAppend() 方法的执行逻辑是这样的：先检测producerBatch里是否有空间存这条消息，如果有空间会调用recordsBuilder的append()方法把消息写入缓存；然后构建FutureRecordMetadata类对象future，把future和消息的callback作为参数构建Thunk类对象，并放入thunks集合中。</p>
<p>这个方法让生产者主线程完成了消息的缓存，但是并没有实现真正的网络发送。</p>
<p>接下来我们再来说说done()这个方法 <strong>。当调用done()方法时说明客户端已经收到这个批次的响应，这才调用这个方法来完成回调</strong>。相关代码如下所示：</p>
<pre><code>public boolean done(long baseOffset, long logAppendTime, RuntimeException exception) {
    //1.设定batch的最终状态
    final FinalState tryFinalState = (exception == null) ? FinalState.SUCCEEDED : FinalState.FAILED;
    if (tryFinalState == FinalState.SUCCEEDED) {
        log.trace("Successfully produced messages to {} with base offset {}.", topicPartition, baseOffset);
    } else {
        log.trace("Failed to produce messages to {} with base offset {}.", topicPartition, baseOffset, exception);
    }
    if (this.finalState.compareAndSet(null, tryFinalState)) {
        //2.执行回调
        completeFutureAndFireCallbacks(baseOffset, logAppendTime, exception);
        return true;
    }
    ......忽略
    return false;
}
</code></pre>
<p>具体逻辑是：先根据是否有异常设定batch的最终状态，如果没有异常，batch的最终状态就是SUCCEEDED，否则是FAILED，然后就执行回调方法。</p>
<p>可以看到，这里的回调方法是completeFutureAndFireCallbacks()，下面我们就来分析下这个方法。</p>
<p>completeFutureAndFireCallbacks()方法有两个功能：<strong>完成future和调用回调方法</strong>。其源代码如下所示：</p>
<pre><code>//执行ProduceBatch中所有的回调,并执行ProduceRequestResult的done()方法，
private void completeFutureAndFireCallbacks(long baseOffset, long logAppendTime, RuntimeException exception) {

    //1.设置produceFuture的相关数据
    produceFuture.set(baseOffset, logAppendTime, exception);

    // execute callbacks
    //2.轮询thunks集合，调用callback
    for (Thunk thunk : thunks) {
        try {
            if (exception == null) {
                //3.获取消息元数据
                RecordMetadata metadata = thunk.future.value();
                if (thunk.callback != null)
                    //4.调用回调方法
                    thunk.callback.onCompletion(metadata, null);
            } else {
                if (thunk.callback != null)
                    thunk.callback.onCompletion(null, exception);
            }
        } catch (Exception e) {
            log.error("Error executing user-provided callback on message for topic-partition '{}'", topicPartition, e);
        }
    }
    //4.释放主线程的阻塞
    produceFuture.done();
}
</code></pre>
<p>这里的执行逻辑可总结为如下：首先设置produceFuture的相关数据，包括基本位移、消息追加的时间、异常，这些数据都是给回调方法用的；然后，轮询thunks集合里的元素调用回调方法；最后，释放主线程的await()阻塞。</p>
<h2>总结</h2>
<p>这一讲我给大家讲解了RecordAccumlator整体流程，消息通过分区器判断属于哪个分区，然后发往缓存区中分区对应的队列中。对于源码的讲解，涉及了缓存存储底层的两个关键类MemoryRecords和MemoryRecordsBuilder，同时讲解了appendStream,bufferStream,ByteBuffer三者的关系。然后又讲了ProduceRequestResult、FutureRecordMetadata和RecordMetadata这三个类，这三个类在一起实现了收到响应后的回调方法。最后，给大家讲解了producerBatch如何缓存消息、如何处理响应，以及如何调用回调方法的。</p></div>
</body></html>
<!DOCTYPE html><html lang="en"><head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>第 01 讲：设计一份吸引面试官的简历</title>
<style type="text/css">
:root {
    --control-text-color: #777;
    --select-text-bg-color: rgba(223, 197, 223);  /*#7e66992e;*/
    
    /* side bar */
    --side-bar-bg-color: rgb(255, 255, 255);
    --active-file-text-color: #8163bd;
    --active-file-bg-color: #E9E4F0;
    --item-hover-bg-color: #E9E4F0;
    --active-file-border-color: #8163bd;

    --title-color: #6c549c;
    --font-sans-serif: 'Ubuntu', 'Source Sans Pro', sans-serif !important;
    --font-monospace: 'Fira Code', 'Roboto Mono', monospace !important;
    --purple-1: #8163bd;
    --purple-2: #79589F;
    --purple-3: #fd5eb8;
    --purple-light-1: rgba(99, 99, 172, .05);
    --purple-light-2: rgba(99, 99, 172, .1);
    --purple-light-3: rgba(99, 99, 172, .2);
    --purple-light-4: rgba(129, 99, 189, .3);
    --purple-light-5: #E9E4F0;
    --purple-light-6: rgba(129, 99, 189, .8);
}

/* html {
    font-size: 16px;
} */

body {
    font-family: var(--font-sans-serif);
    color: #34495e;
    -webkit-font-smoothing: antialiased;
    line-height: 1.6rem;
    letter-spacing: 0;
    margin: 0;
    overflow-x: hidden;
}

/* 页边距 和 页面大小 */
#write {
    padding-left: 6ch;
    padding-right: 6ch;
    margin: 0 auto;
}

#write p {
    line-height: 1.6rem;
    word-spacing: .05rem;
}

#write ol li {
    padding-left: 0.5rem;
}

#write > ul:first-child,
#write > ol:first-child {
    margin-top: 30px;
}

body > *:first-child {
    margin-top: 0 !important;
}

body > *:last-child {
    margin-bottom: 0 !important;
}

a {
    color: var(--purple-1);
    padding: 0 2px;
    text-decoration: none;
}
.md-content {
    color: var(--purple-light-6);
}
#write a {
    border-bottom: 1px solid var(--purple-1);
    color: var(--purple-1);
    text-decoration: none;
}

h1,
h2,
h3,
h4,
h5,
h6 {
    position: relative;
    margin-top: 1rem;
    margin-bottom: 0.5rem;
    /* font-weight: bold; */
    font-weight: 500 !important;
    line-height: 1.4;
    cursor: text;
    color: var(--title-color);
    font-family: var(--font-sans-serif);
}

h1:hover a.anchor,
h2:hover a.anchor,
h3:hover a.anchor,
h4:hover a.anchor,
h5:hover a.anchor,
h6:hover a.anchor {
    text-decoration: none;
}

h1 tt,
h1 code {
    font-size: inherit !important;
}
h2 tt,
h2 code {
    font-size: inherit !important;
}
h3 tt,
h3 code {
    font-size: inherit !important;
}
h4 tt,
h4 code {
    font-size: inherit !important;
}
h5 tt,
h5 code {
    font-size: inherit !important;
}
h6 tt,
h6 code {
    font-size: inherit !important;
}


h1 {
    padding-bottom: .4rem;
    font-size: 2.2rem;
    line-height: 1.3;
}
h1 {
    text-align: center;
    padding-bottom: 0.3em;
    font-size: 2.2em;
    line-height: 1.2;
    margin: 2.4em auto 1.2em;
}
h1:after {
    content: '';
    display: block;
    margin: 0.2em auto 0;
    width: 100px;
    height: 2px;
    border-bottom: 2px solid var(--title-color);
}

h2 {
    margin: 1.6em auto 0.5em;
    padding-left: 10px;
    line-height: 1.4;
    font-size: 1.8em;
    border-left: 9px solid var(--title-color);
    border-bottom: 1px solid var(--title-color);
}
h3 {
    font-size: 1.5rem;
    margin: 1.2em auto 0.5em;
}
h4 {
    font-size: 1.3rem;
}
h5 {
    font-size: 1.2rem;
}
h6 {
    font-size: 1.1rem;
}

p,
blockquote,
ul,
ol,
dl,
table {
    margin: 0.8em 0;
}

li > ol,
li > ul {
    margin: 0 0;
}

hr {
    height: 2px;
    padding: 0;
    margin: 16px 0;
    background-color: #e7e7e7;
    border: 0 none;
    overflow: hidden;
    box-sizing: content-box;
}

body > h2:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0;
}

body > h3:first-child,
body > h4:first-child,
body > h5:first-child,
body > h6:first-child {
    margin-top: 0;
    padding-top: 0;
}

a:first-child h1,
a:first-child h2,
a:first-child h3,
a:first-child h4,
a:first-child h5,
a:first-child h6 {
    margin-top: 0;
    padding-top: 0;
}

h1 p,
h2 p,
h3 p,
h4 p,
h5 p,
h6 p {
    margin-top: 0;
}

li p.first {
    display: inline-block;
}

ul,
ol {
    padding-left: 30px;
}

ul:first-child,
ol:first-child {
    margin-top: 0;
}

ul:last-child,
ol:last-child {
    margin-bottom: 0;
}

/* 引用 */
blockquote {
    /* margin-left: 1rem; */
    border-left: 4px solid var(--purple-light-4);
    padding: 10px 15px;
    color: #777;
    background-color: var(--purple-light-1);
}

/* 表格 */
table {
    padding: 0;
    word-break: initial;
}

table tr {
    border-top: 1px solid #dfe2e5;
    margin: 0;
    padding: 0;
}

/* 表格 背景色 */
table tr:nth-child(2n),
thead {
    background-color: var(--purple-light-1);
}
#write table thead th {
    background-color: var(--purple-light-2);
}

table tr th {
    font-weight: bold;
    border: 1px solid #dfe2e5;
    border-bottom: 0;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr td {
    border: 1px solid #dfe2e5;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr th:first-child,
table tr td:first-child {
    margin-top: 0;
}

table tr th:last-child,
table tr td:last-child {
    margin-bottom: 0;
}

/* 粗体 */
#write strong {
    padding: 0 2px;
    color: var(--purple-1);
}

/* 斜体 */
#write em {
    padding: 0 5px 0 2px;
    /* font-style: normal; */
    color: #42b983;
}

/* inline code */
#write code, tt {
    padding: 2px 4px;
    border-radius: 2px;
    font-family: var(--font-monospace);
    font-size: 0.92rem;
    color: var(--purple-3); 
    background-color: rgba(99, 99, 172, .05);
}

tt {
    margin: 0 2px;
}

#write .md-footnote {
    background-color: #f8f8f8;
    color: var(--purple-3);
}

/* heighlight. */
#write mark {
    background-color: #fbd3ea;
    border-radius: 2px;
    padding: 2px 4px;
    margin: 0 2px;
}

#write del {
    padding: 1px 2px;
}

.md-task-list-item > input {
    margin-left: -1.3em;
}

@media print {
    html {
        font-size: 0.9rem;
    }

    table,
    pre {
        page-break-inside: avoid;
    }

    pre {
        word-wrap: break-word;
    }
}

#write pre.md-meta-block {
    padding: 1rem;
    font-size: 85%;
    line-height: 1.45;
    background-color: #f7f7f7;
    border: 0;
    border-radius: 3px;
    color: #777777;
    margin-top: 0 !important;
}

.mathjax-block > .code-tooltip {
    bottom: .375rem;
}

/* 图片 */
.md-image > .md-meta {
    border-radius: 3px;
    font-family: var(--font-monospace);
    padding: 2px 0 0 4px;
    font-size: 0.9em;
    color: inherit;
}
p .md-image:only-child{
    width: auto;
    text-align: left;
    margin-left: 2rem;
}
.md-tag {
    color: inherit;
}
/* 当 “![shadow-随便写]()”写时，会有阴影 */
.md-image img[alt|='shadow'] {
    /* box-shadow: 0 4px 24px -6px #ddd; */
    box-shadow:var(--purple-light-2) 0px 10px 15px;
}

#write a.md-toc-inner {
    line-height: 1.6;
    white-space: pre-line;
    border-bottom: none;
    font-size: 0.9rem;
}

#typora-quick-open {
    border: 1px solid #ddd;
    background-color: #f8f8f8;
}

#typora-quick-open-item {
    background-color: #FAFAFA;
    border-color: #FEFEFE #e5e5e5 #e5e5e5 #eee;
    border-style: solid;
    border-width: 1px;
}

#md-notification:before {
    top: 10px;
}

header,
.context-menu,
.megamenu-content,
footer {
    font-family: var(--font-sans-serif);
}

.file-node-content:hover .file-node-icon,
.file-node-content:hover .file-node-open-state {
    visibility: visible;
}

.md-lang {
    color: #b4654d;
}

.html-for-mac .context-menu {
    --item-hover-bg-color: #E6F0FE;
}

/* 代码框 */
/* CodeMirror 3024 Day theme */

/* 代码段 背景 */
pre {
    --select-text-bg-color: rgba(223, 197, 223) !important;
    margin: .5em 0;
    padding: 1em 1.4em;
    border-radius: 8px;
    background: #f6f8fa;
    overflow-x: auto;
    box-sizing: border-box;
    font-size: 14px;
}

/* 边框 */
.md-fences {
    border: 1px solid #e7eaed;
    border-radius: 3px;
}

.cm-s-inner {
  padding: .25rem;
  border-radius: .25rem;
}

.cm-s-inner.CodeMirror, .cm-s-inner .CodeMirror-gutters {
  background-color: #f8f8f8 !important;
  color: #3a3432 !important;
  border: none;
}

.cm-s-inner .CodeMirror-gutters {
  color: #6d8a88;
}

.cm-s-inner .CodeMirror-cursor {
  border-left: solid thin #5c5855 !important;
}

.cm-s-inner .CodeMirror-linenumber {
  color: #807d7c;
}

.cm-s-inner .CodeMirror-line::selection, .cm-s-inner .CodeMirror-line::-moz-selection,
.cm-s-inner .CodeMirror-line > span::selection,
.cm-s-inner .CodeMirror-line > span::-moz-selection,
.cm-s-inner .CodeMirror-line > span > span::selection,
.cm-s-inner .CodeMirror-line > span > span::-moz-selection {
  background: var(--purple-light-2);
}

.cm-s-inner span.cm-comment {
  color: #cdab53;
}

.cm-s-inner span.cm-string, .cm-s-inner span.cm-string-2 {
  color: #f2b01d;
}

.cm-s-inner span.cm-number {
  color: #a34e8f;
}

.cm-s-inner span.cm-variable {
  color: #01a252;
}

.cm-s-inner span.cm-variable-2 {
  color: #01a0e4;
}

.cm-s-inner span.cm-def {
  /* color: #e8bbd0; */
  color: #e2287f;
}

.cm-s-inner span.cm-operator {
  color: #ff79c6;
}

.cm-s-inner span.cm-keyword {
  color: #db2d20;
}

.cm-s-inner span.cm-atom {
  color: #a34e8f;
}

.cm-s-inner span.cm-meta {
  color: inherit;
}

.cm-s-inner span.cm-tag {
  color: #db2d20;
}

.cm-s-inner span.cm-attribute {
  color: #01a252;
}

.cm-s-inner span.cm-qualifier {
  color: #388aa3;
}

.cm-s-inner span.cm-property {
  color: #01a252;
}

.cm-s-inner span.cm-builtin {
  color: #388aa3;
}

.cm-s-inner span.cm-variable-3, .cm-s-inner span.cm-type {
  color: #ffb86c;
}

.cm-s-inner span.cm-bracket {
  color: #3a3432;
}

.cm-s-inner span.cm-link {
  color: #a34e8f;
}

.cm-s-inner span.cm-error {
  background: #db2d20;
  color: #5c5855;
}

/* .md-fences.md-focus .cm-s-inner .CodeMirror-activeline-background {
  background: var(--purple-light-2);
} */

.cm-s-inner .CodeMirror-matchingbracket {
  text-decoration: underline;
  color: #a34e8f !important;
}

#fences-auto-suggest .active {
  background: #ddd;
}

#write .code-tooltip {
  bottom: initial;
  top: calc(100% - 1px);
  background: #f7f7f7;
  border: 1px solid #ddd;
  border-top: 0;
}

.auto-suggest-container {
  border-color: #b4b4b4;
}

.auto-suggest-container .autoComplt-hint.active {
  background: #b4b4b4;
  color: inherit;
}

/* task list */
#write .md-task-list-item > input {
  -webkit-appearance: initial;
  display: block;
  position: absolute;
  border: 1px solid #b4b4b4;
  border-radius: .25rem;
  margin-top: .1rem;
  margin-left: -1.8rem;
  height: 1.2rem;
  width: 1.2rem;
  transition: background 0.3s;
}

#write .md-task-list-item > input:focus {
  outline: none;
  box-shadow: none;
}

#write .md-task-list-item > input:hover {
  background: #ddd;
}

#write .md-task-list-item > input[checked]::before {
  content: '';
  position: absolute;
  top: 20%;
  left: 50%;
  height: 60%;
  width: 2px;
  transform: rotate(40deg);
  background: #333;
}

#write .md-task-list-item > input[checked]::after {
  content: '';
  position: absolute;
  top: 46%;
  left: 25%;
  height: 30%;
  width: 2px;
  transform: rotate(-40deg);
  background: #333;
}

#write .md-task-list-item > p {
  transition: color 0.3s, opacity 0.3s;
}

#write .md-task-list-item.task-list-done > p {
  color: #b4b4b4;
  text-decoration: line-through;
}

#write .md-task-list-item.task-list-done > p > .md-emoji {
  opacity: .5;
}

#write .md-task-list-item.task-list-done > p > .md-link > a {
  opacity: .6;
}

/* sidebar and outline */
.pin-outline .outline-active {
  color: var(--active-file-text-color); 
}

.file-list-item {
    border-bottom: 1px solid;
    border-color: var(--purple-light-5);
}

.file-list-item-summary {
    font-weight: 400;
}

.file-list-item.active {
    color: var(--active-file-text-color);
    background-color: var(--purple-light-5);
}

.file-tree-node.active>.file-node-background {
    background-color: var(--purple-light-5);
    font-weight: 700;
} 

.file-tree-node.active>.file-node-content {
    color: var(--active-file-text-color);
    font-weight: 700;
}

.file-node-content {
    color: #5e676d;
}

.sidebar-tabs {
    border-bottom: none;
}
.sidebar-tab.active {
    font-weight: 400;
}

.sidebar-content-content {
    font-size: 0.9rem;
}

img {
    max-width: 100%;
}

body {
    background-color: rgb(237, 237, 237);
}
#content {
    width: 836px;
    padding: 50px;
    background: #fff;
    margin: 0 auto;
}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/purple.css*/</style><style type="text/css">.hljs{display:block;overflow-x:auto;padding:.5em;color:#383a42;background:#fafafa}.hljs-comment,.hljs-quote{color:#a0a1a7;font-style:italic}.hljs-doctag,.hljs-formula,.hljs-keyword{color:#a626a4}.hljs-deletion,.hljs-name,.hljs-section,.hljs-selector-tag,.hljs-subst{color:#e45649}.hljs-literal{color:#0184bb}.hljs-addition,.hljs-attribute,.hljs-meta-string,.hljs-regexp,.hljs-string{color:#50a14f}.hljs-built_in,.hljs-class .hljs-title{color:#c18401}.hljs-attr,.hljs-number,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-pseudo,.hljs-template-variable,.hljs-type,.hljs-variable{color:#986801}.hljs-bullet,.hljs-link,.hljs-meta,.hljs-selector-id,.hljs-symbol,.hljs-title{color:#4078f2}.hljs-emphasis{font-style:italic}.hljs-strong{font-weight:700}.hljs-link{text-decoration:underline}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/atom-one-light.min.css*/</style></head>
<body>
<div id="content"><h1>简介 Message 的家 ：存储层简介和日志读写的大体流程</h1>
<p>从今天开始，我们就来讲解Kafka服务端的存储层，首先我们需要介绍一下服务端存储层的相关概念。</p>
<h2>服务端存储层总体介绍</h2>
<p>服务端的存储层是很复杂的，为了让你在总体上有一个了解，我们先从服务端存储层的总体结构入手。</p>
<h3>服务端存储层的总体结构</h3>
<p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/aa17130427c44b0b915e6b1537d8ca1b~tplv-k3u1fbpfcp-watermark.image?" alt="kafka服务端集群架构.png"></p>
<p>涉及到 Kafka 服务端存储层的概念主要有以下几个。</p>
<ul>
<li>
<p>broker。Kafka 集群中包含的服务器，一个 broker 表示 Kafka 集群中的一个节点。</p>
</li>
<li>
<p>topic。每条发布到 Kafka 集群的消息属于的类别，即 Kafka 是面向 topic 的。</p>
</li>
<li>
<p>partition。这里主要包括以下两个要点：</p>
</li>
</ul>
<ol>
<li>每个topic包含一个或多个partition，其中1个partition是leader，其他的partition是follower。</li>
<li>leader partition负责数据的读写，Follower Partition负责从Leader Partition同步数据。</li>
</ol>
<ul>
<li>replica。一个topic有很多分区，每个分区可以设置多个副本，用来保证数据的安全性。</li>
</ul>
<p>好，服务端存储层的大体有哪些组成基本介绍完了，现在我们重点学习一下日志在服务端是如何存储的。</p>
<h3>日志存储方式</h3>
<p>Kafka使用日志文件的方式保存生产者发送的消息。每条消息都有一个offset值来表示它在分区中的偏移量，这个offset值是逻辑值，并不是消息实际存放的物理地址。offset值类似于数据库表中的主键，主键唯一确定了数据库表中的一条记录， offset 唯一确定了分区中的一条消息。</p>
<p>Kafka 存储机制在逻辑上如下图所示：</p>
<p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/50398acb51bb4806a1519c4757ecd2fc~tplv-k3u1fbpfcp-watermark.image?" alt="日志存储结构.png"></p>
<p>为了提高写入的性能，同一个分区中的消息是顺序写入的，这就避免了随机写入带来的性能问题。一个 Topic 可以划分成多个分区，而每个分区又有多个副本。当一个分区的副本被划分到某个Broker上时，Kafka就要在此Broker上为此分区建立相应的Log，而生产者发送的消息会存储在Log中，供消费者拉取后消费。</p>
<p>Kafka 中存储的一般都是海量消息数据，为了避免日志文件太大，Log并不是直接对应于磁盘上的一个日志文件，而是对应磁盘上的一个目录，这个目录的命名规则是<code>&#x3C;topic_name>+下划线+&#x3C;partition_id></code>，Log与分区之间的关系是一一对应的，对应分区中的全部消息都存储在此目录下的日志文件中。</p>
<p>Kafka 通过分段的方式将 Log 分为多个LogSegment，LogSegment是一个逻辑上的概念，一个LogSegment对应磁盘上的一个日志文件和一个索引文件，其中日志文件用于记录消息，索引文件中保存了消息的索引。随着消息的不断写入，日志文件的大小到达一个阈值时，就创建新的日志文件和索引文件继续写入后续的消息和索引信息。日志文件的文件名的命名规则是<code>[baseOffset].log</code>，baseOffset 是日志文件中第一条消息的offset。</p>
<p>下图是一个 Log 的结构：</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/458612fb4b30415b8506a669cf4f25eb~tplv-k3u1fbpfcp-watermark.image?" alt="Log结构.png"></p>
<p>为了提高查询消息的效率，每个日志文件都对应一个索引文件，这个索引文件并没有为每条消息都建立索引项，而是使用稀疏索引方式为日志文件中的部分消息建立了索引。下图展示了索引文件与日志文件之间的对应关系。</p>
<h3>副本管理类 ReplicaManager</h3>
<p>对于日志管理的相关组件和类以及他们之间的关系如下图所示:</p>
<p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6b3907fdd0d144f89dc114f1a806d04e~tplv-k3u1fbpfcp-watermark.image?" alt="log存储的组件.png"></p>
<p>对于服务端代码的分析，我的方法是<code>自顶向下</code>的讲解。你可以看到最上面的组件是 ReplicaManager，<strong>ReplicaManager功能是负责对一个broker上所有副本的管理</strong>。</p>
<p>好，接下来我开始解析日志管理的相关组件最上层的类ReplicaManager的源码，让你对整个日志管理有个总体的认识。</p>
<p>ReplicaManager这个类的作用是管理broker中所有的分区副本，其中最重要的两个功能是读取副本对象和写入副本对象，这节我们主要分析读写日志这里两个功能，其他的功能后面几节会给你继续讲解的。</p>
<p>ReplicaManager依赖于日志存储子系统、DelayedOperationPurgarory、KafkaScheduler等组件，底层依赖于Partition和Replica，这些在后面我都会给你介绍。这里我们先从服务端接到读写日志请求的地方开始讲解。</p>
<h3>生产者写消息时，服务端是如何处理的？</h3>
<p>这个过程离不开我们在服务端网络层介绍的KafkaApis类，对应的方法是sendResponseCallback()，我们可以截取相关对应的代码进行分析。</p>
<p>我们还是要从KafkaApis这个类的handle()方法看：</p>
<pre><code>override def handle(request: RequestChannel.Request): Unit = {
try {
trace(s"Handling request:${request.requestDesc(true)} from connection ${request.context.connectionId};" +

s"securityProtocol:${request.context.securityProtocol},principal:${request.context.principal}")

request.header.apiKey match {

case ApiKeys.PRODUCE => handleProduceRequest(request)

case ApiKeys.FETCH => handleFetchRequest(request)
</code></pre>
<p>可以看到对应 PRODUCE 请求调用的方法 handleProduceRequest()，那handleProduceRequest()做了什么呢？</p>
<pre><code>def handleProduceRequest(request: RequestChannel.Request): Unit = {

......省略

// 把接收到的消息追加到磁盘文件中。

replicaManager.appendRecords(

timeout = produceRequest.timeout.toLong,

requiredAcks = produceRequest.acks,

internalTopicsAllowed = internalTopicsAllowed,

origin = AppendOrigin.Client,

entriesPerPartition = authorizedRequestInfo,

responseCallback = sendResponseCallback,//传入发送响应回调方法。把响应添加到响应队列中。

recordConversionStatsCallback = processingStatsCallback)
}
}
</code></pre>
<p>也就是说会调用replicaManager.appendRecords()方法把消息记录写到磁盘中。那么好，我们继续看看replicaManager.appendRecords()方法都做了什么工作。</p>
<h4>对于写消息流程的大体分析</h4>
<pre><code>def appendRecords(timeout: Long,

// 是否需要等待其他副本写入。

// 对于生产者而言，它就是 acks 参数的值。

requiredAcks: Short,

// 是否允许写入内部主题。

internalTopicsAllowed: Boolean,

// 写入方来源,3 类写入方，分别是 Replication、Coordinator 和 Client。

//Client 表示本次写入由客户端发起。前面我们说过了，Follower 副本同步过程不调用 appendRecords 方法，因此，这里的 origin 值只可能是 Replication 或 Coordinator。

origin: AppendOrigin,

//按分区分组的、实际要写入的消息集合。

entriesPerPartition: Map[TopicPartition, MemoryRecords],

//写入成功之后，要调用的回调逻辑函数。

responseCallback: Map[TopicPartition, PartitionResponse] => Unit,

//专门用来保护消费者组操作线程安全的锁对象，在其他场景中用不到。

delayedProduceLock: Option[Lock] = None,

recordConversionStatsCallback: Map[TopicPartition, RecordConversionStats] => Unit = _ => ()): Unit = {

// 第一步：requiredAcks合法取值是-1，0，1，否则视为非法

if (isValidRequiredAcks(requiredAcks)) {

val sTime = time.milliseconds

// 第二步：调用appendToLocalLog方法写入消息集合到本地日志

val localProduceResults = appendToLocalLog(internalTopicsAllowed = internalTopicsAllowed,

origin, entriesPerPartition, requiredAcks)

debug("Produce to local log in %d ms".format(time.milliseconds - sTime))

//第三步：根据写日志返回的结果，封装返回给客户端的响应。

val produceStatus = localProduceResults.map { case (topicPartition, result) =>

topicPartition ->

ProducePartitionStatus(

result.info.lastOffset + 1,

// 设置下一条待写入消息的位移值

// 构建PartitionResponse封装写入结果

new PartitionResponse(result.error, result.info.firstOffset.getOrElse(-1), result.info.logAppendTime,

result.info.logStartOffset, result.info.recordErrors.asJava, result.info.errorMessage)) // response status

}

actionQueue.add {

() =>

localProduceResults.foreach {

case (topicPartition, result) =>

val requestKey = TopicPartitionOperationKey(topicPartition)

result.info.leaderHwChange match {

case LeaderHwChange.Increased =>

delayedProducePurgatory.checkAndComplete(requestKey)

delayedFetchPurgatory.checkAndComplete(requestKey)

delayedDeleteRecordsPurgatory.checkAndComplete(requestKey)

case LeaderHwChange.Same =>

delayedFetchPurgatory.checkAndComplete(requestKey)

case LeaderHwChange.None =>

// nothing

}

}

}

// 尝试更新消息格式转换的指标数据

recordConversionStatsCallback(localProduceResults.map { case (k, v) => k -> v.info.recordConversionStats })

// 第四步：需要等待其他副本完成写入

//如果acks是-1，需要所有副本都保存了消息才能返回客户端。

if (delayedProduceRequestRequired(requiredAcks, entriesPerPartition, localProduceResults)) {

// create delayed produce operation

val produceMetadata = ProduceMetadata(requiredAcks, produceStatus)

// 创建 DelayedProduce 延时请求对象

val delayedProduce = new DelayedProduce(timeout, produceMetadata, this, responseCallback, delayedProduceLock)

// 遍历有哪些topic需要检查延迟操作是否完成。

val producerRequestKeys = entriesPerPartition.keys.map(TopicPartitionOperationKey(_)).toSeq

// 再一次尝试完成该延时请求

// 如果暂时无法完成，则将对象放入到相应的Purgatory中等待后续处理

// try to complete the request immediately, otherwise put it into the purgatory

// this is because while the delayed produce operation is being created, new

// requests may arrive and hence make this operation completable.

delayedProducePurgatory.tryCompleteElseWatch(delayedProduce, producerRequestKeys)

} else {

// we can respond immediately 不需要等待直接返回

val produceResponseStatus = produceStatus.map { case (k, status) => k -> status.responseStatus }

//第五步：调用回调方法

responseCallback(produceResponseStatus)

}

// 构造INVALID_REQUIRED_ACKS异常并封装进回调函数调用中，acks参数不合法的处理。

} else {

// If required.acks is outside accepted range, something is wrong with the client

// Just return an error and don't handle the request at all

//封装acks参数异常的响应，生产者会受到异常响应。

val responseStatus = entriesPerPartition.map { case (topicPartition, _) =>

topicPartition -> new PartitionResponse(Errors.INVALID_REQUIRED_ACKS,

LogAppendInfo.UnknownLogAppendInfo.firstOffset.getOrElse(-1), RecordBatch.NO_TIMESTAMP, LogAppendInfo.UnknownLogAppendInfo.logStartOffset)

}

//调用回调方法

responseCallback(responseStatus)

}

}

</code></pre>
<p>首先，我们先看一下这个方法的一些重要参数。</p>
<h5>重要参数</h5>
<ul>
<li>
<p>requiredAcks：对于生产者而言，它就是 acks 参数的值。而在其他场景中，Kafka 默认使用 -1，表示等待其他副本全部写入成功再返回。这个参数的另一个含义是是否等待其他副本的写入再返回给生产者，目的是保证消息的可靠性。</p>
</li>
<li>
<p>internalTopicsAllowed：是否允许写入内部主题。所谓内部主题是为了维护消费者消费的offset，前面的章节有介绍，这里就不详细说明了。</p>
</li>
<li>
<p>AppendOrigin：写入方来源，有3类写入方，分别是 Replication、Coordinator 和 Client。Client表示本次写入由客户端发起；Replication表示Follower副本从Leader副本同步消息；Coordinator表示group coordinator发起的向内部主题__consumer_offsets的消息的追加，用来保存消费者消费的offset。</p>
</li>
<li>
<p>entriesPerPartition：按分区分组的、实际要写入的消息集合。</p>
</li>
<li>
<p>responseCallback：写入成功之后，要调用的回调逻辑函数。</p>
</li>
</ul>
<h5>方法体的解析</h5>
<p>第一步：requiredAcks合法取值是-1、0、1，否则视为非法，因为生产者只会发送这三个参数，如果不是这三个参数说明有问题。参数的意义就不具体说明了，前面的章节都有介绍。</p>
<p>第二步：调用appendToLocalLog方法写入消息集合到本地日志。具体是调用方法appendToLocalLog()来实现消息在本地log文件的存储，这个方法的具体实现会给你介绍。</p>
<p>第三步：根据写日志返回的结果，封装返回给客户端的响应。响应包括下一条待写入消息的位移以及消息写入对应分区的结果类PartitionResponse。</p>
<p>第四步：需要等待其他副本完成写入。因为如果Acks是-1，表示所有的副本都要同步消息，这样的话就需要等待其他副本同步成功。Kafka服务端在处理客户端的一些请求时，如果不能及时返回响应结果给客户端，会在服务端创建一个延迟操作的对象（DelayedOperation），并放在延迟缓存中（DelayedOperationPurgatory）。kafka的延迟操作有很多种：延迟生产，延迟响应，延迟加入，延迟心跳等。然后创建DelayedProduce对象，超过timeout时间后这个操作会被认定为超时，并立刻返回，发送响应给客户端。</p>
<p>第五步：遍历有哪些topic需要检查延迟操作是否完成，然后尝试完成该延时请求，如果暂时无法完成，则将对象放入到相应的Purgatory中等待后续处理。</p>
<p>第六步：调用回调方法，完成整个消息写入的流程。</p>
<p>好，整体流程就给你介绍完了，下面重点给你介绍一下把消息追加到本地leader分区副本的方法appendToLocalLog()。</p>
<h4>消息是如何追加到本地leader分区副本的？</h4>
<pre><code>
/**

* 把消息追加到本地leader副本日志中。

*/

private def appendToLocalLog(internalTopicsAllowed: Boolean,

origin: AppendOrigin,

entriesPerPartition: Map[TopicPartition, MemoryRecords],

requiredAcks: Short): Map[TopicPartition, LogAppendResult] = {

val traceEnabled = isTraceEnabled

def processFailedRecord(topicPartition: TopicPartition, t: Throwable) = {

val logStartOffset = getPartition(topicPartition) match {

case HostedPartition.Online(partition) => partition.logStartOffset

case HostedPartition.None | HostedPartition.Offline => -1L

}

brokerTopicStats.topicStats(topicPartition.topic).failedProduceRequestRate.mark()

brokerTopicStats.allTopicsStats.failedProduceRequestRate.mark()

error(s"Error processing append operation on partition $topicPartition", t)

logStartOffset

}

if (traceEnabled)

trace(s"Append [$entriesPerPartition] to local log")

//第一步：遍历分区及分区对应的消息数据,一个分区一个分区的写消息集合。

entriesPerPartition.map { case (topicPartition, records) =>

brokerTopicStats.topicStats(topicPartition.topic).totalProduceRequestRate.mark()

brokerTopicStats.allTopicsStats.totalProduceRequestRate.mark()

// reject appending to internal topics if it is not allowed

// 第二步：是否是内部主题__consumer_offsets

if (Topic.isInternal(topicPartition.topic) &#x26;&#x26; !internalTopicsAllowed) {

(topicPartition, LogAppendResult(

LogAppendInfo.UnknownLogAppendInfo,

Some(new InvalidTopicException(s"Cannot append to internal topic ${topicPartition.topic}"))))

} else {

//第三步：正常业务的topic要走的逻辑

try {

// 获取分区对象

val partition = getPartitionOrException(topicPartition)

// 向该分区对象写入消息集合，一个分区一个分区的写

val info = partition.appendRecordsToLeader(records, origin, requiredAcks)

// 返回写入了多少条数据。

val numAppendedMessages = info.numMessages

// 第四步：更新统计数据。

brokerTopicStats.topicStats(topicPartition.topic).bytesInRate.mark(records.sizeInBytes)

brokerTopicStats.allTopicsStats.bytesInRate.mark(records.sizeInBytes)

brokerTopicStats.topicStats(topicPartition.topic).messagesInRate.mark(numAppendedMessages)

brokerTopicStats.allTopicsStats.messagesInRate.mark(numAppendedMessages)

if (traceEnabled)

trace(s"${records.sizeInBytes} written to log $topicPartition beginning at offset " +

s"${info.firstOffset.getOrElse(-1)} and ending at offset ${info.lastOffset}")

// 第五步：返回写入结果

(topicPartition, LogAppendResult(info))

} catch {

// 第六步：找不到主题或分区异常，没有主分区或从分区异常。

case e@ (_: UnknownTopicOrPartitionException |

_: NotLeaderOrFollowerException |

_: RecordTooLargeException |

_: RecordBatchTooLargeException |

_: CorruptRecordException |

_: KafkaStorageException) =>

(topicPartition, LogAppendResult(LogAppendInfo.UnknownLogAppendInfo, Some(e)))

case rve: RecordValidationException =>

val logStartOffset = processFailedRecord(topicPartition, rve.invalidException)

val recordErrors = rve.recordErrors

(topicPartition, LogAppendResult(LogAppendInfo.unknownLogAppendInfoWithAdditionalInfo(

logStartOffset, recordErrors, rve.invalidException.getMessage), Some(rve.invalidException)))

case t: Throwable =>

val logStartOffset = processFailedRecord(topicPartition, t)

(topicPartition, LogAppendResult(LogAppendInfo.unknownLogAppendInfoWithLogStartOffset(logStartOffset), Some(t)))

}

}

}

}

</code></pre>
<h5>重点参数</h5>
<p>重点参数就一个entriesPerPartition，其他的参数上面都给你介绍过了。</p>
<ul>
<li><code>entriesPerPartition: Map[TopicPartition, MemoryRecords]</code>：要写入的分区及对应的消息数据。TopicPartition指要追加的分区，MemoryRecords指要追加的批量消息。</li>
</ul>
<h5>方法体的讲解</h5>
<p>第一步：遍历分区及分区对应的消息数据，一个分区一个分区的写消息集合。方法执行一次会同时向多个分区追加消息，所以会遍历所有要追加的分区并把要追加的记录追加到分区尾部。</p>
<p>第二步：是否是内部主题__consumer_offsets并允许追加内部主题__consumer_offsets的分区。因为有的broker可能不适于保存主题__consumer_offsets，这时可以设置不保存内部主题，所以这里需要一个判断。</p>
<p>第三步：正常业务的topic要走的逻辑。包括：1.获取分区对象；2.向该分区对象写入消息集合，一个分区一个分区地写；3.写完后，返回写入了多少条数据。</p>
<p>第四步：更新统计数据。如追加成功了多少条消息，追加成功消息的字节数。</p>
<p>第五步：返回写入结果。</p>
<p>第六步：异常处理，比如，找不到主题或分区异常，没有主分区或从分区异常，等等。</p>
<p>到这里，消息是如何写入broker的大体流程就介绍完了。那么，消费者或follow副本是如何从leader副本获取消息的呢？这就是拉取消息的流程了。</p>
<h3>消费者或follow副本是如何读取消息的？</h3>
<p>我们还是要从KafkaApis这个类的handle()方法看：</p>
<pre><code>override def handle(request: RequestChannel.Request): Unit = {

try {

trace(s"Handling request:${request.requestDesc(true)} from connection ${request.context.connectionId};" +

s"securityProtocol:${request.context.securityProtocol},principal:${request.context.principal}")

request.header.apiKey match {

case ApiKeys.PRODUCE => handleProduceRequest(request)

case ApiKeys.FETCH => handleFetchRequest(request)

</code></pre>
<p>可以看到对应Fetch请求调用的方法handleFetchRequest()，那我们再看一下handleFetchRequest()做了什么？</p>
<pre><code class="hljs language-/**">
* Handle a fetch request

* 处理获取消息的请求。

*/

def handleFetchRequest(request: RequestChannel.Request): Unit = {

......省略。

if (interesting.isEmpty)

processResponseCallback(Seq.empty)

else {

replicaManager.fetchMessages(

fetchRequest.maxWait.toLong,

fetchRequest.replicaId,

fetchMinBytes,

fetchMaxBytes,

versionId &#x3C;= 2,

interesting,

replicationQuota(fetchRequest),

processResponseCallback,

fetchRequest.isolationLevel,

clientMetadata)

}

}
</code></pre>
<p>可以看到还是调用了<code>ReplicaManager</code>类的相关方法，那么我们只要分析replicaManager.fetchMessages()方法就可以了。</p>
<h4>对于获取消息流程的大体分析</h4>
<pre><code>
/**

* Broker 端接收到该请求后，调用 fetchMessages 方法从底层的 Leader 副本取出消息。

*/

def fetchMessages(timeout: Long,

replicaId: Int,

fetchMinBytes: Int,

fetchMaxBytes: Int,

hardMaxBytesLimit: Boolean,

fetchInfos: Seq[(TopicPartition, PartitionData)],

quota: ReplicaQuota,

responseCallback: Seq[(TopicPartition, FetchPartitionData)] => Unit,

isolationLevel: IsolationLevel,

clientMetadata: Option[ClientMetadata]): Unit = {

// 第一步： 验证请求者的种类，以及获取消息的隔离级别

val isFromFollower = Request.isValidBrokerId(replicaId)

val isFromConsumer = !(isFromFollower || replicaId == Request.FutureLocalReplicaId)

val fetchIsolation = if (!isFromConsumer)

FetchLogEnd

else if (isolationLevel == IsolationLevel.READ_COMMITTED)

FetchTxnCommitted

else

FetchHighWatermark

// 拉取

val fetchOnlyFromLeader = isFromFollower || (isFromConsumer &#x26;&#x26; clientMetadata.isEmpty)

// 第二步：定义读取本地日志的方法

def readFromLog(): Seq[(TopicPartition, LogReadResult)] = {

val result = readFromLocalLog(

replicaId = replicaId,

fetchOnlyFromLeader = fetchOnlyFromLeader,

fetchIsolation = fetchIsolation,

fetchMaxBytes = fetchMaxBytes,

hardMaxBytesLimit = hardMaxBytesLimit,

readPartitionInfo = fetchInfos,

quota = quota,

clientMetadata = clientMetadata)

if (isFromFollower) updateFollowerFetchState(replicaId, result)

else result

}

// 第三步：调用读取本地日志的方法，并返回读取日志的结果。

val logReadResults = readFromLog()

var bytesReadable: Long = 0

var errorReadingData = false

var hasDivergingEpoch = false

val logReadResultMap = new mutable.HashMap[TopicPartition, LogReadResult]

logReadResults.foreach { case (topicPartition, logReadResult) =>

brokerTopicStats.topicStats(topicPartition.topic).totalFetchRequestRate.mark()

brokerTopicStats.allTopicsStats.totalFetchRequestRate.mark()

if (logReadResult.error != Errors.NONE)

errorReadingData = true

if (logReadResult.divergingEpoch.nonEmpty)

hasDivergingEpoch = true

bytesReadable = bytesReadable + logReadResult.info.records.sizeInBytes

logReadResultMap.put(topicPartition, logReadResult)

}

// 第四步: 根据读取日志的结果，判断是否要立即返回给客户端

if (timeout &#x3C;= 0 || fetchInfos.isEmpty || bytesReadable >= fetchMinBytes || errorReadingData || hasDivergingEpoch) {

val fetchPartitionData = logReadResults.map { case (tp, result) =>

val isReassignmentFetch = isFromFollower &#x26;&#x26; isAddingReplica(tp, replicaId)

tp -> FetchPartitionData(

result.error,

result.highWatermark,

result.leaderLogStartOffset,

result.info.records,

result.divergingEpoch,

result.lastStableOffset,

result.info.abortedTransactions,

result.preferredReadReplica,

isReassignmentFetch)

}

responseCallback(fetchPartitionData)

} else {

// 第五步: 如果无法立即完成请求,就要延迟处理了

val fetchPartitionStatus = new mutable.ArrayBuffer[(TopicPartition, FetchPartitionStatus)]

fetchInfos.foreach { case (topicPartition, partitionData) =>

logReadResultMap.get(topicPartition).foreach(logReadResult => {

val logOffsetMetadata = logReadResult.info.fetchOffsetMetadata

fetchPartitionStatus += (topicPartition -> FetchPartitionStatus(logOffsetMetadata, partitionData))

})

}

val fetchMetadata: SFetchMetadata = SFetchMetadata(fetchMinBytes, fetchMaxBytes, hardMaxBytesLimit,

fetchOnlyFromLeader, fetchIsolation, isFromFollower, replicaId, fetchPartitionStatus)

val delayedFetch = new DelayedFetch(timeout, fetchMetadata, this, quota, clientMetadata,

responseCallback)

// 构建DelayedFetch延时请求对象

val delayedFetchKeys = fetchPartitionStatus.map { case (tp, _) => TopicPartitionOperationKey(tp) }

delayedFetchPurgatory.tryCompleteElseWatch(delayedFetch, delayedFetchKeys)

}

}

</code></pre>
<p>不论是 Java 消费者 API，还是 Follower 副本，它们拉取消息的主要途径都是向 Broker 发送 FETCH 请求，而上述这个方法就是来处理fetch请求的。我们来具体分析一下这个大体的流程。</p>
<p>第一步：验证请求者的种类，以及获取消息的隔离级别。</p>
<p>第二步：定义读取本地日志的方法。本质上底层还是调用了方法readFromLocalLog()。方法readFromLocalLog()的具体解析会在后面介绍。</p>
<p>第三步：调用读取本地日志的方法，并返回读取日志的结果。</p>
<p>第四步：根据读取日志的结果，判断是否要立即返回给客户端。因为出于性能的考虑，broker并不是获取一条消息就返回给消费者或follower副本的，而是批量返回，具体什么时候返回呢？只要满足下面 5 个条件之一就可以了：</p>
<ol>
<li>fetch请求等待超时，默认是500ms；</li>
<li>fetch请求不要求任何数据，没有数据要求自然可以立即返回；</li>
<li>数据量够了需要响应，也就是说批量的大小满足了返回的条件；</li>
<li>读数据时，出现了一些错误；</li>
<li>离散的epoch。</li>
</ol>
<p>第五步：如果无法立即完成请求，就要延迟处理了。</p>
<h4>消息是如何从本地 leader 分区副本读取的？</h4>
<p>消息从本地leader分区读取消息主要是调用方法readFromLocalLog()，接下来我们重点分析方法readFromLocalLog()的代码。readFromLocalLog方法会遍历要读取的分区循环调用内部方法read（），源码如下：</p>
<pre><code>
/**

* 用给定分区的offset，从多个主题分区读取消息，直到消息的大小满足设定的最大的值maxSize。

*/

def readFromLocalLog(replicaId: Int,// 要读取的replicaId。

fetchOnlyFromLeader: Boolean,//是否只从leader 分区读取。

fetchIsolation: FetchIsolation,// 获取隔离级别

fetchMaxBytes: Int,// 获取消息的大小

hardMaxBytesLimit: Boolean,

readPartitionInfo: Seq[(TopicPartition, PartitionData)],//读哪些分区，从哪个offset开始读取

quota: ReplicaQuota,

clientMetadata: Option[ClientMetadata]): Seq[(TopicPartition, LogReadResult)] = {

val traceEnabled = isTraceEnabled

// 真正负责读取的内部方法。

def read(tp: TopicPartition, fetchInfo: PartitionData, limitBytes: Int, minOneMessage: Boolean): LogReadResult = {

// 第一步，获取要获取消息的关键参数，读哪个分区，获取消息大小等。

val offset = fetchInfo.fetchOffset

val partitionFetchSize = fetchInfo.maxBytes

val followerLogStartOffset = fetchInfo.logStartOffset

val adjustedMaxBytes = math.min(fetchInfo.maxBytes, limitBytes)

try {

if (traceEnabled)

trace(s"Fetching log segment for partition $tp, offset $offset, partition fetch size $partitionFetchSize, " +

s"remaining response limit $limitBytes" +

(if (minOneMessage) s", ignoring response/partition size limits" else ""))

val partition = getPartitionOrException(tp)

val fetchTimeMs = time.milliseconds

// 第二步，判断哪个副本是最优的副本。kafka从2.4开始支持从 读取效果最好的分区（包括follower 分区）读取消息，这样能提升读取效率。

val preferredReadReplica = clientMetadata.flatMap(

metadata => findPreferredReadReplica(partition, metadata, replicaId, fetchInfo.fetchOffset, fetchTimeMs))

// 第三步，如果要从follower副本读取，那么就给客户端返回follower副本的信息。

if (preferredReadReplica.isDefined) {

replicaSelectorOpt.foreach { selector =>

debug(s"Replica selector ${selector.getClass.getSimpleName} returned preferred replica " +

s"${preferredReadReplica.get} for $clientMetadata")

}

val offsetSnapshot = partition.fetchOffsetSnapshot(fetchInfo.currentLeaderEpoch, fetchOnlyFromLeader = false)

LogReadResult(info = FetchDataInfo(LogOffsetMetadata.UnknownOffsetMetadata, MemoryRecords.EMPTY),

divergingEpoch = None,

highWatermark = offsetSnapshot.highWatermark.messageOffset,

leaderLogStartOffset = offsetSnapshot.logStartOffset,

leaderLogEndOffset = offsetSnapshot.logEndOffset.messageOffset,

followerLogStartOffset = followerLogStartOffset,

fetchTimeMs = -1L,

lastStableOffset = Some(offsetSnapshot.lastStableOffset.messageOffset),

preferredReadReplica = preferredReadReplica,

exception = None)

} else {

// 第四步：如果是调用leader副本，那么就调用底层的partition.readRecords()读取本地的消息。

val readInfo: LogReadInfo = partition.readRecords(

lastFetchedEpoch = fetchInfo.lastFetchedEpoch,

fetchOffset = fetchInfo.fetchOffset,

currentLeaderEpoch = fetchInfo.currentLeaderEpoch,

maxBytes = adjustedMaxBytes,

fetchIsolation = fetchIsolation,

fetchOnlyFromLeader = fetchOnlyFromLeader,

minOneMessage = minOneMessage)

val fetchDataInfo = if (shouldLeaderThrottle(quota, partition, replicaId)) {

FetchDataInfo(readInfo.fetchedData.fetchOffsetMetadata, MemoryRecords.EMPTY)

} else if (!hardMaxBytesLimit &#x26;&#x26; readInfo.fetchedData.firstEntryIncomplete) {

FetchDataInfo(readInfo.fetchedData.fetchOffsetMetadata, MemoryRecords.EMPTY)

} else {

readInfo.fetchedData

}

// 第五步：构建日志读取结构。

LogReadResult(info = fetchDataInfo,

divergingEpoch = readInfo.divergingEpoch,

highWatermark = readInfo.highWatermark,

leaderLogStartOffset = readInfo.logStartOffset,

leaderLogEndOffset = readInfo.logEndOffset,

followerLogStartOffset = followerLogStartOffset,

fetchTimeMs = fetchTimeMs,

lastStableOffset = Some(readInfo.lastStableOffset),

preferredReadReplica = preferredReadReplica,

exception = None)

}

} catch {
//......省略

}

}

var limitBytes = fetchMaxBytes

val result = new mutable.ArrayBuffer[(TopicPartition, LogReadResult)]

var minOneMessage = !hardMaxBytesLimit

//循环调用read()方法，获取每个分区的日志，

readPartitionInfo.foreach { case (tp, fetchInfo) =>

val readResult = read(tp, fetchInfo, limitBytes, minOneMessage)

val recordBatchSize = readResult.info.records.sizeInBytes

if (recordBatchSize > 0)

minOneMessage = false

limitBytes = math.max(0, limitBytes - recordBatchSize)

result += (tp -> readResult)

}

result

}

</code></pre>
<p>整个步骤可梳理为如下。</p>
<p>第一步，在 read（）方法中获取要获取消息的关键参数，比如读哪个分区、获取消息的大小等。</p>
<p>第二步，判断哪个副本是最优的副本。Kafka从2.4开始支持从读取效果最好的分区（包括follower 分区）读取消息，这样能提升读取效率。</p>
<p>第三步，如果要从follower副本读取，那么就给客户端返回follower副本的信息。</p>
<p>第四步，如果是调用leader副本，那么就调用底层的partition.readRecords()读取本地的消息。</p>
<p>第五步，构建日志读取结果对象。</p>
<p>第六步，外部循环调用read()方法，获取每个分区的消息，并组装result返回对象，result里面包含了每个分区及分区对应的读取日志结果。</p>
<h2>总结</h2>
<p>今天这一讲我们主要介绍了 Kafka 存储层各个组件的关系、日志存储方式，然后还讲解了 ReplicaManager 是如何支持日志读写的。其中，ReplicaManager 是 Kafka 存储系统最上层的组件，所以这里只是大体上分析了日志的读写流程，具体细节会在后面给大家讲解的。</p></div>
</body></html>
<!DOCTYPE html><html lang="en"><head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>第 01 讲：设计一份吸引面试官的简历</title>
<style type="text/css">
:root {
    --control-text-color: #777;
    --select-text-bg-color: rgba(223, 197, 223);  /*#7e66992e;*/
    
    /* side bar */
    --side-bar-bg-color: rgb(255, 255, 255);
    --active-file-text-color: #8163bd;
    --active-file-bg-color: #E9E4F0;
    --item-hover-bg-color: #E9E4F0;
    --active-file-border-color: #8163bd;

    --title-color: #6c549c;
    --font-sans-serif: 'Ubuntu', 'Source Sans Pro', sans-serif !important;
    --font-monospace: 'Fira Code', 'Roboto Mono', monospace !important;
    --purple-1: #8163bd;
    --purple-2: #79589F;
    --purple-3: #fd5eb8;
    --purple-light-1: rgba(99, 99, 172, .05);
    --purple-light-2: rgba(99, 99, 172, .1);
    --purple-light-3: rgba(99, 99, 172, .2);
    --purple-light-4: rgba(129, 99, 189, .3);
    --purple-light-5: #E9E4F0;
    --purple-light-6: rgba(129, 99, 189, .8);
}

/* html {
    font-size: 16px;
} */

body {
    font-family: var(--font-sans-serif);
    color: #34495e;
    -webkit-font-smoothing: antialiased;
    line-height: 1.6rem;
    letter-spacing: 0;
    margin: 0;
    overflow-x: hidden;
}

/* 页边距 和 页面大小 */
#write {
    padding-left: 6ch;
    padding-right: 6ch;
    margin: 0 auto;
}

#write p {
    line-height: 1.6rem;
    word-spacing: .05rem;
}

#write ol li {
    padding-left: 0.5rem;
}

#write > ul:first-child,
#write > ol:first-child {
    margin-top: 30px;
}

body > *:first-child {
    margin-top: 0 !important;
}

body > *:last-child {
    margin-bottom: 0 !important;
}

a {
    color: var(--purple-1);
    padding: 0 2px;
    text-decoration: none;
}
.md-content {
    color: var(--purple-light-6);
}
#write a {
    border-bottom: 1px solid var(--purple-1);
    color: var(--purple-1);
    text-decoration: none;
}

h1,
h2,
h3,
h4,
h5,
h6 {
    position: relative;
    margin-top: 1rem;
    margin-bottom: 0.5rem;
    /* font-weight: bold; */
    font-weight: 500 !important;
    line-height: 1.4;
    cursor: text;
    color: var(--title-color);
    font-family: var(--font-sans-serif);
}

h1:hover a.anchor,
h2:hover a.anchor,
h3:hover a.anchor,
h4:hover a.anchor,
h5:hover a.anchor,
h6:hover a.anchor {
    text-decoration: none;
}

h1 tt,
h1 code {
    font-size: inherit !important;
}
h2 tt,
h2 code {
    font-size: inherit !important;
}
h3 tt,
h3 code {
    font-size: inherit !important;
}
h4 tt,
h4 code {
    font-size: inherit !important;
}
h5 tt,
h5 code {
    font-size: inherit !important;
}
h6 tt,
h6 code {
    font-size: inherit !important;
}


h1 {
    padding-bottom: .4rem;
    font-size: 2.2rem;
    line-height: 1.3;
}
h1 {
    text-align: center;
    padding-bottom: 0.3em;
    font-size: 2.2em;
    line-height: 1.2;
    margin: 2.4em auto 1.2em;
}
h1:after {
    content: '';
    display: block;
    margin: 0.2em auto 0;
    width: 100px;
    height: 2px;
    border-bottom: 2px solid var(--title-color);
}

h2 {
    margin: 1.6em auto 0.5em;
    padding-left: 10px;
    line-height: 1.4;
    font-size: 1.8em;
    border-left: 9px solid var(--title-color);
    border-bottom: 1px solid var(--title-color);
}
h3 {
    font-size: 1.5rem;
    margin: 1.2em auto 0.5em;
}
h4 {
    font-size: 1.3rem;
}
h5 {
    font-size: 1.2rem;
}
h6 {
    font-size: 1.1rem;
}

p,
blockquote,
ul,
ol,
dl,
table {
    margin: 0.8em 0;
}

li > ol,
li > ul {
    margin: 0 0;
}

hr {
    height: 2px;
    padding: 0;
    margin: 16px 0;
    background-color: #e7e7e7;
    border: 0 none;
    overflow: hidden;
    box-sizing: content-box;
}

body > h2:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0;
}

body > h3:first-child,
body > h4:first-child,
body > h5:first-child,
body > h6:first-child {
    margin-top: 0;
    padding-top: 0;
}

a:first-child h1,
a:first-child h2,
a:first-child h3,
a:first-child h4,
a:first-child h5,
a:first-child h6 {
    margin-top: 0;
    padding-top: 0;
}

h1 p,
h2 p,
h3 p,
h4 p,
h5 p,
h6 p {
    margin-top: 0;
}

li p.first {
    display: inline-block;
}

ul,
ol {
    padding-left: 30px;
}

ul:first-child,
ol:first-child {
    margin-top: 0;
}

ul:last-child,
ol:last-child {
    margin-bottom: 0;
}

/* 引用 */
blockquote {
    /* margin-left: 1rem; */
    border-left: 4px solid var(--purple-light-4);
    padding: 10px 15px;
    color: #777;
    background-color: var(--purple-light-1);
}

/* 表格 */
table {
    padding: 0;
    word-break: initial;
}

table tr {
    border-top: 1px solid #dfe2e5;
    margin: 0;
    padding: 0;
}

/* 表格 背景色 */
table tr:nth-child(2n),
thead {
    background-color: var(--purple-light-1);
}
#write table thead th {
    background-color: var(--purple-light-2);
}

table tr th {
    font-weight: bold;
    border: 1px solid #dfe2e5;
    border-bottom: 0;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr td {
    border: 1px solid #dfe2e5;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr th:first-child,
table tr td:first-child {
    margin-top: 0;
}

table tr th:last-child,
table tr td:last-child {
    margin-bottom: 0;
}

/* 粗体 */
#write strong {
    padding: 0 2px;
    color: var(--purple-1);
}

/* 斜体 */
#write em {
    padding: 0 5px 0 2px;
    /* font-style: normal; */
    color: #42b983;
}

/* inline code */
#write code, tt {
    padding: 2px 4px;
    border-radius: 2px;
    font-family: var(--font-monospace);
    font-size: 0.92rem;
    color: var(--purple-3); 
    background-color: rgba(99, 99, 172, .05);
}

tt {
    margin: 0 2px;
}

#write .md-footnote {
    background-color: #f8f8f8;
    color: var(--purple-3);
}

/* heighlight. */
#write mark {
    background-color: #fbd3ea;
    border-radius: 2px;
    padding: 2px 4px;
    margin: 0 2px;
}

#write del {
    padding: 1px 2px;
}

.md-task-list-item > input {
    margin-left: -1.3em;
}

@media print {
    html {
        font-size: 0.9rem;
    }

    table,
    pre {
        page-break-inside: avoid;
    }

    pre {
        word-wrap: break-word;
    }
}

#write pre.md-meta-block {
    padding: 1rem;
    font-size: 85%;
    line-height: 1.45;
    background-color: #f7f7f7;
    border: 0;
    border-radius: 3px;
    color: #777777;
    margin-top: 0 !important;
}

.mathjax-block > .code-tooltip {
    bottom: .375rem;
}

/* 图片 */
.md-image > .md-meta {
    border-radius: 3px;
    font-family: var(--font-monospace);
    padding: 2px 0 0 4px;
    font-size: 0.9em;
    color: inherit;
}
p .md-image:only-child{
    width: auto;
    text-align: left;
    margin-left: 2rem;
}
.md-tag {
    color: inherit;
}
/* 当 “![shadow-随便写]()”写时，会有阴影 */
.md-image img[alt|='shadow'] {
    /* box-shadow: 0 4px 24px -6px #ddd; */
    box-shadow:var(--purple-light-2) 0px 10px 15px;
}

#write a.md-toc-inner {
    line-height: 1.6;
    white-space: pre-line;
    border-bottom: none;
    font-size: 0.9rem;
}

#typora-quick-open {
    border: 1px solid #ddd;
    background-color: #f8f8f8;
}

#typora-quick-open-item {
    background-color: #FAFAFA;
    border-color: #FEFEFE #e5e5e5 #e5e5e5 #eee;
    border-style: solid;
    border-width: 1px;
}

#md-notification:before {
    top: 10px;
}

header,
.context-menu,
.megamenu-content,
footer {
    font-family: var(--font-sans-serif);
}

.file-node-content:hover .file-node-icon,
.file-node-content:hover .file-node-open-state {
    visibility: visible;
}

.md-lang {
    color: #b4654d;
}

.html-for-mac .context-menu {
    --item-hover-bg-color: #E6F0FE;
}

/* 代码框 */
/* CodeMirror 3024 Day theme */

/* 代码段 背景 */
pre {
    --select-text-bg-color: rgba(223, 197, 223) !important;
    margin: .5em 0;
    padding: 1em 1.4em;
    border-radius: 8px;
    background: #f6f8fa;
    overflow-x: auto;
    box-sizing: border-box;
    font-size: 14px;
}

/* 边框 */
.md-fences {
    border: 1px solid #e7eaed;
    border-radius: 3px;
}

.cm-s-inner {
  padding: .25rem;
  border-radius: .25rem;
}

.cm-s-inner.CodeMirror, .cm-s-inner .CodeMirror-gutters {
  background-color: #f8f8f8 !important;
  color: #3a3432 !important;
  border: none;
}

.cm-s-inner .CodeMirror-gutters {
  color: #6d8a88;
}

.cm-s-inner .CodeMirror-cursor {
  border-left: solid thin #5c5855 !important;
}

.cm-s-inner .CodeMirror-linenumber {
  color: #807d7c;
}

.cm-s-inner .CodeMirror-line::selection, .cm-s-inner .CodeMirror-line::-moz-selection,
.cm-s-inner .CodeMirror-line > span::selection,
.cm-s-inner .CodeMirror-line > span::-moz-selection,
.cm-s-inner .CodeMirror-line > span > span::selection,
.cm-s-inner .CodeMirror-line > span > span::-moz-selection {
  background: var(--purple-light-2);
}

.cm-s-inner span.cm-comment {
  color: #cdab53;
}

.cm-s-inner span.cm-string, .cm-s-inner span.cm-string-2 {
  color: #f2b01d;
}

.cm-s-inner span.cm-number {
  color: #a34e8f;
}

.cm-s-inner span.cm-variable {
  color: #01a252;
}

.cm-s-inner span.cm-variable-2 {
  color: #01a0e4;
}

.cm-s-inner span.cm-def {
  /* color: #e8bbd0; */
  color: #e2287f;
}

.cm-s-inner span.cm-operator {
  color: #ff79c6;
}

.cm-s-inner span.cm-keyword {
  color: #db2d20;
}

.cm-s-inner span.cm-atom {
  color: #a34e8f;
}

.cm-s-inner span.cm-meta {
  color: inherit;
}

.cm-s-inner span.cm-tag {
  color: #db2d20;
}

.cm-s-inner span.cm-attribute {
  color: #01a252;
}

.cm-s-inner span.cm-qualifier {
  color: #388aa3;
}

.cm-s-inner span.cm-property {
  color: #01a252;
}

.cm-s-inner span.cm-builtin {
  color: #388aa3;
}

.cm-s-inner span.cm-variable-3, .cm-s-inner span.cm-type {
  color: #ffb86c;
}

.cm-s-inner span.cm-bracket {
  color: #3a3432;
}

.cm-s-inner span.cm-link {
  color: #a34e8f;
}

.cm-s-inner span.cm-error {
  background: #db2d20;
  color: #5c5855;
}

/* .md-fences.md-focus .cm-s-inner .CodeMirror-activeline-background {
  background: var(--purple-light-2);
} */

.cm-s-inner .CodeMirror-matchingbracket {
  text-decoration: underline;
  color: #a34e8f !important;
}

#fences-auto-suggest .active {
  background: #ddd;
}

#write .code-tooltip {
  bottom: initial;
  top: calc(100% - 1px);
  background: #f7f7f7;
  border: 1px solid #ddd;
  border-top: 0;
}

.auto-suggest-container {
  border-color: #b4b4b4;
}

.auto-suggest-container .autoComplt-hint.active {
  background: #b4b4b4;
  color: inherit;
}

/* task list */
#write .md-task-list-item > input {
  -webkit-appearance: initial;
  display: block;
  position: absolute;
  border: 1px solid #b4b4b4;
  border-radius: .25rem;
  margin-top: .1rem;
  margin-left: -1.8rem;
  height: 1.2rem;
  width: 1.2rem;
  transition: background 0.3s;
}

#write .md-task-list-item > input:focus {
  outline: none;
  box-shadow: none;
}

#write .md-task-list-item > input:hover {
  background: #ddd;
}

#write .md-task-list-item > input[checked]::before {
  content: '';
  position: absolute;
  top: 20%;
  left: 50%;
  height: 60%;
  width: 2px;
  transform: rotate(40deg);
  background: #333;
}

#write .md-task-list-item > input[checked]::after {
  content: '';
  position: absolute;
  top: 46%;
  left: 25%;
  height: 30%;
  width: 2px;
  transform: rotate(-40deg);
  background: #333;
}

#write .md-task-list-item > p {
  transition: color 0.3s, opacity 0.3s;
}

#write .md-task-list-item.task-list-done > p {
  color: #b4b4b4;
  text-decoration: line-through;
}

#write .md-task-list-item.task-list-done > p > .md-emoji {
  opacity: .5;
}

#write .md-task-list-item.task-list-done > p > .md-link > a {
  opacity: .6;
}

/* sidebar and outline */
.pin-outline .outline-active {
  color: var(--active-file-text-color); 
}

.file-list-item {
    border-bottom: 1px solid;
    border-color: var(--purple-light-5);
}

.file-list-item-summary {
    font-weight: 400;
}

.file-list-item.active {
    color: var(--active-file-text-color);
    background-color: var(--purple-light-5);
}

.file-tree-node.active>.file-node-background {
    background-color: var(--purple-light-5);
    font-weight: 700;
} 

.file-tree-node.active>.file-node-content {
    color: var(--active-file-text-color);
    font-weight: 700;
}

.file-node-content {
    color: #5e676d;
}

.sidebar-tabs {
    border-bottom: none;
}
.sidebar-tab.active {
    font-weight: 400;
}

.sidebar-content-content {
    font-size: 0.9rem;
}

img {
    max-width: 100%;
}

body {
    background-color: rgb(237, 237, 237);
}
#content {
    width: 836px;
    padding: 50px;
    background: #fff;
    margin: 0 auto;
}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/purple.css*/</style><style type="text/css">.hljs{display:block;overflow-x:auto;padding:.5em;color:#383a42;background:#fafafa}.hljs-comment,.hljs-quote{color:#a0a1a7;font-style:italic}.hljs-doctag,.hljs-formula,.hljs-keyword{color:#a626a4}.hljs-deletion,.hljs-name,.hljs-section,.hljs-selector-tag,.hljs-subst{color:#e45649}.hljs-literal{color:#0184bb}.hljs-addition,.hljs-attribute,.hljs-meta-string,.hljs-regexp,.hljs-string{color:#50a14f}.hljs-built_in,.hljs-class .hljs-title{color:#c18401}.hljs-attr,.hljs-number,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-pseudo,.hljs-template-variable,.hljs-type,.hljs-variable{color:#986801}.hljs-bullet,.hljs-link,.hljs-meta,.hljs-selector-id,.hljs-symbol,.hljs-title{color:#4078f2}.hljs-emphasis{font-style:italic}.hljs-strong{font-weight:700}.hljs-link{text-decoration:underline}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/atom-one-light.min.css*/</style></head>
<body>
<div id="content"><h1>Message 的家是什么样？：日志分段文件与索引文件</h1>
<p>今天我们主要学习日志分段和日志文件的源码。生产者向broker的某个主题分区文件不断追加消息，如果我们不做处理，那么这个文件会越来越大，造成管理上的诸多困难。比如，我们删除过期的消息，如果同时在一个文件上做文件的追加和文件的部分删除势必造成并发问题，而且会造成过多的其他工作，所以在设计上必须考虑日志文件过大的问题。</p>
<h2>日志存储三个核心类及关系</h2>
<p>Kafka为了防止日志Log过大，将逻辑上的Log文件切分成多个物理上的日志文件，每个日志文件对应多个 LogSegment。LogSegment通过FileRecords映射一个物理文件。Log、LogSegment、FileRecords这三者的关系如下：</p>
<p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1db3981f74e54a489051f51c272047d9~tplv-k3u1fbpfcp-watermark.image?" alt="log存储的核心类及关系 (3).png"></p>
<p>这里我们先从最底层的 FileRecords 类谈起。</p>
<h3>FileRecords 类</h3>
<p><strong>FileRecords 类用于描述和管理日志（分片）文件数据，对应一个 log 文件。FileRecords是日志段文件上的原始消息视图</strong>。一个日志段对应一个原始消息视图（可变，因为日志在追加）。同时，因为可以设置start、end，就可以提供不可变的消息视图。如果isSlice为false，说明消息视图是原始消息视图，否则如果为true是消息视图。</p>
<h4>字段</h4>
<p>我们先从类的字段开始学习，源码如下：</p>
<pre><code>private final boolean isSlice;

private final int start;

private final int end;

private final Iterable&#x3C;FileLogInputStream.FileChannelRecordBatch> batches;

private final AtomicInteger size;

private final FileChannel channel;

private volatile File file;

</code></pre>
<ul>
<li>isSlice：是否为分片。isSlice为false，说明文件是原始的日志文件，是可以追加的；如果isSlice为true，那么就是截取日志的一个片段。</li>
<li>start：分片的开始位置。</li>
<li>end：分片的结束位置。</li>
<li>batches：组成FileRecords的消息批次。</li>
<li>size：如果是分片，则表示分片的大小（end - start）；如果不是分片，则表示整个日志文件的大小。</li>
<li>channel：FileChannel类型，用于读写对应的日志文件。</li>
<li>file：磁盘上的日志文件。</li>
</ul>
<h4>方法</h4>
<p>介绍完字段后，接下来继续介绍相关方法，这里我先给你介绍下文件追加的方法。</p>
<h4>append()</h4>
<p>append()方法的目的是<strong>把消息批次从内存写到日志文件中</strong>。不过，需要说明的是：<code>这个方法不是线程安全的，必须有锁保护</code>。</p>
<pre><code>
public int append(MemoryRecords records) throws IOException {

if (records.sizeInBytes() > Integer.MAX_VALUE - size.get())

throw new IllegalArgumentException("Append of size " + records.sizeInBytes() +

" bytes is too large for segment with current file position at " + size.get());

// 第一步：把内存中的消息数据写入channel，但这时不一定写到磁盘中了，因为还没有刷盘

int written = records.writeFullyTo(channel);

// 第二步：计算写入了多少字节的消息

size.getAndAdd(written);

return written;

}

</code></pre>
<p>整体步骤可分为下面两步。</p>
<p>第一步：把内存中的消息数据写入channel，但这时不一定写到磁盘中了，因为还没有刷盘。</p>
<p>第二步：计算写入了多少字节的消息，并返回。</p>
<h4>flush()</h4>
<p><strong>append() 方法并没有把消息写入到磁盘文件中，而是通过flush()方法刷到磁盘里的。</strong></p>
<pre><code>
public void flush() throws IOException {

channel.force(true);

}

</code></pre>
<p>flush()方法的目的是<strong>写消息到磁盘文件</strong>，底层采用了FileChannel来实现，因为性能方面的考虑，操作系统会将数据缓存到内存中（os cache），所以无法保证写入到FileChannel里的数据一定及时地写到磁盘上，要保证写到磁盘就要调用force()方法。</p>
<p>好了，FileRecords类基本上就介绍完了，其实FileRecords类里还有一些其他有意思的方法，你若有兴趣的话，可以去了解一下。</p>
<h3>日志索引介绍</h3>
<p>为了提高查询消息的效率，每个日志分段文件都对应一个索引文件，这个索引文件并没有为每条消息都建立索引项，而是使用稀疏索引方式为日志文件中的部分消息建立了索引，如下图所示：</p>
<p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e3860fa52b25485383d7d6123069b6f0~tplv-k3u1fbpfcp-watermark.image?" alt="log的索引 (1).png"></p>
<p>可以看到，并不是每个offset都建立索引了，而是隔着几个消息才会给某条消息的偏移量做索引项。索引项分为两个部分，一个部分是offset偏移量，另一个部分是offset对应的物理位置。</p>
<p>Kafka使用稀疏索引的方式构造消息的索引，它不保证每个消息在索引文件中都有对应的索项，这算是磁盘空间、内存空间、查找时间等多方面的折中。不断减小索引文件大小的目的是将索引文件映射到内存，在OffsetIndex中会使用MappedByteBuffer索引文件映射到内存中。这样做的好处是<strong>提升追加和查询索引效率</strong>。</p>
<p>索引文件的内存映射是在抽象类AbstractIndex里定义的，所以，我们先来了解抽象类AbstractIndex的代码。</p>
<h4>AbstractIndex</h4>
<p>这里我们主要了解一下它相关的重要字段。</p>
<ul>
<li>file：对应的一个索引文件，字段是 var 型，说明它是可以被修改的，Kafka 允许迁移底层的日志路径，所以，索引文件自然是可以更换的。</li>
<li>baseOffset：对应日志字段的起始位移。</li>
<li>maxIndexSize：最大索引大小。该参数的默认值是 Broker 端参数 segment.index.bytes 的值，即 10MB。</li>
<li>entrySize：一个索引项的大小，OffsetIndex是 8 个字节，TimeIndex是 12 个字节。</li>
<li>_length：索引文件的长度。</li>
<li>mmap：创建索引文件并把索引文件映射到内存中。</li>
</ul>
<p>我们看其具体代码：</p>
<pre><code>
protected var mmap: MappedByteBuffer = {

//1.尝试创建索引文件，可能已经创建了，就返回false，如果没创建就新创建，然后返回true。

val newlyCreated = file.createNewFile()

val raf = if (writable) new RandomAccessFile(file, "rw") else new RandomAccessFile(file, "r")

try {

/* pre-allocate the file if necessary */

if(newlyCreated) {

// 2.预设的索引文件大小不能太小，如果连一个索引项都保存不了，直接抛出异常

if(maxIndexSize &#x3C; entrySize)

throw new IllegalArgumentException("Invalid max index size: " + maxIndexSize)

// 第3步：设置索引文件长度，roundDownToExactMultiple计算的是不超过maxIndexSize的最大整数倍entrySize（8个字节）

// 比如maxIndexSize=1234567字节，entrySize=8字节，那么调整后的文件长度为1234560字节

raf.setLength(roundDownToExactMultiple(maxIndexSize, entrySize))

}

// 第4步：

/* memory-map the file */

_length = raf.length()

// 第五步，把索引文件映射到内存中。

val idx = {

if (writable)

raf.getChannel.map(FileChannel.MapMode.READ_WRITE, 0, _length)

else

raf.getChannel.map(FileChannel.MapMode.READ_ONLY, 0, _length)

}

/* set the position in the index for the next entry */

// 第6步：如果是新创建的索引文件，将MappedByteBuffer对象的当前位置设置成0

// 如果索引文件已存在，将MappedByteBuffer对象的当前位置设置成最后一个索引项所在的位置

if(newlyCreated)

idx.position(0)

else

// if this is a pre-existing index, assume it is valid and set position to last entry

idx.position(roundDownToExactMultiple(idx.limit(), entrySize))

// 第7步：返回创建的MappedByteBuffer对象

idx

} finally {

CoreUtils.swallow(raf.close(), AbstractIndex)

}

}

</code></pre>
<p>整体步骤可总结为如下。</p>
<p>第一步：尝试创建索引文件，可能已经创建了，就返回false，如果没创建就新创建，然后返回true。</p>
<p>第二步：预设的索引文件大小不能太小，如果连一个索引项都保存不了，直接抛出异常。</p>
<p>第三步：设置索引文件长度，roundDownToExactMultiple计算的是不超过maxIndexSize的最大整数倍entrySize（8个字节）。比如，maxIndexSize=1234567字节，entrySize=8字节，那么调整后的文件长度为1234560字节。</p>
<p>第四步：更新索引长度字段_length。</p>
<p>第五步：把索引文件映射到内存中。</p>
<p>第六步：如果是新创建的索引文件，将MappedByteBuffer对象的当前位置设置成0。如果索引文件已存在，将MappedByteBuffer对象的当前位置设置成最后一个索引项所在的位置。</p>
<p>第七步：返回创建的MappedByteBuffer对象。</p>
<p>为了你更好地理解，这里我再用流程图形象地描述一下：</p>
<p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d982b58cb4d34fa8b61b79bced4539d3~tplv-k3u1fbpfcp-watermark.image?" alt="索引文件与mmap创建过程.png"></p>
<p>日志索引分为两种，一种是<code>基于偏移量的索引</code>，另一种是<code>基于时间戳的索引</code>。基于时间戳的索引的基础是基于偏移量的索引，了解了偏移量的索引就了解了基于时间戳的索引。我们这里就只介绍基于偏移量的索引，如果你有兴趣可以自学基于时间戳的索引。</p>
<h4>OffsetIndex</h4>
<p><strong>偏移量索引把偏移量映射到一个特定的日志分段物理文件的位置</strong>。这个索引是<code>稀疏索引</code>，就是说索引并没有把日志内的所有消息都索引化。</p>
<p>有下面几个点需要你了解和多加注意。</p>
<ul>
<li>
<p>索引保存在物理文件中，每个索引项都是固定大小，8 个字节。</p>
</li>
<li>
<p>索引支持针对在物理文件的内存映射的查找。查找是通过简单的二分查找法去定位小于等于目标偏移量中最大的偏移量/位置对。</p>
</li>
<li>
<p>索引文件有两种打开方式。第一种是按<code>可变索引文件</code>打开，允许消息日志追加。第二种是按<code>不可变只读索引文件</code>打开，这种文件是以前填充完的索引文件，当新的索引文件创建后，旧的索引文件会从可变索引文件转换为不可变索引文件，并删除多余的字节。</p>
</li>
<li>
<p>索引文件是一系列的条目。格式是4个字节的相对偏移量和对应偏移量的4个字节的文件位置。偏移量的存储是相对偏移量，所谓相对是基于索引文件的基础偏移量（即索引文件对应的日志文件的起始偏移量）来说的。比如，如果索引文件的基础偏移量是50，那么绝对偏移量会存储5作为相对偏移量。使用相对偏移量能大大减少存储空间的占用，否则4byte的空间显然不够用。</p>
</li>
<li>
<p>所有对外提供的API会把相对偏移量转换为绝对偏移量，所以外部仅仅使用索引的话不会去了解索引的内部格式。</p>
</li>
</ul>
<p>那 OffsetIndex 类的源码情况是怎样的呢？首先，还是学习一下它的重要字段。</p>
<ul>
<li>file：指向磁盘上的索引文件。</li>
<li>baseOffset：对应日志文件中第一个消息的offset。</li>
<li>mmap：用来操作索引文件的 MappedByteBuffer。</li>
<li>lock：ReentrantLock对象，在对mmap进行操作时，需要加锁保护。</li>
<li>entries：当前索引文件中的索引项个数。</li>
<li>maxEntries：当前索引文件中最多能够保存的索引项个数。</li>
<li>lastOffset：保存最后一个索引项的offset。</li>
</ul>
<p><strong>对于索引文件来说，主要的操作就是索引项的构建和查询索引这两个操作</strong>，但是还有很多底层的方法也很重要，我们先从底层的方法讲起。</p>
<h5>方法 relativeOffset()</h5>
<p>这个方法的功能是根据索引文件和索引项的编号找到相对偏移量。</p>
<pre><code>
private def relativeOffset(buffer: ByteBuffer, n: Int): Int = buffer.getInt(n * entrySize)

</code></pre>
<p>结合 entrySize 和 buffer.getInt 方法能够轻松地计算出第 n 个索引项所处的物理文件位置，最后读出消息在索引文件的相对偏移量。</p>
<h5>方法 physical()</h5>
<p>这个方法的功能是从索引文件中找到消息在消息文件中的位置。</p>
<pre><code>
private def physical(buffer: ByteBuffer, n: Int): Int = buffer.getInt(n * entrySize + 4)

</code></pre>
<p>结合 entrySize 和 buffer.getInt 方法能够轻松地计算出第 n 个索引项所处的物理文件位置然后加4，读出消息在日志文件的物理位置。</p>
<h5>append()</h5>
<p>这个方法的功能是向索引文件追加索引项，这里我会分步骤给你讲解的。</p>
<pre><code>
def append(offset: Long, position: Int): Unit = {

inLock(lock) {

// 第1步：判断索引文件未写满

require(!isFull, "Attempt to append to a full index (size = " + _entries + ").")

// 第2步：必须满足以下条件之一才允许写入索引项：

// 条件1：当前索引文件为空

// 条件2：要写入的位移大于当前所有已写入的索引项的位移——Kafka规定索引项中的位移值必须是单调增加的

if (_entries == 0 || offset > _lastOffset) {

trace(s"Adding index entry $offset => $position to ${file.getAbsolutePath}")

// 第3步A：向mmap中写入相对位移值

mmap.putInt(relativeOffset(offset))

// 第3步B：向mmap中写入物理位置信息

mmap.putInt(position)

// 第4步：更新其他元数据统计信息，如当前索引项计数器_entries和当前索引项最新位移值_lastOffset

_entries += 1

_lastOffset = offset

// 第5步：执行校验。写入的索引项格式必须符合要求，即索引项个数*单个索引项占用字节数匹配当前文件物理大小，否则说明文件已损坏

require(_entries * entrySize == mmap.position(), s"$entries entries but file position in index is ${mmap.position()}.")

} else {

// 如果第2步中两个条件都不满足，不能执行写入索引项操作，抛出异常

throw new InvalidOffsetException(s"Attempt to append an offset ($offset) to position $entries no larger than" +

s" the last offset appended (${_lastOffset}) to ${file.getAbsolutePath}.")

}

}

}

</code></pre>
<p>第一步：判断索引文件未写满，否则就抛异常。</p>
<p>第二步：必须满足以下条件之一才允许写入索引项：</p>
<ul>
<li>当前索引文件为空；</li>
<li>要写入的偏移量大于当前所有已写入的索引项的偏移量——Kafka规定索引项中的位移值必须是单调增加的。</li>
</ul>
<p>第三步：向索引文件对应的mmap中写入索引项。包括写入相对偏移量和对应的日志文件的物理位置。</p>
<p>第四步：更新其他元数据统计信息，如当前索引项计数器_entries和当前索引项最新位移值_lastOffset。</p>
<p>第五步：执行校验。写入的索引项格式必须符合要求，即索引项个数乘以单个索引项占用字节数匹配当前文件物理大小，否则说明文件已损坏。</p>
<h5>lookup()</h5>
<p>接下来我们再分析一下索引是如何查找的：</p>
<pre><code>
def lookup(targetOffset: Long): OffsetPosition = {

maybeLock(lock) {

//第一步：用私有变量做一个mmap的镜像，防止有新的索引进来，影响一致性。

val idx = mmap.duplicate

// 第二步使用了改进版的二分查找算法寻找对应的槽位

val slot = largestLowerBoundSlotFor(idx, targetOffset, IndexSearchType.KEY)

// 第三步如果没找到，返回一个空的位置，即物理文件位置从0开始，表示从头读日志文件

// 否则返回slot槽对应的索引项

if(slot == -1)

OffsetPosition(baseOffset, 0)

else

//根据返回的槽位和索引文件构建偏移量位置对象

parseEntry(idx, slot)

}

}

</code></pre>
<p>第一步：用私有变量做一个mmap的镜像，防止有新的索引进来，影响一致性。</p>
<p>第二步：使用了改进版的二分查找算法寻找对应的槽位。</p>
<p>第三步：如果没找到，返回一个空的位置，即物理文件位置从0开始，表示从头读日志文件，否则返回slot槽对应的索引项。</p>
<h3>LogSegment类</h3>
<p><strong>LogSegment类其实就是管理segment文件的，在LogSegment中封装了一个FileRecords和一个OffsetIndex对象，提供了日志文件和索引文件的读写功能。</strong></p>
<p>同样，下面我们介绍一下LogSegment类的重要字段和重要方法。</p>
<h4>重要字段</h4>
<pre><code>
class LogSegment private[log] (val log: FileRecords,

val lazyOffsetIndex: LazyIndex[OffsetIndex],

val lazyTimeIndex: LazyIndex[TimeIndex],

val txnIndex: TransactionIndex,

val baseOffset: Long,

val indexIntervalBytes: Int,

</code></pre>
<ul>
<li>log：用于操作对应日志文件的FileMessageSet对象。</li>
<li>lazyOffsetIndex：用于操作对应索引文件的OffsetIndex对象。</li>
<li>lazyTimeIndex: 时间索引。</li>
<li>txnIndex：事务索引。</li>
<li>baseOffset：logSegment第一个消息的offset值。</li>
<li>indexIntervalBytes：索引项之间间隔的最小字节数。</li>
</ul>
<blockquote>
<p>注意：索引字段的命名以lazy开头，比如lazyOffsetIndex、lazyTimeIndex，这是因为索引的创建是用的懒加载，调用的时候才会加载索引文件，这样提升了资源的利用率。</p>
</blockquote>
<h4>重要方法</h4>
<p>介绍完相关重要字段后，接下来我们学习它的几个重要方法。</p>
<h5>方法 shouldRoll()</h5>
<p><strong>方法 shouldRoll() 是用来判断是否新建日志分段文件的</strong>。不过，这里我们需要先讨论一下日志分段文件的意义。</p>
<blockquote>
<p>采用滚动方式创建日志分段的好处是，要根据时间、大小或偏移量3种策略删除日志的部分数据，实现起来比较容易。每个日志分段不仅有对应的大小，也记录了基准偏移量。如果要删除指定偏移量之前的数据，只需要选择满足条件的部分日志分段，并不需要期取分区的所有日志分段。</p>
</blockquote>
<p>其源码如下：</p>
<pre><code>
// 是否要新建segment。

def shouldRoll(rollParams: RollParams): Boolean = {

// 计算多久没有新建日志分段文件了。

val reachedRollMs = timeWaitedForRoll(rollParams.now, rollParams.maxTimestampInMessages) > rollParams.maxSegmentMs - rollJitterMs

// 要新建segment的条件

size > rollParams.maxSegmentBytes - rollParams.messagesSize ||

(size > 0 &#x26;&#x26; reachedRollMs) ||

offsetIndex.isFull ||

timeIndex.isFull ||

!canConvertToRelativeOffset(rollParams.maxOffsetInMessages)

}

</code></pre>
<p><code>以下五个条件满足一个</code>就要新建日志分段文件了。</p>
<ul>
<li>如果加上现在消息的大小，这个 segment 超过1个G，就需要新建一个segment。</li>
<li>距离上次创建日志段的时间达到了一个阈值（log.roll.hours默认7天），并且日志段有数据。</li>
<li>索引文件满了（默认10m）。</li>
<li>时间索引文件满了（默认10m）。</li>
<li>最大的offset，其相对偏移量超过了正整数的阈值，追加的消息的偏移量与当前日志段的偏移量之间的差值大于Integer.MAX_VALUE。因为相对偏移量是4个字节，对应int类型也是4个字节，这样再大就超出了，不满足了。</li>
</ul>
<h5>方法 append()</h5>
<p>append()方法是用来向日志分段文件追加消息的，源码在下面：</p>
<pre><code>
def append(largestOffset: Long,

largestTimestamp: Long,

shallowOffsetOfMaxTimestamp: Long,

records: MemoryRecords): Unit = {

//1.判断消息大小

if (records.sizeInBytes > 0) {

trace(s"Inserting ${records.sizeInBytes} bytes at end offset $largestOffset at position ${log.sizeInBytes} " +

s"with largest timestamp $largestTimestamp at shallow offset $shallowOffsetOfMaxTimestamp")

//2.获取FileRecords文件的末尾，它就是本次消息要写入的物理地址。

val physicalPosition = log.sizeInBytes()

if (physicalPosition == 0)

rollingBasedTimestamp = Some(largestTimestamp)

//3.确保输入参数最大位移是合法的。就是看它与日志段起始位移的差值是否在整数范围内，即 largestOffset - baseOffset 的值是不是介于 [0，Int.MAXVALUE] 之间

ensureOffsetInRange(largestOffset)

// append the messages

//4.往日志段追加日志。

val appendedBytes = log.append(records)

trace(s"Appended $appendedBytes to ${log.file} at end offset $largestOffset")

// Update the in memory max timestamp and corresponding offset.

//5.更新日志段的最大时间戳以及最大时间戳所属消息的位移值属性。

if (largestTimestamp > maxTimestampSoFar) {

maxTimestampSoFar = largestTimestamp

offsetOfMaxTimestampSoFar = shallowOffsetOfMaxTimestamp

}

// append an entry to the index (if needed)

//6.因为日志索引被设计成稀疏索引，所以要判断这个消息是否有索引。

//indexIntervalBytes默认是4096个字节

//也就是说每次写了4096个字节的消息就写一次索引。

if (bytesSinceLastIndexEntry > indexIntervalBytes) {

//真正写索引的方法。

offsetIndex.append(largestOffset, physicalPosition)

//写入时间索引文件

timeIndex.maybeAppend(maxTimestampSoFar, offsetOfMaxTimestampSoFar)

//把bytesSinceLastIndexEntry更新为零

bytesSinceLastIndexEntry = 0

}

//这批数据加到bytesSinceLastIndexEntry变量中。

bytesSinceLastIndexEntry += records.sizeInBytes

}

}

</code></pre>
<p>接下来我们一起分析一下这个方法的执行步骤。</p>
<p>第一步：判断要追加的消息大小要大于零，否则没有意义。</p>
<p>第二步：获取FileRecords日志分段文件的末尾，它就是本次消息要写入的物理地址。</p>
<p>第三步：确保输入参数最大位移是合法的。就是看它与日志段起始位移的差值是否在整数范围内，即 largestOffset - baseOffset 的值是不是介于<code>[0，Int.MAXVALUE]</code>之间。</p>
<p>第四步：往日志段追加日志。调用FileRecords类的append()方法来实现。</p>
<p>第五步：更新日志段的最大时间戳以及最大时间戳所属消息的位移值属性。</p>
<p>第六步：因为日志索引被设计成稀疏索引，所以要判断这个消息是否要有索引。indexIntervalBytes默认是4096个字节，也就是说每次写了4096个字节的消息就写一次索引。</p>
<blockquote>
<p>注意：这个方法不是线程安全的，需要用锁保证一致性。</p>
</blockquote>
<p>好了，日志的追加我们分析完了，那么日志的读取呢？这就是方法read()的工作了。</p>
<h5>方法 read()</h5>
<p>读取一个消息集，从给定的startOffset这个偏移量读起，读maxSize个字节。消费者拉取消息时会调用这个方法，同时分区的follower副本节点从分区的leader副本节点拉取消息的时候，也会调用这个方法。</p>
<p>方法的源码如下：</p>
<pre><code>def read(startOffset: Long,//指定读取的起始消息的offset，如消费者拉取消息时，要给出开始拉取消息的偏移量。

maxSize: Int, //指定读取最大字节数，默认是1M

maxPosition: Long = size,//能读到的最大文件位置

minOneMessage: Boolean = false)//是否允许在消息体过大时至少返回第一条消息，引入这个参数主要是为了确保不出现消费饿死的情况。

: FetchDataInfo = {

if (maxSize &#x3C; 0)

throw new IllegalArgumentException(s"Invalid max size $maxSize for log read from segment $log")

//1.根据给定的消息的offset，查询索引文件，根据返回的索引项里的消息物理位置再去消息文件中顺序查找

val startOffsetAndSize = translateOffset(startOffset)

// if the start position is already off the end of the log, return null

if (startOffsetAndSize == null)

return null

val startPosition = startOffsetAndSize.position

val offsetMetadata = LogOffsetMetadata(startOffset, this.baseOffset, startPosition)

//2.读取最大的消息数

val adjustedMaxSize =

if (minOneMessage) math.max(maxSize, startOffsetAndSize.size)

else maxSize

// return a log segment but with zero size in the case below

if (adjustedMaxSize == 0)

return FetchDataInfo(offsetMetadata, MemoryRecords.EMPTY)

//3.选择最小的消息数

// calculate the length of the message set to read based on whether or not they gave us a maxOffset

val fetchSize: Int = min((maxPosition - startPosition).toInt, adjustedMaxSize)

//4.最终读到这个消息集合。

FetchDataInfo(offsetMetadata, log.slice(startPosition, fetchSize),

firstEntryIncomplete = adjustedMaxSize &#x3C; startOffsetAndSize.size)

}

</code></pre>
<p>先分析重要字段：</p>
<ul>
<li>startOffset：指定读取的起始消息的offset，如消费者拉取消息时，要给出开始拉取消息的偏移量。</li>
<li>maxSize：指定读取最大字节数，默认是1M。</li>
<li>maxPosition：能读到的最大文件位置。</li>
<li>minOneMessage：是否允许在消息体过大时至少返回第一条消息，引入这个参数主要是为了确保不出现消费饿死的情况。</li>
</ul>
<p>接下来分析方法体。</p>
<p>第一步：根据给定的消息的offset，得到对应的物理位置。过程是查询索引文件，根据返回的索引项里的消息物理位置再去消息文件中顺序查找。</p>
<p>这步主要是调用了translateOffset()这个方法来实现的：</p>
<pre><code>
private[log] def translateOffset(offset: Long, startingFilePosition: Int = 0): LogOffsetPosition = {

//1.根据二分查找法找到索引项，得到索引文件中 索引项绝对offset和索引项所处的物理文件位置 的对。

val mapping = offsetIndex.lookup(offset)

//2.根据索引文件搜出来的索引，进一步在日志文件里搜索。

log.searchForOffsetWithSize(offset, max(mapping.position, startingFilePosition))

}

</code></pre>
<p>大体流程是：<strong>因为是稀疏索引，要找的偏移量不一定在索引里，所以要确定最近哪个偏移量有索引，再根据索引找到偏移量，最后再顺序查找到要找的偏移量</strong>。</p>
<p>这个方法具体步骤是：</p>
<p>1）根据二分查找法找到索引项，得到索引文件中索引项绝对offset和索引项所处的物理文件位置的对。</p>
<p>2）根据索引文件搜出来的索引，进一步在日志文件里搜索。</p>
<p>接着我们继续梳理read()方法。</p>
<p>第二步：读取最大的消息数。</p>
<p>第三步：选择最小的消息数。</p>
<p>第四步：最终读到这个消息集合。</p>
<h2>总结</h2>
<p>整体来讲，这节课我们主要剖析了日志存储最底层的组件和类，包括日志在物理存储上最小的单位日志分段文件（LogSegment）、映射日志分段文件的类FileRecords。除此之外，还介绍了FileRecords提供的最底层的追加消息日志的方法。最后，讲解了LogSegment是如何读写日志分段文件（LogSegment）的。</p></div>
</body></html>
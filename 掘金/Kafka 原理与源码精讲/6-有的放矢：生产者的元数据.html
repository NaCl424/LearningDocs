<!DOCTYPE html><html lang="en"><head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>第 01 讲：设计一份吸引面试官的简历</title>
<style type="text/css">
:root {
    --control-text-color: #777;
    --select-text-bg-color: rgba(223, 197, 223);  /*#7e66992e;*/
    
    /* side bar */
    --side-bar-bg-color: rgb(255, 255, 255);
    --active-file-text-color: #8163bd;
    --active-file-bg-color: #E9E4F0;
    --item-hover-bg-color: #E9E4F0;
    --active-file-border-color: #8163bd;

    --title-color: #6c549c;
    --font-sans-serif: 'Ubuntu', 'Source Sans Pro', sans-serif !important;
    --font-monospace: 'Fira Code', 'Roboto Mono', monospace !important;
    --purple-1: #8163bd;
    --purple-2: #79589F;
    --purple-3: #fd5eb8;
    --purple-light-1: rgba(99, 99, 172, .05);
    --purple-light-2: rgba(99, 99, 172, .1);
    --purple-light-3: rgba(99, 99, 172, .2);
    --purple-light-4: rgba(129, 99, 189, .3);
    --purple-light-5: #E9E4F0;
    --purple-light-6: rgba(129, 99, 189, .8);
}

/* html {
    font-size: 16px;
} */

body {
    font-family: var(--font-sans-serif);
    color: #34495e;
    -webkit-font-smoothing: antialiased;
    line-height: 1.6rem;
    letter-spacing: 0;
    margin: 0;
    overflow-x: hidden;
}

/* 页边距 和 页面大小 */
#write {
    padding-left: 6ch;
    padding-right: 6ch;
    margin: 0 auto;
}

#write p {
    line-height: 1.6rem;
    word-spacing: .05rem;
}

#write ol li {
    padding-left: 0.5rem;
}

#write > ul:first-child,
#write > ol:first-child {
    margin-top: 30px;
}

body > *:first-child {
    margin-top: 0 !important;
}

body > *:last-child {
    margin-bottom: 0 !important;
}

a {
    color: var(--purple-1);
    padding: 0 2px;
    text-decoration: none;
}
.md-content {
    color: var(--purple-light-6);
}
#write a {
    border-bottom: 1px solid var(--purple-1);
    color: var(--purple-1);
    text-decoration: none;
}

h1,
h2,
h3,
h4,
h5,
h6 {
    position: relative;
    margin-top: 1rem;
    margin-bottom: 0.5rem;
    /* font-weight: bold; */
    font-weight: 500 !important;
    line-height: 1.4;
    cursor: text;
    color: var(--title-color);
    font-family: var(--font-sans-serif);
}

h1:hover a.anchor,
h2:hover a.anchor,
h3:hover a.anchor,
h4:hover a.anchor,
h5:hover a.anchor,
h6:hover a.anchor {
    text-decoration: none;
}

h1 tt,
h1 code {
    font-size: inherit !important;
}
h2 tt,
h2 code {
    font-size: inherit !important;
}
h3 tt,
h3 code {
    font-size: inherit !important;
}
h4 tt,
h4 code {
    font-size: inherit !important;
}
h5 tt,
h5 code {
    font-size: inherit !important;
}
h6 tt,
h6 code {
    font-size: inherit !important;
}


h1 {
    padding-bottom: .4rem;
    font-size: 2.2rem;
    line-height: 1.3;
}
h1 {
    text-align: center;
    padding-bottom: 0.3em;
    font-size: 2.2em;
    line-height: 1.2;
    margin: 2.4em auto 1.2em;
}
h1:after {
    content: '';
    display: block;
    margin: 0.2em auto 0;
    width: 100px;
    height: 2px;
    border-bottom: 2px solid var(--title-color);
}

h2 {
    margin: 1.6em auto 0.5em;
    padding-left: 10px;
    line-height: 1.4;
    font-size: 1.8em;
    border-left: 9px solid var(--title-color);
    border-bottom: 1px solid var(--title-color);
}
h3 {
    font-size: 1.5rem;
    margin: 1.2em auto 0.5em;
}
h4 {
    font-size: 1.3rem;
}
h5 {
    font-size: 1.2rem;
}
h6 {
    font-size: 1.1rem;
}

p,
blockquote,
ul,
ol,
dl,
table {
    margin: 0.8em 0;
}

li > ol,
li > ul {
    margin: 0 0;
}

hr {
    height: 2px;
    padding: 0;
    margin: 16px 0;
    background-color: #e7e7e7;
    border: 0 none;
    overflow: hidden;
    box-sizing: content-box;
}

body > h2:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0;
}

body > h3:first-child,
body > h4:first-child,
body > h5:first-child,
body > h6:first-child {
    margin-top: 0;
    padding-top: 0;
}

a:first-child h1,
a:first-child h2,
a:first-child h3,
a:first-child h4,
a:first-child h5,
a:first-child h6 {
    margin-top: 0;
    padding-top: 0;
}

h1 p,
h2 p,
h3 p,
h4 p,
h5 p,
h6 p {
    margin-top: 0;
}

li p.first {
    display: inline-block;
}

ul,
ol {
    padding-left: 30px;
}

ul:first-child,
ol:first-child {
    margin-top: 0;
}

ul:last-child,
ol:last-child {
    margin-bottom: 0;
}

/* 引用 */
blockquote {
    /* margin-left: 1rem; */
    border-left: 4px solid var(--purple-light-4);
    padding: 10px 15px;
    color: #777;
    background-color: var(--purple-light-1);
}

/* 表格 */
table {
    padding: 0;
    word-break: initial;
}

table tr {
    border-top: 1px solid #dfe2e5;
    margin: 0;
    padding: 0;
}

/* 表格 背景色 */
table tr:nth-child(2n),
thead {
    background-color: var(--purple-light-1);
}
#write table thead th {
    background-color: var(--purple-light-2);
}

table tr th {
    font-weight: bold;
    border: 1px solid #dfe2e5;
    border-bottom: 0;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr td {
    border: 1px solid #dfe2e5;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr th:first-child,
table tr td:first-child {
    margin-top: 0;
}

table tr th:last-child,
table tr td:last-child {
    margin-bottom: 0;
}

/* 粗体 */
#write strong {
    padding: 0 2px;
    color: var(--purple-1);
}

/* 斜体 */
#write em {
    padding: 0 5px 0 2px;
    /* font-style: normal; */
    color: #42b983;
}

/* inline code */
#write code, tt {
    padding: 2px 4px;
    border-radius: 2px;
    font-family: var(--font-monospace);
    font-size: 0.92rem;
    color: var(--purple-3); 
    background-color: rgba(99, 99, 172, .05);
}

tt {
    margin: 0 2px;
}

#write .md-footnote {
    background-color: #f8f8f8;
    color: var(--purple-3);
}

/* heighlight. */
#write mark {
    background-color: #fbd3ea;
    border-radius: 2px;
    padding: 2px 4px;
    margin: 0 2px;
}

#write del {
    padding: 1px 2px;
}

.md-task-list-item > input {
    margin-left: -1.3em;
}

@media print {
    html {
        font-size: 0.9rem;
    }

    table,
    pre {
        page-break-inside: avoid;
    }

    pre {
        word-wrap: break-word;
    }
}

#write pre.md-meta-block {
    padding: 1rem;
    font-size: 85%;
    line-height: 1.45;
    background-color: #f7f7f7;
    border: 0;
    border-radius: 3px;
    color: #777777;
    margin-top: 0 !important;
}

.mathjax-block > .code-tooltip {
    bottom: .375rem;
}

/* 图片 */
.md-image > .md-meta {
    border-radius: 3px;
    font-family: var(--font-monospace);
    padding: 2px 0 0 4px;
    font-size: 0.9em;
    color: inherit;
}
p .md-image:only-child{
    width: auto;
    text-align: left;
    margin-left: 2rem;
}
.md-tag {
    color: inherit;
}
/* 当 “![shadow-随便写]()”写时，会有阴影 */
.md-image img[alt|='shadow'] {
    /* box-shadow: 0 4px 24px -6px #ddd; */
    box-shadow:var(--purple-light-2) 0px 10px 15px;
}

#write a.md-toc-inner {
    line-height: 1.6;
    white-space: pre-line;
    border-bottom: none;
    font-size: 0.9rem;
}

#typora-quick-open {
    border: 1px solid #ddd;
    background-color: #f8f8f8;
}

#typora-quick-open-item {
    background-color: #FAFAFA;
    border-color: #FEFEFE #e5e5e5 #e5e5e5 #eee;
    border-style: solid;
    border-width: 1px;
}

#md-notification:before {
    top: 10px;
}

header,
.context-menu,
.megamenu-content,
footer {
    font-family: var(--font-sans-serif);
}

.file-node-content:hover .file-node-icon,
.file-node-content:hover .file-node-open-state {
    visibility: visible;
}

.md-lang {
    color: #b4654d;
}

.html-for-mac .context-menu {
    --item-hover-bg-color: #E6F0FE;
}

/* 代码框 */
/* CodeMirror 3024 Day theme */

/* 代码段 背景 */
pre {
    --select-text-bg-color: rgba(223, 197, 223) !important;
    margin: .5em 0;
    padding: 1em 1.4em;
    border-radius: 8px;
    background: #f6f8fa;
    overflow-x: auto;
    box-sizing: border-box;
    font-size: 14px;
}

/* 边框 */
.md-fences {
    border: 1px solid #e7eaed;
    border-radius: 3px;
}

.cm-s-inner {
  padding: .25rem;
  border-radius: .25rem;
}

.cm-s-inner.CodeMirror, .cm-s-inner .CodeMirror-gutters {
  background-color: #f8f8f8 !important;
  color: #3a3432 !important;
  border: none;
}

.cm-s-inner .CodeMirror-gutters {
  color: #6d8a88;
}

.cm-s-inner .CodeMirror-cursor {
  border-left: solid thin #5c5855 !important;
}

.cm-s-inner .CodeMirror-linenumber {
  color: #807d7c;
}

.cm-s-inner .CodeMirror-line::selection, .cm-s-inner .CodeMirror-line::-moz-selection,
.cm-s-inner .CodeMirror-line > span::selection,
.cm-s-inner .CodeMirror-line > span::-moz-selection,
.cm-s-inner .CodeMirror-line > span > span::selection,
.cm-s-inner .CodeMirror-line > span > span::-moz-selection {
  background: var(--purple-light-2);
}

.cm-s-inner span.cm-comment {
  color: #cdab53;
}

.cm-s-inner span.cm-string, .cm-s-inner span.cm-string-2 {
  color: #f2b01d;
}

.cm-s-inner span.cm-number {
  color: #a34e8f;
}

.cm-s-inner span.cm-variable {
  color: #01a252;
}

.cm-s-inner span.cm-variable-2 {
  color: #01a0e4;
}

.cm-s-inner span.cm-def {
  /* color: #e8bbd0; */
  color: #e2287f;
}

.cm-s-inner span.cm-operator {
  color: #ff79c6;
}

.cm-s-inner span.cm-keyword {
  color: #db2d20;
}

.cm-s-inner span.cm-atom {
  color: #a34e8f;
}

.cm-s-inner span.cm-meta {
  color: inherit;
}

.cm-s-inner span.cm-tag {
  color: #db2d20;
}

.cm-s-inner span.cm-attribute {
  color: #01a252;
}

.cm-s-inner span.cm-qualifier {
  color: #388aa3;
}

.cm-s-inner span.cm-property {
  color: #01a252;
}

.cm-s-inner span.cm-builtin {
  color: #388aa3;
}

.cm-s-inner span.cm-variable-3, .cm-s-inner span.cm-type {
  color: #ffb86c;
}

.cm-s-inner span.cm-bracket {
  color: #3a3432;
}

.cm-s-inner span.cm-link {
  color: #a34e8f;
}

.cm-s-inner span.cm-error {
  background: #db2d20;
  color: #5c5855;
}

/* .md-fences.md-focus .cm-s-inner .CodeMirror-activeline-background {
  background: var(--purple-light-2);
} */

.cm-s-inner .CodeMirror-matchingbracket {
  text-decoration: underline;
  color: #a34e8f !important;
}

#fences-auto-suggest .active {
  background: #ddd;
}

#write .code-tooltip {
  bottom: initial;
  top: calc(100% - 1px);
  background: #f7f7f7;
  border: 1px solid #ddd;
  border-top: 0;
}

.auto-suggest-container {
  border-color: #b4b4b4;
}

.auto-suggest-container .autoComplt-hint.active {
  background: #b4b4b4;
  color: inherit;
}

/* task list */
#write .md-task-list-item > input {
  -webkit-appearance: initial;
  display: block;
  position: absolute;
  border: 1px solid #b4b4b4;
  border-radius: .25rem;
  margin-top: .1rem;
  margin-left: -1.8rem;
  height: 1.2rem;
  width: 1.2rem;
  transition: background 0.3s;
}

#write .md-task-list-item > input:focus {
  outline: none;
  box-shadow: none;
}

#write .md-task-list-item > input:hover {
  background: #ddd;
}

#write .md-task-list-item > input[checked]::before {
  content: '';
  position: absolute;
  top: 20%;
  left: 50%;
  height: 60%;
  width: 2px;
  transform: rotate(40deg);
  background: #333;
}

#write .md-task-list-item > input[checked]::after {
  content: '';
  position: absolute;
  top: 46%;
  left: 25%;
  height: 30%;
  width: 2px;
  transform: rotate(-40deg);
  background: #333;
}

#write .md-task-list-item > p {
  transition: color 0.3s, opacity 0.3s;
}

#write .md-task-list-item.task-list-done > p {
  color: #b4b4b4;
  text-decoration: line-through;
}

#write .md-task-list-item.task-list-done > p > .md-emoji {
  opacity: .5;
}

#write .md-task-list-item.task-list-done > p > .md-link > a {
  opacity: .6;
}

/* sidebar and outline */
.pin-outline .outline-active {
  color: var(--active-file-text-color); 
}

.file-list-item {
    border-bottom: 1px solid;
    border-color: var(--purple-light-5);
}

.file-list-item-summary {
    font-weight: 400;
}

.file-list-item.active {
    color: var(--active-file-text-color);
    background-color: var(--purple-light-5);
}

.file-tree-node.active>.file-node-background {
    background-color: var(--purple-light-5);
    font-weight: 700;
} 

.file-tree-node.active>.file-node-content {
    color: var(--active-file-text-color);
    font-weight: 700;
}

.file-node-content {
    color: #5e676d;
}

.sidebar-tabs {
    border-bottom: none;
}
.sidebar-tab.active {
    font-weight: 400;
}

.sidebar-content-content {
    font-size: 0.9rem;
}

img {
    max-width: 100%;
}

body {
    background-color: rgb(237, 237, 237);
}
#content {
    width: 836px;
    padding: 50px;
    background: #fff;
    margin: 0 auto;
}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/purple.css*/</style><style type="text/css">.hljs{display:block;overflow-x:auto;padding:.5em;color:#383a42;background:#fafafa}.hljs-comment,.hljs-quote{color:#a0a1a7;font-style:italic}.hljs-doctag,.hljs-formula,.hljs-keyword{color:#a626a4}.hljs-deletion,.hljs-name,.hljs-section,.hljs-selector-tag,.hljs-subst{color:#e45649}.hljs-literal{color:#0184bb}.hljs-addition,.hljs-attribute,.hljs-meta-string,.hljs-regexp,.hljs-string{color:#50a14f}.hljs-built_in,.hljs-class .hljs-title{color:#c18401}.hljs-attr,.hljs-number,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-pseudo,.hljs-template-variable,.hljs-type,.hljs-variable{color:#986801}.hljs-bullet,.hljs-link,.hljs-meta,.hljs-selector-id,.hljs-symbol,.hljs-title{color:#4078f2}.hljs-emphasis{font-style:italic}.hljs-strong{font-weight:700}.hljs-link{text-decoration:underline}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/atom-one-light.min.css*/</style></head>
<body>
<div id="content"><h1>有的放矢：生产者的元数据</h1>
<blockquote>
<p>这节课我提供了视频讲解，在源码讲解的基础上增加了原理解析和架构学习的部分，对应的视频地址如下
<a href="https://www.bilibili.com/video/BV1ZT4y167Jg" target="_blank" rel="nofollow noopener noreferrer">https://www.bilibili.com/video/BV1ZT4y167Jg</a></p>
</blockquote>
<p>前面我们已经讲解了生产者主线程和后台子线程Sender的源码逻辑，消息从发送请求到接收响应，但是<code>元数据在生产端的获取和管理</code>还没有介绍，今天我们就来学习生产者是如何获取和管理元数据的。</p>
<p>元数据的获取对生产者有什么用呢？比如，主题迁移到别的服务端节点，这时生产者需要及时知道主题都分布在哪些服务端节点上，不然向错误的服务端节点发送消息会失败，所以<code>及时的元数据获取对生产者正常工作是很有必要的</code>。</p>
<p>元数据的获取涉及到的组件是比较多的，大致分为：<strong>主线程KafkaProducer负责的加载元数据、子线程Sender负责的拉取元数据</strong>。</p>
<h2>加载元数据</h2>
<p>首先，我们先学习主线程是如何加载元数据的。</p>
<p>元数据一开始初始化的时候是在KafkaProducer主流程里，你可以看一下相关源代码：</p>
<pre><code>KafkaProducer(Map&#x3C;String, Object> configs,
              Serializer&#x3C;K> keySerializer,
              Serializer&#x3C;V> valueSerializer,
              ProducerMetadata metadata,
              KafkaClient kafkaClient,
              ProducerInterceptors&#x3C;K, V> interceptors,
              Time time) {
    ......忽略
        if (metadata != null) {
          
            this.metadata = metadata;
        } else {
、           //初始化MetaData
            this.metadata = new ProducerMetadata(retryBackoffMs,
                    //元数据过期时间：默认5分钟
                    config.getLong(ProducerConfig.METADATA_MAX_AGE_CONFIG),
                    config.getLong(ProducerConfig.METADATA_MAX_IDLE_CONFIG),
                    logContext,
                    clusterResourceListeners,
                    Time.SYSTEM);
            //启动metadata的引导程序
            this.metadata.bootstrap(addresses);
        }
       ......忽略
}
</code></pre>
<p>在KafkaProducer的构造方法中初始化了元数据类MetaData，然后启动metadata.bootstrap的引导程序，这个时候metaData对象里并没有具体的元数据信息，因为客户端还没发送元数据更新的请求。</p>
<p>下图是Metadata类以及Metadata类相关的类。</p>
<p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/fd883185574549e8b4248284c6be53c8~tplv-k3u1fbpfcp-watermark.image?" alt="5CF9AA7B-AEB2-4EF6-8800-AF3DC0F1344F.png"></p>
<ul>
<li>Metadata类是元数据类，里面封装了元数据的具体信息以及元数据的版本控制、更新等方法。</li>
<li>元数据的信息保存在MetadataCache里，MetadataCache里最核心信息是Cluster，保存了元数据的基础信息。</li>
<li>ProducerMetadata和ConsumerMetadata是Metadata类的两个子类。ConsumerMetadata我会在后面消费者模块给你讲解，其他的类这节课都有涉及。</li>
</ul>
<h3>Metadata类</h3>
<p>这个类封装了元数据具体的数据和元数据的操作，会被生产端的主线程和Sender子线程使用，所以它是个线程安全的类。元数据类仅仅维护着主题子集的相关元数据，并不是全部的主题元数据，这样的好处是能够减少网络传输的数据量，如果集群中有几千个主题网络传输的量肯定是惊人的，生产者只获取自己发送的主题集合的元数据就可以了。同时，如果有一个新的主题需要发送会触发元数据请求。</p>
<p>介绍源码之前，我们先了解下元数据请求和响应的字段。</p>
<ul>
<li><strong>元数据的请求</strong>。对应类MetadataRequest。MetadataRequest请求的格式比较简单，消息体包含了要获取相关元数据的Topic集合。如果Topic集合为Null，就意味着要请求全部的Topic元数据。</li>
<li><strong>元数据的响应</strong>。对应类MetadataResponse。MetadataResponse的结构比较复杂，如下图所示：</li>
</ul>
<p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e2a5e2c34be84eefa8362f80568a3a4e~tplv-k3u1fbpfcp-watermark.image?" alt="8564221B-0D30-4637-855D-6492601A52B4.png"></p>
<p>其每个字段的含义我汇总到了下面的列表里：</p>











































































<table><thead><tr><th>名称</th><th>类型</th><th>含义</th></tr></thead><tbody><tr><td>node_id</td><td>int</td><td>Node节点id</td></tr><tr><td>host</td><td>String</td><td>Node节点的Host名称</td></tr><tr><td>port</td><td>int</td><td>Node节点的端口号</td></tr><tr><td>rack</td><td>String</td><td>每个Broker的机架信息</td></tr><tr><td>controller_id</td><td>int</td><td>controller所在的Node节点id</td></tr><tr><td>topic_error_code</td><td>short</td><td>错误码</td></tr><tr><td>topic</td><td>String</td><td>Topic的名称</td></tr><tr><td>is_internal</td><td>boolean</td><td>是否为Kafka内部的Topic</td></tr><tr><td>partition_error_code</td><td>short</td><td>错误码</td></tr><tr><td>partition_id</td><td>int</td><td>分区编号</td></tr><tr><td>leader</td><td>int</td><td>分区的leader replica所在的 node id</td></tr><tr><td>replicas</td><td>int集合</td><td>此分区所有Replica所在的Node节点的Id的集合</td></tr><tr><td>isr</td><td>int集合</td><td>此分区ISR所在的Node节点的Id的集合</td></tr></tbody></table>
<p>为了更好地了解源码，我们还是需要讲解下Metadata类的相关字段和方法。</p>
<p><strong>字段</strong></p>
<pre><code>public class Metadata implements Closeable {
    private final Logger log;
    private final long refreshBackoffMs;//请求退避时间，默认100ms
    private final long metadataExpireMs;//元数据过期时间，默认5分钟
    private int updateVersion;  // 每次更新元数据时加一
    private int requestVersion; // 每次添加一个新的主题都会加一
    private long lastRefreshMs;//最后一次更新时间
    private long lastSuccessfulRefreshMs;//最后一次成功更新时间戳
    private Set&#x3C;String> invalidTopics;//无效的主题
    private Set&#x3C;String> unauthorizedTopics;//没有权限的主题
    private MetadataCache cache = MetadataCache.empty();//元数据
    private boolean needFullUpdate;//是否需要全部主题更新
    private boolean needPartialUpdate;//是否需要部分主题更新
</code></pre>
<p>这些字段的含义和关键点如下。</p>
<ul>
<li><code>refreshBackoffMs</code>：请求元数据失败重试间隔时间，默认100ms。</li>
<li><code>metadataExpireMs</code>：元数据过期时间，默认5分钟，过期时间一到就会发送更新元数据的请求。</li>
<li><code>updateVersion</code>：生产者本地内存元数据版本，每次从服务端获取到元数据就加1。</li>
<li><code>requestVersion</code>：每次元数据要加入新的主题都会加一。</li>
<li><code>lastRefreshMs</code>：最后一次更新元数据的时间。</li>
<li><code>lastSuccessfulRefreshMs</code>：最后一次成功更新全部主题元数据的时间。</li>
<li><code>invalidTopics</code>：无效的主题集合。</li>
<li><code>unauthorizedTopics</code>：没有权限的主题集合。</li>
<li><code>cache</code>：MetadataCache 类对象。元数据缓存，客户端真正存储元数据的对象。</li>
<li><code>needFullUpdate</code>：是否需要全部主题的更新。对应生产者，这里的整体是指生产者最近发送的主题集合。</li>
<li><code>needPartialUpdate</code>：是否部分主题更新。对于生产者，这里的部分主题指新发送的主题。</li>
</ul>
<p><strong>方法</strong></p>
<p>下面再来解析Metadata类重要方法的源代码。</p>
<p><strong>bootstrap()</strong>，这个方法是引导方法，负责在第一次使用前的一些初始化工作。</p>
<pre><code>public synchronized void bootstrap(List&#x3C;InetSocketAddress> addresses) {
    this.needFullUpdate = true;
    this.updateVersion += 1;
    this.cache = MetadataCache.bootstrap(addresses);
}
</code></pre>
<p>因为是生产者刚启动，本地缓存中的元数据是空的，所以是否全部主题更新赋为true。版本更新为1。最后，初始化元数据缓存。你可以看一下元数据缓存的初始化代码：</p>
<pre><code>static MetadataCache bootstrap(List&#x3C;InetSocketAddress> addresses) {
    Map&#x3C;Integer, Node> nodes = new HashMap&#x3C;>();
    int nodeId = -1;
    for (InetSocketAddress address : addresses) {
        nodes.put(nodeId, new Node(nodeId, address.getHostString(), address.getPort()));
        nodeId--;
    }
    return new MetadataCache(null, nodes, Collections.emptyList(),
            Collections.emptySet(), Collections.emptySet(), Collections.emptySet(),
            null, Cluster.bootstrap(addresses));
}
</code></pre>
<p>因为还没获取到元数据，这时的元数据缓存都是空的数据和集合组成。</p>
<p>向服务器请求元数据在元数据更新器中，元数据类只有解析响应的方法，我们就先看看元数据类是如何解析的，这里又涉及到两个方法——update()和handleMetadataResponse(）。</p>
<p><strong>update()方法</strong>具体情况：</p>
<pre><code>public synchronized void update(int requestVersion, MetadataResponse response, boolean isPartialUpdate, long nowMs) {
    Objects.requireNonNull(response, "Metadata response cannot be null");
    if (isClosed())
        throw new IllegalStateException("Update requested after metadata close");
    //1.判断是否是部分主题更新，以及更新几个字段
    this.needPartialUpdate = requestVersion &#x3C; this.requestVersion;
    this.lastRefreshMs = nowMs;
    this.updateVersion += 1;
    if (!isPartialUpdate) {
        this.needFullUpdate = false;
        this.lastSuccessfulRefreshMs = nowMs;
    }


    String previousClusterId = cache.clusterResource().clusterId();
    //2.解析元数据响应
    this.cache = handleMetadataResponse(response, isPartialUpdate, nowMs);
    ......忽略
}
</code></pre>
<p>可分析为如下。</p>
<ol>
<li>根据requestVersion参数和元数据里的requestVersion比较判断是否是更新部分主题的响应。如果是更新全部主题的响应，说明更新全部主题的响应已经收到了，首先把needFullUpdate标记为零，目的是不要再更新全部主题了，然后把lastSuccessfulRefreshMs 更新为当前时间。</li>
<li>解析响应，并缓存。</li>
</ol>
<p>我们接下来解析下元数据响应的解析方法handleMetadataResponse()。</p>
<p><strong>handleMetadataResponse()</strong>，该方法解析元数据并根据元数据实例化新的MetadataCache对象。</p>
<pre><code>private MetadataCache handleMetadataResponse(MetadataResponse metadataResponse, boolean isPartialUpdate, long nowMs) {
    // All encountered topics.


    Set&#x3C;String> topics = new HashSet&#x3C;>();


    // 1.初始化相关集合Retained topics to be passed to the metadata cache.
    Set&#x3C;String> internalTopics = new HashSet&#x3C;>();
    Set&#x3C;String> unauthorizedTopics = new HashSet&#x3C;>();
    Set&#x3C;String> invalidTopics = new HashSet&#x3C;>();


    List&#x3C;MetadataResponse.PartitionMetadata> partitions = new ArrayList&#x3C;>();
    //2.轮询响应中的主题元数据。
    for (MetadataResponse.TopicMetadata metadata : metadataResponse.topicMetadata()) {
        topics.add(metadata.topic());
        //3.判断是否保留主题元数据。
        if (!retainTopic(metadata.topic(), metadata.isInternal(), nowMs))
            continue;
        //4.判断是否是内部主题。
        if (metadata.isInternal())
            internalTopics.add(metadata.topic());
        //5.如果元数据响应没有错误就更新本地元数据缓存
        if (metadata.error() == Errors.NONE) {
            //6.遍历分区信息
            for (MetadataResponse.PartitionMetadata partitionMetadata : metadata.partitionMetadata()) {
                updateLatestMetadata(partitionMetadata, metadataResponse.hasReliableLeaderEpochs())
                    .ifPresent(partitions::add);
                //分区数据有问题
                if (partitionMetadata.error.exception() instanceof InvalidMetadataException) {
                    log.debug("Requesting metadata update for partition {} due to error {}",
                            partitionMetadata.topicPartition, partitionMetadata.error);
                    //标记需要更新元数据
                    requestUpdate();
                }
            }
            //如果元数据响应有错误
        } else {
            //无效元数据异常
            if (metadata.error().exception() instanceof InvalidMetadataException) {
                log.debug("Requesting metadata update for topic {} due to error {}", metadata.topic(), metadata.error());
                //标记需要更新元数据
                requestUpdate();
            }
            //如果是无效主题的错误
            if (metadata.error() == Errors.INVALID_TOPIC_EXCEPTION)
                invalidTopics.add(metadata.topic());
            //如果是无权限主题的错误
            else if (metadata.error() == Errors.TOPIC_AUTHORIZATION_FAILED)
                unauthorizedTopics.add(metadata.topic());
        }
    }
    //8.如果是部分主题的响应就和现在的元数据缓存整合在一起，如果不是就重建元数据缓存对象
    Map&#x3C;Integer, Node> nodes = metadataResponse.brokersById();
    if (isPartialUpdate)
        return this.cache.mergeWith(metadataResponse.clusterId(), nodes, partitions,
            unauthorizedTopics, invalidTopics, internalTopics, metadataResponse.controller(),
            (topic, isInternal) -> !topics.contains(topic) &#x26;&#x26; retainTopic(topic, isInternal, nowMs));
    else
        return new MetadataCache(metadataResponse.clusterId(), nodes, partitions,
            unauthorizedTopics, invalidTopics, internalTopics, metadataResponse.controller());
}
</code></pre>
<p>给你讲解下主流程方法的步骤：</p>
<ol>
<li>初始化相关集合，包括内部主题集合、无效主题集合、无权限主题集合。</li>
<li>按主题维度轮询元数据响应。</li>
<li>判断是否保留这个主题，因为有可能主题过期了等原因造成没有必要保留这个主题。</li>
<li>判断是否是内部主题，如果是内部主题就放入内部主题集合。</li>
<li>如果主题相关元数据没有error，就开始解析响应。</li>
<li>遍历主题下的分区信息，把分区信息更新到元数据缓存。同时会对异常做处理，如果分区有无效的元数据异常则要打出相应的日志，同时做好需要更新元数据的标记，提醒 Sender 线程去更新元数据。</li>
<li>如果主题元数据有error，则会对不同的error分别做处理。</li>
</ol>
<ul>
<li>如果是无效元数据的error，就做好需要更新元数据的标记，提醒 Sender 线程去更新元数据。</li>
<li>如果是无效主题的error，就把主题放入无效主题集合里。</li>
<li>如果是无权限的主题，就把主题放入无权限主题集合里。</li>
</ul>
<ol start="8">
<li>如果是部分主题的响应，就和现在的元数据缓存整合在一起，如果不是就重建元数据。</li>
</ol>
<p>MetaData类是元数据处理的基础，但对于生产者来说还不能满足生产端对元数据的处理需求，还需要MetaData类的子类ProducerMetadata类来进一步满足了生产者对元数据的处理需求。</p>
<h3>ProducerMetadata类</h3>
<p>我们来分析一下ProducerMetadata类的源码，同样还是从字段和方法维度来分析。</p>
<p><strong>字段</strong></p>
<pre><code>public class ProducerMetadata extends Metadata {
    /* 
    *  主题和主题对应的过期时间。5分钟过期，nowMs+5分钟。
    *  这个集合是比较新的主题，过了期就认为不新了，会被删除
    *  */
    private final Map&#x3C;String, Long> topics = new HashMap&#x3C;>();
    //新的主题集合
    private final Set&#x3C;String> newTopics = new HashSet&#x3C;>();
public class ProducerMetadata extends Metadata {
    private final Map&#x3C;String, Long> topics = new HashMap&#x3C;>();
    private final Set&#x3C;String> newTopics = new HashSet&#x3C;>();
</code></pre>
<ol>
<li><code>topics</code>：类型是map集合，生产者的刷新主题集合，保存着主题和主题过期时间的对应关系。刷新主题集合的作用是，当5分钟元数据过期，我们要向服务端更新元数据时，我们仅仅需要这个集合里的主题对应的元数据，这样就能大大减少响应的数据量。</li>
<li><code>newTopics</code>：第一次发送的主题会进入这个集合。</li>
</ol>
<p><strong>重要方法</strong></p>
<p><strong>add()</strong> 这个方法的作用是向生产者元数据缓存添加主题。</p>
<pre><code>public synchronized void add(String topic, long nowMs) {
    Objects.requireNonNull(topic, "topic cannot be null");
    if (topics.put(topic, nowMs + metadataIdleMs) == null) {
        newTopics.add(topic);
        requestUpdateForNewTopics();
    }
}
</code></pre>
<p>具体步骤是：往刷新主题集合里添加这个主题及对应的过期时间（当前时间+过期时间段，默认5分钟）。如果集合中原来并不存在这个主题，就再把这个主题放到新主题集合里，然后标记要更新新主题元数据的标记，等待后续Sender线程去请求服务端获取新主题的元数据。</p>
<p>那么刷新主题集合里的数据过期了会如何处理呢？我们接下来再了解下retainTopic()方法。</p>
<p><strong>retainTopic()</strong> 这个方法的作用是否元数据中保留这个主题。当解析到元数据响应的时候会调用这个方法。</p>
<pre><code>public synchronized boolean retainTopic(String topic, boolean isInternal, long nowMs) {
    Long expireMs = topics.get(topic);
    if (expireMs == null) {
        return false;
    } else if (newTopics.contains(topic)) {
        return true;
    } else if (expireMs &#x3C;= nowMs) {
        log.debug("Removing unused topic {} from the metadata list, expiryMs {} now {}", topic, expireMs, nowMs);
        topics.remove(topic);
        return false;
    } else {
        return true;
    }
}
</code></pre>
<p>首先在刷新主题集合中找这个主题，如果不存在，说明本来就不在刷新主题集合，就直接返回false。如果在新主题集合里存在这个主题就返回true。</p>
<p>如果超出了过期时间，就从刷新主题集合删除这个主题，说明这个主题很久没有发送消息了，这样在请求元数据时就不用带上这个主题，从而减少了网络传输的数据大小。</p>
<p><strong>update()</strong> 方法，生产端更新元数据缓存的方法。</p>
<pre><code>public synchronized void update(int requestVersion, MetadataResponse response, boolean isPartialUpdate, long nowMs) {
    super.update(requestVersion, response, isPartialUpdate, nowMs);
    // 找出已获得相关元数据的相关主题，并从新主题集合中删除
    if (!newTopics.isEmpty()) {
        for (MetadataResponse.TopicMetadata metadata : response.topicMetadata()) {
            newTopics.remove(metadata.topic());
        }
    }
    notifyAll();
}
</code></pre>
<p>先调用父类update()方法，然后遍历响应的主题并从newTopics中删除，最后通过调用notifyAll()唤醒等待元数据更新完成而阻塞的线程。</p>
<p>那notifyAll()唤醒的是什么操作呢？这就引出了下面我要讲解的awaitUpdate()。</p>
<p><strong>awaitUpdate()</strong> 方法，当生产者主线程发现没有主题对应的元数据时，主线程会等待sender线程把元数据更新完成。你可以看一下下面的相关源码：</p>
<pre><code>public synchronized void awaitUpdate(final int lastVersion, final long timeoutMs) throws InterruptedException {
    long currentTimeMs = time.milliseconds();
    long deadlineMs = currentTimeMs + timeoutMs &#x3C; 0 ? Long.MAX_VALUE : currentTimeMs + timeoutMs;
    time.waitObject(this, () -> {
        maybeThrowFatalException();
        return updateVersion() > lastVersion || isClosed();
    }, deadlineMs);


    if (isClosed())
        throw new KafkaException("Requested metadata update after close");
}
</code></pre>
<p>这个方法主要是调用time.waitObject()实现了线程阻塞的功能，time.waitObject()底层通过调用Object.wait()方法实现了线程的阻塞。代码如下：</p>
<pre><code>public void waitObject(Object obj, Supplier&#x3C;Boolean> condition, long deadlineMs) throws InterruptedException {
    synchronized (obj) {
        while (true) {
            //检查更新是否成功，成功后直接返回
            if (condition.get())
                return;


            long currentTimeMs = milliseconds();
            if (currentTimeMs >= deadlineMs)
                throw new TimeoutException("Condition not satisfied before deadline");
            //调用wait()阻塞线程
            obj.wait(deadlineMs - currentTimeMs);
        }
    }
}
</code></pre>
<p>当每次元数据响应后元数据处理成功时，会唤醒阻塞的线程然后检查获取的元数据版本是否大于现在的元数据版本，即检查是否元数据更新成功。如果元数据更新成功或生产者关闭了，就解除阻塞；如果没有更新成功，就继续阻塞直到阻塞超时。</p>
<p>好了，元数据管理介绍完了，接下来介绍元数据加载。</p>
<h3>元数据同步等待</h3>
<p>我们先看一下，主线程类KafkaProducer是如何等待元数据的更新的，源码如下：
 </p>
<pre><code>private Future&#x3C;RecordMetadata> doSend(ProducerRecord&#x3C;K, V> record, Callback callback) {
    TopicPartition tp = null;
    try {
        throwIfProducerClosed();
        long nowMs = time.milliseconds();
        ClusterAndWaitTime clusterAndWaitTime;
        try {
            //1.等待元数据更新
            clusterAndWaitTime = waitOnMetadata(record.topic(), record.partition(), nowMs, maxBlockTimeMs);
        } catch (KafkaException e) {
            if (metadata.isClosed())
                throw new KafkaException("Producer closed while send in progress", e);
            throw e;
        }
        nowMs += clusterAndWaitTime.waitedOnMetadataMs;
        long remainingWaitMs = Math.max(0, maxBlockTimeMs - clusterAndWaitTime.waitedOnMetadataMs);
        ......忽略
</code></pre>
<p>生产者主线程在发送消息前先获取元数据，这样才能知道消息要发送到哪里。通过调用waitOnMetadata()方法获取元数据和获取元数据消耗的时间，为下面的发送消息提供数据支持。</p>
<p>我们也具体看一下 <strong>waitOnMetadata()</strong> 方法的源码：</p>
<pre><code>private ClusterAndWaitTime waitOnMetadata(String topic, Integer partition, long nowMs, long maxWaitMs) throws InterruptedException {
    // add topic to metadata topic list if it is not there already and reset expiry
    // 1.获取元数据
    Cluster cluster = metadata.fetch();
    //判断是否是无效的缓存
    if (cluster.invalidTopics().contains(topic))
        throw new InvalidTopicException(topic);
    //2.把主题放入元数据主题列表
    metadata.add(topic, nowMs);
    //3.从元数据中找到主题对应的分区数。
    Integer partitionsCount = cluster.partitionCountForTopic(topic);
    // 4.如果客户端缓存中的元数据能找到消息发送对应分区，就不用去服务端请求更新元数据了，直接返回从生产者缓存中的元数据
    // 这里会拦截住大部分的消息发送。
    // 如果消息的主题有对应的分区，而且消息的分区没有设置或消息指定的发送分区在已知分区范围。就认为
    // 生产者元数据缓存中有对应的主题分区，这时就不用再请求最新的元数据了。直接用现在的元数据缓存
    if (partitionsCount != null &#x26;&#x26; (partition == null || partition &#x3C; partitionsCount))
        return new ClusterAndWaitTime(cluster, 0);


    long remainingWaitMs = maxWaitMs;
    long elapsed = 0;
   
    // 5.轮询不断要求Sender更新元数据。
    do {
        if (partition != null) {
            log.trace("Requesting metadata update for partition {} of topic {}.", partition, topic);
        } else {
            log.trace("Requesting metadata update for topic {}.", topic);
        }
        //6.把主题和过期时间加入元数据主题列表中
        metadata.add(topic, nowMs + elapsed);
        //7.标记元数据需要更新，并获得版本
        int version = metadata.requestUpdateForTopic(topic);
        //8.唤醒sender线程。
        sender.wakeup();//因为send()和poll()方法的调用都在sender线程里，需要中断seletor()的阻塞及时把元数据的请求发送出去。
        try {
            //9.阻塞线程。
            metadata.awaitUpdate(version, remainingWaitMs);
        } catch (TimeoutException ex) {
         
            throw new TimeoutException(
                    String.format("Topic %s not present in metadata after %d ms.",
                            topic, maxWaitMs));
        }
        //10.获取元数据
        cluster = metadata.fetch();
        //11.计算等待更新元数据消耗了多少时间。
        elapsed = time.milliseconds() - nowMs;
        //12.超时抛出异常。
        if (elapsed >= maxWaitMs) {
            throw new TimeoutException(partitionsCount == null ?
                    String.format("Topic %s not present in metadata after %d ms.",
                            topic, maxWaitMs) :
                    String.format("Partition %d of topic %s with partition count %d is not present in metadata after %d ms.",
                            partition, topic, partitionsCount, maxWaitMs));
        }
        metadata.maybeThrowExceptionForTopic(topic);
        remainingWaitMs = maxWaitMs - elapsed;
        //13.获取元数据分区数
        partitionsCount = cluster.partitionCountForTopic(topic);
    } while (partitionsCount == null || (partition != null &#x26;&#x26; partition >= partitionsCount));
    //14.返回获取的元数据和更新元数据耗费的时间
    return new ClusterAndWaitTime(cluster, elapsed);
}
</code></pre>
<p>方法步骤可梳理为如下。</p>
<ol>
<li>获取生产者缓存的元数据，判断主题是否是有效主题，如果不是有效主题就放入无效主题集合里。</li>
<li>把主题放入元数据主题列表里。Sender线程会定时请求服务端更新主题列表里相关元数据。</li>
<li>从生产端缓存的元数据中找到主题对应的分区数。</li>
<li>判断生产端缓存的元数据是否能满足这次发送的需要，判断标准是主题对应的分区数不能为零且指定分区id小于分区数，总的来说就是能够找到要发送消息的主题分区。</li>
<li>轮询不断要求Sender更新元数据，直到获得主题及分区信息或获取元数据阻塞时间超时。解决两个问题：主题的分区数量增加了；元数据版本旧。</li>
<li>把主题和过期时间加入元数据主题列表中。</li>
<li>通过标记元数据需要Sender线程更新，并获得当前元数据的版本号。</li>
<li>唤醒Sender后台子线程。Sender线程一直都是运行的，唤醒的目的是让Sender线程从select()阻塞中立即返回，然后把获取元数据channel的网络事件注册在selector上，这样就可以及时监听获取元数据的网络事件了。</li>
<li>阻塞主线程，等待Sender线程完成更新元数据。</li>
<li>Sender子线程更新成功或阻塞超时唤醒主线程的阻塞，主线程获取内存中的元数据。</li>
<li>计算获取元数据耗时多久。</li>
<li>如果耗时大于最大等待时间（默认1分钟）就抛出超时异常。</li>
<li>获取发送主题的分区数。</li>
<li>判断while继续轮询的条件，判断规则是满足下面两个条件中的一个即可：</li>
</ol>
<ul>
<li>从元数据中得到的发送主题的分区数为空；</li>
<li>分区不为空且要发送的分区数大于主题分区数。</li>
</ul>
<p>这个方法涵盖整个元数据加载流程，流程比较复杂，我在下方画了一个流程图，希望能够帮助你理解：</p>
<p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b7bc785c78434e34b38673b16e4082a3~tplv-k3u1fbpfcp-watermark.image?" alt="360166BD-FA44-4C03-B123-3C27A588480A.png"></p>
<p>好了，元数据加载我们学习完了，下面学习元数据的拉取流程。</p>
<h2>拉取元数据</h2>
<p>拉取元数据是Sender子线程负责的工作，具体是调用Sender类的组件NetworkClient的poll()方法，源码在下面：</p>
<pre><code>public List&#x3C;ClientResponse> poll(long timeout, long now) {
    ensureActive();


    if (!abortedSends.isEmpty()) {
        List&#x3C;ClientResponse> responses = new ArrayList&#x3C;>();
        handleAbortedSends(responses);
        completeResponses(responses);
        return responses;
    }
    //1.尝试更新元数据
    long metadataTimeout = metadataUpdater.maybeUpdate(now);
</code></pre>
<p>这里涉及到了元数据更新器的组件，下面是元数据更新类的类图关系：</p>
<p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0e12cc3a40d04b8bac548338c0133cdb~tplv-k3u1fbpfcp-watermark.image?" alt="7EB60D70-1F0F-4B07-BF16-1A85AAA0C222.png"></p>
<p>MetadataUpdater是元数据更新操作的接口，AdminMetadataUpdater类是MetadataUpdater在后台管理的实现，元数据更新接口在客户端的实现是DefaultMetadataUpdater类。</p>
<p>下面我主要讲解DefaultMetadataUpdater类在客户端的应用。</p>
<h2>类DefaultMetadataUpdater</h2>
<p>DefaultMetadataUpdater是NetworkClient的内部类。这里我们主要学习下这个类的方法。</p>
<p><strong>maybeUpdate(long now)，这个方法用于正式发送元数据请求前的判断，主要是判断发送元数据请求的时机</strong>，源代码和注释如下：</p>
<pre><code>public long maybeUpdate(long now) {
    // should we update our metadata?
    // 1.下次更新的时间
    long timeToNextMetadataUpdate = metadata.timeToNextUpdate(now);
    // 2.检测是否已经发送了MetadataRequest请求
    long waitForMetadataFetch = hasFetchInProgress() ? defaultRequestTimeoutMs : 0;
    long metadataTimeout = Math.max(timeToNextMetadataUpdate, waitForMetadataFetch);
    if (metadataTimeout > 0) {
        return metadataTimeout;
    }


    //找到最小负载的node。
    Node node = leastLoadedNode(now);
    //没有node就
    if (node == null) {
        log.debug("Give up sending metadata request since no node is available");
        return reconnectBackoffMs;
    }
    return maybeUpdate(now, node);
}
</code></pre>
<p>首先我们需要计算两个时间戳：</p>
<ul>
<li><strong>根据当前时间计算下一次 MetaData 更新的时间戳</strong>；</li>
<li><strong>根据退避时间（防止服务端连接过于频繁而设置的一个间隔时间）计算下一次重新连接服务器端的时间戳</strong>。</li>
</ul>
<p><strong>然后取这两个时间戳的最大值，作为 metaData 超时时间</strong>（metadataTimeout）。同时还要考虑客户端是不是已经发送了更新元数据的请求，如果发送了，返回值就是Integer.MAX_VALUE。如果当metaData 超时时间为 0，也就是 metadataTimeout == 0，这时从 Broker 中找到一个负载最小的节点。这里的负载大小是通过每个Node在InFlightRequests队列中未收到响应的请求决定的，未收到响应的请求越多则认为负载越大。然后设置到把当前时间和找到的节点当作参数调用无返回值的 maybeUpdate(now, node)。</p>
<p><strong>maybeUpdate(long now, Node node)</strong>，这个方法的功能是向节点发送元数据请求，和普通请求一样，先将请求放入InFlightRequests队列中，然后设置到KafkaChannel的send字段中。我们来看一下具体的发送过程，代码如下所示：
 </p>
<pre><code>private long maybeUpdate(long now, Node node) {
    String nodeConnectionId = node.idString();
    // 1.判断是否能够向这个node发送请求
    if (canSendRequest(nodeConnectionId, now)) {
        //1.1 构建元数据请求
        Metadata.MetadataRequestAndVersion requestAndVersion = metadata.newMetadataRequestAndVersion(now);
        MetadataRequest.Builder metadataRequest = requestAndVersion.requestBuilder;
        log.debug("Sending metadata request {} to node {}", metadataRequest, node);
        //1.2 向指定节点发送元数据请求
        sendInternalMetadataRequest(metadataRequest, nodeConnectionId, now);
        inProgress = new InProgressData(requestAndVersion.requestVersion, requestAndVersion.isPartialUpdate);
        return defaultRequestTimeoutMs;
    }
    ......忽略
    //2.判断节点是否能连接上。
    if (connectionStates.canConnect(nodeConnectionId, now)) {
        // We don't have a connection to this node right now, make one
        log.debug("Initialize connection to node {} for sending metadata request", node);
        //初始化与node的连接
        initiateConnect(node, now);
        return reconnectBackoffMs;
    }
    return Long.MAX_VALUE;
}


void sendInternalMetadataRequest(MetadataRequest.Builder builder, String nodeConnectionId, long now) {
    ClientRequest clientRequest = newClientRequest(nodeConnectionId, builder, now, true);
    doSend(clientRequest, true, now);
}
</code></pre>
<p>首先调用方法<strong>canSendRequest()</strong> 检测选定的这个节点还是否能接收请求的条件（其中canSendRequest()在上节课讲过）。</p>
<p>如果不满足发送条件就去尝试与node连接，然后下次再尝试获取元数据。</p>
<p>如果满足发送条件就<strong>构建元数据请求对象</strong>，然后调用方法<strong>sendInternalMetadataRequest()</strong> 向指定的节点发送元数据请求，先构建ClientRequest对象，然后调用我们上节课讲的NetworkClient.doSend()方法，注意我上节课讲过这个方法只是把请求缓存下来，并没有真正发送，真正的网络发送是由NetworkClient.poll()方法完成的。</p>
<p><strong>handleSuccessfulResponse()</strong> 方法。元数据的请求过程介绍完了，然后给你介绍下<code>收到元数据后的解析</code>，代码如下所示：
 </p>
<pre><code>public void handleSuccessfulResponse(RequestHeader requestHeader, long now, MetadataResponse response) {
    ......忽略
    // 1.查看response的错误信息。
    Map&#x3C;String, Errors> errors = response.errors();
    if (!errors.isEmpty())
        log.warn("Error while fetching metadata with correlation id {} : {}", requestHeader.correlationId(), errors);
    //2.如果没有broker相关信息就认为没有获得元数据
    if (response.brokers().isEmpty()) {
        //更新失败
        this.metadata.failedUpdate(now);
    } else {
        //3.更新meatedata
        this.metadata.update(inProgress.requestVersion, response, inProgress.isPartialUpdate, now);
    }
    inProgress = null;
}
</code></pre>
<p>首先查看response返回信息的error。如果response内的brokers是空，那么我们可以判断更新失败了，这时需要调用failedUpdate(now)方法记录更新失败的时间，<strong>目的是避免立即重试造成服务端网络过载</strong>。如果response数据没有问题，就调用MetaData.update()方法去更新。</p>
<h2>总结</h2>
<p>这一节课我带你分析了<code>生产者获取元数据的相关代码</code>，现在我们一起来总结下。</p>
<p><strong>KafkaProducer主线程</strong>：首先判断是否要更新元数据，然后唤醒Sender线程去更新MetaData，同时阻塞自己等待Sender线程完成更新MetaData。</p>
<p><strong>Sender线程</strong>：真正发送消息的线程，这里主要分析了Sender对metaData request的封装以及解析，最后解除对 KafkaProducer 主线程的阻塞。</p>
<p><strong>DefaultMetadataUpdater</strong>：这是NetworkClient类的内部类，用于客户端更新元数据，包括发起元数据请求，解析最新的元数据，并更新元数据的操作。</p></div>
</body></html>
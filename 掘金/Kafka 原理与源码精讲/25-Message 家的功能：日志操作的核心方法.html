<!DOCTYPE html><html lang="en"><head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>第 01 讲：设计一份吸引面试官的简历</title>
<style type="text/css">
:root {
    --control-text-color: #777;
    --select-text-bg-color: rgba(223, 197, 223);  /*#7e66992e;*/
    
    /* side bar */
    --side-bar-bg-color: rgb(255, 255, 255);
    --active-file-text-color: #8163bd;
    --active-file-bg-color: #E9E4F0;
    --item-hover-bg-color: #E9E4F0;
    --active-file-border-color: #8163bd;

    --title-color: #6c549c;
    --font-sans-serif: 'Ubuntu', 'Source Sans Pro', sans-serif !important;
    --font-monospace: 'Fira Code', 'Roboto Mono', monospace !important;
    --purple-1: #8163bd;
    --purple-2: #79589F;
    --purple-3: #fd5eb8;
    --purple-light-1: rgba(99, 99, 172, .05);
    --purple-light-2: rgba(99, 99, 172, .1);
    --purple-light-3: rgba(99, 99, 172, .2);
    --purple-light-4: rgba(129, 99, 189, .3);
    --purple-light-5: #E9E4F0;
    --purple-light-6: rgba(129, 99, 189, .8);
}

/* html {
    font-size: 16px;
} */

body {
    font-family: var(--font-sans-serif);
    color: #34495e;
    -webkit-font-smoothing: antialiased;
    line-height: 1.6rem;
    letter-spacing: 0;
    margin: 0;
    overflow-x: hidden;
}

/* 页边距 和 页面大小 */
#write {
    padding-left: 6ch;
    padding-right: 6ch;
    margin: 0 auto;
}

#write p {
    line-height: 1.6rem;
    word-spacing: .05rem;
}

#write ol li {
    padding-left: 0.5rem;
}

#write > ul:first-child,
#write > ol:first-child {
    margin-top: 30px;
}

body > *:first-child {
    margin-top: 0 !important;
}

body > *:last-child {
    margin-bottom: 0 !important;
}

a {
    color: var(--purple-1);
    padding: 0 2px;
    text-decoration: none;
}
.md-content {
    color: var(--purple-light-6);
}
#write a {
    border-bottom: 1px solid var(--purple-1);
    color: var(--purple-1);
    text-decoration: none;
}

h1,
h2,
h3,
h4,
h5,
h6 {
    position: relative;
    margin-top: 1rem;
    margin-bottom: 0.5rem;
    /* font-weight: bold; */
    font-weight: 500 !important;
    line-height: 1.4;
    cursor: text;
    color: var(--title-color);
    font-family: var(--font-sans-serif);
}

h1:hover a.anchor,
h2:hover a.anchor,
h3:hover a.anchor,
h4:hover a.anchor,
h5:hover a.anchor,
h6:hover a.anchor {
    text-decoration: none;
}

h1 tt,
h1 code {
    font-size: inherit !important;
}
h2 tt,
h2 code {
    font-size: inherit !important;
}
h3 tt,
h3 code {
    font-size: inherit !important;
}
h4 tt,
h4 code {
    font-size: inherit !important;
}
h5 tt,
h5 code {
    font-size: inherit !important;
}
h6 tt,
h6 code {
    font-size: inherit !important;
}


h1 {
    padding-bottom: .4rem;
    font-size: 2.2rem;
    line-height: 1.3;
}
h1 {
    text-align: center;
    padding-bottom: 0.3em;
    font-size: 2.2em;
    line-height: 1.2;
    margin: 2.4em auto 1.2em;
}
h1:after {
    content: '';
    display: block;
    margin: 0.2em auto 0;
    width: 100px;
    height: 2px;
    border-bottom: 2px solid var(--title-color);
}

h2 {
    margin: 1.6em auto 0.5em;
    padding-left: 10px;
    line-height: 1.4;
    font-size: 1.8em;
    border-left: 9px solid var(--title-color);
    border-bottom: 1px solid var(--title-color);
}
h3 {
    font-size: 1.5rem;
    margin: 1.2em auto 0.5em;
}
h4 {
    font-size: 1.3rem;
}
h5 {
    font-size: 1.2rem;
}
h6 {
    font-size: 1.1rem;
}

p,
blockquote,
ul,
ol,
dl,
table {
    margin: 0.8em 0;
}

li > ol,
li > ul {
    margin: 0 0;
}

hr {
    height: 2px;
    padding: 0;
    margin: 16px 0;
    background-color: #e7e7e7;
    border: 0 none;
    overflow: hidden;
    box-sizing: content-box;
}

body > h2:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0;
}

body > h3:first-child,
body > h4:first-child,
body > h5:first-child,
body > h6:first-child {
    margin-top: 0;
    padding-top: 0;
}

a:first-child h1,
a:first-child h2,
a:first-child h3,
a:first-child h4,
a:first-child h5,
a:first-child h6 {
    margin-top: 0;
    padding-top: 0;
}

h1 p,
h2 p,
h3 p,
h4 p,
h5 p,
h6 p {
    margin-top: 0;
}

li p.first {
    display: inline-block;
}

ul,
ol {
    padding-left: 30px;
}

ul:first-child,
ol:first-child {
    margin-top: 0;
}

ul:last-child,
ol:last-child {
    margin-bottom: 0;
}

/* 引用 */
blockquote {
    /* margin-left: 1rem; */
    border-left: 4px solid var(--purple-light-4);
    padding: 10px 15px;
    color: #777;
    background-color: var(--purple-light-1);
}

/* 表格 */
table {
    padding: 0;
    word-break: initial;
}

table tr {
    border-top: 1px solid #dfe2e5;
    margin: 0;
    padding: 0;
}

/* 表格 背景色 */
table tr:nth-child(2n),
thead {
    background-color: var(--purple-light-1);
}
#write table thead th {
    background-color: var(--purple-light-2);
}

table tr th {
    font-weight: bold;
    border: 1px solid #dfe2e5;
    border-bottom: 0;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr td {
    border: 1px solid #dfe2e5;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr th:first-child,
table tr td:first-child {
    margin-top: 0;
}

table tr th:last-child,
table tr td:last-child {
    margin-bottom: 0;
}

/* 粗体 */
#write strong {
    padding: 0 2px;
    color: var(--purple-1);
}

/* 斜体 */
#write em {
    padding: 0 5px 0 2px;
    /* font-style: normal; */
    color: #42b983;
}

/* inline code */
#write code, tt {
    padding: 2px 4px;
    border-radius: 2px;
    font-family: var(--font-monospace);
    font-size: 0.92rem;
    color: var(--purple-3); 
    background-color: rgba(99, 99, 172, .05);
}

tt {
    margin: 0 2px;
}

#write .md-footnote {
    background-color: #f8f8f8;
    color: var(--purple-3);
}

/* heighlight. */
#write mark {
    background-color: #fbd3ea;
    border-radius: 2px;
    padding: 2px 4px;
    margin: 0 2px;
}

#write del {
    padding: 1px 2px;
}

.md-task-list-item > input {
    margin-left: -1.3em;
}

@media print {
    html {
        font-size: 0.9rem;
    }

    table,
    pre {
        page-break-inside: avoid;
    }

    pre {
        word-wrap: break-word;
    }
}

#write pre.md-meta-block {
    padding: 1rem;
    font-size: 85%;
    line-height: 1.45;
    background-color: #f7f7f7;
    border: 0;
    border-radius: 3px;
    color: #777777;
    margin-top: 0 !important;
}

.mathjax-block > .code-tooltip {
    bottom: .375rem;
}

/* 图片 */
.md-image > .md-meta {
    border-radius: 3px;
    font-family: var(--font-monospace);
    padding: 2px 0 0 4px;
    font-size: 0.9em;
    color: inherit;
}
p .md-image:only-child{
    width: auto;
    text-align: left;
    margin-left: 2rem;
}
.md-tag {
    color: inherit;
}
/* 当 “![shadow-随便写]()”写时，会有阴影 */
.md-image img[alt|='shadow'] {
    /* box-shadow: 0 4px 24px -6px #ddd; */
    box-shadow:var(--purple-light-2) 0px 10px 15px;
}

#write a.md-toc-inner {
    line-height: 1.6;
    white-space: pre-line;
    border-bottom: none;
    font-size: 0.9rem;
}

#typora-quick-open {
    border: 1px solid #ddd;
    background-color: #f8f8f8;
}

#typora-quick-open-item {
    background-color: #FAFAFA;
    border-color: #FEFEFE #e5e5e5 #e5e5e5 #eee;
    border-style: solid;
    border-width: 1px;
}

#md-notification:before {
    top: 10px;
}

header,
.context-menu,
.megamenu-content,
footer {
    font-family: var(--font-sans-serif);
}

.file-node-content:hover .file-node-icon,
.file-node-content:hover .file-node-open-state {
    visibility: visible;
}

.md-lang {
    color: #b4654d;
}

.html-for-mac .context-menu {
    --item-hover-bg-color: #E6F0FE;
}

/* 代码框 */
/* CodeMirror 3024 Day theme */

/* 代码段 背景 */
pre {
    --select-text-bg-color: rgba(223, 197, 223) !important;
    margin: .5em 0;
    padding: 1em 1.4em;
    border-radius: 8px;
    background: #f6f8fa;
    overflow-x: auto;
    box-sizing: border-box;
    font-size: 14px;
}

/* 边框 */
.md-fences {
    border: 1px solid #e7eaed;
    border-radius: 3px;
}

.cm-s-inner {
  padding: .25rem;
  border-radius: .25rem;
}

.cm-s-inner.CodeMirror, .cm-s-inner .CodeMirror-gutters {
  background-color: #f8f8f8 !important;
  color: #3a3432 !important;
  border: none;
}

.cm-s-inner .CodeMirror-gutters {
  color: #6d8a88;
}

.cm-s-inner .CodeMirror-cursor {
  border-left: solid thin #5c5855 !important;
}

.cm-s-inner .CodeMirror-linenumber {
  color: #807d7c;
}

.cm-s-inner .CodeMirror-line::selection, .cm-s-inner .CodeMirror-line::-moz-selection,
.cm-s-inner .CodeMirror-line > span::selection,
.cm-s-inner .CodeMirror-line > span::-moz-selection,
.cm-s-inner .CodeMirror-line > span > span::selection,
.cm-s-inner .CodeMirror-line > span > span::-moz-selection {
  background: var(--purple-light-2);
}

.cm-s-inner span.cm-comment {
  color: #cdab53;
}

.cm-s-inner span.cm-string, .cm-s-inner span.cm-string-2 {
  color: #f2b01d;
}

.cm-s-inner span.cm-number {
  color: #a34e8f;
}

.cm-s-inner span.cm-variable {
  color: #01a252;
}

.cm-s-inner span.cm-variable-2 {
  color: #01a0e4;
}

.cm-s-inner span.cm-def {
  /* color: #e8bbd0; */
  color: #e2287f;
}

.cm-s-inner span.cm-operator {
  color: #ff79c6;
}

.cm-s-inner span.cm-keyword {
  color: #db2d20;
}

.cm-s-inner span.cm-atom {
  color: #a34e8f;
}

.cm-s-inner span.cm-meta {
  color: inherit;
}

.cm-s-inner span.cm-tag {
  color: #db2d20;
}

.cm-s-inner span.cm-attribute {
  color: #01a252;
}

.cm-s-inner span.cm-qualifier {
  color: #388aa3;
}

.cm-s-inner span.cm-property {
  color: #01a252;
}

.cm-s-inner span.cm-builtin {
  color: #388aa3;
}

.cm-s-inner span.cm-variable-3, .cm-s-inner span.cm-type {
  color: #ffb86c;
}

.cm-s-inner span.cm-bracket {
  color: #3a3432;
}

.cm-s-inner span.cm-link {
  color: #a34e8f;
}

.cm-s-inner span.cm-error {
  background: #db2d20;
  color: #5c5855;
}

/* .md-fences.md-focus .cm-s-inner .CodeMirror-activeline-background {
  background: var(--purple-light-2);
} */

.cm-s-inner .CodeMirror-matchingbracket {
  text-decoration: underline;
  color: #a34e8f !important;
}

#fences-auto-suggest .active {
  background: #ddd;
}

#write .code-tooltip {
  bottom: initial;
  top: calc(100% - 1px);
  background: #f7f7f7;
  border: 1px solid #ddd;
  border-top: 0;
}

.auto-suggest-container {
  border-color: #b4b4b4;
}

.auto-suggest-container .autoComplt-hint.active {
  background: #b4b4b4;
  color: inherit;
}

/* task list */
#write .md-task-list-item > input {
  -webkit-appearance: initial;
  display: block;
  position: absolute;
  border: 1px solid #b4b4b4;
  border-radius: .25rem;
  margin-top: .1rem;
  margin-left: -1.8rem;
  height: 1.2rem;
  width: 1.2rem;
  transition: background 0.3s;
}

#write .md-task-list-item > input:focus {
  outline: none;
  box-shadow: none;
}

#write .md-task-list-item > input:hover {
  background: #ddd;
}

#write .md-task-list-item > input[checked]::before {
  content: '';
  position: absolute;
  top: 20%;
  left: 50%;
  height: 60%;
  width: 2px;
  transform: rotate(40deg);
  background: #333;
}

#write .md-task-list-item > input[checked]::after {
  content: '';
  position: absolute;
  top: 46%;
  left: 25%;
  height: 30%;
  width: 2px;
  transform: rotate(-40deg);
  background: #333;
}

#write .md-task-list-item > p {
  transition: color 0.3s, opacity 0.3s;
}

#write .md-task-list-item.task-list-done > p {
  color: #b4b4b4;
  text-decoration: line-through;
}

#write .md-task-list-item.task-list-done > p > .md-emoji {
  opacity: .5;
}

#write .md-task-list-item.task-list-done > p > .md-link > a {
  opacity: .6;
}

/* sidebar and outline */
.pin-outline .outline-active {
  color: var(--active-file-text-color); 
}

.file-list-item {
    border-bottom: 1px solid;
    border-color: var(--purple-light-5);
}

.file-list-item-summary {
    font-weight: 400;
}

.file-list-item.active {
    color: var(--active-file-text-color);
    background-color: var(--purple-light-5);
}

.file-tree-node.active>.file-node-background {
    background-color: var(--purple-light-5);
    font-weight: 700;
} 

.file-tree-node.active>.file-node-content {
    color: var(--active-file-text-color);
    font-weight: 700;
}

.file-node-content {
    color: #5e676d;
}

.sidebar-tabs {
    border-bottom: none;
}
.sidebar-tab.active {
    font-weight: 400;
}

.sidebar-content-content {
    font-size: 0.9rem;
}

img {
    max-width: 100%;
}

body {
    background-color: rgb(237, 237, 237);
}
#content {
    width: 836px;
    padding: 50px;
    background: #fff;
    margin: 0 auto;
}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/purple.css*/</style><style type="text/css">.hljs{display:block;overflow-x:auto;padding:.5em;color:#383a42;background:#fafafa}.hljs-comment,.hljs-quote{color:#a0a1a7;font-style:italic}.hljs-doctag,.hljs-formula,.hljs-keyword{color:#a626a4}.hljs-deletion,.hljs-name,.hljs-section,.hljs-selector-tag,.hljs-subst{color:#e45649}.hljs-literal{color:#0184bb}.hljs-addition,.hljs-attribute,.hljs-meta-string,.hljs-regexp,.hljs-string{color:#50a14f}.hljs-built_in,.hljs-class .hljs-title{color:#c18401}.hljs-attr,.hljs-number,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-pseudo,.hljs-template-variable,.hljs-type,.hljs-variable{color:#986801}.hljs-bullet,.hljs-link,.hljs-meta,.hljs-selector-id,.hljs-symbol,.hljs-title{color:#4078f2}.hljs-emphasis{font-style:italic}.hljs-strong{font-weight:700}.hljs-link{text-decoration:underline}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/atom-one-light.min.css*/</style></head>
<body>
<div id="content"><h1>Message 家的功能：日志操作的核心方法</h1>
<p>在前面章节中，logSegment 相关的方法基本给你讲完了，这节课开始着重讲解日志读写操作的相关方法，主要包括这样两个方法：</p>
<ul>
<li>
<p>appendAsLeader()：作为leader分区向leader分区追加日志。</p>
</li>
<li>
<p>appendAsFollower()：作为follower分区向follower分区追加日志。</p>
</li>
</ul>
<p><strong>这两个底层调用的都是append()方法</strong>，所以，我们需要先来详细分析append()方法。</p>
<h2>append() 方法</h2>
<p><strong>这个方法是用来向日志的active segment文件<code>追加日志</code>，如果有必要会新建segment文件</strong>。源码如下：</p>
<pre><code>
private def append(records: MemoryRecords,

origin: AppendOrigin,

interBrokerProtocolVersion: ApiVersion,

assignOffsets: Boolean,

leaderEpoch: Int,

ignoreRecordSize: Boolean): LogAppendInfo = {

maybeHandleIOException(s"Error while appending records to $topicPartition in dir ${dir.getParent}") {

// 1.验证消息。

val appendInfo = analyzeAndValidateRecords(records, origin, ignoreRecordSize)

// 2.如果没有有效消息就返回。

if (appendInfo.shallowCount == 0)

return appendInfo

//3.清除未验证通过的message。

var validRecords = trimInvalidBytes(records, appendInfo)

lock synchronized {

//确定log对象没关闭。

checkIfMemoryMappedBufferClosed()

//判断是否需要分配offsets，默认是需要的。

if (assignOffsets) {

// 第4步：使用当前LEO值作为待写入消息集合中第一条消息的位移值，也是绝对位移值。

val offset = new LongRef(nextOffsetMetadata.messageOffset)

appendInfo.firstOffset = Some(offset.value)

val now = time.milliseconds

//第5步：对message做进一步的验证：消息格式转换，调整magic的值，修改时间戳等操作，并为message分配offset。

val validateAndOffsetAssignResult = try {

LogValidator.validateMessagesAndAssignOffsets(validRecords,

topicPartition,

offset,

time,

now,

appendInfo.sourceCodec,

appendInfo.targetCodec,

config.compact,

config.messageFormatVersion.recordVersion.value,

config.messageTimestampType,

config.messageTimestampDifferenceMaxMs,

leaderEpoch,

origin,

interBrokerProtocolVersion,

brokerTopicStats)

} catch {

case e: IOException =>

throw new KafkaException(s"Error validating messages while appending to log $name", e)

}

// 更新校验结果对象类 LogAppendInfo

validRecords = validateAndOffsetAssignResult.validatedRecords

//获取最大的时间戳

appendInfo.maxTimestamp = validateAndOffsetAssignResult.maxTimestamp

//最大时间戳的offset

appendInfo.offsetOfMaxTimestamp = validateAndOffsetAssignResult.shallowOffsetOfMaxTimestamp

//更新last offset

appendInfo.lastOffset = offset.value - 1

appendInfo.recordConversionStats = validateAndOffsetAssignResult.recordConversionStats

//在新版本的kafka中，每条msg都有一个对应的时间戳记录，producer端可以设置这个字段message.timestamp.type来选择 timestamp类型。

if (config.messageTimestampType == TimestampType.LOG_APPEND_TIME)

//设置日志追加的时间

appendInfo.logAppendTime = now

// 第6步：验证消息，确保消息大小不超限

if (!ignoreRecordSize &#x26;&#x26; validateAndOffsetAssignResult.messageSizeMaybeChanged) {

for (batch &#x3C;- validRecords.batches.asScala) {

if (batch.sizeInBytes > config.maxMessageSize) {

brokerTopicStats.topicStats(topicPartition.topic).bytesRejectedRate.mark(records.sizeInBytes)

brokerTopicStats.allTopicsStats.bytesRejectedRate.mark(records.sizeInBytes)

throw new RecordTooLargeException(s"Message batch size is ${batch.sizeInBytes} bytes in append to" +

s"partition $topicPartition which exceeds the maximum configured size of ${config.maxMessageSize}.")

}

}

}

} else {

// 直接使用给定的位移值，无需自己分配位移值

//判断offset是否是递增的，不是递增就抛出异常

// we are taking the offsets we are given

if (!appendInfo.offsetsMonotonic)

throw new OffsetsOutOfOrderException(s"Out of order offsets found in append to $topicPartition: " +

records.records.asScala.map(_.offset))

if (appendInfo.firstOrLastOffsetOfFirstBatch &#x3C; nextOffsetMetadata.messageOffset) {

val firstOffset = appendInfo.firstOffset match {

case Some(offset) => offset

case None => records.batches.asScala.head.baseOffset()

}

val firstOrLast = if (appendInfo.firstOffset.isDefined) "First offset" else "Last offset of the first batch"

throw new UnexpectedAppendOffsetException(

s"Unexpected offset in append to $topicPartition. $firstOrLast " +

s"${appendInfo.firstOrLastOffsetOfFirstBatch} is less than the next offset ${nextOffsetMetadata.messageOffset}. " +

s"First 10 offsets in append: ${records.records.asScala.take(10).map(_.offset)}, last offset in" +

s" append: ${appendInfo.lastOffset}. Log start offset = $logStartOffset",

firstOffset, appendInfo.lastOffset)

}

}

// 第7步：更新Leader Epoch缓存

validRecords.batches.forEach { batch =>

if (batch.magic >= RecordBatch.MAGIC_VALUE_V2) {

maybeAssignEpochStartOffset(batch.partitionLeaderEpoch, batch.baseOffset)

} else {

leaderEpochCache.filter(_.nonEmpty).foreach { cache =>

warn(s"Clearing leader epoch cache after unexpected append with message format v${batch.magic}")

cache.clearAndFlush()

}

}

}

// 第8步：确保消息大小不超segment的大小

if (validRecords.sizeInBytes > config.segmentSize) {

throw new RecordBatchTooLargeException(s"Message batch size is ${validRecords.sizeInBytes} bytes in append " +

s"to partition $topicPartition, which exceeds the maximum configured segment size of ${config.segmentSize}.")

}

// 第9步：如果当前日志段剩余容量可能无法容纳新消息集合，执行日志切分，创建一个新的日志段来保存待写入的所有消息。

// 如果当前日志段剩余容量能够容纳新消息集合，就直接返回当前的segment

val segment = maybeRoll(validRecords.sizeInBytes, appendInfo)

val logOffsetMetadata = LogOffsetMetadata(

messageOffset = appendInfo.firstOrLastOffsetOfFirstBatch,

segmentBaseOffset = segment.baseOffset,

relativePositionInSegment = segment.size)

// 第10步：验证事务状态

val (updatedProducers, completedTxns, maybeDuplicate) = analyzeAndValidateProducerState(

logOffsetMetadata, validRecords, origin)

maybeDuplicate.foreach { duplicate =>

appendInfo.firstOffset = Some(duplicate.firstOffset)

appendInfo.lastOffset = duplicate.lastOffset

appendInfo.logAppendTime = duplicate.timestamp

appendInfo.logStartOffset = logStartOffset

return appendInfo

}

// 第11步：执行真正的消息写入操作，主要调用日志段对象的append方法实现。

segment.append(largestOffset = appendInfo.lastOffset,

largestTimestamp = appendInfo.maxTimestamp,

shallowOffsetOfMaxTimestamp = appendInfo.offsetOfMaxTimestamp,

records = validRecords)

// 第12步：更新LEO对象，其中，LEO值是消息集合中最后一条消息位移值+1

// 前面说过，LEO值永远指向下一条不存在的消息

updateLogEndOffset(appendInfo.lastOffset + 1)

// update the producer state

// 第12步：更新事务状态

for (producerAppendInfo &#x3C;- updatedProducers.values) {

producerStateManager.update(producerAppendInfo)

}

// update the transaction index with the true last stable offset. The last offset visible

// to consumers using READ_COMMITTED will be limited by this value and the high watermark.

for (completedTxn &#x3C;- completedTxns) {

val lastStableOffset = producerStateManager.lastStableOffset(completedTxn)

segment.updateTxnIndex(completedTxn, lastStableOffset)

producerStateManager.completeTxn(completedTxn)

}

producerStateManager.updateMapEndOffset(appendInfo.lastOffset + 1)

maybeIncrementFirstUnstableOffset()

trace(s"Appended message set with last offset: ${appendInfo.lastOffset}, " +

s"first offset: ${appendInfo.firstOffset}, " +

s"next offset: ${nextOffsetMetadata.messageOffset}, " +

s"and messages: $validRecords")

// 13.是否需要手动落盘。一般情况下我们不需要设置Broker端参数log.flush.interval.messages默认是Long.MaxValue

// 落盘操作交由操作系统来完成。但某些情况下，可以设置该参数来确保高可靠性

if (unflushedMessages >= config.flushInterval)

flush()

appendInfo

}

}

}

</code></pre>
<p>整体步骤可梳理为如下。</p>
<p>第一步：验证消息。具体是调用<code>analyzeAndValidateRecords()</code>方法来验证消息。代码如下：</p>
<pre><code>
private def analyzeAndValidateRecords(records: MemoryRecords,

origin: AppendOrigin,

ignoreRecordSize: Boolean): LogAppendInfo = {

var shallowMessageCount = 0//外层消息的数量。

var validBytesCount = 0//通过验证的内层消息的字节数。

var firstOffset: Option[Long] = None//第一条消息。

var lastOffset = -1L//最后一条消息。

var sourceCodec: CompressionCodec = NoCompressionCodec

var monotonic = true//表示生产者为消息分配的内部offset是否单调递增。使用浅层迭代器进行迭代，如果是压缩消息，并不会被解压。

var maxTimestamp = RecordBatch.NO_TIMESTAMP

var offsetOfMaxTimestamp = -1L

var readFirstMessage = false

var lastOffsetOfFirstBatch = -1L

//1.遍历MemoryRecords内的所有的batch。浅层遍历

for (batch &#x3C;- records.batches.asScala) {

// 消息的格式只能是V2版本或比V2高的版本。消息格式Version 2的消息批次，起始位移值必须从0开始

if (batch.magic >= RecordBatch.MAGIC_VALUE_V2 &#x26;&#x26; origin == AppendOrigin.Client &#x26;&#x26; batch.baseOffset != 0)

throw new InvalidRecordException(s"The baseOffset of the record batch in the append to $topicPartition should " +

s"be 0, but it is ${batch.baseOffset}")

if (!readFirstMessage) {

if (batch.magic >= RecordBatch.MAGIC_VALUE_V2)

firstOffset = Some(batch.baseOffset)

lastOffsetOfFirstBatch = batch.lastOffset

readFirstMessage = true

}

// 2.一旦出现当前lastOffset不小于下一个batch的lastOffset，说明上一个batch中有消息的位移值大于后面batch的消息

// 这违反了位移值单调递增性

if (lastOffset >= batch.lastOffset)

monotonic = false

lastOffset = batch.lastOffset

// 3.检查消息批次总字节数大小是否超限，即是否大于Broker端参数max.message.bytes值

val batchSize = batch.sizeInBytes

if (!ignoreRecordSize &#x26;&#x26; batchSize > config.maxMessageSize) {

brokerTopicStats.topicStats(topicPartition.topic).bytesRejectedRate.mark(records.sizeInBytes)

brokerTopicStats.allTopicsStats.bytesRejectedRate.mark(records.sizeInBytes)

throw new RecordTooLargeException(s"The record batch size in the append to $topicPartition is $batchSize bytes " +

s"which exceeds the maximum configured value of ${config.maxMessageSize}.")

}

// 4.执行消息批次校验，包括格式是否正确以及CRC校验

if (!batch.isValid) {

brokerTopicStats.allTopicsStats.invalidMessageCrcRecordsPerSec.mark()

throw new CorruptRecordException(s"Record is corrupt (stored crc = ${batch.checksum()}) in topic partition $topicPartition.")

}

// 更新maxTimestamp字段和offsetOfMaxTimestamp

if (batch.maxTimestamp > maxTimestamp) {

maxTimestamp = batch.maxTimestamp

offsetOfMaxTimestamp = lastOffset

}

// 累加消息批次计数器以及有效字节数，更新shallowMessageCount字段

shallowMessageCount += 1

//有效的字节数

validBytesCount += batchSize

val messageCodec = CompressionCodec.getCompressionCodec(batch.compressionType.id)

if (messageCodec != NoCompressionCodec)

sourceCodec = messageCodec

}

// 获取Broker端设置的压缩器类型，即Broker端参数compression.type值。

// 该参数默认值是producer，表示sourceCodec用的什么压缩器，targetCodec就用什么

val targetCodec = BrokerCompressionCodec.getTargetCompressionCodec(config.compressionType, sourceCodec)

// 最后生成LogAppendInfo对象并返回,对象内包含第一个消息的offset,最后一个消息的offset

LogAppendInfo(firstOffset, lastOffset, maxTimestamp, offsetOfMaxTimestamp, RecordBatch.NO_TIMESTAMP, logStartOffset,

RecordConversionStats.EMPTY, sourceCodec, targetCodec, shallowMessageCount, validBytesCount, monotonic, lastOffsetOfFirstBatch)

}

</code></pre>
<p>这里我先给你描述一下<strong>验证消息的过程</strong>。</p>
<ul>
<li>首先遍历MemoryRecords内所有的batch，浅层遍历。因为MemoryRecords里面可能会有多个batch，batch里面才是具体的record，所以batch这层是第一层遍历。</li>
<li>下一步，一旦出现当前lastOffset不小于下一个batch的lastOffset，说明上一个batch中有消息的位移值大于后面batch的消息，这违反了位移值单调递增性。</li>
<li>再下一步，检查消息批次总字节数大小是否超限，即是否大于Broker端参数max.message.bytes值。也就是说这里的消息大小超限是针对消息日志batch大小的。</li>
<li>然后执行消息批次校验，包括格式是否正确以及CRC校验，更新maxTimestamp字段和offsetOfMaxTimestamp，更新shallowMessageCount字段，并更新有效的字节数。</li>
<li>最后，生成LogAppendInfo类对象appendInfo并返回，对象内包含第一个消息的offset、最后一个消息的offset。</li>
</ul>
<p>然后我们接着分析消息追加的过程。</p>
<p>第二步：根据验证后的结果判断，如果没有有效消息就返回。</p>
<p>第三步：清除未验证通过的message。</p>
<p>第四步：使用当前LEO值作为待写入消息集合中第一条消息的位移值，也是绝对位移值。</p>
<p>第五步：对message做进一步的验证，消息格式转换、调整magic的值、修改时间戳等操作，并为message分配offset，接下来是更新appendInfo的一些关键字段。</p>
<p>第六步：验证消息，确保消息大小不超限。这里还要验证一次大小不能超限，原因是<code>上面的步骤会改变日志</code>。</p>
<p>第七步：更新Leader Epoch缓存，Leader Epoch可能会发生变化。这是事务机制涉及的相关参数，这里不做过多讨论。</p>
<p>第八步：确保消息大小不超segment的大小。</p>
<p>第九步：如果当前日志段剩余容量可能无法容纳新消息集合，执行日志切分，创建一个新的日志段来保存待写入的所有消息。如果当前日志段剩余容量能够容纳新消息集合，就直接返回当前的segment。具体是调用了上节课给你讲解的maybeRoll()方法。</p>
<p>第十步：验证事务状态。这是事务机制涉及的领域，这里不做过多讨论。</p>
<p>第十一步：执行真正的消息写入操作，主要调用日志段对象的append方法实现。</p>
<p>第十二步：更新LEO对象，其中，LEO值是消息集合中最后一条消息位移值+1。</p>
<p>第十三步：是否需要手动落盘。一般情况下我们不需要设置Broker端参数log.flush.interval.messages默认是Long.MaxValue。落盘操作交由操作系统来完成。但某些情况下，可以设置该参数来确保高可靠性。</p>
<p>步骤较多，这里还是用一张流程图给你形象地表述一下整体的步骤：</p>
<p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5184b8f7e49140a49643a0bf2e764777~tplv-k3u1fbpfcp-watermark.image?" alt="Log类里追加消息日志的步骤.png"></p>
<h2>read() 方法</h2>
<p>这个方法的功能是<strong>从log文件读取消息</strong>。</p>
<pre><code>
def read(startOffset: Long,

maxLength: Int,

isolation: FetchIsolation,

minOneMessage: Boolean): FetchDataInfo = {

maybeHandleIOException(s"Exception while reading from $topicPartition in dir ${dir.getParent}") {

trace(s"Reading maximum $maxLength bytes at offset $startOffset from log with " +

s"total length $size bytes")

val includeAbortedTxns = isolation == FetchTxnCommitted

// 1.读取消息时没有使用Monitor锁同步机制，因此这里取巧了，用本地变量的方式把LEO对象保存起来，

// 避免争用（race condition）,不会造成因为没加锁造成的多线程数据安全问题。

val endOffsetMetadata = nextOffsetMetadata

// 取出LEO的值

val endOffset = endOffsetMetadata.messageOffset

// 2.找到startOffset值所在的日志段对象。注意要使用floorEntry方法，表示要找baseOffset小于startOffset里最大的baseOffset的segment。

var segmentEntry = segments.floorEntry(startOffset)

// 判断消息越界：

if (startOffset > endOffset || segmentEntry == null || startOffset &#x3C; logStartOffset)

throw new OffsetOutOfRangeException(s"Received request for offset $startOffset for partition $topicPartition, " +

s"but we only have log segments in the range $logStartOffset to $endOffset.")

// 3.查看一下读取隔离级别设置,不同类型的读请求对应的maxOffsetMetadata也是不一样的。

// 普通消费者能够看到[Log Start Offset, 高水位值)之间的消息

// 事务型消费者只能看到[Log Start Offset, Log Stable Offset]之间的消息。Log Stable Offset(LSO)是比LEO值小的位移值，为Kafka事务使用

// Follower副本消费者能够看到[Log Start Offset，LEO)之间的消息

val maxOffsetMetadata = isolation match {

case FetchLogEnd => endOffsetMetadata

case FetchHighWatermark => fetchHighWatermarkMetadata

case FetchTxnCommitted => fetchLastStableOffsetMetadata

}

if (startOffset == maxOffsetMetadata.messageOffset) {

return emptyFetchDataInfo(maxOffsetMetadata, includeAbortedTxns)

} else if (startOffset > maxOffsetMetadata.messageOffset) {

val startOffsetMetadata = convertToOffsetMetadataOrThrow(startOffset)

return emptyFetchDataInfo(startOffsetMetadata, includeAbortedTxns)

}

// 4.开始遍历日志段对象，直到读出东西来或者读到日志末尾

while (segmentEntry != null) {

val segment = segmentEntry.getValue

val maxPosition = {

if (maxOffsetMetadata.segmentBaseOffset == segment.baseOffset) {

maxOffsetMetadata.relativePositionInSegment

} else {

segment.size

}

}

// 调用日志段对象的read方法执行真正的读取消息操作

val fetchInfo = segment.read(startOffset, maxLength, maxPosition, minOneMessage)

if (fetchInfo == null) {

// 如果没有返回任何消息，去下一个偏移量更大的日志段对象试试。

segmentEntry = segments.higherEntry(segmentEntry.getKey)

} else {

return if (includeAbortedTxns)

addAbortedTransactions(startOffset, segmentEntry, fetchInfo)

else

//5.返回读到的消息

fetchInfo

}

}

FetchDataInfo(nextOffsetMetadata, MemoryRecords.EMPTY)

}

}

</code></pre>
<p>第一步：把LEO赋值给本地变量。读取消息时没有使用Monitor锁同步机制，因此这里取巧了，用本地变量的方式把LEO对象保存起来，避免争用（race condition），不会造成因为没加锁而引起的多线程数据安全问题。</p>
<p>第二步：找到startOffset值所在的日志段对象。注意要使用floorEntry方法，表示要找baseOffset小于startOffset里最大的baseOffset的segment。然后判断是否是越界消息。满足下面三点中的一个条件就认为是越界了：</p>
<ul>
<li>要读取的消息位移超过了LEO值；</li>
<li>没找到对应的日志段对象；</li>
<li>要读取的消息在Log Start Offset之前，同样是对外不可见的消息。</li>
</ul>
<p>第三步：查看一下读取隔离级别设置，不同类型的读请求对应的maxOffsetMetadata也是不一样的。可分为普通消费者和事务型消费者：</p>
<ul>
<li>普通消费者能够看到<code>[Log Start Offset, 高水位值)</code>之间的消息；</li>
<li>事务型消费者只能看到<code>[Log Start Offset, Log Stable Offset]</code>之间的消息。Log Stable Offset（LSO）是比LEO值小的位移值，为Kafka事务使用。</li>
</ul>
<p>第四步：开始遍历日志段对象，直到读出对应的偏移量的消息来或者读到日志末尾。具体是调用日志段对象的read方法执行真正的读取消息操作。</p>
<p>第五步：返回读到的消息。</p>
<h2>读消息步骤的全流程</h2>
<p>学到这里，我们就可以跟前面几节的知识串联起来形成查询消息的全流程，具体如下：</p>
<p>第一步：利用segments集合的跳表结构根据要找的偏移量快速定位消息在哪个segmennt里。</p>
<p>第二步：找到对应的偏移量索引（日志分段文件和偏移量索引文件都是以baseoffset命名的，只是后缀名不一样而已）。</p>
<p>第三步：根据索引槽位对应的日志文件的offset顺序查找要得到的offset对应的日志消息。</p>
<p>好，对于日志的追加和查找我们就介绍完了，下面还有几个Log类里的方法需要给你再讲解。</p>
<h2>flush()</h2>
<p>这个方法的作用是<strong>刷新指定偏移量内所有相关的内存数据到磁盘log segments文件里</strong>。一般不会主动刷新磁盘，因为这样就会造成操作系统通过页缓存优化磁盘IO的优化失效。只有在新建log segments文件的时候才会主动调用flush()来刷新，一般高频次的读写不会调用flush()。</p>
<pre><code>
def flush(offset: Long): Unit = {

maybeHandleIOException(s"Error while flushing log for $topicPartition in dir ${dir.getParent} with offset $offset") {

if (offset &#x3C;= this.recoveryPoint)

return

debug(s"Flushing log up to offset $offset, last flushed: $lastFlushTime, current time: ${time.milliseconds()}, " +

s"unflushed: $unflushedMessages")

//1.遍历所有logSegment对象，在（recoveryPoint，offset）区间内的offset都要刷盘。

for (segment &#x3C;- logSegments(this.recoveryPoint, offset)) {

//调用了LogSegment的flush方法。

segment.flush()

}

//2.修改recoveryPoint和lastFlushedTime的值

lock synchronized {

checkIfMemoryMappedBufferClosed()

if (offset > this.recoveryPoint) {

this.recoveryPoint = offset//更新recoveryPoint.

lastFlushedTime.set(time.milliseconds)//修改lastFlushedTime.

}

}

}

}

</code></pre>
<p>第一步：遍历所有logSegment对象，在（recoveryPoint，offset）区间内的offset都要刷盘。</p>
<p>第二步：修改recoveryPoint和lastFlushedTime的值。</p>
<h2>updateLogEndOffset()</h2>
<p>该方法表示更新LEO。</p>
<p>实际上，LEO 对象被更新的时机有 4 个。</p>
<ul>
<li>
<p><strong>Log 对象初始化时</strong>：当 Log 对象初始化时，我们必须要创建一个 LEO 对象，并对其进行初始化。</p>
</li>
<li>
<p><strong>写入新消息时</strong>：这个最容易理解。当不断向 Log 对象插入新消息时，LEO 值就像一个指针一样，需要不停地向右移动，也就是不断地增加。</p>
</li>
<li>
<p><strong>Log 对象发生日志切分（Log Roll）时</strong>：日志切分是啥呢？其实就是创建一个全新的日志段对象，并且关闭当前写入的日志段对象。这通常发生在当前日志段对象已满的时候。一旦发生日志切分，说明 Log 对象切换了 Active Segment，那么，LEO 中的起始位移值和段大小数据都要被更新，因此，在进行这一步操作时，我们必须要更新 LEO 对象。</p>
</li>
<li>
<p><strong>日志截断（Log Truncation）时</strong>：这个也是显而易见的。日志中的部分消息被删除了，自然可能导致 LEO 值发生变化，从而要更新 LEO 对象。</p>
</li>
</ul>
<pre><code>
private def updateLogEndOffset(offset: Long): Unit = {

//1. 构建偏移量元数据类对象。

nextOffsetMetadata = LogOffsetMetadata(offset, activeSegment.baseOffset, activeSegment.size)

//2. 更新高水位。

if (highWatermark >= offset) {

updateHighWatermarkMetadata(nextOffsetMetadata)

}

//3.更新恢复点。

if (this.recoveryPoint > offset) {

this.recoveryPoint = offset

}

}

</code></pre>
<p>第一步：构建偏移量元数据类对象。</p>
<p>第二步：更新高水位，防止高水位在LEO前面。</p>
<p>第三步：更新恢复点，因为恢复点不可能比LEO还大，如果还大就要把恢复点改为LEO的偏移量。</p>
<h2>recoverLog()</h2>
<p>恢复log segments并返回恢复后的下一个offset，<strong>其实恢复就是验证消息是否正常，不正常就截断</strong>。另外，还会重建索引。</p>
<pre><code>
private def recoverLog(): Long = {

// if we have the clean shutdown marker, skip recovery

//1.如果上次broker不是正常关闭，需要进行恢复

if (!hasCleanShutdownFile) {

// okay we need to actually recover this log

// 2.过滤需要恢复的日志段集合，获取全部未刷新的LogSegment，即recoveryPoint后全部的Logsegment。

val unflushed = logSegments(this.recoveryPoint, Long.MaxValue).iterator

var truncated = false

// 3.轮询所有的 logSegment

while (unflushed.hasNext &#x26;&#x26; !truncated) {

val segment = unflushed.next()

info(s"Recovering unflushed segment ${segment.baseOffset}")

val truncatedBytes =

try {

//4.重新建立索引文件并验证日志文件，如果返回验证失败就从失败处截断，并返回截断的字节数。

recoverSegment(segment, leaderEpochCache)

} catch {

case _: InvalidOffsetException =>

val startOffset = segment.baseOffset

warn("Found invalid offset during recovery. Deleting the corrupt segment and " +

s"creating an empty one with starting offset $startOffset")

segment.truncateTo(startOffset)

}

if (truncatedBytes > 0) {

// 如果有无效的消息导致被截断的字节数不为0，直接删除剩余的日志段对象

// we had an invalid message, delete all remaining log

warn(s"Corruption found in segment ${segment.baseOffset}, truncating to offset ${segment.readNextOffset}")

removeAndDeleteSegments(unflushed.toList,

asyncDelete = true,

reason = LogRecovery)

truncated = true

}

}

}

// 4.这些都做完之后，如果日志段集合不为空

if (logSegments.nonEmpty) {

// 至少创建一个新的日志段，以logStartOffset为日志段的起始位移，并加入日志段集合中

//删除logEndOffset比logStartOffset小的segment。

val logEndOffset = activeSegment.readNextOffset

if (logEndOffset &#x3C; logStartOffset) {

warn(s"Deleting all segments because logEndOffset ($logEndOffset) is smaller than logStartOffset ($logStartOffset). " +

"This could happen if segment files were deleted from the file system.")

removeAndDeleteSegments(logSegments,

asyncDelete = true,

reason = LogRecovery)

}

}

if (logSegments.isEmpty) {

// no existing segments, create a new mutable segment beginning at logStartOffset

addSegment(LogSegment.open(dir = dir,

baseOffset = logStartOffset,

config,

time = time,

fileAlreadyExists = false,

initFileSize = this.initFileSize,

preallocate = config.preallocate))

}

recoveryPoint = activeSegment.readNextOffset

recoveryPoint

}

</code></pre>
<p>大体分为如下几步。</p>
<p>第一步：如果上次broker不是正常关闭，需要进行恢复。</p>
<p>第二步：过滤需要恢复的日志段集合，获取全部未刷新的LogSegment，即recoveryPoint后全部的Logsegment。</p>
<p>第三步：轮询所有的 logSegment。重新建立索引文件并验证日志文件，如果返回验证失败就从失败处截断，并返回截断的字节数。如果有无效的消息导致被截断的字节数不为0，直接删除剩余的日志段对象。</p>
<p>第四步：清理工作。具体是如果日志段集合不为空，至少创建一个新的日志段，以logStartOffset为日志段的起始位移，并加入日志段集合中，删除logEndOffset比logStartOffset小的segment。</p>
<p>第五步：这些都做完之后，如果日志段集合为空，新建segment并加到集合里。</p>
<h2>总结</h2>
<p>这节课我们学习了Log类是如何处理日志消息的追加的，涉及消息验证、更新LEO、更新Log start offset、消息追加等功能。然后又学习了消息的查询，同时还跟上几节课串联起来，完善了消息查询的整个过程。最后又跟大家分享了其他一些方法的源码，包括日志的刷新、日志恢复、更新LEO。</p></div>
</body></html>
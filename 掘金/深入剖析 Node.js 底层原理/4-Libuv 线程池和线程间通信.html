<!DOCTYPE html><html lang="en"><head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>第 01 讲：设计一份吸引面试官的简历</title>
<style type="text/css">
:root {
    --control-text-color: #777;
    --select-text-bg-color: rgba(223, 197, 223);  /*#7e66992e;*/
    
    /* side bar */
    --side-bar-bg-color: rgb(255, 255, 255);
    --active-file-text-color: #8163bd;
    --active-file-bg-color: #E9E4F0;
    --item-hover-bg-color: #E9E4F0;
    --active-file-border-color: #8163bd;

    --title-color: #6c549c;
    --font-sans-serif: 'Ubuntu', 'Source Sans Pro', sans-serif !important;
    --font-monospace: 'Fira Code', 'Roboto Mono', monospace !important;
    --purple-1: #8163bd;
    --purple-2: #79589F;
    --purple-3: #fd5eb8;
    --purple-light-1: rgba(99, 99, 172, .05);
    --purple-light-2: rgba(99, 99, 172, .1);
    --purple-light-3: rgba(99, 99, 172, .2);
    --purple-light-4: rgba(129, 99, 189, .3);
    --purple-light-5: #E9E4F0;
    --purple-light-6: rgba(129, 99, 189, .8);
}

/* html {
    font-size: 16px;
} */

body {
    font-family: var(--font-sans-serif);
    color: #34495e;
    -webkit-font-smoothing: antialiased;
    line-height: 1.6rem;
    letter-spacing: 0;
    margin: 0;
    overflow-x: hidden;
}

/* 页边距 和 页面大小 */
#write {
    padding-left: 6ch;
    padding-right: 6ch;
    margin: 0 auto;
}

#write p {
    line-height: 1.6rem;
    word-spacing: .05rem;
}

#write ol li {
    padding-left: 0.5rem;
}

#write > ul:first-child,
#write > ol:first-child {
    margin-top: 30px;
}

body > *:first-child {
    margin-top: 0 !important;
}

body > *:last-child {
    margin-bottom: 0 !important;
}

a {
    color: var(--purple-1);
    padding: 0 2px;
    text-decoration: none;
}
.md-content {
    color: var(--purple-light-6);
}
#write a {
    border-bottom: 1px solid var(--purple-1);
    color: var(--purple-1);
    text-decoration: none;
}

h1,
h2,
h3,
h4,
h5,
h6 {
    position: relative;
    margin-top: 1rem;
    margin-bottom: 0.5rem;
    /* font-weight: bold; */
    font-weight: 500 !important;
    line-height: 1.4;
    cursor: text;
    color: var(--title-color);
    font-family: var(--font-sans-serif);
}

h1:hover a.anchor,
h2:hover a.anchor,
h3:hover a.anchor,
h4:hover a.anchor,
h5:hover a.anchor,
h6:hover a.anchor {
    text-decoration: none;
}

h1 tt,
h1 code {
    font-size: inherit !important;
}
h2 tt,
h2 code {
    font-size: inherit !important;
}
h3 tt,
h3 code {
    font-size: inherit !important;
}
h4 tt,
h4 code {
    font-size: inherit !important;
}
h5 tt,
h5 code {
    font-size: inherit !important;
}
h6 tt,
h6 code {
    font-size: inherit !important;
}


h1 {
    padding-bottom: .4rem;
    font-size: 2.2rem;
    line-height: 1.3;
}
h1 {
    text-align: center;
    padding-bottom: 0.3em;
    font-size: 2.2em;
    line-height: 1.2;
    margin: 2.4em auto 1.2em;
}
h1:after {
    content: '';
    display: block;
    margin: 0.2em auto 0;
    width: 100px;
    height: 2px;
    border-bottom: 2px solid var(--title-color);
}

h2 {
    margin: 1.6em auto 0.5em;
    padding-left: 10px;
    line-height: 1.4;
    font-size: 1.8em;
    border-left: 9px solid var(--title-color);
    border-bottom: 1px solid var(--title-color);
}
h3 {
    font-size: 1.5rem;
    margin: 1.2em auto 0.5em;
}
h4 {
    font-size: 1.3rem;
}
h5 {
    font-size: 1.2rem;
}
h6 {
    font-size: 1.1rem;
}

p,
blockquote,
ul,
ol,
dl,
table {
    margin: 0.8em 0;
}

li > ol,
li > ul {
    margin: 0 0;
}

hr {
    height: 2px;
    padding: 0;
    margin: 16px 0;
    background-color: #e7e7e7;
    border: 0 none;
    overflow: hidden;
    box-sizing: content-box;
}

body > h2:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child {
    margin-top: 0;
    padding-top: 0;
}

body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0;
}

body > h3:first-child,
body > h4:first-child,
body > h5:first-child,
body > h6:first-child {
    margin-top: 0;
    padding-top: 0;
}

a:first-child h1,
a:first-child h2,
a:first-child h3,
a:first-child h4,
a:first-child h5,
a:first-child h6 {
    margin-top: 0;
    padding-top: 0;
}

h1 p,
h2 p,
h3 p,
h4 p,
h5 p,
h6 p {
    margin-top: 0;
}

li p.first {
    display: inline-block;
}

ul,
ol {
    padding-left: 30px;
}

ul:first-child,
ol:first-child {
    margin-top: 0;
}

ul:last-child,
ol:last-child {
    margin-bottom: 0;
}

/* 引用 */
blockquote {
    /* margin-left: 1rem; */
    border-left: 4px solid var(--purple-light-4);
    padding: 10px 15px;
    color: #777;
    background-color: var(--purple-light-1);
}

/* 表格 */
table {
    padding: 0;
    word-break: initial;
}

table tr {
    border-top: 1px solid #dfe2e5;
    margin: 0;
    padding: 0;
}

/* 表格 背景色 */
table tr:nth-child(2n),
thead {
    background-color: var(--purple-light-1);
}
#write table thead th {
    background-color: var(--purple-light-2);
}

table tr th {
    font-weight: bold;
    border: 1px solid #dfe2e5;
    border-bottom: 0;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr td {
    border: 1px solid #dfe2e5;
    text-align: left;
    margin: 0;
    padding: 6px 13px;
}

table tr th:first-child,
table tr td:first-child {
    margin-top: 0;
}

table tr th:last-child,
table tr td:last-child {
    margin-bottom: 0;
}

/* 粗体 */
#write strong {
    padding: 0 2px;
    color: var(--purple-1);
}

/* 斜体 */
#write em {
    padding: 0 5px 0 2px;
    /* font-style: normal; */
    color: #42b983;
}

/* inline code */
#write code, tt {
    padding: 2px 4px;
    border-radius: 2px;
    font-family: var(--font-monospace);
    font-size: 0.92rem;
    color: var(--purple-3); 
    background-color: rgba(99, 99, 172, .05);
}

tt {
    margin: 0 2px;
}

#write .md-footnote {
    background-color: #f8f8f8;
    color: var(--purple-3);
}

/* heighlight. */
#write mark {
    background-color: #fbd3ea;
    border-radius: 2px;
    padding: 2px 4px;
    margin: 0 2px;
}

#write del {
    padding: 1px 2px;
}

.md-task-list-item > input {
    margin-left: -1.3em;
}

@media print {
    html {
        font-size: 0.9rem;
    }

    table,
    pre {
        page-break-inside: avoid;
    }

    pre {
        word-wrap: break-word;
    }
}

#write pre.md-meta-block {
    padding: 1rem;
    font-size: 85%;
    line-height: 1.45;
    background-color: #f7f7f7;
    border: 0;
    border-radius: 3px;
    color: #777777;
    margin-top: 0 !important;
}

.mathjax-block > .code-tooltip {
    bottom: .375rem;
}

/* 图片 */
.md-image > .md-meta {
    border-radius: 3px;
    font-family: var(--font-monospace);
    padding: 2px 0 0 4px;
    font-size: 0.9em;
    color: inherit;
}
p .md-image:only-child{
    width: auto;
    text-align: left;
    margin-left: 2rem;
}
.md-tag {
    color: inherit;
}
/* 当 “![shadow-随便写]()”写时，会有阴影 */
.md-image img[alt|='shadow'] {
    /* box-shadow: 0 4px 24px -6px #ddd; */
    box-shadow:var(--purple-light-2) 0px 10px 15px;
}

#write a.md-toc-inner {
    line-height: 1.6;
    white-space: pre-line;
    border-bottom: none;
    font-size: 0.9rem;
}

#typora-quick-open {
    border: 1px solid #ddd;
    background-color: #f8f8f8;
}

#typora-quick-open-item {
    background-color: #FAFAFA;
    border-color: #FEFEFE #e5e5e5 #e5e5e5 #eee;
    border-style: solid;
    border-width: 1px;
}

#md-notification:before {
    top: 10px;
}

header,
.context-menu,
.megamenu-content,
footer {
    font-family: var(--font-sans-serif);
}

.file-node-content:hover .file-node-icon,
.file-node-content:hover .file-node-open-state {
    visibility: visible;
}

.md-lang {
    color: #b4654d;
}

.html-for-mac .context-menu {
    --item-hover-bg-color: #E6F0FE;
}

/* 代码框 */
/* CodeMirror 3024 Day theme */

/* 代码段 背景 */
pre {
    --select-text-bg-color: rgba(223, 197, 223) !important;
    margin: .5em 0;
    padding: 1em 1.4em;
    border-radius: 8px;
    background: #f6f8fa;
    overflow-x: auto;
    box-sizing: border-box;
    font-size: 14px;
}

/* 边框 */
.md-fences {
    border: 1px solid #e7eaed;
    border-radius: 3px;
}

.cm-s-inner {
  padding: .25rem;
  border-radius: .25rem;
}

.cm-s-inner.CodeMirror, .cm-s-inner .CodeMirror-gutters {
  background-color: #f8f8f8 !important;
  color: #3a3432 !important;
  border: none;
}

.cm-s-inner .CodeMirror-gutters {
  color: #6d8a88;
}

.cm-s-inner .CodeMirror-cursor {
  border-left: solid thin #5c5855 !important;
}

.cm-s-inner .CodeMirror-linenumber {
  color: #807d7c;
}

.cm-s-inner .CodeMirror-line::selection, .cm-s-inner .CodeMirror-line::-moz-selection,
.cm-s-inner .CodeMirror-line > span::selection,
.cm-s-inner .CodeMirror-line > span::-moz-selection,
.cm-s-inner .CodeMirror-line > span > span::selection,
.cm-s-inner .CodeMirror-line > span > span::-moz-selection {
  background: var(--purple-light-2);
}

.cm-s-inner span.cm-comment {
  color: #cdab53;
}

.cm-s-inner span.cm-string, .cm-s-inner span.cm-string-2 {
  color: #f2b01d;
}

.cm-s-inner span.cm-number {
  color: #a34e8f;
}

.cm-s-inner span.cm-variable {
  color: #01a252;
}

.cm-s-inner span.cm-variable-2 {
  color: #01a0e4;
}

.cm-s-inner span.cm-def {
  /* color: #e8bbd0; */
  color: #e2287f;
}

.cm-s-inner span.cm-operator {
  color: #ff79c6;
}

.cm-s-inner span.cm-keyword {
  color: #db2d20;
}

.cm-s-inner span.cm-atom {
  color: #a34e8f;
}

.cm-s-inner span.cm-meta {
  color: inherit;
}

.cm-s-inner span.cm-tag {
  color: #db2d20;
}

.cm-s-inner span.cm-attribute {
  color: #01a252;
}

.cm-s-inner span.cm-qualifier {
  color: #388aa3;
}

.cm-s-inner span.cm-property {
  color: #01a252;
}

.cm-s-inner span.cm-builtin {
  color: #388aa3;
}

.cm-s-inner span.cm-variable-3, .cm-s-inner span.cm-type {
  color: #ffb86c;
}

.cm-s-inner span.cm-bracket {
  color: #3a3432;
}

.cm-s-inner span.cm-link {
  color: #a34e8f;
}

.cm-s-inner span.cm-error {
  background: #db2d20;
  color: #5c5855;
}

/* .md-fences.md-focus .cm-s-inner .CodeMirror-activeline-background {
  background: var(--purple-light-2);
} */

.cm-s-inner .CodeMirror-matchingbracket {
  text-decoration: underline;
  color: #a34e8f !important;
}

#fences-auto-suggest .active {
  background: #ddd;
}

#write .code-tooltip {
  bottom: initial;
  top: calc(100% - 1px);
  background: #f7f7f7;
  border: 1px solid #ddd;
  border-top: 0;
}

.auto-suggest-container {
  border-color: #b4b4b4;
}

.auto-suggest-container .autoComplt-hint.active {
  background: #b4b4b4;
  color: inherit;
}

/* task list */
#write .md-task-list-item > input {
  -webkit-appearance: initial;
  display: block;
  position: absolute;
  border: 1px solid #b4b4b4;
  border-radius: .25rem;
  margin-top: .1rem;
  margin-left: -1.8rem;
  height: 1.2rem;
  width: 1.2rem;
  transition: background 0.3s;
}

#write .md-task-list-item > input:focus {
  outline: none;
  box-shadow: none;
}

#write .md-task-list-item > input:hover {
  background: #ddd;
}

#write .md-task-list-item > input[checked]::before {
  content: '';
  position: absolute;
  top: 20%;
  left: 50%;
  height: 60%;
  width: 2px;
  transform: rotate(40deg);
  background: #333;
}

#write .md-task-list-item > input[checked]::after {
  content: '';
  position: absolute;
  top: 46%;
  left: 25%;
  height: 30%;
  width: 2px;
  transform: rotate(-40deg);
  background: #333;
}

#write .md-task-list-item > p {
  transition: color 0.3s, opacity 0.3s;
}

#write .md-task-list-item.task-list-done > p {
  color: #b4b4b4;
  text-decoration: line-through;
}

#write .md-task-list-item.task-list-done > p > .md-emoji {
  opacity: .5;
}

#write .md-task-list-item.task-list-done > p > .md-link > a {
  opacity: .6;
}

/* sidebar and outline */
.pin-outline .outline-active {
  color: var(--active-file-text-color); 
}

.file-list-item {
    border-bottom: 1px solid;
    border-color: var(--purple-light-5);
}

.file-list-item-summary {
    font-weight: 400;
}

.file-list-item.active {
    color: var(--active-file-text-color);
    background-color: var(--purple-light-5);
}

.file-tree-node.active>.file-node-background {
    background-color: var(--purple-light-5);
    font-weight: 700;
} 

.file-tree-node.active>.file-node-content {
    color: var(--active-file-text-color);
    font-weight: 700;
}

.file-node-content {
    color: #5e676d;
}

.sidebar-tabs {
    border-bottom: none;
}
.sidebar-tab.active {
    font-weight: 400;
}

.sidebar-content-content {
    font-size: 0.9rem;
}

img {
    max-width: 100%;
}

body {
    background-color: rgb(237, 237, 237);
}
#content {
    width: 836px;
    padding: 50px;
    background: #fff;
    margin: 0 auto;
}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/purple.css*/</style><style type="text/css">.hljs{display:block;overflow-x:auto;padding:.5em;color:#383a42;background:#fafafa}.hljs-comment,.hljs-quote{color:#a0a1a7;font-style:italic}.hljs-doctag,.hljs-formula,.hljs-keyword{color:#a626a4}.hljs-deletion,.hljs-name,.hljs-section,.hljs-selector-tag,.hljs-subst{color:#e45649}.hljs-literal{color:#0184bb}.hljs-addition,.hljs-attribute,.hljs-meta-string,.hljs-regexp,.hljs-string{color:#50a14f}.hljs-built_in,.hljs-class .hljs-title{color:#c18401}.hljs-attr,.hljs-number,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-pseudo,.hljs-template-variable,.hljs-type,.hljs-variable{color:#986801}.hljs-bullet,.hljs-link,.hljs-meta,.hljs-selector-id,.hljs-symbol,.hljs-title{color:#4078f2}.hljs-emphasis{font-style:italic}.hljs-strong{font-weight:700}.hljs-link{text-decoration:underline}/*# sourceURL=/Users/young/Documents/Codes/Fun/lagou/public/atom-one-light.min.css*/</style></head>
<body>
<div id="content"><h1>Libuv 线程池和线程间通信</h1>
<p>上节课讲到了 Libuv 中的事件循环，Libuv 在事件循环中处理了大部分的任务，但是有一部分任务是不适合在事件循环里处理的。因为 Libuv 是在一个单线程中执行事件循环的，所以一些<strong>耗时、阻塞的操作</strong>就不适合放到主线程里做，否则对应用会产生比较大的影响，这时候就需要使用<strong>线程</strong> <strong>池</strong>来执行这些任务。</p>
<p>这节课我们就来介绍线程池的相关内容，主要包括线程的基础知识，线程间通信以及线程池的实现。我们可以从中看到线程间是如何实现通信的，Libuv 主线程又是如何和线程池合作的。通过本节课后，大家会对 Node.js 是单线程还是多线程这个问题理解得更加清晰深刻。</p>
<h2>线程的概念和使用</h2>
<p>在操作系统中，线程是一个代码的执行流，是操作系统调度的基本单元。这么说可能有点抽象，我们来看一个例子。</p>
<pre><code class="hljs language-c"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&#x3C;stdio.h></span></span>
<span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&#x3C;pthread.h></span></span>

<span class="hljs-type">void</span> *<span class="hljs-title function_">start</span><span class="hljs-params">(<span class="hljs-type">void</span> *arg)</span>
{
    <span class="hljs-comment">// 执行自定义代码</span>
    <span class="hljs-comment">// 函数执行完之后，线程也就退出了</span>
}

<span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span>
{
    <span class="hljs-type">pthread_t</span> thread_id;
    pthread_create(&#x26;thread_id, <span class="hljs-literal">NULL</span>, start, <span class="hljs-literal">NULL</span>);
    pthread_join(thread_id);
    <span class="hljs-comment">// ...</span>
    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;
}
</code></pre>
<p>上面的代码就创建了一个线程，这个线程从 start 函数开始执行，创建完线程后，主线程和子线程谁先执行是不确定的，这取决于操作系统的调度。如果主线程先执行并结束了，子线程也会被终止执行，所以通常主线程需要调用 pthread_join 等待子线程执行完毕后再退出。通过创建线程，我们可以在一个进程中同时执行多份代码。在多核的环境下，多个线程可以并行执行。在单核情况下，多个线程会轮流执行。</p>
<p>除了在系统层面拥有这些特性以外，在进程里，多个线程共享进程的很多资源，比如代码、内存，打开的文件等等，所以说线程是轻量级的进程，但是线程有自己的栈，用于执行代码。因为线程是共享进程内存的，所以<strong>多个线程间可以直接基于进程的内存</strong>进行通信。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a8155d0105cd49f58d9422da492c3314~tplv-k3u1fbpfcp-zoom-1.image" alt=""></p>
<p>我们来看一下如何实现<a href="https://github.com/theanarkh/nodejs-book/tree/main/src/thread" target="_blank" rel="nofollow noopener noreferrer">线程间通信</a>。</p>
<pre><code class="hljs language-c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&#x3C;unistd.h></span></span>
<span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&#x3C;thread></span> </span>
<span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&#x3C;deque></span></span>
<span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&#x3C;iostream></span></span>
<span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&#x3C;mutex></span></span>
<span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&#x3C;condition_variable></span></span>

<span class="hljs-type">const</span> <span class="hljs-type">int</span> THREADS = <span class="hljs-number">3</span>;
std::thread threads[THREADS];
std::condition_variable condition_variable;
std::deque&#x3C;<span class="hljs-type">int</span>> requests;
std::mutex mutex;

<span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">worker</span><span class="hljs-params">()</span> </span>{
    <span class="hljs-keyword">while</span> (<span class="hljs-number">1</span>) {
        {
            <span class="hljs-function">std::unique_lock&#x3C;std::mutex> <span class="hljs-title">lock</span><span class="hljs-params">(mutex)</span></span>;
            <span class="hljs-keyword">while</span> (requests.<span class="hljs-built_in">size</span>() == <span class="hljs-number">0</span>)
            {
                condition_variable.<span class="hljs-built_in">wait</span>(lock);
            }
            <span class="hljs-type">int</span> num = requests.<span class="hljs-built_in">front</span>();
            requests.<span class="hljs-built_in">pop_front</span>();
            std::cout&#x3C;&#x3C;<span class="hljs-string">"consumer: "</span>&#x3C;&#x3C;num&#x3C;&#x3C;<span class="hljs-string">", thread: "</span>&#x3C;&#x3C;(<span class="hljs-type">uint64_t</span>)<span class="hljs-built_in">pthread_self</span>()&#x3C;&#x3C;std::endl;
        }
    }
}

<span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> 
</span>{ 
   
    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &#x3C; THREADS; i++) {
        threads[i] = std::<span class="hljs-built_in">thread</span>(worker);
    }
    <span class="hljs-type">int</span> j = <span class="hljs-number">0</span>;
    <span class="hljs-keyword">while</span>(<span class="hljs-number">1</span>) {
        {   
            <span class="hljs-built_in">sleep</span>(<span class="hljs-number">1</span>);
            <span class="hljs-function">std::lock_guard&#x3C;std::mutex> <span class="hljs-title">lock</span><span class="hljs-params">(mutex)</span></span>;
            requests.<span class="hljs-built_in">push_back</span>(j++);
            condition_variable.<span class="hljs-built_in">notify_all</span>();
        }
    }

    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &#x3C; THREADS; i++) {
        threads[i].<span class="hljs-built_in">join</span>();
    }

    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;
} 
</code></pre>
<p>上面的代码中定义了一个共享数据结构 requests，主线程负责不断生产数据，由多个子线程负责消费。因为多个线程随时可能被操作系统切换执行，所以需要使用互斥变量 mutex 来保证多个线程互斥访问共享的数据结构，另外，当消费完数据时，消费者（子线程）可以使用条件变量让自己处于等待状态，这样操作系统就会调度其他线程执行，当生产者生产新的数据后，再通过 notify_all 通知消费者。这就是线程间通信的一种实现方式，其他实现方式在思路上都类似。</p>
<h2><strong>线程间通信</strong></h2>
<p>了解了线程的基本概念和使用后，接下来看看 Libuv 中的线程。不过，我们不会讲 Libuv 中线程的实现，因为它本质上是对 C API 的一些封装，我们只关注线程池和线程间通信的实现。下面，我们先来看一下线程间通信的实现。</p>
<p>线程间通信是使用 uv_async_t 结构体实现的。首先看 uv_async_t 的初始化函数 uv_async_init。</p>
<pre><code class="hljs language-c"><span class="hljs-type">int</span> <span class="hljs-title function_">uv_async_init</span><span class="hljs-params">(<span class="hljs-type">uv_loop_t</span>* loop,
                  <span class="hljs-type">uv_async_t</span>* handle,
                  uv_async_cb async_cb)</span> {
                                  
        <span class="hljs-comment">// 给 Libuv 注册一个用于异步通信的 IO 观察者</span>
        uv__async_start(loop);
        <span class="hljs-comment">// 设置相关字段，给 Libuv 插入一个 handle</span>
        uv__handle_init(loop, (<span class="hljs-type">uv_handle_t</span>*)handle, UV_ASYNC);
        <span class="hljs-comment">// 设置回调</span>
        handle->async_cb = async_cb;
        <span class="hljs-comment">// 标记是否有任务完成了</span>
        handle->pending = <span class="hljs-number">0</span>;
        <span class="hljs-comment">// 插入 async 队列，Poll IO 阶段判断是否有任务与完成</span>
        QUEUE_INSERT_TAIL(&#x26;loop->async_handles, &#x26;handle-><span class="hljs-built_in">queue</span>);
        uv__handle_start(handle);

        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;
}
</code></pre>
<p>从上面的代码中可以看到 uv_async_init 的逻辑非常简单，就是初始化 async handle 的一些字段，然后把 handle 插入async_handle 队列中，而且 Libuv 使用 loop->async_handles 记录所有的 uv_async_t 结构体。另外这里还有个 uv__async_start 函数，它是做什么的呢？</p>
<pre><code class="hljs language-c"><span class="hljs-comment">// 初始化异步通信的 IO 观察者</span>
<span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">uv__async_start</span><span class="hljs-params">(<span class="hljs-type">uv_loop_t</span> loop)</span> {
    <span class="hljs-type">int</span> pipefd[<span class="hljs-number">2</span>];
    <span class="hljs-type">int</span> err;
    <span class="hljs-comment">/*
        父子线程通信时，Libuv 是优先使用 eventfd，如果不支持会回退到匿名管道。
        如果是匿名管道，loop->async_io_watcher.fd 是管道的读端，loop->async_wfd 是管道的写端
        如果是 eventfd，loop->async_io_watcher.fd 是读端也是写端。async_wfd 是 -1
        
        所以这里判断 loop->async_io_watcher.fd 而不是 async_wfd 的值
    */</span>
    <span class="hljs-keyword">if</span> (loop->async_io_watcher.fd != <span class="hljs-number">-1</span>)
        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;
    <span class="hljs-comment">// 通过 eventfd 机制，获取一个用于进程间通信的 fd</span>
    err = uv__async_eventfd();
    <span class="hljs-comment">// 成功则保存起来，否则使用管道作为降级方案</span>
    <span class="hljs-keyword">if</span> (err >= <span class="hljs-number">0</span>) {
        pipefd[<span class="hljs-number">0</span>] = err;
        pipefd[<span class="hljs-number">1</span>] = <span class="hljs-number">-1</span>;
    }
    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (err == UV_ENOSYS) {
        <span class="hljs-comment">// 创建一个管道，两个 fd 保存到 pipefd 数组</span>
        err = uv__make_pipe(pipefd, UV__F_NONBLOCK);
    }
    <span class="hljs-comment">// 初始化 IO 观察者 async_io_watcher，回调为 uv__async_io，fd 为 pipefd[0]，即读端</span>
    uv__io_init(&#x26;loop->async_io_watcher, uv__async_io, pipefd[<span class="hljs-number">0</span>]);
    <span class="hljs-comment">// 注册 IO 观察者到事件驱动模块里，并注册需要监听的事件 POLLIN，等待可读事件</span>
    uv__io_start(loop, &#x26;loop->async_io_watcher, POLLIN);
    <span class="hljs-comment">// 用于主线程和子线程通信的 fd，管道的写端，子线程使用</span>
    loop->async_wfd = pipefd[<span class="hljs-number">1</span>];
    
    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;
}
</code></pre>
<p>uv__async_start 用于创建主线程和子线程通信的通道，它只会执行一次。当子线程完成任务时，就可以通过这个通道的写端写入数据，通知主线程有任务完成，而主线程会在 Poll IO 阶段检测到通道的读端有数据到来，再进行处理，主要逻辑是如下所示。</p>
<ol>
<li>申请用于主线程和子线程通信的文件描述符。</li>
</ol>

<ol start="2">
<li>把读端和回调封装到 IO 观察者 loop->async_io_watcher 中，再注册 IO 观察者到事件循环。</li>
</ol>

<ol start="3">
<li>写端保存在 loop->async_wfd，子线程完成任务后往写端写入标记通知主线程。</li>
</ol>
<p>通过上面的逻辑可以看到，loop->async_io_watcher 会作为所有 uv_async_t 结构体的 IO 观察者。第一次注册 uv_async_t 结构体到 async_handle 队列时会初始化 IO 观察者，如果再次注册 一 个 async_handle，只会在 loop->async_handle 队列和 handle 队列插入一个节点，而不是新增一个 IO 观察者。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d2f53785e82e40f7a9c821bcf5a90537~tplv-k3u1fbpfcp-zoom-1.image" alt=""></p>
<p>我们看一下当有任务需要处理时，如何通知主线程。</p>
<pre><code class="hljs language-c"><span class="hljs-type">int</span> <span class="hljs-title function_">uv_async_send</span><span class="hljs-params">(<span class="hljs-type">uv_async_t</span>* handle)</span> {
    <span class="hljs-comment">/* Do a cheap read first. */</span>
    <span class="hljs-keyword">if</span> (ACCESS_ONCE(<span class="hljs-type">int</span>, handle->pending) != <span class="hljs-number">0</span>)
            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;
    <span class="hljs-comment">/*
        设置 async handle的 pending 标记为 1
        如果 pending 是 0 ，则设置为 1，返回 0 ，如果是 1 则返回 1 ，
        所以同一个 handle 如果多次调用该函数是没有副作用的
    */</span>
    <span class="hljs-keyword">if</span> (cmpxchgi(&#x26;handle->pending, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>) == <span class="hljs-number">0</span>)
        <span class="hljs-comment">// 设置 IO 观察者有事件触发</span>
        uv__async_send(handle->loop);
    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;
}
</code></pre>
<p>uv_async_send 最终会调用 uv__async_send。</p>
<pre><code class="hljs language-c"><span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title function_">uv__async_send</span><span class="hljs-params">(<span class="hljs-type">uv_loop_t</span>* loop)</span> {
    <span class="hljs-type">const</span> <span class="hljs-type">void</span>* buf;
    <span class="hljs-type">ssize_t</span> len;
    <span class="hljs-type">int</span> fd;
    <span class="hljs-type">int</span> r;
    
    buf = <span class="hljs-string">""</span>;
    len = <span class="hljs-number">1</span>;
    <span class="hljs-comment">// 获取异步通信管道的写端</span>
    fd = loop->async_wfd;
    <span class="hljs-comment">// 执行写触发管道的可写事件</span>
    write(fd, buf, len);
}
</code></pre>
<p>uv__async_send 最后调用 write 函数通知主线程，结构图如下。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5b7c3cdb78744fc297453635eb54c6ab~tplv-k3u1fbpfcp-zoom-1.image" alt=""></p>
<p>刚才提到，初始化第一个 uv_async_t 时会在事件循环中注册一个 IO 观察者，所以当主线程执行到 Poll IO 阶段时，就会发现有可读事件触发。那么事件触发后如何执行的回调呢？</p>
<pre><code class="hljs language-c"><span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title function_">uv__async_io</span><span class="hljs-params">(<span class="hljs-type">uv_loop_t</span>* loop, <span class="hljs-type">uv__io_t</span>* w, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> events)</span> {
    <span class="hljs-type">char</span> buf[<span class="hljs-number">1024</span>];
    <span class="hljs-type">ssize_t</span> r;
    QUEUE <span class="hljs-built_in">queue</span>;
    QUEUE* q;
    <span class="hljs-type">uv_async_t</span>* h;
    <span class="hljs-keyword">for</span> (;;) {
        <span class="hljs-comment">// 判断通信内容</span>
        r = read(w->fd, buf, <span class="hljs-keyword">sizeof</span>(buf));
        <span class="hljs-comment">// 如果数据等于 buf 的长度，说明可能还有数据，接着读，直到不等于 buf 大小</span>
        <span class="hljs-keyword">if</span> (r == <span class="hljs-keyword">sizeof</span>(buf))
            <span class="hljs-keyword">continue</span>;
        <span class="hljs-comment">// 不等于 -1，说明读成功，但读取大小小于 buf 大小，说明读完了</span>
        <span class="hljs-keyword">if</span> (r != <span class="hljs-number">-1</span>)
            <span class="hljs-keyword">break</span>;
        <span class="hljs-comment">// 失败的时候返回- 1 ，errno 是错误码</span>
        <span class="hljs-comment">// 说明没有数据了，即读完了</span>
        <span class="hljs-keyword">if</span> (errno == EAGAIN || errno == EWOULDBLOCK)
            <span class="hljs-keyword">break</span>;
        <span class="hljs-comment">// 被信号中断，继续读</span>
        <span class="hljs-keyword">if</span> (errno == EINTR)
            <span class="hljs-keyword">continue</span>;
        <span class="hljs-comment">// 出错，发送 abort 信号</span>
        <span class="hljs-built_in">abort</span>();
    }
    <span class="hljs-comment">// 把队列里的节点移到 queue 变量中</span>
    QUEUE_MOVE(&#x26;loop->async_handles, &#x26;<span class="hljs-built_in">queue</span>);
    <span class="hljs-keyword">while</span> (!QUEUE_EMPTY(&#x26;<span class="hljs-built_in">queue</span>)) {
        <span class="hljs-comment">// 逐个遍历队列中的节点</span>
        q = QUEUE_HEAD(&#x26;<span class="hljs-built_in">queue</span>);
        <span class="hljs-comment">// 根据结构体字段获取结构体首地址</span>
        h = QUEUE_DATA(q, <span class="hljs-type">uv_async_t</span>, <span class="hljs-built_in">queue</span>);
        <span class="hljs-comment">// 从队列中移除该节点</span>
        QUEUE_REMOVE(q);
        <span class="hljs-comment">// 重新插入 async_handles 队列，等待下次事件</span>
        QUEUE_INSERT_TAIL(&#x26;loop->async_handles, q);
        <span class="hljs-comment">/*
            将第一个参数和第二个参数进行比较，如果相等，
            则将第三参数写入第一个参数，返回第二个参数的值，
            如果不相等，则返回第一个参数的值。
        */</span>
        <span class="hljs-comment">/*
            判断哪些 async 被触发了。pending 在 uv_async_send 里设置成 1 ，
            如果 pending 等于 1 ，则清 0 ，返回 1，
            如果 pending等于 0 ，则返回 0
        */</span>
        <span class="hljs-keyword">if</span> (cmpxchgi(&#x26;h->pending, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>) == <span class="hljs-number">0</span>)
            <span class="hljs-keyword">continue</span>;
        <span class="hljs-comment">// 执行上层回调</span>
        h->async_cb(h);
    }
}
</code></pre>
<p>首先，uv__async_io 会不断消费写端写入的数据，直到消费完毕。如果只读取了一部分，下次哪怕没有任务需要处理，事件驱动模块也会通知 Libuv 有任务处理。这些无效操作之所以出现，是因为 Libuv 中事件驱动模块的工作模式是水平触发的。</p>
<p>消费完数据后，uv__async_io 会遍历 loop->async_handles 队里中所有的 uv_async_t，通过 uv_async_t->pending 判断哪个 uv_async_t 有任务完成，接着执行该 uv_async_t 的回调。</p>
<p>好，了解了原理后，我们来看一下如何使用 async handle 机制来实现线程间通信，<a href="https://github.com/theanarkh/nodejs-book/tree/main/src/async" target="_blank" rel="nofollow noopener noreferrer">具体可参考</a>。</p>
<pre><code class="hljs language-c"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">"uv.h"</span></span>

<span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span> {
  <span class="hljs-type">uv_async_t</span> async_handle;
  <span class="hljs-type">uv_thread_t</span> thread;
  
  uv_async_init(uv_default_loop(), &#x26;async_handle, [](<span class="hljs-type">uv_async_t</span>* handle) {
    <span class="hljs-built_in">printf</span>(<span class="hljs-string">"done\n"</span>);
    uv_close((<span class="hljs-type">uv_handle_t</span>*) handle, nullptr);
  });

  uv_thread_create(&#x26;thread, [] (<span class="hljs-type">void</span>* args) {
    uv_async_send((<span class="hljs-type">uv_async_t</span>*)args);
  }, &#x26;async_handle);
  
  uv_run(uv_default_loop(), UV_RUN_DEFAULT);
  uv_thread_join(&#x26;thread);
  <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;
}
</code></pre>
<p>首先在主线程中初始化一个 uv_async_t 结构体并设置回调，再创建一个子线程，最后通过 uv_run 启动来事件循环。因为 uv_async_t 是一个 handle，所以事件循环不会退出，同时 uv_async_t 是通过 fd 完成通信的，所以事件循环会阻塞在 Poll IO 阶段。当子线程开始执行时，调用 uv_async_send 告诉主线程有任务执行完毕，从而唤醒主线程，接着主线程在 Poll IO 阶段执行 uv_async_t 回调，输出 done 并且关闭 uv_async_t，最后事件循环退出。</p>
<h2>线程池的实现</h2>
<p>了解了线程间通信的机制后，接着看一下线程池的实现，包括线程池的创建、消费者 / 生产者的实现以及线程池是如何通过线程间通信和主线程配合处理任务的。</p>
<ol>
<li><strong>线程</strong> <strong>池的创建</strong></li>
</ol>
<p>首先来看一下线程池的创建。线程池是懒初始化的，只有在用户第一次提交任务时才会被创建。</p>
<pre><code class="hljs language-c"><span class="hljs-comment">// 提交一个任务到线程池</span>
<span class="hljs-type">void</span> <span class="hljs-title function_">uv__work_submit</span><span class="hljs-params">(...)</span> {
  <span class="hljs-comment">// 保证已经初始化线程，并只执行一次</span>
  uv_once(&#x26;once, init_once);
  <span class="hljs-comment">// ...</span>
}

<span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title function_">init_once</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span> {
  init_threads();
}
</code></pre>
<p>uv__work_submit 是提交任务到线程池的函数，从代码中可以看到它通过 uv_once 保证了线程池的初始化，并且只初始化一次，因为其他线程可能会同时往 Libuv 的线程池提交任务，所以这里需要使用 uv_once 解决多线程并发的问题，uv_once 中执行了 init_threads 函数。</p>
<pre><code class="hljs language-c"><span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title function_">init_threads</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span> {
    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> i;
    <span class="hljs-type">const</span> <span class="hljs-type">char</span>* val;
    <span class="hljs-type">uv_sem_t</span> sem;
    <span class="hljs-comment">// 计算 default_threads 数组大小获取默认的线程数，static uv_thread_t default_threads[4];</span>
    nthreads = ARRAY_SIZE(default_threads);
    <span class="hljs-comment">// 如果用户设置了环境变量则取用户设置的值</span>
    val = getenv(<span class="hljs-string">"UV_THREADPOOL_SIZE"</span>);
    <span class="hljs-keyword">if</span> (val != <span class="hljs-literal">NULL</span>)
        nthreads = atoi(val);
    <span class="hljs-comment">// 值无效则默认创建 1 个线程</span>
    <span class="hljs-keyword">if</span> (nthreads == <span class="hljs-number">0</span>)
        nthreads = <span class="hljs-number">1</span>;
    <span class="hljs-comment">// #define MAX_THREADPOOL_SIZE 128 最多 128 个线程</span>
    <span class="hljs-keyword">if</span> (nthreads > MAX_THREADPOOL_SIZE)
        nthreads = MAX_THREADPOOL_SIZE;
    
    threads = default_threads;
    <span class="hljs-comment">// 如果线程数比默认大小大，则需要分配新的内存保存数据</span>
    <span class="hljs-keyword">if</span> (nthreads > ARRAY_SIZE(default_threads)) {
        threads = uv__malloc(nthreads * <span class="hljs-keyword">sizeof</span>(threads[<span class="hljs-number">0</span>]));
        <span class="hljs-comment">// 内存分配失败，则使用默认值</span>
        <span class="hljs-keyword">if</span> (threads == <span class="hljs-literal">NULL</span>) {
            nthreads = ARRAY_SIZE(default_threads);
            threads = default_threads;
        }
    }
    <span class="hljs-comment">// 初始化条件变量和互斥变量，用于线程间同步</span>
    uv_cond_init(&#x26;cond);
    uv_mutex_init(&#x26;mutex);
    
    <span class="hljs-comment">// 初始化线程池任务队列，多个子线程共同消费这个队列</span>
    QUEUE_INIT(&#x26;wq);
    <span class="hljs-comment">// 慢任务队列</span>
    QUEUE_INIT(&#x26;slow_io_pending_wq);
    <span class="hljs-comment">// 标记有慢任务需要处理的节点</span>
    QUEUE_INIT(&#x26;run_slow_work_message);
    
    <span class="hljs-comment">// 初始化信号量为 0，为 0 则线程调 uv_sem_wait 时会阻塞</span>
    uv_sem_init(&#x26;sem, <span class="hljs-number">0</span>);
    <span class="hljs-comment">// 开始创建子线程，在子线程中执行 worker 函数的代码，sem 为 worker 入参</span>
    <span class="hljs-keyword">for</span> (i = <span class="hljs-number">0</span>; i &#x3C; nthreads; i++)
        uv_thread_create(threads + i, worker, &#x26;sem);
    <span class="hljs-comment">// 为 0 则阻塞，非 0 则减一，用于等待所有线程启动成功再往下执行</span>
    <span class="hljs-keyword">for</span> (i = <span class="hljs-number">0</span>; i &#x3C; nthreads; i++)
        uv_sem_wait(&#x26;sem);
    
    uv_sem_destroy(&#x26;sem);
}
</code></pre>
<p>init_threads 中初始化一些数据结构和创建多个工作子线程，然后在每个子线程中执行工作函数 worker。</p>
<ol start="2">
<li><strong>生产者的实现</strong></li>
</ol>
<p>接着我们继续看一下生产者的逻辑。</p>
<pre><code class="hljs language-c"><span class="hljs-comment">// 给线程池提交一个任务</span>
<span class="hljs-type">void</span> <span class="hljs-title function_">uv__work_submit</span><span class="hljs-params">(<span class="hljs-type">uv_loop_t</span>* loop,
                     <span class="hljs-keyword">struct</span> uv__work* w,
                     <span class="hljs-keyword">enum</span> uv__work_kind kind,
                     <span class="hljs-type">void</span> (work)(<span class="hljs-keyword">struct</span> uv__work w),
                     <span class="hljs-type">void</span> (done)(<span class="hljs-keyword">struct</span> uv__work w, <span class="hljs-type">int</span> status))</span> {
    w->loop = loop;
    <span class="hljs-comment">// 工作函数，比如执行耗时 / 或会阻塞的函数</span>
    w->work = work;
    <span class="hljs-comment">// 任务完成后到回调</span>
    w->done = done;
    <span class="hljs-comment">// 提交任务</span>
    post(&#x26;w->wq, kind);
}
</code></pre>
<p>uv__work_submit 是 Libuv 内部使用的函数，它把调用者的任务函数和任务完成后的执行的回调函数封装到 uv__work 结构体中，另外Libuv把任务分为三种类型，CPU 密集型、快 IO（文件操作）、慢 IO（DNS 解析），kind 表示任务的类型，Libuv 针对不同类型的任务有不同的处理策略。uv__work_submit 中调用了 post 函数实现任务的插入。</p>
<pre><code class="hljs language-c"><span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title function_">post</span><span class="hljs-params">(QUEUE* q, <span class="hljs-keyword">enum</span> uv__work_kind kind)</span> {
    <span class="hljs-comment">// 访问任务队列前需要加锁，因为队列是由子线程共享的</span>
    uv_mutex_lock(&#x26;mutex);
    <span class="hljs-comment">// 慢 IO 类型的任务</span>
    <span class="hljs-keyword">if</span> (kind == UV__WORK_SLOW_IO) {
        <span class="hljs-comment">/*
            Libuv 单独维护了一个队列 slow_io_pending_wq 管理慢 IO 任务，
            提交慢 IO 类型的任务时，首先把节点插入 slow_io_pending_wq，然后再把 
            run_slow_work_message 插入到主队列 wq，处理到 run_slow_work_message
            节点时，Libuv 会逐个执行 slow_io_pending_wq 中的节点。
        */</span>
        QUEUE_INSERT_TAIL(&#x26;slow_io_pending_wq, q);
        <span class="hljs-comment">/*
            如果 run_slow_work_message 非空，说明已经插入线程池的任务队列了。
            解锁然后直接返回。
            如果 run_slow_work_message 是空，说明还没有插入主队列。
            需要进行把待插入的节点改成 run_slow_work_message，然后插入主队列。
        */</span>
        <span class="hljs-keyword">if</span> (!QUEUE_EMPTY(&#x26;run_slow_work_message)) {
            uv_mutex_unlock(&#x26;mutex);
            <span class="hljs-keyword">return</span>;
        }
        <span class="hljs-comment">// 说明 run_slow_work_message 还没有插入队列，准备插入队列</span>
        q = &#x26;run_slow_work_message;
    }
    <span class="hljs-comment">// 把节点插入主队列</span>
    QUEUE_INSERT_TAIL(&#x26;wq, q);
    <span class="hljs-comment">// 有空闲线程在睡眠则唤醒它，如果都在忙，则不需要通知，因为它处理任务后会主动判断是否还有新任务</span>
    <span class="hljs-keyword">if</span> (idle_threads > <span class="hljs-number">0</span>)
        uv_cond_signal(&#x26;cond);
    uv_mutex_unlock(&#x26;mutex);
}
</code></pre>
<p>以上是 Libuv 中线程池生产者的实现，具体的流程结构可以看下图。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/55f3ee50e51946cd81e962a22484f856~tplv-k3u1fbpfcp-zoom-1.image" alt=""></p>
<p>因为一个线程每次只能处理一个任务，如果某类型的任务非常慢且数量多，就会消耗完线程池的线程，无法执行一些比较快的任务。为此，Libuv 区分了快 IO 和 慢 IO 任务，在一定程度上保证了公平性和稳定性。</p>
<p>除了上面的方式，Libuv 还提供了 uv_queue_work 函数提交任务，不过这个函数是只针对 CPU 密集型的。从实现来看，它和 uv__work_submit 的区别是，通过 uv_queue_work 提交的任务，请求数会加一，如果该请求对应的任务没有执行完，则事件循环不会退出。而通过 uv__work_submit 方式提交的任务就算没有执行完，也不会影响事件循环的退出，但是通常调用 uv__work_submit 的函数会主动把请求数加一，比如文件操作。下面我们来看下 uv_queue_work 的实现。</p>
<pre><code class="hljs language-c"><span class="hljs-type">int</span> <span class="hljs-title function_">uv_queue_work</span><span class="hljs-params">(<span class="hljs-type">uv_loop_t</span>* loop,
    <span class="hljs-type">uv_work_t</span>* req,
    uv_work_cb work_cb,
    uv_after_work_cb after_work_cb)</span> {
        <span class="hljs-comment">// 请求数加一</span>
        uv__req_init(loop, req, UV_WORK);
        req->loop = loop;
        req->work_cb = work_cb;
        req->after_work_cb = after_work_cb;
        uv__work_submit(loop,
                        &#x26;req->work_req,
                        UV__WORK_CPU,
                        uv__queue_work,
                        uv__queue_done);
        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;
}
</code></pre>
<p>uv_queue_work 保存了调用者的工作函数和回调函数到 req 中，然后把 uv__queue_work 和 uv__queue_done 封装到 req->work_req 中， 最后提交到线程池 。当子线程处理这个任务时，uv__queue_work 会被执行。</p>
<pre><code class="hljs language-c"><span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title function_">uv__queue_work</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> uv__work* w)</span> {
    <span class="hljs-comment">// 通过结构体 work_req 字段计算出结构体首地址</span>
    <span class="hljs-type">uv_work_t</span>* req = container_of(w, <span class="hljs-type">uv_work_t</span>, work_req);
    req->work_cb(req);
}
</code></pre>
<p>uv__queue_work 中会执行用户设置的函数，同理，uv__queue_done 也只是对用户回调的简单封装。</p>
<p>uv__queue_work 有一个比较好玩的用法是在我们写 Addon 的时候，比如我们注册了 V8 GC 回调用于统计 GC 的耗时。</p>
<pre><code class="hljs language-c++"><span class="hljs-comment">// 注册 GC 开始回调</span>
<span class="hljs-built_in">isolate</span>()-><span class="hljs-built_in">AddGCPrologueCallback</span>([](
    Isolate* isolate,
    GCType type,
    GCCallbackFlags flags,
    <span class="hljs-type">void</span>* data) {
     <span class="hljs-comment">// </span>
 },
 <span class="hljs-literal">nullptr</span>);
 
<span class="hljs-comment">// 注册 GC 结束回调</span>
<span class="hljs-built_in">isolate</span>()-><span class="hljs-built_in">AddGCEpilogueCallback</span>([](
    Isolate* isolate,
    GCType type,
    GCCallbackFlags flags,
    <span class="hljs-type">void</span>* data) {
     <span class="hljs-comment">// 通知 JS</span>
 },
 <span class="hljs-literal">nullptr</span>);
</code></pre>
<p>在上面的代码中，我们注册了 GC 开始和结束时的回调，然后在 GC 结束回调中我们把收集到的数据告诉 JS。但是在 GC 回调中是不能执行 JS 的，那应该怎么处理呢？一种方式是先缓存到 C++ 的数据结构中，然后再暴露 API 给 JS 定时消费，另一种方式就是通过 uv_queue_work 提交一个空的任务。</p>
<pre><code class="hljs language-c">uv_queue_work(..., 
<span class="hljs-comment">// 空任务</span>
[](<span class="hljs-type">uv_work_t</span> * req) {}, 
[](<span class="hljs-type">uv_work_t</span> * req, <span class="hljs-type">int</span> status) {
    <span class="hljs-comment">// 通知 JS</span>
});
</code></pre>
<p>给线程池提交一个空的任务，Libuv 的线程池执行完这个空任务之后，就会在 Poll IO 阶段执行回调，在回调里我们就可以回调 JS 了。</p>
<ol start="3">
<li><strong>消费者的实现</strong></li>
</ol>
<p>讲完线程池的生产者后，接着看下消费者的实现。</p>
<pre><code class="hljs language-c"><span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title function_">worker</span><span class="hljs-params">(<span class="hljs-type">void</span>* arg)</span> {
    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">uv__work</span>* <span class="hljs-title">w</span>;</span>
    QUEUE* q;
    <span class="hljs-type">int</span> is_slow_work;
    <span class="hljs-comment">// uv_sem_post 表示当前线程期待成功</span>
    uv_sem_post((<span class="hljs-type">uv_sem_t</span>*) arg);
    arg = <span class="hljs-literal">NULL</span>;
    <span class="hljs-comment">// 访问共享任务队列需要加锁</span>
    uv_mutex_lock(&#x26;mutex);
    <span class="hljs-comment">// 在死循环中不断处理任务，满足条件时则结束循环</span>
    <span class="hljs-keyword">for</span> (;;) {
        <span class="hljs-comment">/*
            以下情况时，线程进入阻塞等待任务状态
            1 没有任务可处理
            2 只有慢 IO 任务且正在处理的慢 IO 任务数量已经达到阈值，
              防止慢 IO 占用过多子线程，导致其他快的任务无法得到执行，线程选择进入阻塞，空闲线程加一。
        */</span>
        <span class="hljs-keyword">while</span> (QUEUE_EMPTY(&#x26;wq) ||
              (QUEUE_HEAD(&#x26;wq) == &#x26;run_slow_work_message &#x26;&#x26;
               QUEUE_NEXT(&#x26;run_slow_work_message) == &#x26;wq &#x26;&#x26;
               slow_io_work_running >= slow_work_thread_threshold())) {
                
            idle_threads += <span class="hljs-number">1</span>;
            <span class="hljs-comment">// 进入阻塞状态，有新任务时被唤醒，但是只有正在处理的慢 IO 任务数小于阈值时，</span>
            <span class="hljs-comment">// 后续的任务才能被处理</span>
            uv_cond_wait(&#x26;cond, &#x26;mutex);
            <span class="hljs-comment">// 被唤醒，空闲线程数减一</span>
            idle_threads -= <span class="hljs-number">1</span>;
        }
        <span class="hljs-comment">// 取出当前待处理任务，可能是退出任务、慢 IO 任务，一般任务</span>
        q = QUEUE_HEAD(&#x26;wq);
        <span class="hljs-comment">// 如果结点是退出任务，则线程结束执行</span>
        <span class="hljs-keyword">if</span> (q == &#x26;exit_message) {
            <span class="hljs-comment">// 唤醒其他因为没有任务正阻塞等待任务的线程，通知它们准备退出</span>
            uv_cond_signal(&#x26;cond);
            uv_mutex_unlock(&#x26;mutex);
            <span class="hljs-comment">// 自己先退出，但是不能从队列中删除该退出任务，</span>
            <span class="hljs-comment">// 因为其他线程被唤醒后也需要依赖这个节点判断是否需要退出</span>
            <span class="hljs-keyword">break</span>;
        }
        <span class="hljs-comment">// 移除节点</span>
        QUEUE_REMOVE(q);
        QUEUE_INIT(q);
        is_slow_work = <span class="hljs-number">0</span>;
        <span class="hljs-comment">/*
            上面的 while 中只判断了是不是只有慢 IO 任务且达到阈值。但是没有判断慢 IO 和非慢 IO 任务都有的情况
            所以执行到这说明队列中肯定有非慢 IO 任务，可能有慢 IO，如果有慢 IO 并且正在执行的个数达到阈值，
            则先不处理该慢 IO 任务，继续判断是否还有非慢 IO 任务可执行。
        */</span>
        <span class="hljs-keyword">if</span> (q == &#x26;run_slow_work_message) {
            <span class="hljs-comment">// 达到阈值，重新插入队列</span>
            <span class="hljs-keyword">if</span> (slow_io_work_running >= slow_work_thread_threshold()) {
                QUEUE_INSERT_TAIL(&#x26;wq, q);
                <span class="hljs-keyword">continue</span>;
            }
            
            <span class="hljs-comment">// 没有慢 IO 任务需要处理则继续处理其他任务</span>
            <span class="hljs-keyword">if</span> (QUEUE_EMPTY(&#x26;slow_io_pending_wq))
                <span class="hljs-keyword">continue</span>;
            <span class="hljs-comment">// 有慢 IO，开始处理慢 IO 任务</span>
            is_slow_work = <span class="hljs-number">1</span>;
            <span class="hljs-comment">// 记录正在处理的慢 IO 任务数量，用于其他线程判断慢 IO 任务数量是否达到阈值</span>
            slow_io_work_running++;
            <span class="hljs-comment">// 从 slow_io_pending_wq 队列获取一个慢 IO 任务</span>
            q = QUEUE_HEAD(&#x26;slow_io_pending_wq);
            QUEUE_REMOVE(q);
            QUEUE_INIT(q);
            <span class="hljs-comment">/*
                取出一个任务后，如果还有慢 IO 任务则把慢 IO 标记节点重新入队，
                表示还有慢 IO 任务，因为上面把该标记节点出队了
            */</span>
            <span class="hljs-keyword">if</span> (!QUEUE_EMPTY(&#x26;slow_io_pending_wq)) {
                QUEUE_INSERT_TAIL(&#x26;wq, &#x26;run_slow_work_message);
                <span class="hljs-comment">// 有空闲线程则唤醒他，因为还有任务处理</span>
                <span class="hljs-keyword">if</span> (idle_threads > <span class="hljs-number">0</span>)
                    uv_cond_signal(&#x26;cond);
            }
        }
        
        <span class="hljs-comment">// 不需要操作队列了，先释放锁</span>
        uv_mutex_unlock(&#x26;mutex);
        <span class="hljs-comment">// q 是慢 IO 或者一般任务</span>
        w = QUEUE_DATA(q, <span class="hljs-keyword">struct</span> uv__work, wq);
        <span class="hljs-comment">// 执行业务的任务函数，该函数一般会很耗时或者阻塞线程</span>
        w->work(w);
        <span class="hljs-comment">// 准备修改 loop 的任务完成队列，加锁</span>
        uv_mutex_lock(&#x26;w->loop->wq_mutex);
        <span class="hljs-comment">// 置空说明指向完了，不能被取消了，见 cancel 逻辑</span>
        w->work = <span class="hljs-literal">NULL</span>;
        <span class="hljs-comment">// 执行完任务,插入到事件循环的 wq 队列,在 Poll IO 阶段会执行 uv__work_done 处理这个队列</span>
        QUEUE_INSERT_TAIL(&#x26;w->loop->wq, &#x26;w->wq);
        <span class="hljs-comment">// 通过 wq_async 异步通知主线程有任务完成，主线程在 Poll IO 阶段会执行已完成的任务的回调</span>
        uv_async_send(&#x26;w->loop->wq_async);
        uv_mutex_unlock(&#x26;w->loop->wq_mutex);
        <span class="hljs-comment">// 为下一轮操作任务队列加锁</span>
        uv_mutex_lock(&#x26;mutex);
        <span class="hljs-comment">// 执行完慢 IO 任务，记录正在执行的慢 IO 个数变量减 1 ，上面加锁保证了互斥访问这个变量</span>
        <span class="hljs-keyword">if</span> (is_slow_work) {
            slow_io_work_running--;
        }
    }
}
</code></pre>
<p>我们看到消费者的逻辑似乎比较复杂，主要是多了处理慢 IO 任务的逻辑。大概分为三种情况。</p>
<ol>
<li>对于一般任务，则互斥访问任务队列，然后取出任务执行其中的任务函数。</li>
</ol>

<ol start="2">
<li>对于慢 IO 类型的任务，需要特殊处理一下，主要是限制了它消耗的线程数。</li>
</ol>

<ol start="3">
<li>如果收到了 exit_message 节点说明子线程需要退出。</li>
</ol>
<p>执行完任务后，把节点插入事件循环的队列，然后通知主线程，由主线程进行后续处理。</p>
<ol start="4">
<li><strong>线程</strong> <strong>池和主线程的通信</strong></li>
</ol>
<p>接着看一下线程池是如何利用 async handle 机制通知主线程的，在 Libuv 初始化时会执行 uv_loop_init 进行初始化。uv_loop_init 中有以下代码。</p>
<pre><code class="hljs language-c">uv_async_init(loop, &#x26;loop->wq_async, uv__work_done);
</code></pre>
<p>wq_async 是用于线程池和主线程通信的 async handle。他对应的回调是 uv__work_done 。所以当一个线程池的线程任务完成时，通过 <code>uv_async_send(&#x26;w->loop->wq_async) </code>设置 loop->wq_async.pending = 1，然后通知 IO 观察者。主线程在Poll IO 阶段就会执行该 handle 对应的回调 uv__work_done 函数。</p>
<pre><code class="hljs language-c"><span class="hljs-type">void</span> <span class="hljs-title function_">uv__work_done</span><span class="hljs-params">(<span class="hljs-type">uv_async_t</span>* handle)</span> {
    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">uv__work</span>* <span class="hljs-title">w</span>;</span>
    <span class="hljs-type">uv_loop_t</span>* loop;
    QUEUE* q;
    QUEUE wq;
    
    <span class="hljs-type">int</span> err;
    loop = container_of(handle, <span class="hljs-type">uv_loop_t</span>, wq_async);
    uv_mutex_lock(&#x26;loop->wq_mutex);
    <span class="hljs-comment">/*
        把 loop->wq 队列的节点全部移到 wp 变量中，这样可以尽快释放锁
    */</span>
    QUEUE_MOVE(&#x26;loop->wq, &#x26;wq);
    uv_mutex_unlock(&#x26;loop->wq_mutex);
    <span class="hljs-comment">// wq 队列的节点来源于子线程的 worker 函数</span>
    <span class="hljs-keyword">while</span> (!QUEUE_EMPTY(&#x26;wq)) {
        q = QUEUE_HEAD(&#x26;wq);
        QUEUE_REMOVE(q);
        w = container_of(q, <span class="hljs-keyword">struct</span> uv__work, wq);
        <span class="hljs-comment">// 等于 uv__cancelled 说明任务被取消了</span>
        err = (w->work == uv__cancelled)? UV_ECANCELED : <span class="hljs-number">0</span>;
        <span class="hljs-comment">// 执行回调</span>
        w->done(w, err);
    }
}
</code></pre>
<p>uv__work_done 逐个处理已完成的任务节点，执行回调，比如 DNS 解析时，我们会执行 dns.lookup(..., function cb() => {})，这个回调函数 cb 就会被执行。在上面代码中，我们还需要注意 w->work == uv__cancelled 的判断。uv__cancelled 这个值是通过 uv_cancel 中设置的，而 uv_cancel 用于取消一个任务，底层对应的函数是 uv__work_cancel。</p>
<pre><code class="hljs language-c"><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">uv__work_cancel</span><span class="hljs-params">(<span class="hljs-type">uv_loop_t</span>* loop, <span class="hljs-type">uv_req_t</span>* req, <span class="hljs-keyword">struct</span> uv__work* w)</span> {
    <span class="hljs-type">int</span> cancelled;
    <span class="hljs-comment">// 加锁，为了把节点移出队列</span>
    uv_mutex_lock(&#x26;mutex);
    <span class="hljs-comment">// 加锁，为了判断 w->wq 是否为空</span>
    uv_mutex_lock(&#x26;w->loop->wq_mutex);
    <span class="hljs-comment">/*
        当子线程处理完一个任务后，会把 work 置 NULL，
        所以如果任务函数 work 不为空，说明还没有开始被处理，
        如果还在任务队列中，则可取消。
    */</span>
    cancelled = !QUEUE_EMPTY(&#x26;w->wq) &#x26;&#x26; w->work != <span class="hljs-literal">NULL</span>;
    <span class="hljs-comment">// 从任务队列中删除该节点</span>
    <span class="hljs-keyword">if</span> (cancelled)
        QUEUE_REMOVE(&#x26;w->wq);
    
    uv_mutex_unlock(&#x26;w->loop->wq_mutex);
    uv_mutex_unlock(&#x26;mutex);
    <span class="hljs-comment">// 不能取消则返回错误码</span>
    <span class="hljs-keyword">if</span> (!cancelled)
        <span class="hljs-keyword">return</span> UV_EBUSY;
    <span class="hljs-comment">// 设置 work 为 uv__cancelled，表示任务取消，uv__work_done 中会判断这个标记</span>
    w->work = uv__cancelled;
    
    uv_mutex_lock(&#x26;loop->wq_mutex);
    <span class="hljs-comment">/*
        插入事件循环的 wq 队列，对于取消的动作，Libuv 认为是任务执行完了，
        所以插入已完成的队列
    */</span>
    QUEUE_INSERT_TAIL(&#x26;loop->wq, &#x26;w->wq);
    <span class="hljs-comment">// 通知主线程有任务完成</span>
    uv_async_send(&#x26;loop->wq_async);
    uv_mutex_unlock(&#x26;loop->wq_mutex);
    
    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;
}
</code></pre>
<p>从上面的逻辑中可以看到，Libuv 中，取消任务的前提是任务还没开始执行，也就是说任务正常被处理也无法取消了。</p>
<ol start="5">
<li><strong>销毁</strong> <strong>线程</strong> <strong>池</strong></li>
</ol>
<p>当 Node.js 退出时，需要先保证线程池的线程先退出。</p>
<pre><code class="hljs language-c">UV_DESTRUCTOR(<span class="hljs-type">static</span> <span class="hljs-type">void</span> cleanup(<span class="hljs-type">void</span>)) {
  <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> i;

  <span class="hljs-keyword">if</span> (nthreads == <span class="hljs-number">0</span>)
    <span class="hljs-keyword">return</span>;
  <span class="hljs-comment">// 提交一个特殊任务通知子线程退出</span>
  post(&#x26;exit_message, UV__WORK_CPU);
  <span class="hljs-comment">// 等到线程退出</span>
  <span class="hljs-keyword">for</span> (i = <span class="hljs-number">0</span>; i &#x3C; nthreads; i++)
    <span class="hljs-keyword">if</span> (uv_thread_join(threads + i))
      <span class="hljs-built_in">abort</span>();

  <span class="hljs-keyword">if</span> (threads != default_threads)
    uv__free(threads);

  uv_mutex_destroy(&#x26;mutex);
  uv_cond_destroy(&#x26;cond);

  threads = <span class="hljs-literal">NULL</span>;
  nthreads = <span class="hljs-number">0</span>;
}
</code></pre>
<p>线程退出是编程多线程程序时需要处理的问题，和前面讲的一样，其中一个需要做的事情是调用 thread_join（Libuv 中是 uv_thread_join）等待线程退出，那么线程怎么样才能退出呢？一种是代码执行完了主动退出，第二种是需要主动通知它退出，这里就是第二种，Libuv 中通过提交一个特殊的任务 exit_message 通知子线程退出，子线程收到这个任务后就会跳出循环，从而结束代码的执行。</p>
<p>讲完线程池的创建、消费者 / 生产者的实现、线程池和主线程的通信后，最后通过一张图总结下整个流程。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1f3bb5dff2e84ef7941f9b45930bb625~tplv-k3u1fbpfcp-zoom-1.image" alt=""></p>
<h2>总结</h2>
<p>这节课我们学习了线程的一些概念和基本使用。线程是操作系统的最小调度单位，它们可以通过互斥访问进程内存的方式进行通信，是非常重要的基础知识，也是解决很多问题的利器。</p>
<p>基于线程的基本原理，我们又进一步了解了 Libuv 中可以通过 async handle 机制实现线程间通信，接着又介绍了线程池的创建、生产者 / 消费者的实现、线程池利用 async handle 机制实现了和主线程的通信以及多线程编程中，子线程退出的两种情况。</p>
<p>最后，再回到 Node.js 是单线程还是多线程这个问题上。当我们说 Node.js 是单线程时，指的是所有 JS 代码都在单个线程（主线程）里执行；当我们说 Node.js 是多线程时，指的是 Node.js 处理任务时。底层其实是由多个线程一起工作的，但是子线程只负责某一个任务的处理，处理完之后通过主线程去执行回调，而不是在子线程里直接执行回调。</p></div>
</body></html>